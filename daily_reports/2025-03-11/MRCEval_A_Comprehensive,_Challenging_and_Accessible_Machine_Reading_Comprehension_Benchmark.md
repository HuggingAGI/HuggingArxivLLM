# MRCEval：一个全面、具挑战性且易于获取的机器阅读理解基准
发布时间：2025年03月10日


> MRCEval: A Comprehensive, Challenging and Accessible Machine Reading Comprehension Benchmark
>
> 机器阅读理解（MRC）是评估自然语言理解能力的重要任务。然而，现有的MRC数据集主要针对阅读理解的特定方面，缺乏一个全面的评估基准。为了解决这一问题，我们首先提出了一种新的分类法，用于系统地划分阅读理解所需的关键能力。基于这一分类法，我们构建了MRCEval，这是一个全新的MRC基准测试，它创新性地使用先进大型语言模型（LLMs）作为样本生成器和选择评委。MRCEval是一个全面、具有挑战性且易于使用的基准，旨在全面评估LLMs的阅读理解能力。该基准涵盖13种不同的阅读理解技能，包含2.1K个高质量的多选题。我们对28个广泛使用的开源和专有模型进行了全面评估，结果表明，即使在LLMs时代，MRC仍然是一个极具挑战性的任务。
>
> https://arxiv.org/abs/2503.07144

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2503.07144](https://arxiv.org/abs/2503.07144)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)