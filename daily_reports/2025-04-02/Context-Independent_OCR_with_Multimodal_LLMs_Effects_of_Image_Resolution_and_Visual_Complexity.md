# 上下文无关 OCR 与多模态大语言模型：图像分辨率与视觉复杂度的影响
发布时间：2025年03月30日


> Context-Independent OCR with Multimodal LLMs: Effects of Image Resolution and Visual Complexity
>
> 多模态大型语言模型（LLMs）在图像描述、文档分析和自动化内容生成等任务中表现出色，因此在多个工业领域备受关注。尤其是在光学字符识别（OCR）方面，它们已超越了专门的模型。然而，它们在不同图像条件下的性能仍有待深入研究，且由于依赖上下文线索，单个字符识别的可靠性尚未得到保证。本研究通过使用具有不同视觉复杂度的单字符图像，探索了一个上下文无关的 OCR 任务，以确定准确识别的条件。我们的研究发现，在约 300 ppi 时，多模态 LLMs 可与传统 OCR 方法相媲美，但低于 150 ppi 时性能显著下降。此外，我们观察到视觉复杂度与误识别之间存在非常弱的相关性，而传统 OCR 专用模型则无此相关性。这些结果表明，图像分辨率和视觉复杂度可能在多模态 LLMs 可靠应用于需要精确字符级准确性的 OCR 任务中发挥重要作用。
>
> https://arxiv.org/abs/2503.23667

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2503.23667](https://arxiv.org/abs/2503.23667)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)