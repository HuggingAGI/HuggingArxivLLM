# 本实证研究深入探讨了检索辅助长篇文章生成中的 Groundedness 问题。
`RAG`
> 本研究通过检索增强的大型语言模型（LLMs）对长篇幅问答（LFQA）中的事实基础进行了实证分析。研究发现，在三个不同数据集和四种模型系列中，即便句子中包含了准确的答案，仍有大量生成的句子缺乏事实依据。同时，我们还探讨了模型规模、解码策略和指令调整等因素对事实基础的影响。结果表明，虽然大型模型更可能使其输出具有事实基础，但正确答案的准确性仍受到幻觉的显著影响。这项研究揭示了LFQA中事实基础的挑战，并强调了在LLMs中建立更稳固机制以减少无事实依据内容产生的重要性。

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.07060/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.07060/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.07060/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.07060/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.07060/x5.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.07060/x6.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.07060/x7.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.07060/x8.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.07060/x9.png)

[https://wx.zsxq.com/dweb2/index/topic_detail/5122528211542214](https://wx.zsxq.com/dweb2/index/topic_detail/5122528211542214)

[https://arxiv.org/abs/2404.07060](https://arxiv.org/abs/2404.07060)