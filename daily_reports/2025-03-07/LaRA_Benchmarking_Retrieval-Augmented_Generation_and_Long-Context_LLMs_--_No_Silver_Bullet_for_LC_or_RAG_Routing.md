# LaRA: 评估增强生成与长上下文LLM -- 针对LC或RAG路由并无万能解
发布时间：2025年02月14日


> LaRA: Benchmarking Retrieval-Augmented Generation and Long-Context LLMs -- No Silver Bullet for LC or RAG Routing
>
> # 摘要
将外部知识有效融入大型语言模型（LLMs）对于提升其能力以应对现实需求至关重要。检索增强生成（RAG）通过检索最相关的片段注入LLMs，提供了一种有效的方法。然而，随着LLMs上下文窗口规模的提升，出现了另一种方法，这促使我们思考RAG是否仍有必要用于有效处理外部知识。现有研究在RAG与长上下文（LC）LLM之间的对比上尚无定论，这主要归因于基准设计的局限性。本文提出了LaRA，一个专门设计用于严格比较RAG与LC LLMs的新型基准。LaRA涵盖四大实践问答任务类别及三种自然长文本类型，共计2326个测试用例。通过对七种开源和四种专有LLMs的系统性评估，我们发现RAG与LC之间的最优选择取决于模型参数规模、长文本处理能力、上下文长度、任务类型及检索片段特征等多重因素的复杂交互。我们的研究发现为实践者提供了切实可行的指导，助其在开发和部署LLM应用时有效利用RAG与LC方法。我们的代码与数据集可在以下链接获取：\href{this https URL}{	extbf{this https URL}}.
>
> https://arxiv.org/pdf/2502.09977

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/pdf/2502.09977](https://arxiv.org/pdf/2502.09977)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)