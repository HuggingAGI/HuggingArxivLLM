# 更多文档，相同长度：RAG中的多文档挑战解析
发布时间：2025年03月06日

`RAG`
> More Documents, Same Length: Isolating the Challenge of Multiple Documents in RAG
>
> 检索增强生成（RAG）为大型语言模型（LLMs）提供相关文档。尽管之前的研究指出，检索大量文档可能会降低性能效果，但他们并未单独研究文档数量对性能的影响，同时控制上下文长度不变。我们在源自多跳问答任务的自定义数据集上评估了各种语言模型。我们保持上下文长度和相关信息的位置不变，同时改变文档数量，发现增加RAG设置中的文档数量对LLMs提出了重大挑战。此外，我们的结果表明，处理多个文档与处理长上下文是两个独立的挑战。我们还提供了数据集和代码：https://github.com/shaharl6000/MoreDocsSameLen 。
>
> https://arxiv.org/abs/2503.04388

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2503.04388](https://arxiv.org/abs/2503.04388)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)