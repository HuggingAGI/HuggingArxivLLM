# RAGME：基于检索增强的视频生成方法，提升运动真实感
发布时间：2025年04月09日


> RAGME: Retrieval Augmented Video Generation for Enhanced Motion Realism
>
> 视频生成领域正蓬勃发展，这得益于扩散模型的突破性进展和更优质、更大规模数据集的开发。然而，生成高质量视频仍面临挑战，主要源于视频数据的高维度特性和任务本身的复杂性。近期研究主要集中在提升视觉质量和解决时间不一致问题，如画面闪烁现象。尽管在这些方面已取得进展，但生成视频在运动复杂性和物理合理性上仍显不足，许多输出视频或显静态，或呈现不切实际的运动方式。本研究提出了一种框架，旨在提升生成视频中运动的逼真度，探索了一种与现有文献互补的新方向。具体而言，我们提倡在生成过程中引入检索机制。检索到的视频作为基准信号，为模型提供物体运动方式的演示。我们的流程设计适用于任何文本到视频的扩散模型，通过在检索样本上微调预训练模型，仅需少量调整。我们通过已建立的评估指标、最新的基准测试以及定性结果，证明了我们方法的优越性，并展示了该框架的更多潜在应用。
>
> https://arxiv.org/abs/2504.06672

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2504.06672](https://arxiv.org/abs/2504.06672)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)