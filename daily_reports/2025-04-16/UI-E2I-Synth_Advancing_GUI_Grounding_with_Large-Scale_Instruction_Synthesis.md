# # 标题
UI-E2I-Synth: 提升GUI定位能力，通过大规模指令合成实现新突破
发布时间：2025年04月15日


> UI-E2I-Synth: Advancing GUI Grounding with Large-Scale Instruction Synthesis
>
> 大型视觉语言模型的突破正在推动基于人类视觉感知能力的图形用户界面（GUI）代理的发展，从而提升数字设备的生产力。与依赖平台且易受实现差异影响的基于GUI元数据的方法相比，视觉方法具有更广泛的应用前景。在这一视觉范式下，GUI指令定位（将用户指令映射到给定截图中对应元素的位置）仍然是一个关键挑战，尤其是由于公共训练数据集的有限和资源密集型的人工指令数据标注。在本文中，我们深入探讨了这一任务中尚未被研究的挑战，包括元素与屏幕比例、元素类型不平衡以及隐式指令。为了解决这些挑战，我们引入了一个大规模数据合成管道UI-E2I-Synth，利用GPT-4o生成各种复杂指令数据集，而不是依赖人工标注者。此外，我们提出了一个新的GUI指令定位基准UI-I2E-Bench，该基准通过整合多样化的标注方面，旨在克服现有基准的局限性。在合成数据上训练的我们的模型在GUI指令定位任务中表现出色，展示了所提数据合成管道的优势。该基准配合详尽的分析，为未来GUI定位研究提供了实用的见解。我们将在https://colmon46.github.io/i2e-bench-leaderboard/发布相关成果。
>
> https://arxiv.org/abs/2504.11257

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2504.11257](https://arxiv.org/abs/2504.11257)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)