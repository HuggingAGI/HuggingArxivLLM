# 高效动态聚类文档压缩技术：提升检索增强生成性能的三大关键
发布时间：2025年04月04日

`RAG`
> Efficient Dynamic Clustering-Based Document Compression for Retrieval-Augmented-Generation
>
> 检索增强生成（RAG）近年来已成为大型语言模型（LLM）推理过程中知识整合的主流方法。然而，现有RAG实现难以有效应对检索内容中的噪声、重复和冗余问题，这主要源于其在利用细粒度跨文档关系方面的局限性。为突破这一限制，我们提出了一种高效动态聚类的文档压缩框架——	extbf{E}fficient 	extbf{D}ynamic 	extbf{C}lustering-based document 	extbf{C}ompression（	extbf{EDC	extsuperscript{2}-RAG}），该框架不仅能够有效挖掘潜在的跨文档关系，还能同时去除无关信息和冗余内容。我们基于GPT-3.5构建的方法在多个常用的知识问答和幻觉检测数据集上进行了验证。实验结果表明，该方法在各种场景和实验设置下均实现了性能的显著提升，展现出强大的鲁棒性和广泛的适用性。我们的代码和数据集可在https://github.com/Tsinghua-dhy/EDC-2-RAG获取。
>
> https://arxiv.org/abs/2504.03165

![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2025/02/12/1739367812022-81912e8f-5f91-4b9d-b4b2-52b0e322d137.png)
**添加请注明[]**
**如遇无法添加，请+ vx: iamxxn886**
<hr />



## 为什么需要高效动态聚类文档压缩技术？

### 1.1 大语言模型的挑战与检索增强生成（RAG）的兴起

近年来，大语言模型（Large Language Models, LLMs）在自然语言处理任务中表现出色，比如问答、代码生成甚至医疗诊断。然而，LLMs面临两大挑战：知识更新成本高和幻觉问题（即生成误导性内容）。为了解决这些问题，检索增强生成（Retrieval-Augmented Generation, RAG）应运而生。RAG通过结合检索与生成，使LLMs能够访问外部知识，减少幻觉并提高可靠性。比如，当LLMs需要回答一个复杂的历史问题时，RAG可以从外部知识库中检索相关文档，帮助模型生成更准确的答案。

然而，现有的RAG方法在处理检索内容中的噪声、重复和冗余时效果有限。例如，检索到的文档可能包含大量与查询无关的信息，或者多个文档之间内容高度相似，导致LLMs在生成答案时效率低下，甚至可能引入错误信息。

### 1.2 现有RAG方法的局限性

当前RAG框架主要基于查询与候选文档的相似性进行检索，忽略了文档之间的细粒度关系。这导致检索结果中可能存在大量冗余和噪声，影响LLMs的推理质量。例如，当检索到的文档包含多个重复的段落时，LLMs可能会重复生成相同的信息，浪费计算资源。

此外，基于知识图的RAG方法虽然提高了检索灵活性，但未能有效解决内容冗余和冲突问题。知识图的构建和维护成本高昂，且在处理大规模文档时效率较低。例如，当面对数百万个实体时，构建一个完整的知识图不仅耗时，还可能导致检索效率下降。

### 1.3 高效动态聚类文档压缩技术的必要性

为了解决上述问题，清华大学的研究团队提出了一种高效动态聚类文档压缩框架（Efficient Dynamic Clustering-based document Compression, EDC²-RAG）。该技术通过聚类和压缩技术，利用文档之间的潜在关系，减少噪声和冗余，从而提升RAG系统的性能和鲁棒性。例如，EDC²-RAG可以将相似的文档聚类在一起，并通过LLMs生成简洁的摘要，确保最终输入到模型中的信息既相关又高效。

通过这种方式，EDC²-RAG不仅减少了LLMs的计算负担，还提高了生成答案的准确性和一致性。实验表明，EDC²-RAG在多个数据集上均取得了显著的性能提升，尤其是在处理噪声和冗余内容时表现出色。这种技术为大语言模型的进一步应用提供了新的方向，特别是在需要处理大规模外部知识的场景中。




## 二、高效动态聚类文档压缩技术是什么？

#### 2.1 技术核心：动态聚类与压缩

EDC²-RAG（Efficient Dynamic Clustering-based document Compression for Retrieval-Augmented Generation）的核心思想是通过动态聚类将语义相似的文档分组，然后使用大语言模型（LLM, Large Language Model）进行压缩，提取关键信息。具体步骤如下：

1. **文档编码**：首先，将文档转换为密集的向量表示。这一步类似于我们平时用搜索引擎时，输入的查询会被转化为计算机能理解的数字形式。通过这种方式，文档的内容被编码为高维向量，便于后续的相似性计算。

2. **动态聚类**：基于文档与查询的相似性，将文档分组为多个簇。与传统的静态聚类方法不同，动态聚类能够根据查询动态调整簇的大小和数量。比如，当你搜索“人工智能”时，系统会自动将与“机器学习”和“深度学习”相关的文档归为一组，而将与“自然语言处理”相关的文档归为另一组。这种方法确保了检索结果的相关性和信息密度。

3. **压缩**：使用大语言模型对每个簇进行查询感知的压缩，去除冗余信息。举个例子，如果你搜索“人工智能的历史”，系统会从相关文档中提取出关键事件和时间节点，而不是把所有细节都呈现给你。这样既节省了时间，又提高了信息的精准度。

4. **生成**：将压缩后的内容整合到提示中，生成最终响应。这一步就像是把筛选后的信息打包成一个简洁的答案，直接呈现给用户。

#### 2.2 动态聚类的优势

与传统的静态聚类方法相比，动态聚类有以下几个显著优势：

- **灵活性**：动态聚类能够根据查询动态调整簇的大小和数量，确保检索结果的相关性和信息密度。比如，当你搜索“人工智能的应用”时，系统会自动将与“医疗”、“金融”、“自动驾驶”等不同领域的应用文档分组，而不是将所有文档混在一起。
  
- **减少冗余**：通过动态聚类，系统能够将相似的文档归为一组，避免重复信息的出现。比如，如果你搜索“深度学习框架”，系统会自动将关于“TensorFlow”和“PyTorch”的文档归为一组，而不是分别呈现多个重复的文档。

- **提高推理效率**：动态聚类减少了文档的数量，使得大语言模型在生成答案时更加高效。比如，当你搜索“人工智能的未来趋势”时，系统会从相关文档中提取出关键趋势，而不是让模型处理大量冗余信息。

#### 2.3 开源资源

EDC²-RAG的代码和数据集已开源，地址为：[https://github.com/Tsinghua-dhy/EDC-2-RAG](https://github.com/Tsinghua-dhy/EDC-2-RAG)。这意味着任何对这项技术感兴趣的研究者或开发者都可以下载代码，进行实验或改进。开源资源的提供不仅促进了技术的传播，也为后续的研究和应用提供了便利。




## 3. 高效动态聚类文档压缩技术效果如何？

### 3.1 实验设置与数据集
为了验证EDC²-RAG（Efficient Dynamic Clustering-based Compression for Retrieval-Augmented Generation）的有效性，研究团队在多个数据集上进行了实验，包括知识问答（KQA）数据集和幻觉检测数据集。实验使用了GPT-3.5作为基础模型，评估了在不同噪声和冗余率下的性能表现。这些数据集涵盖了开放域问答和幻觉检测任务，能够全面测试模型的鲁棒性和适用性。

### 3.2 知识问答数据集上的表现
在TriviaQA和WebQ数据集上，EDC²-RAG在不同Top-k设置下均表现出色。例如，在WebQ数据集上，EDC²-RAG的平均F1得分比标准RAG方法提高了0.48，显示出其在处理多样化上下文中的优势。具体来说，EDC²-RAG在TriviaQA数据集上的平均F1得分为93.81，略高于标准RAG方法的93.78，而Raw Compression方法的得分则下降了0.49。这表明EDC²-RAG在处理冗余和噪声时能够有效保留关键信息，从而提升问答系统的性能。

### 3.3 噪声与冗余处理能力
在噪声和冗余率较高的场景下，EDC²-RAG表现出更强的鲁棒性。例如，在40%噪声率下，EDC²-RAG在TriviaQA数据集上的F1得分比标准RAG方法提高了0.76。在WebQ数据集上，EDC²-RAG在高噪声率下的平均F1得分为88.22，比标准RAG方法高出0.48。这些结果表明，EDC²-RAG能够有效处理噪声和冗余，确保在复杂环境下仍能提供高质量的答案。

### 3.4 幻觉检测数据集上的表现
在FELM、WikiBio GPT-3和HaluEval数据集上，EDC²-RAG在平衡准确率上均优于现有方法。例如，在FELM数据集上，EDC²-RAG在Top-10设置下的准确率达到了64.03，比标准RAG方法提高了6.61。在WikiBio GPT-3数据集上，EDC²-RAG的平衡准确率比CEG方法提高了0.45。这些结果证明了EDC²-RAG在减少幻觉和提升模型可靠性方面的有效性。

### 3.5 动态聚类的关键作用
通过对比动态聚类与随机聚类和平均聚类的效果，研究发现动态聚类在噪声率较高的情况下仍能保持稳定的性能。例如，在WebQ数据集上，动态聚类方法的平均F1得分为87.25，而随机聚类和平均聚类方法的得分分别为86.69和86.78。这表明动态聚类在文档压缩中具有不可替代的作用，能够有效减少冗余和噪声，提升模型的整体性能。

总结来说，EDC²-RAG在多个数据集上均表现出色，尤其是在处理噪声和冗余方面展现了强大的鲁棒性。动态聚类技术的引入进一步提升了模型的性能，使其在复杂环境下仍能保持高效和准确。




## 四、总结

高效动态聚类文档压缩技术（Efficient Dynamic Clustering-Based Document Compression, EDC²-RAG）通过挖掘文档之间的细粒度语义关系，显著提升了检索增强生成系统（Retrieval-Augmented Generation, RAG）的性能和鲁棒性。该技术在知识问答（Knowledge QA）和幻觉检测（Hallucination Detection）任务中均表现出色，为大语言模型（Large Language Models, LLMs）的知识更新和幻觉问题提供了新的解决方案。

### 技术必要性
LLMs虽然在自然语言处理任务中表现出色，但仍面临两个主要挑战：一是知识更新的成本高昂，二是幻觉问题导致生成内容的不准确。RAG通过引入外部知识库来缓解这些问题，但现有的RAG方法在处理检索到的文档时，往往忽略了文档之间的细粒度关系，导致噪声、重复和冗余内容影响最终生成结果。EDC²-RAG通过动态聚类和压缩技术，有效解决了这些问题，提升了RAG系统的性能。

### 技术解析
EDC²-RAG的核心思想是通过动态聚类将语义相似的文档分组，然后利用LLM进行查询感知的压缩，去除冗余和噪声内容。具体步骤如下：
1. **文档编码与聚类**：首先使用嵌入模型将文档编码为密集向量表示，然后基于文档与查询的相似性进行动态聚类，确保高相关性的文档被分到同一组。
2. **文档压缩**：对每个聚类中的文档，利用LLM生成查询感知的摘要，保留关键信息，去除冗余内容。
3. **生成响应**：将压缩后的文档集成到提示词中，供LLM生成最终响应。

### 应用评估
实验结果表明，EDC²-RAG在多个数据集上均表现出色：
- **知识问答任务**：在TriviaQA和WebQ数据集上，EDC²-RAG的F1得分分别达到93.81和88.22，显著优于传统RAG方法。
- **幻觉检测任务**：在FELM、WikiBio GPT-3和HaluEval数据集上，EDC²-RAG的平衡准确率（Balanced Acc）和准确率（Acc）均有所提升，最高提升达6.61。
- **噪声与冗余处理**：在高噪声和高冗余率的情况下，EDC²-RAG仍能保持稳定的性能，展现了其强大的鲁棒性。

### 总结与展望
EDC²-RAG通过动态聚类和压缩技术，有效提升了RAG系统的性能，为LLMs的知识更新和幻觉问题提供了新的解决方案。开源代码和数据集的发布，为后续研究和应用提供了便利。未来，我们计划在更多数据集和基础模型上验证该方法的泛化能力，并进一步优化其计算效率。



<hr />

- 论文原文: [https://arxiv.org/abs/2504.03165](https://arxiv.org/abs/2504.03165)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)