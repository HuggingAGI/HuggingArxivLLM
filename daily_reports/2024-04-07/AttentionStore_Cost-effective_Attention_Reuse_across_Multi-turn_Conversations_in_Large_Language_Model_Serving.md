# AttentionStore 通过在大型语言模型的多轮对话中实现注意力机制的高效重用，降低了成本。
`动手训练`
> 大型语言模型（LLMs）的核心能力之一是与人类进行多轮对话。但目前执行此类对话的LLM服务引擎效率不高，因为它们需要不断重新计算历史对话标记的关键值（KV）缓存，造成高昂的服务成本。为此，我们提出了AttentionStore，这一新注意力机制能够实现多轮对话间的KV缓存重用，大幅降低了重复计算的负担。AttentionStore建立了一个分层的KV缓存系统，巧妙利用高性价比的存储介质保存所有请求的缓存。通过层级预加载和异步保存技术，它还能在GPU计算期间并行处理KV缓存访问，进一步提升效率。此外，AttentionStore通过调度器感知的策略，智能地安排KV缓存的层级位置，确保最快速的访问。为了避免上下文窗口溢出导致缓存失效，它还创新性地解耦了位置编码，并有效截断缓存，保持其有效性。实验证明，AttentionStore能显著提升效率，将首个标记生成时间缩短至原来的12%，多轮对话的提示填充速率提升8.2倍，整体推理成本降低56%。在处理长序列时，其效果更为显著，首个标记生成时间缩短高达95%，提示填充速率飙升22倍。

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x5.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x6.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x7.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x8.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x9.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x10.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x11.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x12.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x13.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x14.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x15.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x16.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x17.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x18.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x19.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x20.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x21.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x22.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x23.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x24.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x25.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x26.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x27.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x28.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x29.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x30.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x31.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x32.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x33.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x34.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x35.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x36.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2403.19708/x37.png)

[https://wx.zsxq.com/dweb2/index/topic_detail/4844811858554188](https://wx.zsxq.com/dweb2/index/topic_detail/4844811858554188)

[https://arxiv.org/abs/2403.19708](https://arxiv.org/abs/2403.19708)