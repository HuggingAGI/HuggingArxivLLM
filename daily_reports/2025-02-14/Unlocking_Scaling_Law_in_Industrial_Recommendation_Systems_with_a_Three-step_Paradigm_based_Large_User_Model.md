# 揭秘工业推荐系统中的规模法则：基于大型用户模型的三步式方法
发布时间：2025年02月12日

`推荐系统`
> Unlocking Scaling Law in Industrial Recommendation Systems with a Three-step Paradigm based Large User Model
>
> 自回归大型语言模型（LLMs）近期取得了重大进展，这些成就主要归功于其可扩展性，这一特性常被称为“缩放法则”。受到这些成果的启发，人们逐渐开始尝试将LLMs应用于推荐系统（RecSys），通过将RecSys任务重新表述为生成问题来实现。然而，这些端到端生成推荐（E2E-GR）方法往往过于追求理想化的目标，常常忽视了传统基于深度学习的推荐模型（DLRMs）在特征、架构和实践中所提供的实际优势。这种理想化目标与实际需求之间的差距带来了诸多挑战和限制，使得缩放法则在工业级推荐系统中难以应用。本文中，我们引入了一种大型用户模型（LUM），通过一个三步范式来解决这些限制，旨在满足工业环境中的严格要求，同时释放可扩展推荐的潜力。我们进行了广泛的实验评估，结果表明LUM在性能上优于现有的DLRMs和E2E-GR方法。值得注意的是，LUM表现出色的可扩展性，随着模型参数规模扩展至70亿级别，性能得到了显著提升。此外，我们成功地将LUM部署到工业应用中，在A/B测试中取得了显著的增益，进一步验证了其有效性和实用性。
>
> https://arxiv.org/abs/2502.08309

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.08309](https://arxiv.org/abs/2502.08309)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)