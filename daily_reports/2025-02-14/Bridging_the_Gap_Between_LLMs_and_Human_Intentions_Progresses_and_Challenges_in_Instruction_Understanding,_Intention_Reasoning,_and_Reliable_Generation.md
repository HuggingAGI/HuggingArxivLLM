# 弥合大型语言模型与人类意图之间的差距：指令理解、意图推理与可靠生成的进展与挑战
发布时间：2025年02月13日


> Bridging the Gap Between LLMs and Human Intentions: Progresses and Challenges in Instruction Understanding, Intention Reasoning, and Reliable Generation
>
> 大型语言模型 (LLMs) 在理解和生成方面表现出色，但在现实场景中与人类指令交互时，仍面临三大核心挑战：准确理解指令、合理推理意图以及稳定生成内容。针对复杂指令，LLMs在处理长上下文和多轮对话时表现欠佳。在意图推理方面，LLMs存在推理不一致、难以处理错误信息指令、理解模糊语言困难以及意图捕捉能力较弱等问题。就生成质量而言，LLMs可能出现内容不稳定或不道德生成的情况。本文系统分析了LLMs在这些挑战性场景中的表现，评估现有解决方案，并基于上述三大核心挑战构建了基准测试体系。最后，我们展望了未来研究方向，致力于提升LLMs在实际应用中的可靠性和适应性。
>
> https://arxiv.org/abs/2502.09101

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.09101](https://arxiv.org/abs/2502.09101)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)