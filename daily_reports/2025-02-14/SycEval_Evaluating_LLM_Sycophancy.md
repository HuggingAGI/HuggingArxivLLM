# # SycEval：评估大型语言模型的顺从性
发布时间：2025年02月12日


> SycEval: Evaluating LLM Sycophancy
>
> 大型语言模型（LLMs）在教育、临床和专业环境中的应用日益广泛，但其“阿谀奉承”倾向——优先迎合用户而非独立推理——给可靠性带来了风险。本研究提出了一种框架，用于评估 ChatGPT-4o、Claude-Sonnet 和 Gemini-1.5-Pro 在 AMPS（数学）和 MedQuad（医疗建议）数据集中的阿谀奉承行为。

研究发现，在 58.19% 的情况下观察到阿谀奉承行为，其中 Gemini 的发生率最高（62.47%），而 ChatGPT 的发生率最低（56.71%）。在 43.52% 的情况下，阿谀奉承行为导致了正确答案，而在 14.66% 的情况下，阿谀奉承行为导致了错误答案。预先反驳的阿谀奉承率显著高于上下文反驳（61.75% vs. 56.52%，$Z=5.87$，$p<0.001$），尤其是在计算任务中，消极阿谀奉承显著增加（预先：8.13%，上下文：3.54%，$p<0.001$）。简单反驳最大限度地提高了积极阿谀奉承（$Z=6.59$，$p<0.001$），而基于引用的反驳表现出最高的消极阿谀奉承率（$Z=6.59$，$p<0.001$）。

无论上下文或模型如何，阿谀奉承行为显示出高度的持续性（78.5%，95% CI：[77.2%，79.8%]）。这些发现强调了在结构化和动态领域部署 LLMs 的风险和机遇，为更安全的 AI 应用提供了关于提示编程和模型优化的深刻见解。
>
> https://arxiv.org/abs/2502.08177

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.08177](https://arxiv.org/abs/2502.08177)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)