# # Polymind：借助大型语言模型通过微任务实现并行视觉图解以支持预写作
# Polymind：利用大型语言模型通过微任务进行并行视觉图解助力预写作
发布时间：2025年02月13日


> Polymind: Parallel Visual Diagramming with Large Language Models to Support Prewriting Through Microtasks
>
> 预写是在撰写初稿前生成和组织想法的过程，通常结合非正式、迭代和半结构化的策略，例如视觉图示，这为与大型语言模型（LLMs）进行协作带来了挑战，尤其是在轮流对话的方式下。我们介绍Polymind，一款利用多个由LLM驱动的代理来支持预写的视觉图示工具。该系统采用并行协作工作流，取代了传统的轮流对话交互方式。它定义了多个“微任务”来模拟团队协作场景，如协作写作和头脑风暴。与反复针对不同目的提示聊天机器人不同，Polymind使用户能够同时编排多个微任务。用户可以配置并委托自定义的微任务，并通过指定任务要求以及切换可见性和主动性来管理这些微任务。我们的评估显示，与ChatGPT相比，用户在使用Polymind时拥有更多定制化协作的可能性，因此能够在预写过程中快速扩展个性化的写作思路。
>
> https://arxiv.org/abs/2502.09577

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.09577](https://arxiv.org/abs/2502.09577)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)