# 提升法律LLM的回答：通过法律推理，利用可训练的逻辑结构和语义知识
发布时间：2025年02月11日


> Elevating Legal LLM Responses: Harnessing Trainable Logical Structures and Semantic Knowledge with Legal Reasoning
>
> 大型语言模型（LLMs）在众多领域展现出了卓越的能力，但在法律问答任务中仍存在明显不足。LLMs 生成的回答往往过于泛化，缺乏专家级法律咨询所需的逻辑具体性，且容易出现幻觉现象，提供看似正确但不可靠的答案。检索增强生成（RAG）技术为这一挑战提供了部分解决方案，但现有方法通常仅关注语义相似性，忽视了法律推理中至关重要的逻辑结构。本文提出了一种名为逻辑-语义整合模型（LSIM）的新型监督框架，旨在连接语义和逻辑连贯性。LSIM 包含三个组件：强化学习用于为每个问题预测结构化的事实-规则链，可训练的深度结构化语义模型（DSSM）通过整合语义和逻辑特征检索最相关的问题，以及通过检索内容生成最终答案的 in-context 学习。我们在一个经过自动评估指标和人工评估验证的真实法律问答数据集上进行的实验表明，与现有方法相比，LSIM 显著提高了准确性和可靠性。
>
> https://arxiv.org/abs/2502.07912

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.07912](https://arxiv.org/abs/2502.07912)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)