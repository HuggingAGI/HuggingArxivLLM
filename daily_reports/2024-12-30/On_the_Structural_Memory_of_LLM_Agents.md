# 论 LLM 智能体的结构记忆
发布时间：2024年12月16日

`Agent应用`
> On the Structural Memory of LLM Agents
>
> 内存对于基于大型语言模型（LLM）的代理能够参与诸如问答（QA）和对话系统之类的复杂且长期的交互起着关键作用。尽管针对这些任务已提出了各种各样的内存模块，然而不同内存结构在不同任务中的影响仍未得到充分探究。本文探讨了内存结构和内存检索方法对基于 LLM 的代理性能的影响。具体来说，我们评估了包括块、知识三元组、原子事实和摘要在内的四种内存结构，以及将这些组件相结合的混合内存。另外，我们还评估了三种被广泛使用的内存检索方法：单步检索、重新排序和迭代检索。通过在四个任务和六个数据集上进行的大量实验，得出了以下关键见解：（1）不同的内存结构具有各自的优势，能够适配特定任务；（2）混合内存结构在嘈杂环境中展现出显著的适应性；（3）迭代检索在各种场景中始终优于其他方法。我们的研究旨在推动基于 LLM 的代理的内存系统设计的进一步探索。
>
> https://arxiv.org/abs/2412.15266

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2412.15266](https://arxiv.org/abs/2412.15266)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)