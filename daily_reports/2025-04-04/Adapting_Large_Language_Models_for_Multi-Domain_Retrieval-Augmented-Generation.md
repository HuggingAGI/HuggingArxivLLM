# # 将大型语言模型应用于跨领域检索增强生成
发布时间：2025年04月03日

`RAG`
> Adapting Large Language Models for Multi-Domain Retrieval-Augmented-Generation
>
> 检索增强生成（RAG）虽然提升了大型语言模型的事实准确性，但在多领域应用中仍面临两大挑战：缺乏多样化的基准测试和跨领域泛化能力不足。本研究的两大贡献分别是：首先，我们引入了一个涵盖13个领域、整合了8个来源的多样化基准测试集；其次，我们系统性地评估了典型RAG微调策略的跨领域泛化性能。研究发现，标准微调方法难以实现有效泛化，而采用教师生成标签的序列级蒸馏方法，通过提供更连贯的监督信号，显著提升了跨领域性能。这些发现为提升多领域RAG的鲁棒性提供了关键策略。
>
> https://arxiv.org/abs/2504.02411

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2504.02411](https://arxiv.org/abs/2504.02411)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)