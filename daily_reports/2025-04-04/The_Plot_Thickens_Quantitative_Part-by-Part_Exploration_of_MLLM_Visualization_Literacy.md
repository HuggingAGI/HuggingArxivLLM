# 情节渐趋复杂：多模态大语言模型可视化素养的分层定量探索
发布时间：2025年04月02日

`图表问答`
> The Plot Thickens: Quantitative Part-by-Part Exploration of MLLM Visualization Literacy
>
> 多模态大型语言模型（MLLMs）能够解读数据可视化，但什么因素使这些模型能够理解可视化呢？颜色、形状和文字等因素是否会影响可读性？这些因素对模型的影响与人类感知有何异同？在本文中，我们基于先前的研究，系统性地评估了哪些可视化特征会影响MLLM的可解释性。我们通过改变图表类型、颜色和标题，将可视化素养评估测试（VLAT）的测试集从12个扩展到了380个可视化样本。这使我们能够统计分析这些特征对模型性能的影响。我们的研究发现，虽然颜色方案对准确率没有显著影响，但图表类型和标题类型对MLLM的性能有显著影响。我们还观察到类似的趋势存在于模型遗漏的情况中。基于这些见解，我们探讨了在不同任务中哪些图表类型对MLLMs有益，并提出了增强MLLM可读性的可视化设计原则。此外，我们还将扩展后的VLAT测试集VLAT ex公开发布在https://osf.io/ermwx/，同时提供了补充材料，以供未来对模型进行测试和评估使用。
>
> https://arxiv.org/abs/2504.02217

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2504.02217](https://arxiv.org/abs/2504.02217)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)