# WritingBench：面向生成式写作的综合性基准测试
发布时间：2025年03月07日


> WritingBench: A Comprehensive Benchmark for Generative Writing
>
> 大型语言模型（LLMs）的最新进展显著提升了文本生成能力，但评估其在生成性写作中的表现仍是难题。现有基准主要关注通用文本生成或特定写作任务，未能全面涵盖高质量书面内容的多样化需求。为解决这一问题，我们推出了WritingBench，一个全面评估LLMs的基准测试，涵盖6个核心写作领域和100个子领域，包括创意、说服性、信息性和技术性写作。我们还提出了一种基于查询的评估框架，使LLMs能够动态生成特定实例的评估标准。该框架结合了经过微调的评判模型，用于标准感知评分，能够在风格、格式和长度方面进行评估。该框架的有效性通过其数据整理能力得到验证，使7B参数模型能够达到当前最优（SOTA）性能。我们开源了该基准测试、评估工具和模块化框架组件，以推动LLMs在写作领域的开发。
>
> https://arxiv.org/abs/2503.05244

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2503.05244](https://arxiv.org/abs/2503.05244)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)