# R1-Searcher：通过强化学习提升大型语言模型的搜索能力
发布时间：2025年03月07日


> R1-Searcher: Incentivizing the Search Capability in LLMs via Reinforcement Learning
>
> 现有的大型推理模型（LRMs）已经展示了强化学习（RL）在提升大型语言模型（LLMs）复杂推理能力方面的潜力。尽管它们在数学和编程等具有挑战性的任务上表现卓越，但这些模型往往依赖于自身的内部知识来解决问题，这在面对时间敏感或知识密集型问题时可能显得不足，从而导致不准确和幻觉现象。为了解决这一问题，我们提出了	extbf{R1-Searcher}，一种旨在提升LLMs搜索能力的创新性两阶段结果导向型RL方法。该方法使LLMs能够在推理过程中自主调用外部搜索系统，以获取额外的知识。我们的框架完全依赖于RL，无需过程奖励或蒸馏即可实现冷启动。实验结果表明，我们的方法显著超越了先前的强RAG方法，甚至在与闭源的GPT-4o-mini相比时也表现更优。
>
> https://arxiv.org/abs/2503.05592

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2503.05592](https://arxiv.org/abs/2503.05592)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)