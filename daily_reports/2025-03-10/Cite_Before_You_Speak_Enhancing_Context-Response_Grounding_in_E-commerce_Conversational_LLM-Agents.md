# 引文前置：提升电商对话LLM代理的上下文-响应关联性
发布时间：2025年03月09日


> Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents
>
> 对话式大型语言模型（LLMs）的进步催生了多种基于LLM的对话式购物代理（CSA），它们在电子商务领域帮助客户解答问题，提升购物体验。然而，构建一个值得信赖的CSA面临两大挑战：LLMs可能产生幻觉或无支持声明，导致信息不准确，损害客户信任；CSA的回答缺乏知识来源归属，使客户难以验证信息。为解决这些问题，我们提出了一种易于部署的解决方案，利用In-context Learning (ICL) 和 Multi-UX-Inference (MUI) 来生成带引文的回答，将原始来源归属到回答中，同时不影响其他用户体验功能。通过适当的用户体验设计，这些引文标记可链接到相关产品信息，向客户展示来源。我们还构建了自动度量和可扩展的基准测试，全面评估LLM的 grounding 和归属能力。实验表明，引入这种引文生成范式使LLM回答的 grounding 提升了13.83%。因此，我们的解决方案不仅解决了LLM grounding 的问题，还为对话式AI增加了透明度。
>
> https://arxiv.org/abs/2503.04830

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2503.04830](https://arxiv.org/abs/2503.04830)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)