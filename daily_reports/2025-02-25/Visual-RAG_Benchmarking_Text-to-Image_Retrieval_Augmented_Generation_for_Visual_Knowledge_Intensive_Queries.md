# Visual-RAG：图像生成增强检索基准测试，专为视觉知识密集型查询而设计
发布时间：2025年02月23日

`RAG`
> Visual-RAG: Benchmarking Text-to-Image Retrieval Augmented Generation for Visual Knowledge Intensive Queries
>
> 检索增强生成（RAG）是一种流行的提升大型语言模型（LLMs）能力的方法，它通过弥补模型在事实验证和回答知识密集型问题上的不足来实现。随着LLM研究扩展到处理文本以外的输入模态（如图像），一些多模态RAG基准被提出。然而，这些方法主要依赖文本知识库作为增强的主要证据来源。目前仍缺乏专门设计用于评估RAG系统中图像增强效果及其对视觉知识利用的基准。我们提出了Visual-RAG，这是一个专注于视觉知识密集型问题的新问答基准。与以往依赖文本证据的工作不同，Visual-RAG需要进行文本到图像的检索，并整合相关线索图像以提取视觉知识作为证据。通过Visual-RAG，我们评估了5个开源和3个专有的多模态LLM（MLLMs），发现图像可以作为良好的证据用于RAG；然而，即使是SOTA模型也难以有效提取和利用视觉知识。
>
> https://arxiv.org/abs/2502.16636

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.16636](https://arxiv.org/abs/2502.16636)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)