# 探索知识密集型检索增强生成中的多视角洞察。
发布时间：2024年04月19日
`RAG`
> 检索增强生成（RAG）对于大型语言模型（LLMs）的应用至关重要，但在法律和医学等知识密集型领域，现有检索方法因缺少多视角视图而受限，这些视角对于增强模型的解释力和可靠性极为关键。过往研究多聚焦于查询的多种语义形态，却忽视了特定领域知识视角的展现。本文提出了一个创新的多视图RAG框架——MVRAG，专为知识密集型领域设计，通过从多个领域视角进行意图驱动的查询重写，以提升检索的精准度，进而增强最终推理的效果。在法律和医学案例检索的实验中，我们的框架显著提升了召回率和精确率。这种多视角检索策略充分发挥了多视图信息的潜力，为RAG任务带来增益，推动了LLMs在知识密集型行业的更广泛应用。

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.12879/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.12879/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.12879/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.12879/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.12879/x5.png)

[https://wx.zsxq.com/dweb2/index/topic_detail/8855282485151552](https://wx.zsxq.com/dweb2/index/topic_detail/8855282485151552)

[https://arxiv.org/abs/2404.12879](https://arxiv.org/abs/2404.12879)