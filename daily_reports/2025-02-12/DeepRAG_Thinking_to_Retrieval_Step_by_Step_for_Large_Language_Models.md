# DeepRAG: 大型语言模型的逐步检索思考
发布时间：2025年02月03日

`RAG`
> DeepRAG: Thinking to Retrieval Step by Step for Large Language Models
>
> 大型语言模型（LLMs）在推理方面展现了巨大潜力，但受限于参数知识的时效性、准确性和覆盖范围，它们仍面临严重的事实幻觉问题。同时，将推理与检索增强生成（RAG）结合也颇具挑战，任务分解无效和冗余检索可能引入噪声，降低响应质量。本文提出DeepRAG框架，将检索增强推理建模为马尔可夫决策过程（MDP），实现战略性和自适应的检索。通过迭代分解查询，DeepRAG在每一步动态决定是检索外部知识还是依赖参数推理。实验表明，DeepRAG在提升检索效率的同时，将答案准确率提高了21.99%，展现了其在优化检索增强推理方面的卓越效果。
>
> https://arxiv.org/abs/2502.01142

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.01142](https://arxiv.org/abs/2502.01142)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)