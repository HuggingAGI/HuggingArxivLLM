# # POLYRAG: 将多重视图整合到检索增强生成中用于医疗应用
发布时间：2025年04月21日

`RAG`
> POLYRAG: Integrating Polyviews into Retrieval-Augmented Generation for Medical Applications
>
> 大型语言模型 (LLMs) 正在以颠覆性力量重塑行业格局，为自然语言处理与逻辑推理等领域带来前所未有的突破。然而，在医疗场景中，知识更新与幻觉问题的挑战限制了 LLMs 的应用，而检索增强生成 (RAG) 则为此提供了重要解决方案。现有检索后阅读方法通常忽视了检索结果的时效性、权威性和普遍性，我们发现这些方法在现实场景中可能效果欠佳。为此，我们提出了 PolyRAG，它通过多角度整合信息，最终将多重视图融入医疗场景的检索增强生成。鉴于缺乏现实世界基准用于评估，我们构建了 PolyEVAL 基准，包含来自真实医疗场景（如医疗政策、医院及医生咨询和医疗保健）的查询和文档，并标注了多维度信息（如时效性、权威性）。在 PolyEVAL 上的实验结果充分证明了 PolyRAG 的优越性。
>
> https://arxiv.org/abs/2504.14917

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2504.14917](https://arxiv.org/abs/2504.14917)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)