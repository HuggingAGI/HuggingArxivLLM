# 检索增强生成系统中上下文大小与模型选择的影响研究
发布时间：2025年02月20日

`RAG`
> On the Influence of Context Size and Model Choice in Retrieval-Augmented Generation Systems
>
> 检索增强生成（RAG）作为一种方法，通过减少大型语言模型（LLMs）对静态知识的依赖并提高答案的事实性，增强了LLMs的能力。RAG通过检索相关上下文片段并基于这些片段生成答案。尽管RAG在工业界的应用日益普及，但对其组成部分的系统性探索仍然不足，特别是在理想上下文大小、基础LLM选择以及检索方法选择方面。为了帮助开发更强大的RAG系统，我们评估了不同大小的上下文、BM25和语义搜索作为检索器，以及八种基础LLMs。与常见的基于简短答案的RAG评估不同，我们探索了更具挑战性的长篇问答任务，在两个领域中，优秀答案需要充分利用整个上下文。我们的研究发现，问答性能随着上下文片段数量增加到15个而稳步提升，但超过这个数量则趋于平稳或下降。最后，我们发现不同通用LLMs在生物医学领域表现优于百科全书式领域，并且在大规模语料库中进行开放领域证据检索具有挑战性。
>
> https://arxiv.org/abs/2502.14759

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.14759](https://arxiv.org/abs/2502.14759)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)