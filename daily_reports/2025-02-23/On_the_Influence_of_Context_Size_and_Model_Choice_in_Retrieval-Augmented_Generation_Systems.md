# 揭秘RAG系统：如何通过上下文大小和模型选择提升问答性能？
发布时间：2025年02月20日

`RAG`
> On the Influence of Context Size and Model Choice in Retrieval-Augmented Generation Systems
>
> 检索增强生成（RAG）作为一种方法，通过减少大型语言模型（LLMs）对静态知识的依赖并提高答案的事实性，增强了LLMs的能力。RAG通过检索相关上下文片段并基于这些片段生成答案。尽管RAG在工业界的应用日益普及，但对其组成部分的系统性探索仍然不足，特别是在理想上下文大小、基础LLM选择以及检索方法选择方面。为了帮助开发更强大的RAG系统，我们评估了不同大小的上下文、BM25和语义搜索作为检索器，以及八种基础LLMs。与常见的基于简短答案的RAG评估不同，我们探索了更具挑战性的长篇问答任务，在两个领域中，优秀答案需要充分利用整个上下文。我们的研究发现，问答性能随着上下文片段数量增加到15个而稳步提升，但超过这个数量则趋于平稳或下降。最后，我们发现不同通用LLMs在生物医学领域表现优于百科全书式领域，并且在大规模语料库中进行开放领域证据检索具有挑战性。
>
> https://arxiv.org/abs/2502.14759

![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2025/02/12/1739367812022-81912e8f-5f91-4b9d-b4b2-52b0e322d137.png)
**添加请注明[]**
**如遇无法添加，请+ vx: iamxxn886**
<hr />


## 一、RAG系统的背景与挑战

在自然语言处理（NLP）领域，大型语言模型（LLMs）如GPT、BERT等已经展现出了强大的文本生成、问答和摘要能力。然而，这些模型也存在一些显著的局限性。首先，LLMs的知识是静态的，这意味着它们无法及时更新以反映新信息，导致生成的回答可能过时。其次，LLMs有时会生成听起来合理但事实上错误的回答，这种现象被称为“幻觉”。最后，LLMs在涉及高级专业领域的知识时，往往缺乏足够的深度。

为了应对这些挑战，检索增强生成（Retrieval-Augmented Generation, RAG）系统应运而生。RAG系统通过引入检索组件，使LLMs能够动态地利用外部知识源，从而生成更准确、更及时的回答。RAG系统已经在多个行业中得到广泛应用，尤其是在企业内部文档查询等场景中。然而，尽管RAG系统的应用日益广泛，关于其最佳配置的研究却相对缺乏，特别是在上下文大小、基础LLM选择以及检索方法等方面。

## 二、RAG系统的架构与特点

RAG系统通常由两个主要组件构成：检索器（Retriever）和生成器（Reader）。检索器负责从外部知识库中检索相关的上下文片段，这些片段随后被传递给生成器，生成器基于这些上下文生成最终的回答。我们的研究重点探讨了这三个方面（检索器、上下文、生成器）对系统整体性能的影响。

### 1. 上下文大小的影响

我们首先研究了上下文大小对生成器问答能力的影响。实验表明，随着上下文片段数量的增加，系统的性能逐步提升，但当片段数量达到10到15个时，性能开始趋于稳定，甚至在某些情况下会出现下降。这一现象表明，过多的上下文片段可能会导致信息过载，反而影响生成器的表现。

### 2. 基础LLM的选择

我们还测试了不同大小和类型的基础LLM在利用上下文片段生成准确回答方面的表现。结果显示，在生物医学领域的任务中，Mistral和Qwen表现最佳，而在百科全书领域的任务中，GPT和Llama则更为出色。这表明，不同领域的任务可能需要不同类型的LLM来达到最佳效果。

### 3. 检索方法的选择

在开放域设置中，我们评估了两种不同的检索方法：BM25和语义搜索。BM25在精确度上表现优异，而语义搜索则能够覆盖更广泛的信息。然而，开放域设置下的性能与黄金设置相比仍有较大差距，这表明在大型知识库中进行检索仍然是一个具有挑战性的任务。

## 三、RAG系统的测评效果

为了全面评估RAG系统的性能，我们选择了两个不同领域的数据集进行实验：生物医学领域的BioASQ-QA任务和百科全书领域的QuoteSum数据集。这两个数据集都提供了黄金证据片段和基于这些片段生成的人类编写的答案，为我们研究RAG系统的表现提供了宝贵的资源。

### 1. 上下文片段的数量

我们的实验结果显示，随着上下文片段数量的增加，系统的性能逐步提升，但当片段数量达到10到15个时，性能开始趋于稳定。这一现象表明，过多的上下文片段可能会导致信息过载，反而影响生成器的表现。

### 2. 基础LLM的表现

在生物医学领域的任务中，Mistral和Qwen表现最佳，而在百科全书领域的任务中，GPT和Llama则更为出色。这表明，不同领域的任务可能需要不同类型的LLM来达到最佳效果。

### 3. 检索方法的影响

在开放域设置中，BM25在精确度上表现优异，而语义搜索则能够覆盖更广泛的信息。然而，开放域设置下的性能与黄金设置相比仍有较大差距，这表明在大型知识库中进行检索仍然是一个具有挑战性的任务。

## 四、总结与展望

通过系统的实验和分析，我们为RAG系统的实现提供了一些最佳实践建议。首先，上下文片段的数量应控制在10到15个之间，以避免信息过载。其次，不同领域的任务可能需要不同类型的LLM来达到最佳效果。最后，在开放域设置中，BM25和语义搜索各有优劣，开发者应根据具体需求选择合适的检索方法。

未来的研究可以进一步探索如何优化RAG系统的检索和生成过程，特别是在处理复杂、多领域的任务时。我们相信，随着技术的不断进步，RAG系统将在更多应用场景中发挥重要作用，为用户提供更准确、更及时的信息服务。

我们已将代码公开在GitHub上，欢迎开发者们参考和使用。


<hr />

- 论文原文: [https://arxiv.org/abs/2502.14759](https://arxiv.org/abs/2502.14759)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)