# 输出长度对 DeepSeek-R1 强制思考安全性的影响
发布时间：2025年03月02日

`DEEPSEEK`
> Output Length Effect on DeepSeek-R1's Safety in Forced Thinking
>
> 大型语言模型（LLMs）拥有强大的推理能力，但其在对抗条件下的安全性仍需改进。本研究聚焦于输出长度对DeepSeek-R1模型鲁棒性的影响，特别是在强制思考场景中。通过对多种对抗提示的响应分析，我们发现：较长的输出虽然能通过自我修正提升安全性，但也可能被某些攻击方式所利用。研究结果表明，动态控制输出长度是平衡推理效果与安全性的关键。为此，我们提出基于强化学习的策略调整和自适应令牌长度调节方法，以有效提升LLMs的安全性。
>
> https://arxiv.org/abs/2503.01923

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2503.01923](https://arxiv.org/abs/2503.01923)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)