# CORBA：基于大型语言模型的多智能体系统中的传染性递归阻塞攻击
发布时间：2025年02月20日

`模型安全`
> CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems Based on Large Language Models
>
> 基于大语言模型的多智能体系统（LLM-MASs）在复杂任务协作中表现出色，尽管这些系统内置了安全机制，例如通过校准拒绝有害指令，但其安全性仍存在重大研究空白，使系统易受定向攻击。本文提出了一种名为传染性递归阻塞攻击（Corba）的新型攻击手段，该方法简单却极具破坏性，能够扰乱LLM-MAS中智能体间的交互。Corba的两大核心特性使其威力倍增：其传染性使其能在任意网络拓扑中快速传播，而其递归性则可导致计算资源持续耗尽。特别值得注意的是，这些阻塞攻击往往以看似无害的指令形式出现，这使得传统的校准方法难以有效应对。我们在AutoGen和Camel这两个广泛应用的LLM-MAS系统上对Corba进行了全面评估，覆盖了多种网络拓扑和商业模型。此外，我们还在开放式的交互式LLM-MAS环境中进行了更深入的实验，进一步验证了Corba在复杂拓扑结构和开源模型中的显著效果。我们的实验代码已开源，地址为：https://github.com/zhrli324/Corba。
>
> https://arxiv.org/abs/2502.14529

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.14529](https://arxiv.org/abs/2502.14529)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)