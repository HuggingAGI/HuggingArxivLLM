# ParetoRAG：基于句子上下文注意力机制的健壮高效检索增强生成
发布时间：2025年02月12日

`RAG`
> ParetoRAG: Leveraging Sentence-Context Attention for Robust and Efficient Retrieval-Augmented Generation
>
> 检索增强生成（RAG）系统通过整合外部知识来提升大型语言模型（LLMs）的能力，但它们仍然面临检索效率低下和模型无法有效过滤无关信息的持续挑战。我们提出了ParetoRAG，一个基于帕累托法则的无监督框架，通过句子级优化来提升RAG系统的性能。ParetoRAG将段落分解为句子，并在保持上下文连贯性的同时动态调整核心内容的权重，从而在不额外训练或使用API资源的情况下，实现了检索精度和生成质量的双重提升。这一框架已在多种数据集、LLMs和检索器上得到了实证验证。
>
> https://arxiv.org/abs/2502.08178

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.08178](https://arxiv.org/abs/2502.08178)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)