# 本研究利用公共社交媒体数据，对大型语言模型在健康相关文本分类任务中的表现进行评估。
`文本分类`
> 大型语言模型（LLMs）在自然语言处理（NLP）任务上取得了卓越成就。但针对社交媒体健康相关文本的分析，这类任务通常难以获得高分，相关研究却寥寥无几。我们对六项文本分类任务进行了评估，包括一个基于支持向量机（SVMs）的监督式经典机器学习模型、三个基于RoBERTa、BERTweet和SocBERT的预训练语言模型（PLMs），以及GPT3.5和GPT4两个LLM分类器。我们提出了三种利用LLMs进行文本分类的方法：直接使用LLMs作为零-shot分类器，让LLMs充当注释工具来标注训练数据，以及用少量样本的LLMs增强手动注释的数据。综合实验显示，结合少量人工注释数据，运用LLMs（GPT-4）进行数据增强，能够训练出比单独使用人工数据更优秀的轻量级监督模型。在零-shot场景下，监督学习器同样超越了GPT-4和GPT-3.5。通过这种数据增强策略，我们可以充分利用LLMs的能力，打造更小巧、更高效的特定领域NLP模型。然而，未经人工指导的LLM注释数据在训练轻量级监督模型方面效果不佳。尽管如此，作为零-shot分类器的LLM在筛除假阴性结果和可能降低人工注释负担方面仍具有潜力。未来的研究亟需确定最优的训练数据量和最佳的数据增强比例。


[https://wx.zsxq.com/dweb2/index/topic_detail/5122188124584524](https://wx.zsxq.com/dweb2/index/topic_detail/5122188124584524)

[https://arxiv.org/abs/2403.19031](https://arxiv.org/abs/2403.19031)