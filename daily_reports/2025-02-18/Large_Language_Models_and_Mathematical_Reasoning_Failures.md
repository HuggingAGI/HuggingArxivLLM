# # 大型语言模型的数学推理困境
发布时间：2025年02月17日


> Large Language Models and Mathematical Reasoning Failures
>
> 本文通过50道新编的高中水平数学题，深入研究了大型语言模型 (LLMs) 的数学推理能力。与以往仅关注答案正确性的研究不同，我们不仅检验了最终答案，还对解答过程进行了细致分析，以识别推理中的潜在失误。通过对包括 Mixtral、Llama、Gemini、GPT-4o 以及 OpenAI o1 系列在内的八种先进模型的评估，我们发现尽管 newer 模型（如 o3-mini、deepseek-r1）在准确率上表现更优，但所有模型在空间推理、战略规划和算术方面均存在明显缺陷，有时甚至通过错误的逻辑得出正确答案。常见的失误模式包括不合理假设、过度依赖数值模式以及难以将物理直觉转化为数学步骤。手动分析表明，尽管这些模型具备广泛的数学知识，但在处理需要多步推理或涉及现实世界知识的问题时仍显吃力。我们的研究结果强调了评估推理过程的重要性，而不仅仅是答案的正确性，并提醒我们不要高估 LLMs 的问题解决能力。本研究突显了 LLMs 在泛化能力上的持续差距，强调了在结构化推理和约束处理方面进行针对性改进的必要性。
>
> https://arxiv.org/abs/2502.11574

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.11574](https://arxiv.org/abs/2502.11574)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)