# 通过自我选择优化检索增强生成中的知识整合
发布时间：2025年02月09日

`RAG`
> Optimizing Knowledge Integration in Retrieval-Augmented Generation with Self-Selection
>
> 检索增强生成（RAG）通过将外部知识整合到大型语言模型（LLMs）中，已被证明能有效提升LLMs生成更准确可靠回答的能力。然而，如何有效融合外部检索知识与LLMs内部参数知识仍是一项重大挑战。本研究提出了一种新颖的自选式RAG框架，使LLMs能够从仅基于内部参数知识生成的回答与结合外部检索知识生成的回答中进行选择，从而提升回答的准确性。为此，我们设计了一种自选式-RGP方法，通过在经过筛选的检索生成偏好（RGP）数据集上对LLMs进行直接偏好优化（DPO）训练，来增强LLMs在生成和选择正确答案方面的能力。实验结果表明，使用两个开源LLMs（即Llama2-13B-Chat和Mistral-7B）在自然问答（NQ）和简单问答（TrivialQA）数据集上的测试，我们的方法相较于其他基线方法具有明显优势。
>
> https://arxiv.org/abs/2502.06148

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.06148](https://arxiv.org/abs/2502.06148)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)