# MATH-Perturb：评测大型语言模型在面对困难干扰时的数学推理能力
发布时间：2025年02月10日


> MATH-Perturb: Benchmarking LLMs' Math Reasoning Abilities against Hard Perturbations
>
> 大型语言模型在复杂数学推理任务中表现出色，但其能力究竟源于真正推理还是简单记忆尚存疑问。先前研究通过保持解题思路的简单扰动构建了数学测试基准，但尚未探索会彻底改变问题本质的困难扰动。为此，我们基于MATH数据集（Hendrycks等，2021）中最难的第5级问题，通过简单扰动和困难扰动分别构建了MATH-P-Simple和MATH-P-Hard数据集，每个包含279道变形数学题。实验结果显示，包括o1-mini（-16.49%）和gemini-2.0-flash-thinking（-12.9%）在内的多个模型在MATH-P-Hard上表现大幅下降。我们发现模型存在盲目套用所学解题技巧而不评估其适用性的记忆问题，这一现象在使用原始问题进行上下文学习时尤为突出。我们呼吁研究界深入探索这一挑战，这对于开发更强大可靠的推理模型具有重要意义。
>
> https://arxiv.org/abs/2502.06453

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2502.06453](https://arxiv.org/abs/2502.06453)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)