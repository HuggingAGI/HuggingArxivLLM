# 采用模型上下文协议的LLMs存在重大安全漏洞——MCP安全审核
发布时间：2025年04月02日

`MCP`
> MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits
>
> 为了降低开发成本并实现任意生成式AI应用组件的无缝集成，模型上下文协议（MCP）（Anthropic，2024）近期发布并被广泛采用。MCP是一个开放协议，标准化了对大型语言模型（LLMs）、数据源和智能工具的API调用。通过连接多个MCP服务器，每个服务器都定义了一组工具、资源和提示，用户能够定义完全由LLMs驱动的自动化工作流。然而，我们发现当前MCP设计对终端用户存在多种安全风险。特别是，我们演示了行业领先的LLMs可能被迫使用MCP工具通过各种攻击（如恶意代码执行、远程访问控制和凭证窃取）来破坏AI开发者的系统。为了主动缓解这些及相关攻击，我们引入了一个安全审计工具MCPSafetyScanner，这是首个用于评估任意MCP服务器安全性的智能工具。MCPSafetyScanner利用多个代理来（a）根据MCP服务器的工具和资源自动确定对抗样本；（b）基于这些样本搜索相关漏洞和补救措施；（c）生成一份详细说明所有发现的安全报告。我们的工作突显了通用智能工作流的安全问题，同时提供了一个主动工具来审计MCP服务器的安全性并在部署前修复检测到的漏洞。

    描述的MCP服务器审计工具MCPSafetyScanner可在以下链接免费获取：https://github.com/leidosinc/McpSafetyScanner
>
> https://arxiv.org/abs/2504.03767

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2504.03767](https://arxiv.org/abs/2504.03767)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)