# MT-R1-Zero：利用R1-Zero风格的强化学习提升基于LLM的机器翻译能力
发布时间：2025年04月14日


> MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like Reinforcement Learning
>
> 大规模强化学习（RL）方法在提升大型语言模型（LLMs）的推理能力方面表现出色，尤其在数学和编码等具有可验证解决方案的任务中。然而，将其应用于机器翻译（MT）领域仍具挑战，因为MT输出格式灵活且难以通过明确规则自动评估。在本研究中，我们推出了MT-R1-Zero，这是首个无需监督微调或冷启动的开源R1-Zero RL框架在MT领域的应用。我们提出了一种规则与指标混合奖励机制，引导LLMs通过涌现推理能力提升翻译质量。在WMT 24英汉基准测试中，我们的MT-R1-Zero-3B-Mix模型表现出色，平均分超越TowerInstruct-7B-v0.2达1.26分。同时，MT-R1-Zero-7B-Mix模型在所有评估指标中取得了62.25的高平均分，与GPT-4o和Claude-3.5-Sonnet等先进专有模型持平，而MT-R1-Zero-7B-Sem变体则在语义指标上达到了最新水平。此外，我们的方法在分布外MT任务中展现了强大的泛化能力，为多语言和低资源环境提供了有力支持。通过对不同初始化和奖励指标下模型行为的深入分析，我们为理解R1-Zero范式在MT中的奖励设计、LLM适应性、训练动态及涌现推理模式提供了开创性见解。我们的代码可在https://github.com/fzp0424/MT-R1-Zero获取。
>
> https://arxiv.org/abs/2504.10160

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2504.10160](https://arxiv.org/abs/2504.10160)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)