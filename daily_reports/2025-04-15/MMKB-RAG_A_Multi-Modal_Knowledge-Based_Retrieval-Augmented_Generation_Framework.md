# MMKB-RAG：一个多模态知识增强检索生成框架
发布时间：2025年04月14日

`RAG`
> MMKB-RAG: A Multi-Modal Knowledge-Based Retrieval-Augmented Generation Framework
>
> 近年来，大型语言模型（LLMs）和多模态大型语言模型取得了显著进展。然而，这些模型仍完全依赖于其参数化的知识储备，这限制了它们生成最新信息的能力，同时增加了生成错误内容的风险。检索增强生成（RAG）通过整合外部数据源部分缓解了这些挑战，但对数据库和检索系统的依赖可能引入不相关或不准确的文档，最终损害性能和推理质量。本文中，我们提出了一种新型的多模态知识增强检索生成框架（MMKB-RAG），该框架利用模型自身的知识边界动态生成语义标签以优化检索过程。这种策略实现了对检索文档的联合筛选，仅保留最相关和最准确的参考资料。在基于知识的视觉问答任务上的广泛实验验证了我们方法的有效性：在E-VQA数据集上，我们的方法在单跳子集上的性能提升了+4.2%，在完整数据集上提升了+0.4%。而在InfoSeek数据集上，我们的方法在未见问题子集上提升了+7.8%，在未见实体子集上提升了+8.2%，在完整数据集上提升了+8.1%。这些结果凸显了与当前最先进的多模态大型语言模型和RAG框架相比，我们在准确性和鲁棒性方面取得了显著提升。
>
> https://arxiv.org/abs/2504.10074

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2504.10074](https://arxiv.org/abs/2504.10074)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)