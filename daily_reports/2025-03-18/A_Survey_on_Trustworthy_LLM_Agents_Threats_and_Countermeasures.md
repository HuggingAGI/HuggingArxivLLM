# # 可信LLM智能体的威胁与对策调查
可信LLM智能体的威胁与对策调查
发布时间：2025年03月12日


> A Survey on Trustworthy LLM Agents: Threats and Countermeasures
>
> 大型语言模型（LLMs）的快速发展推动了基于LLMs的智能体和多智能体系统（MAS）的演进，显著扩展了LLM生态的能力。这种演进源于为LLMs赋予了记忆、工具、环境和其他智能体等额外模块。然而，这种进步也带来了更复杂的可信性问题，这是之前仅关注LLMs的研究无法涵盖的。在本研究中，我们提出了TrustAgent框架，这是一个关于智能体可信性的全面研究，具有模块化分类、多维内涵和技术实现的特征。

通过全面调查和总结针对智能体和MAS新出现的攻击、防御和评估方法，我们将可信LLM的概念扩展到了新兴的可信智能体范式。在TrustAgent框架中，我们首先分解并介绍了智能体和MAS的各种组件。然后，我们将它们的可信性分为内在（大脑、记忆和工具）和外在（用户、智能体和环境）两个方面。接着，我们阐述了可信性的多方面含义，并详细说明了现有研究中与这些内部和外部模块相关的实现技术。最后，我们提出了对我们领域的一些见解和展望，旨在为未来的研究提供指导。
>
> https://arxiv.org/abs/2503.09648

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2503.09648](https://arxiv.org/abs/2503.09648)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)