# 对用于代码漏洞检测的大型语言模型的探究：一项实验研究
发布时间：2024年12月24日

`代码编写`
> Investigating Large Language Models for Code Vulnerability Detection: An Experimental Study
>
> 代码漏洞检测（CVD）对于解决和防范系统安全问题极为重要，在保障软件安全方面发挥着关键作用。以往基于学习的漏洞检测方法，要么依靠微调中等规模的序列模型，要么从头训练较小的神经网络。大型预训练语言模型（LLMs）的最新进展在包括代码理解和生成等各类代码智能任务中展现出了非凡能力。然而，LLMs 在检测代码漏洞方面的有效性在很大程度上还未被充分挖掘。本研究旨在通过为 CVD 任务微调 LLMs 来探究这一差距，涉及四个广泛使用的开源 LLMs。同时，我们还实现了其他五个先前的基于图或中等规模的序列模型以作对比。实验在五个常用的 CVD 数据集上开展，涵盖了短样本和长样本的部分。另外，我们进行了定量实验，以研究类别不平衡问题以及模型在不同长度样本上的表现，这些在以往的工作中鲜少被研究。为更好地服务社区，我们在 https://github.com/SakiRinn/LLM4CVD 和 https://huggingface.co/datasets/xuefen/VulResource 开源了本研究的所有代码和资源。
>
> https://arxiv.org/abs/2412.18260

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2412.18260](https://arxiv.org/abs/2412.18260)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)