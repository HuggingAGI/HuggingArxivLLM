# 大型语言模型可能只是死记硬背的高手。
发布时间：2025年04月11日


> Large language models could be rote learners
>
> 多选题（MCQ）基准测试是评估大型语言模型（LLMs）的常用方法，但基准污染问题严重削弱了其可靠性。本研究将污染重新定义为学习过程中的固有组成部分，并致力于在LLMs评估中区分真实能力获取与浅层记忆。通过分析模型在不同记忆条件下的表现，我们发现了一个反直觉的趋势：LLMs在记忆过的MCQ上表现不如未记忆过的，这表明死记硬背和真实能力学习这两种不同的学习现象并存。为区分这两种现象，我们提出了TrinEval，这是一种全新的评估框架，将MCQ重新表述为三元组格式，从而减少记忆同时保持知识评估。实验验证了TrinEval在重新表述方面的有效性，其评估结果表明，常见LLMs可能通过死记硬背记忆了20.5%的知识点（平均基于MMLU）。
>
> https://arxiv.org/abs/2504.08300

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2504.08300](https://arxiv.org/abs/2504.08300)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)