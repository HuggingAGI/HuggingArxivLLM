# SafeAgentBench：用于具身 LLM 智能体安全任务规划的基准
发布时间：2024年12月18日


> SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents
>
> 随着大型语言模型（LLMs）的融入，具身智能体拥有了用自然语言执行复杂指令的强大能力，为具身机器人的潜在应用铺平了道路。然而，一个可预见的问题是，这些具身智能体还能出色地执行某些危险任务，可能会在现实世界中造成危害。为研究此问题，我们推出了 SafeAgentBench——一个针对具身 LLM 智能体安全感知任务规划的新基准。SafeAgentBench 涵盖：（1）包含 750 个任务的新数据集，涵盖 10 种潜在危险和 3 种任务类型；（2）SafeAgentEnv，一个带有低级控制器的通用具身环境，支持多智能体执行，具备 17 种高级动作，适用于 8 种先进基线；（3）从执行和语义两方面出发的可靠评估方法。实验结果显示，表现最佳的基线在安全任务上的成功率为 69%，但在危险任务上的拒绝率仅为 5%，这表明存在显著的安全风险。更多详情和代码可在 https://github.com/shengyin1224/SafeAgentBench 查看。
>
> https://arxiv.org/abs/2412.13178

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2412.13178](https://arxiv.org/abs/2412.13178)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)