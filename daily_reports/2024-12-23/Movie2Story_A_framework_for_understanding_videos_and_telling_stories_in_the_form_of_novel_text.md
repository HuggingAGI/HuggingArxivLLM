# Movie2Story：一个用于理解视频并以新颖文本形式讲述故事的框架
发布时间：2024年12月19日


> Movie2Story: A framework for understanding videos and telling stories in the form of novel text
>
> 多模态视频到文本模型已取得显著进展，主要体现在对视频内容的简短描述生成上。但在生成融合视频与音频的丰富长文本描述方面，仍存在欠缺。本文引入了名为 M2S 的框架，旨在结合音频、视频和字符识别来生成新长度的文本。M2S 涵盖了用于视频长文本描述与理解、基于音频的情感、语速和字符对齐分析，以及基于视觉的字符识别对齐等模块。借助大型语言模型 GPT4o 整合多模态信息，M2S 在多模态文本生成领域表现出色。我们通过对比实验和人工评估，证实了 M2S 的有效性和准确性。此外，该模型框架具备良好的可扩展性，未来研究潜力巨大。
>
> https://arxiv.org/abs/2412.14965

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2412.14965](https://arxiv.org/abs/2412.14965)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)