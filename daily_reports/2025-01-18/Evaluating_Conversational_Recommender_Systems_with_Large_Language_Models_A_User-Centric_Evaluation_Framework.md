# 基于大型语言模型的对话推荐系统评估：用户中心评价框架
发布时间：2025年01月16日


> Evaluating Conversational Recommender Systems with Large Language Models: A User-Centric Evaluation Framework
>
> 对话推荐系统（CRS）结合了推荐与对话任务，其评估颇具挑战性。尽管已有研究从用户角度探讨了影响CRS交互满意度的因素，但相关评估指标仍较为匮乏。近期研究表明，LLMs能够与人类偏好对齐，并已推出多种基于LLM的文本质量评估方法。然而，LLMs在CRS评估中的应用尚不广泛。为填补这一研究空白并推动以用户为中心的CRS发展，本研究提出了一种基于LLM的自动化CRS评估框架，该框架结合了人机交互与心理学的研究成果，从对话行为、语言表达、推荐项目和响应内容四个维度对CRS进行评估。我们利用该框架对四种不同的CRS进行了评估。
>
> https://arxiv.org/abs/2501.09493

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2501.09493](https://arxiv.org/abs/2501.09493)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)