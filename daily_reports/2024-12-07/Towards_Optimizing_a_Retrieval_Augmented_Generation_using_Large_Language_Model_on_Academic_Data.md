# 朝着在学术数据上使用大型语言模型优化检索增强生成的方向发展
发布时间：2024年11月13日

`RAG`
> Towards Optimizing a Retrieval Augmented Generation using Large Language Model on Academic Data
>
> 鉴于许多组织将检索增强生成（RAG）纳入其运营的趋势日益增长，我们在特定领域的数据上评估 RAG，并在各种优化技术下测试最先进的模型。我们纳入了四种优化；多查询、子父检索器、集成检索器和上下文学习，以增强学术领域的功能和性能。我们专注于数据检索，特别是针对一所大型技术大学的各种学习项目。我们还引入了一种新颖的评估方法，即 RAG 混淆矩阵，旨在评估 RAG 框架内各种配置的有效性。通过探索开源（例如，Llama2、Mistral）和闭源（GPT-3.5 和 GPT-4）大型语言模型的集成，我们为特定领域中 RAG 框架的应用和优化提供了有价值的见解。我们的实验表明，在检索阶段包含多查询时性能显著提高。
>
> https://arxiv.org/abs/2411.08438

**如遇无法添加，请+ vx: iamxxn886**
<hr />


<hr />

- 论文原文: [https://arxiv.org/abs/2411.08438](https://arxiv.org/abs/2411.08438)
- 获取更多最新Arxiv论文更新: [https://github.com/HuggingAGI/HuggingArxiv](https://github.com/HuggingAGI/HuggingArxiv)!
- 加入社群，+v: iamxxn886
- 点击公众号菜单加入讨论
![](https://raw.githubusercontent.com/HuggingAGI/wx_assets/main/2024/07/31/1722434818326-94339e92-22f1-4472-9d27-fed232f70b5d.jpeg)