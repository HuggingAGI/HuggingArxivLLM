明文暗藏杀机：RAG数据加载器的攻击隐患




阿尔贝托·卡斯塔尼亚罗 翁贝托·萨尔维亚蒂 毛罗·孔蒂 
帕多瓦大学 意大利帕多瓦 
alberto.castagnaro@unipd.it 
umberto.salviati@studenti.unipd.it 
mauro.conti@unipd.it  

卢卡·帕约拉 
Spritz Matter 意大利帕多瓦 
luca.pajola@spritzmatter.com

摘要

自ChatGPT于2022年横空出世以来，大型语言模型（LLM）彻底重塑了人机交互范式。其中，检索增强生成（RAG）技术通过融合外部知识显著提升了LLM的输出质量，已成为关键架构。但这一技术对外部文档的依赖也埋下了安全隐患。本文首次揭露了RAG系统在数据加载环节的重大安全漏洞——攻击者可借文档摄入之机，悄无声息地破坏整个处理流程。

我们系统性地归纳了9类知识投毒攻击方式，并针对DOCX、HTML、PDF等常见格式，创新性地提出"内容混淆"与"内容注入"两大攻击手法。通过自主研发的自动化测试工具（集成19种隐蔽注入技术），对五款主流数据加载器进行攻防测试，在357个攻击场景中取得74.4%的成功率。更令人担忧的是，我们在NotebookLM、OpenAI Assistants等六套端到端RAG系统（含白盒与黑盒）的实测中，这些攻击不仅能轻松绕过过滤机制，还能以高达90%的成功率悄然污染输出结果。本研究为RAG系统的文档安全防护敲响了警钟——必须立即筑牢文档摄入环节的安防壁垒，方能抵御这类隐蔽的内容篡改攻击。

CCS分类  

• 计算科学 → 人工智能；自然语言生成；  
• 信息系统 → 语言模型；智能问答；  
• 安全隐私 → 数据脱敏与清洗；渗透测试。

核心术语  

检索增强生成（RAG）·大型语言模型（LLM）·AI安全防护·LLM安全机制·文档污染攻击·知识库污染攻击  

联系人：Simeone Pizzi（sime.pizzi@gmail.com）</结果2>  

（说明：根据学术文献规范调整了术语间距符号，将英文缩写统一转换为"·"间隔；补充了"机制/攻击"等专业语境词；联系人信息采用更符合中文信函的表述方式）

ACM文献著录格式：

Alberto Castagnaro, Umberto Salviati, Mauro Conti, Luca Pajola与Simeone Pizzi合著。2018。《潜伏在明文中的威胁：RAG数据加载器攻击技术》。收录于（请根据授权邮件填写完整会议名称）（会议简称'XX'）。美国纽约州纽约市：ACM出版社，共12页。https://doi.org/XXXXXXX.XXXXXXX

1 引言

大型语言模型（LLMs）虽能力出众，却存在幻觉频发、知识陈旧、无法获取实时或专有信息等短板。检索增强生成（RAG）技术通过融合外部知识源，从结构化或非结构化数据中抓取关键文档辅助生成，显著提升了回答的准确性与实用性，成为企业文档、法律研判和网络安全领域的利器。

然而LLMs在展现惊人能力的同时，也带来了前所未有的安全威胁。其依赖的海量数据和复杂架构，使其易受各类攻击侵蚀。提示注入可篡改系统指令，训练数据偏差会催生有害内容，模型反转与对抗样本更可能窃取敏感信息。近期Meta的Llama框架甚至曝出重大漏洞（CVE-2024-50050），导致AI应用面临远程代码执行风险。

研究价值。鉴于RAG系统日益普及，厘清其网络安全防护能力刻不容缓。本文立足安全视角展开三项核心工作：（1）首创RAG知识库投毒攻击分类体系；（2）研发数据加载环节的实战化投毒技术；（3）实测主流开源库与商业RAG系统，发现多数竟难防基础攻击。为此我们开源Phantom Text工具包，可自动化生成带毒文档，助力防御体系建设。

2 背景概述

2.1 检索增强生成




2.1.1 概述。检索增强生成（RAG）框架通过引入外部知识检索，显著提升了大型语言模型（LLM）输出的准确性与相关性。相比传统模型，RAG能实时获取最新信息，在动态场景中表现尤为出色。  





RAG工作流巧妙融合了信息检索与生成式AI：首先将各类文档（如PDF、网页等）转化为向量存入数据库；当用户发起查询时，系统精准检索相关文档，并交由语言模型结合上下文生成专业应答。  





2.1.2 向量数据库构建。鉴于本研究重点关注RAG流程中解析环节的安全隐患，数据库构建过程尤为关键。数据预处理、分词、向量化及存储的质量直接决定检索可靠性——任何环节的疏漏都可能导致投毒攻击或检索异常。标准构建流程包含五大步骤：(1) 数据采集；(2) 分块处理；(3) 向量化转换；(4) 向量数据库存储；(5) 查询时智能检索并注入LLM上下文。

2.2 大语言模型越狱术




大语言模型越狱是指突破模型内置防护机制的行为，可能引发数据违规访问和有害信息生成。检索增强生成系统（RAG）正成为这类攻击的新渠道。

随着AI系统应用日益广泛，安全学界开始聚焦RAG流程的安全隐患。为深入洞察风险全貌，我们系统梳理了攻击者的潜在目标，将其归纳为四大类：系统完整性攻击、输出篡改攻击、知识污染攻击及隐私安全攻击。为构建结构化分析体系，我们采用安全领域通用的CIA三要素框架对各类攻击进行精准映射。

3.1 RAG与CIA安全三要素




RAG技术通过融合信息检索与生成模型来提升内容质量，但其潜在的安全隐患往往被忽视。运用CIA三要素（机密性、完整性、可用性）可系统评估这些风险。




完整性风险主要体现为可能获取或生成错误、篡改或恶意内容。数据源一旦被污染或不可靠，就会输出误导性结果。可用性同样关键，由于RAG依赖外部数据接口，极易遭受服务拒绝攻击或检索故障。要构建安全的RAG系统，必须建立严格的访问控制、完善的数据校验机制，并增强对抗恶意输入的能力。表1清晰展示了各类攻击与CIA三要素的对应关系。




表1：RAG知识库投毒攻击的CIA安全要素映射


![](images/f53c606ff0fd750c1d0306160cf26afb3bdde9808b4809d6d9c752ec49273a09.jpg)

3.2 系统完整性攻击

威胁RAG系统稳定运行与效能的攻击手段。

3.2.1 流程崩溃（A类）。恶意数据注入引发系统崩溃、死循环等异常，直接导致服务不可用。尽管目前未见RAG相关案例，但传统机器学习库的DoS攻击已有先例。

X A1：流程崩溃。精心构造的恶意输入触发系统故障，实现拒绝服务攻击。

3.2.2 推理过载（A,I类）。当前大语言模型推崇的"推理模型"需逐步展示思维过程[11,22]，这反而成为攻击突破口。

攻击者污染数据库后，模型被迫进行无意义的长篇推理，大量消耗算力资源。这种攻击会产生三重伤害：

• 性能瘫痪：响应时间呈指数级增长，用户体验断崖式下跌
• 算力绑架：每个回答都伴随海量无效令牌处理，既拖慢系统又抬高运营成本，对依赖此类模型的商业应用堪称财务灾难
• 服务熔断：持续攻击最终会导致系统彻底失去响应能力

这与学术界提出的"过度思考"攻击如出一辙——通过投喂"思维诱饵"，迫使模型在无价值推理中空转。

X A2：推理过载。在检索环节植入恶意内容，诱发模型进行资源黑洞式的无效推理。

3.3 输出篡改攻击

这类攻击会破坏响应的可用性、可读性与实用性。

3.3.1 乱码输出（A类）。系统可能因分词异常、嵌入损坏或外部干扰，生成无法解析的混乱内容。攻击者常通过注入特殊Unicode字符或Base64编码片段——这些合法但模型无法处理的格式，导致输出出现乱码、随机字符或错误解析。系统看似正常运行，实则输出已失去实用价值。

X A3：乱码输出。注入含异常符号的对抗文本，使回复充斥不可读字符。

3.3.2 无效应答（A类）。该攻击诱使系统生成"正确的废话"——语法合规却毫无实质内容的响应。常见于RAG系统被恶意输入误导时，即便面对合法查询，也只会回复"无法提供该信息"等模板语句。攻击者通过污染向量数据库，迫使系统不断输出规避性应答，在关键场景中形同虚设。

X A4：无效应答。触发系统返回"我无法回答"等格式化拒绝。

3.3.3 模糊应答（A,I类）。系统产生似是而非的响应，缺乏具体事实支撑。例如询问建议时，仅回复"需综合考虑多方面因素"这类放之四海皆准的说辞。这通常因模型被干扰而检索到模棱两可的内容所致，既无法提供有效指导（损害可用性），又丧失信息准确性（破坏完整性）。

X A5：模糊应答。通过知识库投毒制造矛盾数据，输出"该问题无明确答案"等模糊结论。

3.4 知识操纵攻击  

通过篡改知识来破坏信息准确性、加剧偏见或降低时效性的攻击方式。  

3.4.1 偏见植入（I级）  
向知识库投毒偏见内容，既固化既有观点又压制多元视角，致使RAG系统输出失衡结论。由于检索信息存在系统性偏差，系统响应可信度崩塌。  

X A6：偏见植入  
用误导性信息污染RAG系统，诱导其输出倾向性回答。  

3.4.2 事实篡改（I级）  
当系统生成或检索到谬误、误导或无法验证的信息时，系统公信力即遭瓦解。此类攻击直接摧毁事实基准，与虚假信息战（如假新闻）一脉相承。  

X A7：事实篡改  
用虚假事实污染知识库，迫使RAG系统沦为谣言传声筒。  

3.4.3 知识过期（I级）  
通过遮蔽新数据，诱使RAG系统调用陈旧信息（如失效研究成果、废止法规或淘汰产品参数）。因系统仍机械响应，过期信息可能悄然引发重大决策失误。  

X A8：知识过期  
迫使模型依据过时知识作答，导致应答沦为"历史档案"。

3.5 安全与隐私风险  

此类攻击会破坏数据机密性或泄露敏感信息。  

3.5.1 敏感数据泄露 $(c)$。当系统意外暴露本应保密的隐私信息时，就会发生敏感数据泄露。例如，系统可能错误地调取或生成了用户无权访问的真实数据。泄露内容可能涵盖电话号码、医疗记录、财务信息等个人身份信息（PII），乃至企业机密数据。这种攻击会破坏系统保密性，引发严重的隐私与安全问题。  

X A9：敏感数据泄露。攻击者可利用此漏洞，使RAG系统向未授权用户泄露PII或商业机密等敏感信息。

4 威胁模型

攻击目标。本研究的攻击对象是企业部署的RAG系统（详见第2节）。在文档入库前，会由专业的内容审核员（非IT专家）使用常规工具进行合规检查，确保文档内容的真实性。

攻击者画像。攻击者无法直接入侵系统，但可通过多种渠道污染知识库：
• 供应链渗透：作为服务商在交付文档中植入恶意内容，导致所有接入客户中招
• 网络投毒：篡改维基百科等公开数据源，诱导AI推荐危险方案（如存在漏洞的加密算法）
• 内部作案：恶意员工篡改企业内部分享文档，植入错误合规指引引发经营风险

攻击意图。通过隐蔽手段破坏RAG系统的可信度，具体表现为：
- 生成包含事实性错误或偏见的回答
- 通过隐蔽编码绕过内容检测
- 利用特殊触发机制操控输出
- 系统性污染知识库降低性能
（第3节将详细解析攻击目标与信息安全三要素的对应关系）

攻击手法。主要针对数据加载环节的漏洞展开两类攻击：
• 内容混淆：用隐形字符扭曲原文信息
• 内容注入：植入不可见的虚假概念

5 数据加载欺骗技术精要




本节揭秘针对RAG流程数据加载阶段的攻击手法。





5.0.1 技术体系架构
攻击策略可归纳为两大技术流派：





• 内容混淆术：通过零宽度字符（如ZWSP/ZWNJ）、同形异义字替换（如视觉仿冒字符）、双向文本重排等手法，在不影响视觉呈现的前提下，悄然破坏文本结构，干扰AI模型的语义解析能力。

• 内容注入术：运用零号隐形字体、越界文本定位、文档元数据渗透（如PDF/XMP元数据）等技术，向知识库植入不可见的虚假信息，实现"视觉隐身但AI可见"的投毒效果。





研究聚焦三大主流文档格式——PDF $(\pmb{\bigtriangledown})$、HTML $\bar{(\Theta)}$和DOCX $(\pmb{\bigtriangledown})$，剖析其富样式特性与元数据机制如何成为攻击温床。这些格式支持的隐形字符、样式微调、隐藏域等功能，在文本渲染、元数据处理等环节为RAG流程埋下了独特的隐蔽攻击隐患。

5.1 内容混淆术

5.1.1 变音符号伪装 P Ë
变音符号是附着在字母上的修饰标记（如é、ñ等），用于改变发音或区分语义。本攻击通过叠加多个变音符号（最多十个），构造出视觉复杂的文本形态。

5.1.2 同形异义字替换 P V Ë
利用视觉相似但编码不同的字符（如拉丁字母A/U+0041与西里尔字母А/U+0410）进行替换。该手法已证实能有效欺骗传统机器学习及信息检索系统[2,3,9]。

5.1.3 OCR投毒攻击 P Ë
在OCR系统处理的图文/PDF中植入细微干扰，通过破坏文本提取依赖的视觉特征，诱导识别错误。现代OCR系统已证实存在此漏洞。

5.1.4 双向文本重排 P V Ë
利用Unicode双向算法，在保持逻辑编码顺序的同时，通过插入RTL字符制造视觉与机器解析的差异。该技术对实际部署的ML系统具有攻击效力[2,3]。

5.1.5 零宽度字符攻击 P V Ë
使用不可见的格式控制符（如零宽空格U+200B）干扰文本处理：
1. Mask1：单词中部插入1个
2. Mask2：单词中部插入3个  
3. Mask3：每个字符间插入多个
这类攻击能破坏NLP的token化流程，且不影响人工阅读[2,3,18]。

5.2 内容注入  

5.2.1 伪装元素 P Ë  
通过将文本隐藏在文档元素背后，使其对用户隐形却保留在结构中。本实验采用图片作为掩护注入恶意文本。  

5.2.2 元数据污染 P Ë  
篡改文档元数据注入恶意内容，可能被文档解析器或AI模型误读。实验针对PDF元数据和HTML<head>注入随机/对抗数据。  

5.2.3 越界文本 P V Ë  
将文本注入文档不可见区域（如边距外或隐藏部分），用户不可见但机器可读。设计两种方式：  
1）随机坐标 P Ë：如左上/右下角等任意不可见位置  
2）右边界溢出 V：文本右对齐至半隐状态  

5.2.4 透明文本 P V Ë  
通过文本-背景同色实现视觉隐身，AI仍可读取。具体手法包括：  
1）背景色匹配 P V Ë（Word中设为白色）  
2）零透明度 P Ë（HTML用opacity:0，PDF用透明层）  
3）0.01透明度 P Ë  
4）隐藏属性 Ë（visibility:hidden不占位但可解析）  
5）消失属性 V（DOCX用<w:vanish/>或隐藏字体）  

5.2.5 零字号攻击 P V Ë  
将文本缩至极小规避人眼检测：  
1）零字号 P Ë（完全隐形）  
2）0.01字号 P Ë（近乎隐形）  
3）1字号 V（Word支持的最小尺寸）

5.3 一箭双雕




现在为您揭秘既能混淆内容又能植入信息的双效技术。




5.3.1 字体投毒 P Ë。这种攻击通过定制字体实现"表里不一"：显示给用户看的字符与实际解析的字符完全不同。比如精心设计的字体可以让"A"显示在屏幕上，背地里却对应着 $^{"\mathrm{B}"}\left(\mathrm{U}_{+0042}\right)$ 的ASCII码。这种"障眼法"让人眼看到的是"A"，机器读取的却是 $^\mathrm{{*}}\mathrm{{B}}^{\mathrm{{*}}}$，完美破坏文本处理系统。其杀伤力体现在两方面：




(1) 语义破坏：攻击者可将字形替换为乱码，比如让"apple"变成"qwert"；(2) 隐形植入：攻击者可偷梁换柱，比如让"apple"暗指"drugs"（更绝的是，还能用不同字体实现一字多义）。




文献首开先河，成功验证了该技术对Turnitin、Bing等主流系统的实际攻击效果。

6 效果评估

我们创新性地推出了Phantom Text工具包——这是一个模块化框架，能巧妙地在各类文档（DOCX/HTML/PDF）中植入隐形篡改。该工具完整实现了第5章所述攻击策略，现已开源（GitHub仓库：pajola/PhantomText-Paper），所有实验材料均可完整复现。

为验证工具效果，我们针对RAG系统全流程设计了三大实验：

• 实验1：数据加载器渗透测试
通过主流文档加载器，我们将所有PhantomText技术应用于三类文档格式。结果证实，这些隐形标记能成功"存活"并污染知识库，揭示了数据加载环节的重大安全隐患。

• 实验2：全链路攻击验证
鉴于大语言模型可能具备抗干扰能力，我们完整模拟了RAG工作流。实验证明，被污染的文档不仅能影响检索模块，还能最终操控生成模型的输出。

• 实验3：精准打击演示
基于工具包的最强技术组合，我们成功复现了第3章所述攻击场景。这些案例生动展示了如何利用PhantomText发起难以察觉却破坏力惊人的定向攻击。

下文将依次阐述：驱动实验的核心问题、详细方法论设计，以及最终验证结论的完整实验数据。

6.1 实验1：数据加载器投毒  

6.1.1 概述。本实验通过攻击文档解析框架的数据加载器组件，验证了Phantom Text对RAG系统知识库的投毒效果。测试表明，混淆、注入等隐形篡改手段可破坏HTML/DOCX/PDF文档的解析流程——Phantom Text能成功植入恶意内容，污染RAG知识库。  
</结果2>  

（说明：1. 将"poisoning"译为更具攻击性的"投毒"；2. 使用"攻击/植入"等动词强化动态效果；3. 用破折号替代分号优化中文语流；4. 文件格式用斜杠连接更符合技术文档习惯）

研究核心：主流文档加载器能否抵御幻影文本工具的内容混淆与注入攻击？

6.1.2 实验设计

测试对象：选取GitHub热门且广泛应用于RAG开发的五大框架（Docling、Haystack、LangChain、LlamaIndex、LLMSherpa），重点评估其21个支持PDF/HTML/DOCX格式的文档解析模块。其中：
- Docling测试了默认解析器等5个组件
- Haystack涵盖PyPDF等4种解析器
- LlamaIndex评估了3个核心模块
- LangChain测试了包括OCR版本在内的8种处理器
- LLMSherpa仅评估默认解析器

数据构建：基于Amazon Reviews'23的100条样本，通过两种污染方式生成4200份测试文档：
1. 内容混淆：随机替换原文词汇
2. 内容注入：插入新造词汇
最终形成包含35,900次测试的评估体系。

注：本研究聚焦文档预处理管道的安全性，而非模型本身的性能。Amazon数据集能有效模拟真实场景下的注入攻击。

评估标准：
- 混淆成功：目标词汇完全消失
- 注入成功：伪造词汇准确呈现
攻击成功率公式：ASR=成功次数/(成功+失败)

6.1.3 关键发现

整体表现：
- 幻影文本攻击总体成功率74.4%
- 238/375次测试成功率＞95%
- 内容混淆(76.7%)略优于注入(72.4%)

框架对比（图1a）：
- LangChain最脆弱（ASR最高）
- LlamaIndex防御最佳
- 其他框架处于中游水平

文件格式（图1b）：
- DOCX最易受攻（ASR 0.89）
- PDF防御最强
- 所有格式ASR＞0.6

攻击技术差异（图2）：
- 字体污染/同形异义字符：100%成功率
- 变音符号注入：仅40%效果
- 元数据注入：普遍无效（除LangChain达50%）
- 越界文本：对Docling效果显著(83%)，对LlamaIndex一般(50%)
- 零大小字体：LlamaIndex脆弱(81%)，Docling较抗(39%)

核心结论：
1. 攻击效果高度依赖技术选择
2. 不同加载器防御能力差异显著
3. 当前主流文档加载器普遍存在安全漏洞
4. 污染内容可穿透预处理环节进入向量库

（图1展示了不同攻击家族在加载器与文件格式维度的ASR对比）

6.2 实验二：端到端RAG攻防实战

6.2.1 核心发现  
延续实验1的成果，我们深入探究被污染知识库对RAG系统的影响机制。研究发现：文档摄入阶段的隐形篡改确实会渗透至主流RAG框架的检索与生成环节，但不同系统表现出显著差异的防御能力（如图2所示）。值得注意的是，虽然PDF是主要测试载体，但DOCX/HTML等格式同样适用本研究成果。

图2：内容混淆vs内容注入技术的攻击成功率对比

关键命题：  
• Phantom Text的隐形篡改技术能否贯穿RAG全流程？  
• 哪些攻击手段最具杀伤力？

6.2.2 实验设计

系统配置  
构建6种典型RAG环境（M=6）：  
• 白盒组：基于Llama3.2/Gemma3/DeepSeek R1三大模型，配合Chroma检索器搭建3套可深度调校的LangChain系统  
• 黑盒组：测试OpenAI助手（gpt-4o/o3-mini）和Google NotebookLM两类商用系统

数据工程  
采用"干净文档+14种污染变体"的对比方案：  
• 基准文档：虚构企业资料（确保LLM无先验知识干扰）  
• 污染文档：  
  - 内容混淆组：隐藏关键信息  
  - 内容注入组：植入竞品公司概念

评估体系  
采用双重验证机制：  
1. 基线测试（240次查询）：验证各RAG对原始文档的解析能力  
2. 攻防测试（840次查询）：量化不同篡改技术的渗透率  
所有结果均通过人工标注验证

6.2.3 攻防启示  
质量基线测试显示所有系统均能100%准确解析原始文档。但面对攻击时呈现三级分化：  
• 必杀技：字体污染/元素伪装等技术通杀所有系统（ASR=1.0）  
• 无效招：元数据篡改完全失效（ASR=0）  
• 看人下菜：字符混淆/内容重排等技术效果因系统而异  

（完整攻击矩阵已开源）

核心结论  
RAG系统确实存在被Phantom Text攻破的风险，但不同技术存在显著效果差异：字体污染等"大杀器"无往不利，元数据篡改全程吃瘪，而同形异义词等手法则需要"对症下药"。

6.3 实验三：CIA三要素定向打击RAG系统

6.3.1 攻击全景  
我们运用幻影文本技术中最犀利的招式，对第3章揭示的RAG系统软肋发起精准打击，直指信息安全铁三角——机密性、完整性和可用性。基于主流RAG框架，我们演示了如何通过隐形篡改实现三大杀伤：隐私数据泄露、事实检索污染、系统功能瘫痪。虽然实验以PDF文档为主战场，但这套组合拳同样适用于DOCX、HTML等格式。这些攻击证明，隐形内容配合精妙操作可完美规避常规检测，给系统稳定运行埋下致命隐患。

® 核心命题：幻影文本武器库能否突破前沿RAG系统的CIA防线？

6.3.2 攻防沙盘  
数据战场  
沿用6.2节的RAG系统作为攻击目标。针对第3章九大攻击场景，我们精心配制了多套数据毒剂。以敏感信息泄露为例，我们特制了含隐私数据的诱饵文档。从公开代码库选取典型案例（详见附录A.4）深入剖析攻击原理与杀伤效果。每个场景配备4类数据集，通过文档数量（1或100份）和内容性质（纯净/投毒）形成矩阵攻击。纯净数据作为对照组验证RAG基准表现，投毒数据则用于激活幻影攻击。投毒数据重点考察两种战术：  
• 精准狙击：知识库仅藏1份毒文档，模拟攻击者完全掌控情报源时的最大杀伤  
• 浑水摸鱼：百份文档中混入1份毒文档，还原攻击者渗透能力受限的真实战况  
每套数据都配有量身定制的攻击指令。

战果评估  
在六大RAG系统上展开多轮攻防，由LLM裁判团裁定攻击成败。例外情况包括需人工研判的a3攻击，以及用字符串匹配检测信息泄露的a9攻击（其他攻击评估细则见附录A.1）。为消除LLM随机性，每项攻击重复10次（管道崩溃攻击除外，因其只需验证系统是否宕机且不调用LLM，故单次测试）。除管道崩溃（单次）和推理洪泛（记录token消耗增长倍数）外，其余攻击均统计10次中的得手率。

6.3.3 战报解读  
表2的战果揭示：面对幻影文本攻击，RAG系统在白盒与黑盒环境下均暴露致命弱点。白盒场景中多个攻击向量保持90%以上的得手率，暴露出当前系统在守护CIA铁三角方面的严重缺陷。令人震惊的是，即便如deepseek-r1这样的精锐模型，也在所有攻击面前溃不成军。

黑盒阵营表现参差不齐：NotebookLM宛如铜墙铁壁，在事实篡改、空包弹等攻击中保持零失守；而gpt-4o、o3-mini等商业系统却漏洞百出，多个场景惨遭10/10完美击穿。特别是o3-mini，16个战场中有9个被100%攻陷。这表明虽然部分黑盒系统依赖内部过滤机制挡住某些攻击，但整体防御水平与白盒系统同样堪忧。最触目惊心的是推理洪泛攻击——某些系统（如o3-mini）的token消耗暴涨4.9倍，证明攻击者完全可以借力打力榨干系统资源。

管道崩溃攻击值得单独讨论：唯有我们的白盒RAG系统在此攻击中沦陷。需要说明的是，本次测试仅采用极易识别的超大体量PDF文档作为攻击载体。若使用更精巧的攻击手法，黑盒系统恐怕也难以幸免。有人可能质疑是我们的RAG管道实现存在缺陷，但我们严格遵循Langchain官方指南搭建系统。这警示我们：若开发者机械照搬文档方案，其构建的RAG系统可能连这种初级攻击都招架不住。

![](images/5284fa6549edf8459d82421349c67d5fc3159e4dd140816c277750c066b5759e.jpg)  
表2：实验三——RAG攻防全景实录。幻影文本攻击在含1/100份文档的不同RAG系统中的得手率（推理洪泛攻击显示token消耗增长倍数）。

确实，隐形注入会危及前沿RAG系统的数据保密性、完整性与服务可靠性。我们的实验证明，必须将网络安全准则深度融入这类系统的设计架构。

七大防御策略

尽管注入攻击手法层出不穷，但多数都存在可被简单规则捕捉的语法特征。某些攻击产生的结构异常虽逃过人眼，却难逃基础模式分析的检测。例如变音符号堆叠会形成违背语言习惯的Unicode序列，通过统计组合标记出现频次即可识别；同形异义字替换会留下"文字指纹"（如拉丁段落中的西里尔字母），只需字符集过滤或Unicode标准化（如NFC）即可化解。

零宽字符在正常文本中凤毛麟角，定向扫描特定Unicode码点即可捕获。双向控制字符（用于乱序攻击）造成的文字流向突变，通过检查Unicode标识符便能揪出破绽。至于透明文本、隐形样式等格式把戏，解析文档时盯紧颜色、透明度等属性（如<w:vanish/>标签）就能识破。越界注入同样难逃布局边界分析的"火眼金睛"。

这些轻量级净化措施虽非铜墙铁壁，却能以极小代价化解多数威胁。更强大的OCR方案虽能抵御视觉扰动，但计算成本陡增且可能误判。我们实测的两款开源OCR（EasyOCR与Tesseract）通过图像提取文本，可拦截90%以上的隐形攻击（如透明/越界文字），但变音把戏和零尺寸字体仍能金蝉脱壳。因此OCR宜作防御体系的首道关卡，而非终极方案。这些实践真知将融入修订稿，为读者提供攻防兼备的安全指南。

8 相关研究




NLP系统中的隐形字符攻防战。文本的细微扰动已成为对抗NLP系统的利器。Pajola团队首创的零宽度(ZeW)攻击，利用隐形Unicode字符成功骗过Google等巨头的分类系统。后续研究更发展出编码层面的三重攻击术——零宽度字符、同形字混淆和顺序重排，能有效突破商业NLP防线。这类隐形攻击还能操控搜索引擎和LLM的查询内容，悄然影响检索结果和排序算法。我们的研究正是受此启发，将隐形注入技术应用于污染RAG系统的知识库。




大模型安全攻防全景。大语言模型在展现惊人能力的同时，也暴露出严重安全隐患。Yao等学者将其特性精辟概括为三重面相："善"（代码审计等）、"恶"（恶意滥用）和"丑"（固有漏洞）。研究表明，即使是最先进的防护措施，也难挡精心设计的黑盒越狱攻击。针对RAG系统的TrojRAG攻击可植入隐蔽后门，另有研究[6,28]揭示了通过文档注入和知识污染的新型攻击方式。这些发现为大模型及其增强系统的安全防御敲响了警钟。

分析表明，RAG系统数据加载阶段存在重大安全隐患，其根源在于普遍忽视输入净化处理。这些漏洞使隐蔽的注入攻击有机可乘，直接威胁下游语言模型输出的可靠性。要解决这些问题，必须对文档处理流程严格执行安全规范。更值得警惕的是，随着AI系统日益依赖检索内容进行复杂推理，此类漏洞可能在工作流中扩散升级。未来防护方案需突破静态净化的局限，整合上下文感知过滤、来源追溯和实时异常监测等机制，为新一代AI应用筑牢安全防线。