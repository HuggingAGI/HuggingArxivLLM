智能体协同网络：多智能体大语言模型中的协调与推理




弗洛里安·格勒奇拉∗† 路易斯·穆勒∗ 扬·通斯霍夫∗ 
苏黎世联邦理工学院 | 亚琛工业大学 | 亚琛工业大学 
米哈伊尔·加尔金 | 谷歌研究院  
布莱恩·佩罗齐 | 谷歌研究院

摘要

大型语言模型（LLM）展现出惊人的问题解决能力，尤其当它们组成多智能体系统时。然而，这类系统的兴起也引发了关键问题：复杂的智能体网络能否高效自组织与协同合作？传统基准测试虽能衡量多智能体系统的推理能力，却难以评估其拓扑结构的利用效率。为此，我们推出全新基准AGENTSNET——它从分布式系统与图论的经典问题中汲取灵感，专门测试多智能体系统在特定网络结构下实现策略协同、自主组织与高效沟通的能力。我们测试了多种基线方案，包括需要先达成组织与通信协议的同构网络。结果显示，前沿LLM在小规模网络中表现优异，但随着网络扩张性能逐渐下滑。现有基准最多支持2-5个智能体，而AGENTSNET具备无限扩展性，可适配新一代LLM的发展。我们甚至成功测试了包含100个智能体的超大规模实验场景。

1 引言

人类文明因协作而生生不息，语言作为沟通的桥梁，让个体得以携手实现共同目标。无论是小型团队还是庞大组织，高效沟通都能催生结构化决策、问题解决以及超越个体极限的集体智慧。这种协作与沟通的共生关系，在计算领域同样得到印证——分布式系统通过结构化信息交换，攻克单机无法处理的难题。正如心理学探索个体思维、社会学研究群体行为，分布式系统领域则聚焦于突破单机极限的多智能体协同。

近年来，基于大语言与视觉模型（LLMs）的通用多智能体系统异军突起，让分布式计算在AI领域大放异彩。生成式智能体等框架已证明，基于LLM的智能体具备解决复杂问题的潜力。研究表明，LLM智能体网络的表现可超越单智能体[9,38,53,29]，这与人类团队协作原理不谋而合。例如GPTSwarm受语言心智社会启发，采用图结构组织LLM智能体，使其在MMLU、HumanEval等基准测试中表现更优。然而现有评测体系仍存在盲区：未能系统评估多智能体系统的核心能力——可扩展协同、去中心化通信与协作推理。为此，我们推出AGENTSNET基准测试，通过多样化网络结构与规模，科学量化这些关键能力。

AGENTSNET从分布式计算经典问题切入，评估智能体的协同效能。我们精选五大核心问题构建测试任务，解决方案可能涉及本地信息聚合或多轮全局协调。典型如共识问题——多智能体系统必须就解决方案达成一致；又如领导者选举——先推举领袖再在其指导下完成任务。这些经过充分理论验证的问题，为评估多智能体协同能力提供了理想试金石。

现有基准测试虽多，却鲜少关注结构化协同这一分布式系统的核心能力。AGENTSNET独树一帜，立足分布式系统理论，兼顾网络拓扑与扩展性，填补了这一空白。我们的核心贡献包括：

1. 基于图着色、最小顶点覆盖等五大分布式计算难题构建AGENTSNET，全面检验智能体在自组织、协同通信等方面的表现

2. 设计可扩展的消息传递协议，并采用小世界网络等多样化图结构进行测试，确保贴近现实场景

3. 评测范围涵盖Llama 4等开源模型到GPT-4等前沿系统，测试规模最高达100智能体，远超现有基准

4. 通过深度定性分析，揭示LLM在协同能力上的瓶颈，为改进指明方向

图1：模型性能与API成本关系（2025.5.15数据），金色星标为帕累托最优模型

图2：三智能体在简化拓扑中的通信示例（完整对话分析见附录E）

2 研究背景

协同多个智能体进行协商决策，已成为提升大语言模型处理复杂任务效能的重要途径[13,46,24]。学者们进一步探索了不同网络拓扑结构，以优化智能体间的协作交互：既有研究采用预设图结构[39,38]，也有学者提出自适应拓扑方法[27,9,53]。实验显示，特定任务需要匹配最佳拓扑[9,53]，且大规模智能体网络会呈现典型社会现象[48,12]。另一研究方向聚焦LLM的图数据推理能力，相关成果包括：单智能体图文本编码评估体系[15,44,51,43,42]，其中Fatemi团队专研图编码，Sanford等人按难度分级图推理问题，Wang与Skianis团队则深耕提示技术。本研究创新性地融合上述方向，构建多智能体协同图推理系统。我们的测试框架既兼容最新智能体基准[26,50,1,49,33]，又借助问题生成协议实现智能体规模的无限扩展（实验达100个）。值得关注的是，社交网络去中心化求解的人类研究证实，拓扑结构与规模是协调成败的关键[22,21,11]（详见附录F扩展讨论）。

为检验多智能体系统的自组织、协同与高效沟通能力，我们构建了一个基于分布式计算核心问题的测试基准。这些问题复杂度各异，既有仅需简单协同的本地任务，也包含需多轮交互的全局性问题。下文将阐述这些理论问题，并说明如何将其转化为对应的智能体任务，最后介绍AGENTS NET中采用的图模型分布。

3.1 基准测试任务

我们通过一系列分布式计算问题评估多智能体系统，测试其信息整合、自组织和协同能力。这些任务既体现了分布式计算的基础特性，又是复杂任务中常见的子问题原型。从局部信息交换到全局决策，它们覆盖了多样化的协同需求和通信复杂度（详见表1对AGENTSNET所选理论任务的概述）。

图3：AGENTSNET任务总览
- 领导者选举：推举单一智能体作为网络核心
- 共识协议：全体智能体对二元值（0/1）达成一致
- 最大匹配：实现无冲突的智能体两两配对
- 节点着色：确保相邻智能体不同组（颜色）
- 最小顶点覆盖：构建最精简的协调者网络覆盖

$(\Delta+1)$着色问题：在最大度数为$\Delta$的图中，用不超过$\Delta+1$种颜色为节点着色。该问题在有界度图中具有$O(\log^{*}n)$的分布式复杂度。该任务特别适用于多智能体系统的角色分配——例如为相邻智能体分配不同功能（网络搜索/推理/编程等），避免能力冗余。对应的智能体任务要求：预定义分组数量，通过消息传递后各智能体自主选择组别，最终形成合法着色方案（AGENTSNET中称为COLORING）。

最小顶点覆盖：图中满足"每条边至少有一个端点属于该集合"的最小节点集。作为分布式计算的基础问题，其随机化解法可在$O(\log^{*}n)$轮完成。在智能体网络中，这对应构建最精简的监控网关体系，这些核心智能体负责消息中继、行为审计等关键职能。任务要求识别具有全局影响力的最小节点集，对应操作是：通过消息传递后，各智能体声明是否担任协调者，最终形成最小覆盖（VERTEXCOVER）。

最大匹配：构建无法再扩充的边集（无公共端点）。该任务检验智能体在缺乏全局信息时达成双边协议的能力，适用于资源分配等场景。典型随机算法复杂度为$O(\log^{*}n)$轮。操作流程：智能体通过消息传递后提名配对对象（若无匹配则声明None），最终形成最大匹配（MATCHING）。

领导者选举：确立唯一领导节点。这个经典任务评估智能体建立层级结构的能力，对应多智能体系统中的中央决策者选拔。一般网络需$O(D)$轮完成（D为网络直径）。实施方式：消息传递后各智能体声明领导身份，最终确认唯一领导者（LEADERELECTION）。

共识协议：全体智能体对二元值达成一致。基准测试中我们关注无故障场景，要求通过纯本地通信实现全局收敛，典型需要$\mathcal{O}(D)$轮。执行过程：各智能体在消息交换后公布选择值（0/1），全体一致即告完成（CONSENSUS）。

表1：AGENTSNET基础理论任务及其在随机LOCAL模型下的轮复杂度下界（可能非紧）

这些任务全面覆盖了分布式计算的核心问题谱系，能有效评估多智能体系统的推理、通信与组织能力。

3.2 网络拓扑结构




传统分布式计算常以Erd˝os-Renyi网络等随机图为研究对象，却难以准确刻画现实网络的结构特征。为此，我们重点研究三种经典网络模型：兼具短平均路径与高聚类特性的Watts-Strogatz小世界网络、存在枢纽节点且符合幂律分布的Barabási-Albert无标度网络，以及通过二维点集Delaunay三角剖分构建的几何网络（保持相邻智能体空间关联）。详见附录D中的模型详解。

4 智能体间的消息传递通信机制

为系统探究智能体间的信息交互与协作机制，我们借鉴经典分布式计算思想，结合现代LLM智能体的特性，设计了一套通信模型。该模型基于分布式算法中的LOCAL模型，采用同步轮次计算架构，限定每个智能体仅能与通信图中的直接相邻节点交换信息。所有决策完全依赖多轮本地交互积累的数据，完美诠释了去中心化推理的精髓——无需中央调控，仅通过局部交互即可涌现全局策略。与传统确定性系统节点不同，LLM智能体因生成过程的随机性而具有概率特征，这使得我们的模型更贴近随机化版本的LOCAL模型。

在具体实现中，通信网络的每个节点（即智能体）均由指令调优的LLM实例化，通过结构化聊天记录与邻接节点交互。初始化阶段，每个智能体会收到包含任务详情（如着色问题）、消息传递规则、邻居节点名称等信息的系统提示，并明确要求在固定轮次交互后提交最终响应（完整提示模板参见附录A）。下文将具体阐述任务定义、消息传递规范及最终响应生成规则。

任务定义模块为每个任务提供简明说明及预期输出要求。以领导者选举为例，其任务描述如下：

系统  

你们需要协同完成单一领导者的选举任务。[...] 系统将询问每位成员是否担任领导者，只需回答"是"或"否"。最终必须达成严格共识：仅有一位成员应答"是"，其余成员均应答"否"，确保领导者唯一性。  

注："[...]"表示任务说明会分段显示在系统提示中。  

消息传递机制。采用迭代式交互：每次向智能体展示包含邻居最新消息的完整对话记录，要求其生成扁平化JSON格式的邻居专属消息（键为邻居名称，值为消息内容）。可选开启思维链推导功能。示例如下：

人类  

邻居留言如下：  
Emma说：你好Evelyn，我是Emma。谢谢你的回复和[...]  
Dorothy说：[...]请先一步步梳理你的思路，再按既定JSON格式给邻居们回消息。  

实际应用中（尤其是小模型），我们发现智能体偶尔会生成无效的JSON。这时只需让模型带着完整对话记录（含之前出错的回答）和重试指令再试一次。  

最终阶段：经过数轮消息传递后，模型需基于对话记录生成任务响应。这次改用更简洁的字符串格式输出结构化结果。以LEADER ELECTION为例，最终提示模板为：

人类




你是负责人吗？请按格式回答：'### Final Answer ###'，并选择唯一正确答案：'是'或'否'。




实验表明，模型最多只需重试一次即可生成有效响应。最终测试结果将基于这些回答，并采用第3节所述的评估方法进行计算。

5 实验  

基于第3节构建的AGENTS NET核心模块和第4节设计的消息传递协议，我们正式展开基准测试并呈现实验结果。  

![](images/81864ea5c0f72dda294d60c7840a21484e684b67602d91234c464aa628e4df4c.jpg)  

表2：AGENTS NET系统在同一图分布（灰色）的多次独立采样中，问题实例的解决率及标准误差。Gemini $2.5\:\mathrm{FT}=$ Gemini 2.5闪存思维模式。

5.1 实验配置

我们构建了包含27种网络拓扑的测试集（9个小世界网络、9个无标度网络、9个Delaunay图），节点规模覆盖4至16个。具体生成规则为：在{4,8,16}节点规模下，对{小世界网络，无标度网络，Delaunay图}三类拓扑各生成三个实例。消息传递轮数设置如下：全局任务（领导选举和共识协议）要求智能体与全网通信，故轮数设为2D+1（D为图直径），确保节点对至少交互一次；局部任务（着色/匹配/顶点覆盖）则根据图规模设定固定轮数（4节点4轮，8节点5轮，16节点6轮）。

模型选型。测试涵盖多款前沿大模型：Claude 3.5 Haiku/3.7 Sonnet、Gemini 2.0 Flash/2.5 Flash、GPT-4.1-mini，以及开源代表Llama 4 Maverick/Scout。特别纳入Gemini 2.5 Flash Thinking、Gemini 2.5 Pro和o4-mini等推理模型。选型标准要求16K tokens以上的上下文窗口，以应对8/16节点图在消息传递后期产生的长通信历史。

评估体系。采用全有或全无的严格标准——仅当整个智能体网络完全满足任务要求时才计为成功。这契合分布式计算的本质特征：局部正确性往往无法保证全局协同。例如在图着色任务中，随机正确的局部着色不能证明协同避碰能力。附录B补充了软评估分数（受Schaeffer等启发），通过连续性指标捕捉涌现行为。

每个测试单元（任务+图规模）包含三种拓扑各三个实例，每个实例至少重复一次。最终结果取平均解决率与标准误差，统计方法详见附录C。

技术实现。基于LangChain开发消息传递协议（第4节方案），利用其多模型集成优势；图生成采用NetworkX*框架。系统支持灵活扩展新图类型、规模及大模型。项目已开源：代码库https://github.com/floriangroetschl/AgentsNet，数据集https://huggingface.co/datasets/disco-eth/AgentsNet。

图4：分任务分模型展示不同图规模（4/8/16节点）下的解决率。五个基准任务等权重分布（各占20%上限），推理模型与非推理模型分区呈现。该视图通过细粒度任务分析补充图1的整体表现。

5.2 智能体网络实验结果

表2展示了各任务的解决率。我们采纳Miller的建议，同时给出了结果的均值标准误差。图4呈现了不同图规模的细分表现，图1则对比了各模型在所有任务中的性能与API成本。研究发现：即便是4节点图，也没有模型能在所有任务中保持稳定优势——多数模型能轻松处理C ONSENSUS任务，却在V ERTEX C OVER任务（尤其是8/16节点时）表现欠佳。性能前三甲分别是Claude 3.7 Sonnet、Gemini 2.5 Pro和Gemini 2.5 Flash，其中后者以仅为Claude 3.7二十分之一的运行成本实现了相近效果。值得注意的是，模型性能普遍随图规模扩大而衰减。后续我们通过扩展图规模的消融实验，探索智能体网络能否随未来模型能力升级同步扩展。

5.3 智能体网络扩展

除核心发现外，我们在图5中展示了Gemini 2.0 Flash支持100个智能体网络的扩展测试结果：在AGENTSNET上既保持优异性能又兼顾成本效益。我们共构建了81种网络拓扑，采用$2D+1$轮消息传递（$D$为网络直径）这一经验法则。数据显示，随着网络规模扩大，各任务性能呈平稳下降趋势。虽然MATCHING和COLORING等任务在小规模网络中比CONSENSUS或LEADERELECTION更易完成，但当网络增至100个智能体时，所有任务成功率均趋近于零。这表明通过扩展网络规模，可循序渐进提升AGENTSNET挑战性——这一特性无需修改系统设计，因其原生支持任意规模的网络扩展。

5.4 定性分析




本文对不同大语言模型（LLM）的响应表现展开定性分析，深入探究其整体沟通能力、解题策略与协作特性。我们重点选取了在AGENTS NET测试中表现各异的代表模型——包括Llama Maverick、Gemini 2.5 Flash、Gemini $2.5\;\mathrm{Pr}\mathrm{o}$和o4-mini，对其对话转录数据进行深度解析。以下将呈现核心发现与典型示例，完整分析报告及更多对话片段详见附录E。主要研究发现如下：

发现1：策略协调是AGENTS NET的核心难题  

研究发现，智能体间的策略协调问题常导致任务失败：有时因策略共识达成过晚，剩余通信轮次不足；有时则因智能体全程默守初始策略，却未与邻居同步。  

发现2：智能体易轻信邻居信息  

智能体通常会采纳邻居传递的网络信息、策略建议或候选方案，但这一机制存在隐患——当面对错误的拓扑假设或无效策略时，缺乏质疑机制会导致系统性错误。  

发现3：智能体具备冲突调解能力  

在着色问题中，智能体展现出主动协调能力：能识别其他智能体间的颜色分配冲突并协助化解。附录E收录了详实的成功案例与典型失误。

6 局限性

我们在分布式计算的LOCAL模型基础上构建了AGENTSNET系统，采用同步消息传递机制。但值得探讨的是，在协同求解场景中，其他通信协议或许更具优势——比如同步机制会导致智能体必须等待下一轮通信才能获取响应。当前系统采用JSON解析应答的方式也存在语义模糊和容错性差的短板。需要强调的是，这些都属于实现层面的设计选择，而非框架本身的缺陷。例如未来采用更高效的通信协议或结构化输出†方案时，都能无缝融入AGENTSNET架构。更多技术细节详见附录G。

7 总结

本研究提出了A GENTS N ET——一个基于分布式计算核心问题的多智能体基准测试平台，用于评估智能体网络的协同问题解决能力。不同于现有仅支持2-5个智能体的测试框架，A GENTS N ET初始版本即可支持100个智能体的协同测试，且具备近乎无限的扩展能力，能持续生成更复杂的任务以匹配前沿模型的迭代演进。为此，我们开发了鲁棒的消息传递协议，支持智能体间的多轮交互，并在多种图模型生成的不同规模图实例上进行评估。测试表明，即便是最先进的LLM模型，在面对A GENTS N ET的挑战性任务时也表现出了明显的局限性。