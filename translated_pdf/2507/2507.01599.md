数据智能体：构建数据与AI生态系统的全局架构




孙兆岩，王佳怡，赵新阳，王家驰，李国梁 清华大学计算机科学系，北京 { liguoliang@tsinghua.edu.cn }

摘要

传统的数据+AI系统虽能通过数据驱动技术优化性能，但其流程编排仍高度依赖人工，以应对数据、查询、任务及环境的动态变化。尽管现有数据科学工具种类繁多，但构建能协调这些工具的流程规划系统仍面临挑战——根源在于当前系统在语义理解、推理与规划上的能力局限。值得庆幸的是，大型语言模型（LLM）已展现出增强这些核心能力的巨大潜力，将其融入数据系统以重塑数据+AI应用编排模式势在必行。

为此，我们提出"数据智能体"这一创新架构，通过整合知识理解、推理与规划能力，构建面向数据+AI生态的智能协调中枢。我们系统剖析了设计过程中的关键挑战：包括数据/查询/环境/工具的语义解析、流程/工作流的动态编排、执行优化与自我演进等。同时展示了数据科学智能体、多类型数据分析智能体（涵盖非结构化数据、语义结构化数据、数据湖及多模态场景）以及DBA智能体等典型应用案例，并指明了该领域亟待突破的研究方向。

1 引言

过去十年，数据库界为Data+AI领域立下汗马功劳。在AI赋能数据（AI4Data）方面，我们运用AI技术攻克了诸多难题：从离线NP难问题（如索引优化[2,3]、视图推荐）到在线挑战（如查询重写），从基数估计[10,11]等回归问题到学习型索引等数据结构创新。这些成果虽丰，却因过度依赖专家调参，难以及时适应数据环境的变化。

在数据赋能AI（Data4AI）方向，我们将数据库优化技术拓展至AI全生命周期，涵盖从数据清洗到模型管理等环节。但如何实现系统管线的智能编排，仍是悬而未决的难题。

图1揭示症结所在：现有技术缺乏语义理解与自主决策能力。而大语言模型(LLMs)恰能补此短板[22,23]。为此，我们开创性地提出"数据智能体"框架，通过三大核心能力重塑Data+AI生态：
• 知识理解
• 自动规划 
• 自我进化

并提炼出五大核心挑战：
1. 多模态理解（查询/数据/工具）
2. 异构数据桥梁构建
3. 智能体协同调度
4. 管线效能优化
5. 持续自我迭代

解决方案包含三大模块：
✓ 智能探索引擎
✓ 动态调度中枢
✓ 管线编排系统

实践层面，我们打造了三类标杆应用：
☆ 数据科学助手
☆ 分析智能体集群（含非结构化、结构化、数据湖方案）
☆ DBA智能管家[42,43]

本文贡献四重奏：
① 首创具备认知能力的数据智能体
② 提出端到端系统架构
③ 落地三大应用场景
④ 指明未来研究方向

图2揭示了数据智能体的成功要素。

2 数据智能体

数据智能体专为自主处理数据任务而设计，集知识理解、自动规划和自我反思于一体。

其核心架构需统筹六大要素（如图2所示）：

环境感知：智能体需实时感知数据生态，包括环境状态、任务需求、协作伙伴及工具资源。通过离线微调或预设提示模板实现精准对齐。

推理决策：既擅长拆解复杂任务为多级流程（规划），又能做出精准的单步判断（推理）。每个决策可能触发深度推理、二次规划，或调用专业工具获取领域知识。

工具调度：可灵活调用计算工具、领域数据库或环境指令集。通过模型上下文协议（MCP）实现标准化交互，确保跨系统信息无损传递，各类模型的中间推理结果皆可互通复用。

记忆系统：包含领域知识库（长期记忆）和用户会话记录（短期记忆），依托向量数据库高效管理。创新性引入反思记忆模块，持续优化决策质量。

进化机制：通过自我反思、强化学习和奖励模型实现能力迭代，使智能体越用越聪明。

协同网络：突破单智能体能力边界，通过多智能体协作矩阵应对复杂场景，显著提升系统鲁棒性与并行效率。

我们构建了三位一体的数据智能体架构（图3），包含：
• 数据勘探层：建立语义化数据目录和智能数据织物，通过元数据索引实现高效检索，集成各类数据预处理工具链。
• 引擎调度层：深度适配Spark/DBMS/Pandas等异构计算引擎，根据任务特征智能匹配最佳执行方案。
• 流程工厂：将自然语言查询智能解析为可执行流水线，利用大语言模型的推理能力进行动态优化，平衡时效性、成本与精度需求。

记忆中枢采用分级存储架构，向量数据库同时承载领域知识库（长期记忆）和会话上下文（短期记忆），并支持反思型记忆存储。

多智能体协作网络（图4）包含三大引擎：
1. 智能体优选系统：建立能力画像库，实现精准任务匹配
2. 协同计算框架：通过A2A协议实现状态同步与群体智能
3. 弹性执行引擎：支持串行/并行混合调度，具备故障自愈能力

工具调度中心依托MCP协议实现"即插即用"，可智能匹配Pandas/PyData等数百种数据处理工具，构建动态能力组合。

本文首先解析i Data Science的数据智能体架构（见图5），继而系统阐述其核心组件。

3.1 i Data Science概览

i Data Science通过灵活调度多样化数据智能体的协同能力，实现数据科学任务的自适应处理——这一前沿课题仍充满挑战。如图5所示，系统采用双阶段架构：

离线基准构建阶段：通过组合基础数据技能，打造覆盖全场景的智能体评估体系。首先运用大语言模型对海量数据案例进行质量筛选和技能挖掘；随后通过递归聚类建立技能层级体系，并依据使用频率或用户偏好为每个技能赋予权重；最后基于权重概率采样核心技能，由大语言模型生成对应测试用例。

![](images/43066cd83576b97b5bc9624e105f3e7abb04c3f694df1b8797ad8304d9ef13b7.jpg)

为确保在线评估的精准性，系统还构建了支持相似度检索的测试用例索引库（详见3.2节）。

在线智能调度阶段：当新任务到来时，系统自动拆解任务流、匹配最优智能体，并动态优化执行方案。具体包含两大核心机制：

1. 智能体优选机制
通过微调的任务嵌入模型，将待处理任务与基准库中的测试用例进行向量化匹配，快速锁定Top K相似案例。综合评估结果后，选择综合得分最高的智能体。对于特殊场景，支持通过文档解析或小样本测试进行专项评估（详见3.3节）。

2. 流程动态编排
先由大语言模型基于智能体画像拆解任务依赖图，为每个子任务分配合适的智能体，并通过合并/细分等操作持续优化方案。执行时采用拓扑排序的并行流水线，同时支持两种弹性调整：
- 局部调整：单个智能体层面的子任务修正
- 全局重构：基于中间结果的完整重规划
所有中间产物均存入数据目录避免重复计算（详见3.4节）。

系统扩展性：支持通过文档解析快速接入新智能体。当资源允许时，可运行基准测试完善其能力画像，使其无缝融入现有调度体系。这种持续进化机制确保系统始终保持在最优状态。

3.2 数据智能体基准测试

面对数据科学任务的多领域特性，现有基准测试往往局限于固定任务类型[26,27]，难以灵活评估数据智能体的真实能力。为此，我们创新性地提出基于数据技能的自适应基准测试框架（图5）。该框架首先通过LLM S从海量语料中提取代表性数据技能，构建具有语义关联的层次化技能树，每个技能节点均配有动态权重。评估时，系统能智能组合目标场景所需的技能集，并驱动LLM S生成量身定制的测试用例，实现多维度的精准评估。

3.2.1 数据技能体系构建

智能技能挖掘。我们整合Stack Overflow等技术社区、Kaggle竞赛及现有基准库，构建包含三大要素的优质数据科学样本库：（1）多模态数据集与自然语言任务描述；（2）分步骤解决方案；（3）由LLM S解析的核心数据技能。通过三重过滤机制确保数据质量：先用LLM S将杂乱代码转换为清晰步骤，再淘汰不完整方案，最终精准提取如"列计算"、"回归分析"等原子技能。

技能森林架构。采用"分治"策略构建技能体系：通过文本嵌入捕捉语义特征，运用高斯混合模型进行多粒度聚类，配合流形降维技术优化处理。每个技能簇由LLM生成概括性主题节点，当子簇技能量达标时继续递归细分，形成层次分明的技能森林。例如"数据清洗"节点下可能包含"缺失值处理"等叶节点。

动态权重系统。基础权重源自技能在样本库的出现频率，采用"自底向上"的分数聚合算法：叶节点权重=关联样本量/总样本量，父节点权重为子节点权重之和。同时支持用户交互式调权——提升关键技能权重时，系统自动平衡同层节点分值，并保持子树内的相对比例。

3.2.2 智能测试工场

测试用例包含任务描述（含数据集）和可量化的评估函数（0-10分制）。传统LLM直接生成方式存在两大缺陷：技能覆盖不全、脱离实际场景。我们的解决方案（图6）创新性地采用：

技能驱动生成。根据权重概率抽取k个叶节点技能，通过语义检索获取关联性最强的真实案例（相关性分数=Σ技能权重）。这些案例作为上下文样本输入LLM，确保生成任务既涵盖目标技能，又保持现实可行性。

评估函数设计。要求必须满足：（1）使用限定数据集；（2）综合运用全部指定技能；（3）采用模块化评估：多个布尔判断子函数组合成最终评分，提升结果可比性。针对大数据集，采用元数据辅助的采样策略；对模糊标准，则通过LLM动态生成评估规则。

该框架支持通过调节k值控制测试复杂度，满足不同应用场景需求。如图7所示，经过微调的任务嵌入能有效区分各类数据科学任务特征。

3.3 数据智能体优选策略

面对众多处理同类数据科学任务的数据智能体[26,27]，最直观的优选方案是参考基准测试成绩。具体而言，通过汇总各测试用例的评估得分，总分最高的智能体自然脱颖而出。但这种方法忽视了测试用例与目标任务的相关性差异，因此需要引入权重调节机制来保证评估的客观性。

我们创新性地采用任务嵌入技术解决这一问题：首先训练数据科学任务的嵌入模型，使解决方案相似的任务在嵌入空间相邻。智能体的最终得分由其各测试用例得分的加权总和决定，权重取决于测试用例与目标任务的嵌入相似度，得分最高者即为最优选。

针对特殊场景，我们还开发了三种补充评估方案：当基准测试耗时过长时，改用LLM解析智能体技术文档快速评估；面对超大规模计算任务时，通过采样实验验证智能体性能。这三种方法各具特色（详见表1），形成完整的优选体系。

（插入表格图片）

3.3.1 任务语义嵌入技术

数据科学任务通常包含多模态数据和文字说明，我们采用多模态大语言模型（MLLM）提取语义嵌入：文本和图像直接编码，表格转为CSV格式处理。对于超大数据集，则采用3.2.2节所述的样本替代方案。但原始嵌入容易受到任务领域、数据格式等无关因素的干扰。

为此，我们设计了一种精调方案：以标注数据技能的优质案例库为基础，构建对比学习框架。将正确解法作为正样本，互斥技能的解法作为负样本，通过多重负例排序损失优化模型，使相似解决方案的任务在嵌入空间紧密聚集。经过训练后，嵌入距离可准确反映任务解决流程的相似度，为智能体优选提供可靠依据。

3.3.2 智能体优选三部曲

我们构建了三位一体的优选体系：

智能基准聚合：离线阶段运行完整基准测试建立评分库，并构建测试用例的嵌入索引。在线服务时，先计算目标任务的嵌入向量，检索最相关的k个测试用例，以归一化相似度作为权重，计算各智能体的加权得分进行排序。

文档智能解析：对于待评估的新智能体，指导LLM深度分析其技术文档的三大核心要素：1）设计理念，比对目标任务与智能体设计定位的匹配度；2）典型案例，评估其与目标任务的嵌入相似度；3）实验结果，通过LLM补全缺失数据后，预测智能体在目标任务上的表现。最终生成0-10分的标准化评估。

样本实验验证：针对计算密集型任务，先对数据集进行随机采样，筛选评分最高的候选智能体进行样本实验，最后由LLM对比执行效果，确定最优解决方案。

这套组合拳既保证了评估效率，又确保了优选质量，为数据智能体的落地应用提供了完整的技术支撑。

3.4 多智能体协同编排

面对超越单个数据智能体能力边界的复杂任务[36-38]，亟需建立协同框架突破能力瓶颈。现有方案多依赖专家经验预设固定智能体组合，难以灵活扩展。为此，我们创新提出自适应流程编排算法：首先通过专业化档案、异构选择和LLM动态调优生成最优任务分解方案；随后采用交互式执行机制，支持智能体级微调与全局重规划的双重优化策略。

3.4.1 智能体导向任务规划

基于文献方法，我们驱动LLM S将原始任务与智能体档案库结合，生成包含三个显著特征的任务蓝图：(1)专业化档案驱动：构建含设计原理、典型范例（含正负基准案例）和实验指标的三维档案体系，兼容A2A协议；(2)异构优选机制：通过依赖图谱分析建立子任务上下文，动态合成虚拟数据集作为筛选依据；(3)弹性调整策略：支持智能体缺失时的任务再分解，以及相关性强的子任务智能合并。

3.4.2 动态流程执行

突破传统刚性架构，iDataScience系统实现双重创新：(1)并行拓扑执行引擎：依据依赖关系图实现子任务并行推进，每个节点由专属智能体驱动，LLM S实时校验中间结果；(2)分级自愈机制：当子任务受阻时，先启动智能体级诊断（包括输入优化、备选智能体切换等局部调整）；若仍不奏效则触发全局重构，利用数据目录保存的中间成果进行全流程再规划。这种"微创手术式"优化与"系统重启式"重构相结合的弹性架构，显著提升了复杂任务处理的鲁棒性。

四大数据分析智能体

我们首先纵览数据分析智能体的整体架构[19,41]，随后详解四类核心智能体：非结构化数据解析专家、语义结构化数据管家、数据湖勘探者和多模态数据通才。

智能体架构精要。在准备阶段，智能体会构建语义目录与索引库，并定义语义过滤器、分组器、排序器等系列语义算子。这些算子既以逻辑实体形式存在（如"满足某条件的对象"），又与LLM执行、预编程函数等物理实现绑定。处理查询时，智能体如同交响乐指挥——先拆解自然语言指令为任务乐章，再优化算子编排方案，最终奏响高效执行的协奏曲。

非结构化数据解析专家。这位专家擅长用自然语言对话挖掘文本宝藏。其绝活包括：将模糊查询转化为精准流水线、实时自检执行效果、平衡成本与精度的优化算法。我们研发的"逻辑蓝图生成器"能通过推理链破解复杂问题，"物理引擎优化器"则基于创新成本模型打造高效方案，配合可动态调校的弹性执行机制，形成闭环智能系统。更妙的是，它还能自动提炼数据特征图谱，为后续分析提供导航。

语义结构化数据管家。传统数据库如同戴着镣铐跳舞，而这位管家借助LLM打破了封闭世界的枷锁。它将语义获取、智能过滤等LLM超能力注入SQL，创造出"语义SQL"新语种。通过专用翻译官（NL2SQL智能体），自然语言指令可无缝转换为语义SQL。执行时采用三重优化：传统算子替代（如用"北京"代指"中国首都"）、多级语义过滤漏斗、基于代价的智能调度，让开放世界查询快如闪电。

数据湖勘探者。这位探险家专攻半结构化数据迷宫，其装备包括：异构数据连通器（统一嵌入技术）、语义分析工具包、以及能自适应调整的智能流水线工厂。相比过去削足适履的有损提取方案，它凭借LLM的语义理解天赋，在保持数据原貌的同时实现高效分析，如同为数据湖装上了声呐探测系统。

多模态数据通才。这位全能选手精通文本、图像、音视频的"多国语言"。其核心技术突破包括：跨模态统一编码器（保留各模态DNA的嵌入技术）、智能语义转换器（NLP+CV+音频处理的联合算法）、弹性查询解释引擎。就像精通多国语言的同声传译，它能实时对齐融合不同维度的数据流，构建立体的语义宇宙。

数据库管理员（DBA）在同时管理多个数据库并确保实时响应时常常捉襟见肘——对于许多在线业务场景而言，即便数小时的延迟都可能造成严重后果。现有经验方法对数据库诊断的支持有限，更让这一任务雪上加霜。为此，我们推出了一款基于大语言模型（LLM）的DBA智能体诊断系统[42,43]。该系统能自动从技术文档中汲取知识，生成详实的诊断报告，精准定位数据库异常根源。该智能体包含四大核心模块：智能文档知识提取、基于知识图谱的提示生成、树状搜索的根因分析，以及高效执行管道的优化。实验证明，在分析新型数据库异常时，该智能体的表现远超传统方法和GPT-4等标准模型。

6 机遇与挑战




理论保障。由于大语言模型和语义算子可能产生幻觉，数据智能体并非总能给出百分之百准确的结果。因此，建立数据智能体系统的可靠性理论保障至关重要。




自省与激励机制。数据智能体需持续提升准确性与效率，实时反馈是其进化的关键。设计高效的自省机制与激励模型，是突破这些瓶颈的有效途径。




评估基准。构建数据智能体评估体系势在必行，尤其在数据科学、分析挖掘及库管等领域更需建立专业基准。




隐私安全防护。数据智能体必须构建敏感信息防火墙，在满足隐私合规要求的同时抵御未授权访问。




弹性扩展能力。面对海量复杂数据，智能体需在保证处理速度与精度的前提下实现弹性扩容。随着数据规模激增，系统设计要确保性能无损的线性扩展能力。

7 总结  

本文提出了数据智能体的概念，旨在为数据+AI应用提供自主支持。我们设计了一套完整的架构，涵盖数据理解与探索、数据引擎调度及流程编排等核心模块，并展示了数据科学智能体、分析智能体及DBA智能体等典型应用案例。数据智能体的发展将带来诸多挑战，亟待数据社区协同攻克；同时在数据库开发、设计、转换、数据飞轮及数据编织等领域，也蕴藏着广阔的创新空间。

致谢




本研究获得国家重点研发计划（2023YFB4503600）、国家自然科学基金（62525202、62232009）、深圳市科技计划（CJGJZD20230724093403007）、中关村实验室、华为公司及北京信息科学与技术国家研究中心（BNRist）资助。通讯作者为李国良教授。