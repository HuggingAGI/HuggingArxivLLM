面向大规模RAG系统的非结构化文本知识图谱高效构建与检索技术




作者：Congmin Min, Rhea Mathew, Joyce Pan（SAP，美国帕洛阿尔托）  
Sahil Bansal, Abbas Keshavarzi, Amar Viswanathan Kannan（SAP，美国帕洛阿尔托）  

联系方式：congmin.min@sap.com等对应邮箱

摘要

本文提出了一种可扩展、高性价比的企业级图检索增强生成（GraphRAG）部署框架。虽然GraphRAG在多跳推理和结构化检索方面潜力显著，但其应用长期受限于两大瓶颈：基于大语言模型（LLM）构建知识图谱的高昂算力消耗，以及图检索的延迟问题。为此，我们突破性地提出两项创新：（1）基于语法依赖的工业级知识图谱构建方案，运用专业NLP工具直接从非结构化文本中提取实体关系，彻底摆脱对LLM的依赖；（2）轻量化图检索策略，通过混合查询节点定位与高效单跳遍历相结合，实现高召回、低延迟的子图提取。在SAP遗留代码迁移场景的实测中，本系统较传统RAG方案取得显著提升——基于LLM-as-Judge和RAGAS指标分别实现15%和4.35%的性能突破。更值得关注的是，我们的依赖解析方案以仅6%的性能差距（61.87% vs 65.83%）媲美LLM生成的知识图谱，同时大幅降低计算成本并提升扩展性。这些成果证实了GraphRAG在真实企业级场景落地的可行性，为构建高效、可解释、可定制的检索增强推理系统开辟了新路径。

CCS分类  

• 信息系统 → 智能问答；文档筛选；数据库Top-k检索。

核心关键词




知识图谱 | 检索增强生成(RAG) | 依存分析 | 混合检索 | 可扩展GraphRAG | GraphRAG架构 | 代码迁移

ACM文献著录格式：




闵丛敏、Rhea Mathew、Joyce Pan、Sahil Bansal、Abbas Keshavarzi与Amar Viswanathan Kannan合著。2025。《面向大规模RAG系统的非结构化文本知识图谱高效构建与检索》，收录于《第34届ACM国际信息与知识管理会议论文集》（CIKM '25），美国纽约：ACM出版社，全文8页。

1 引言

检索增强生成（RAG）通过将大语言模型（LLM）的输出锚定在外部知识源上，显著提升了模型性能。其标准流程是：用户查询触发密集向量检索，从文档库中获取语义相关段落作为LLM的上下文输入，从而确保响应内容基于事实依据。这种架构既能减少幻觉现象，又能实时更新信息，且无需昂贵的模型重训练。在企业场景中，RAG可整合专有数据，使生成结果始终与最新领域知识同步。

尽管RAG擅长处理简单的事实性查询，但在需要跨文档推理的复杂任务中往往表现不佳。例如涉及政策依赖、多系统协作或遗留代码迁移的问题，通常需要串联多个内容片段并理解其隐含关联。此时标准RAG系统只能返回零散片段，无法捕捉内在联系，导致输出结果逻辑断裂——这在关键业务场景中尤为致命。

现代ERP系统（如财务、采购、HR、制造模块）持续产生海量异构数据。典型的企业查询需要综合分析配置规则、事务关联、变更日志等分散在各系统的信息。以SAP S/4HANA的代码迁移评估为例，需同时关联遗留功能、弃用报告、兼容性矩阵等多维数据，这正是传统RAG的软肋。

图检索技术天然契合此类需求，因其能建模结构化关联并实现跨实体遍历查询，使GraphRAG成为ERP应用的理想解决方案。

GraphRAG通过构建知识图谱突破传统局限：索引阶段提取文档中的实体关系并构建图结构；查询时同步检索文本片段和关联子图。这种机制支持沿语义路径进行多跳推理，最终生成逻辑严密的递进式响应。

但企业级部署面临三大挑战：

• 图谱构建成本高：海量实体关系抽取依赖LLM/NLP流水线，GPU/CPU开销大，导致高延迟且难以实时更新
• 扩展性瓶颈：文档规模增长使图谱维护成本剧增，现有方案普遍无法突破百万节点量级，缺乏高效的增量更新机制
• 检索性能瓶颈：大规模图谱查询延迟明显，即使优化后的图数据库也难以实现多跳遍历的实时响应

1.1 核心创新  

本文针对企业级场景，提出GraphRAG框架，主要突破包括：  

- **低成本知识图谱构建**：基于工业级NLP工具链的依赖关系建模方案，摆脱LLM依赖，显著降低规模化部署成本；  
- **高效图谱检索**：通过混合查询节点定位与单跳遍历的轻量化策略，实现高召回率的语义子图精准捕捉；  
- **首例代码迁移验证**：首次将GraphRAG应用于遗留系统改造实战，在效果与效率上全面超越传统密集检索方法。  

这些创新证明GraphRAG能为企业级复杂任务提供兼具可解释性、精准度与扩展性的检索增强推理。后文将结合检索技术、图推理及知识集成领域的研究进展展开深入探讨。

2 研究背景

检索增强生成（RAG）技术由文献首创，通过融合维基百科密集向量检索与seq2seq语言模型，在问答质量上超越了传统参数化模型。但后续研究[4,5]揭示了其在企业级应用中存在的安全、可解释和扩展性等系统性缺陷，并提出了相应的评估框架。

为突破这些限制，GraphRAG创新性地在检索与生成环节间植入了知识图谱。微软研究表明，将检索内容转化为实体关系图并进行语义聚类，可显著提升问答效果。在此基础上，LightRAG等轻量化方案[1,14,18]着力优化图表示效率，而HyperTree Planning则采用分层图推理实现多步推断。最新研究系统梳理了GraphRAG技术路线，"从局部到全局"框架则专门优化了摘要任务的图上下文聚合。

图基础设施的性能直接影响GraphRAG的扩展能力。GraphScope系列[15,21]通过模块化设计，在万亿边规模实现近线性加速；AliGraph凭借采样存储优化，训练速度达到基线系统的12倍。

实时子图检索仍是待解难题：GRAG的分治策略会随子图增多产生延迟，RGL库虽通过动态索引提升检索速度，但其有限的数据库兼容性制约了企业应用。我们创新性地采用依存句法分析[6,31,33]等轻量级语法方法构建图谱。

现有研究多聚焦传统RAG架构的源优先级和检索评估，而我们的GraphRAG框架独辟蹊径，基于领域通用知识图谱构建语义化检索层，既能生成精准可解释的响应，又通过轻量级NLP处理栈实现工业级部署，与大规模图系统形成优势互补。

2.1 图表示技术




图神经网络（GNNs）虽能编码图结构并生成节点嵌入以支持检索，但其推理速度在大规模系统中仍显不足。跨越数百万节点和边的消息传递计算开销，使其难以在低延迟的企业场景中实时应用——除非进行大幅剪枝或缓存。为提升扩展性，替代算法应运而生。个性化PageRank（PPR）作为轻量级的邻近度节点排序机制，在小世界图中表现优异，相关信息仅需几跳即可获取。但在高吞吐环境下，为每个查询实时计算PPR仍代价高昂，且动态演变的图结构使预计算方案难以维持[11,29,45]。我们现已实现基础PPR模块，正开发优化版本以增强实时处理能力。另一创新方向是通过社区检测锁定语义密集的子图，微软GraphRAG采用Leiden等模块化算法预筛关键图区域，将检索聚焦于少量社区，显著提升响应速度与结果质量。总体而言，GNNs、PPR和社区筛选策略各自攻克了GraphRAG检索瓶颈的不同环节，但如何将其融合为统一、可扩展的企业级解决方案仍是待解难题。我们正通过架构设计中效率、适应性与可解释性的三重优化，逐步实现这一目标。

3 技术方案

我们的系统采用双引擎架构：(i) 灵活切换的知识图谱框架，既支持基于大语言模型的高精度构建，也支持基于轻量级语法解析器的快速生成；(ii) 智能检索系统，融合图遍历与向量化重排序技术。

知识图谱提供两种构建模式：采用大语言模型可获得高质量图谱但需较高算力成本，使用语法解析器则能以较低成本快速生成。所有图谱统一存储，为后续检索提供支持。

我们的构建方法源自依存语法理论，将句子解析为"中心词-依存词"的网状结构。例如"开发者重构S/4HANA的Z报告"中，"重构"作为核心动作，关联着执行者、对象和目标系统。这些语法关系经提炼后，能自然形成反映业务逻辑的知识图谱，如"开发者→重构→Z报告→适配→S/4HANA"这样的语义链条。

查询处理采用"初筛+精排"的二级架构：先通过图遍历广撒网捕获相关节点，再借助OpenAI嵌入向量进行相似度精排。最终由大语言模型对筛选出的子图、原文片段和关键实体进行智能摘要，生成精准应答。这种设计延续了信息检索领域的经典级联范式[2,30,32]，通过小世界网络理论确保在保持语义关联性的同时控制计算规模，特别适合企业级知识图谱应用。

下文将完整展示这套端到端解决方案，涵盖从图谱构建、智能检索到精准摘要的全流程。

图1：多模态知识图谱构建流水线

3.1 知识图谱构建

图1展示了我们的多模态知识图谱构建流水线，支持基于大语言模型(LLM)的智能抽取和轻量级依存分析双路径方案。输入文档经过预处理和过滤后，三元组被精准抽取、标准化并存储至目标图数据库。

核心构建模块详解：

文档解析器：支持PDF/HTML/XLSX/CSV等多格式输入，通过开源Docling库1统一转换为保留版式、表格和元数据的中间表示，最终输出JSON或Markdown格式文档，为下游GraphRAG处理提供便利。

智能分块器：借鉴Hearst等的研究，采用分层分块策略：先按Markdown标题保持语义连贯性分块，超长段落再按字符拆分。配置2048字符上限和200字符重叠，基于LangChain递归文本分割器2优化，新增空格感知等企业级特性。

句子分割器：采用语言专属分隔符将文本分句，既解决LLM长文本性能衰减问题[26,36]，又便于句法分析过滤。使用Spacy3库解析并过滤无动词句，大幅减少LLM调用。采用滑动窗口批量处理（3句窗口/1句重叠）提升API调用效率。

内容过滤器：基于句法分析过滤无动词内容，这种业界验证的高效剪枝策略可显著提升处理效率。

三元组抽取器：双模选择机制支持商用LLM(GPT-4o/Sonnet)或依存分析方案。本文采用依存分析法，系统可根据成本智能切换。针对不同规模数据集，我们对比测试了GPT-4o与依存图模型的适用场景。

3.1.1 依存分析技术：融合传统句法与专业启发式规则，打造跨领域知识抽取方案。其领域无关特性无需定制训练即可适配各类文本。选择Spacy因其工业级性能与顶尖依存解析能力，相比专用信息抽取模型在开放域任务中表现更优。如图2所示，"SAP推出Joule for Consultants"的解析树需经后续逻辑转换才能生成标准三元组{SAP, 推出, Joule for Consultants}，完整流程包括：

![](images/84885e6cf1b34daf99bdec526d53970fa7ab8b5701679a3bc44f8572e72e38a2.jpg)

图2：Spacy生成的解析树

• 名词短语提取净化
• 动词处理与关系抽取  
• 主宾语识别
• 特殊模式识别
• 三元组生成与后处理
• 高级上下文分析

成本优化器：实时计算API调用成本，根据商用LLM的token计价动态更新，确保预算可控。

实体关系标准化器：解决自然语言噪声问题，统一实体/关系表述格式，处理特殊字符兼容性问题（如去除冒号等），实现数据去重和图数据库适配。

模式过滤器：支持无模式与专家定义模式双轨制，通过后处理确保抽取结果符合领域规范。

图谱生成器：将三元组转换为属性图格式（未来将扩展RDF支持），适配不同图数据库。

知识加载器：针对可视化、分析和生产等不同场景，提供多目标数据加载方案。

3.2 高效图检索架构




图3展示了索引与检索流程的核心组件。我们采用双存储策略：知识图谱同时存入向量数据库Milvus和图数据库iGraph。前者存储节点、文本块及关系的向量化表示，支持快速相似性检索；后者基于内存存储节点与边关系，实现高效图遍历。下文将详解各检索模块的设计。





3.2.1 智能实体识别。相较依赖大语言模型的传统GraphRAG方案[3,19,24]，我们创新性地采用优化版SpaCy名词短语提取器精准捕捉查询核心概念，同时结合查询向量与节点向量的相似度搜索，智能获取图谱中Top5相关节点。最终融合两种方法的识别结果，作为关系挖掘的种子节点。





3.2.2 图结构探索。从种子节点出发，通过模糊匹配定位关联边，随后进行一度邻居遍历（通过Δk_relations参数控制探索范围）。经实验验证，中小型图谱Δk=100效果最佳，大型图谱则参照文献设为200，在效率与覆盖率间取得平衡。





3.2.3 智能排序策略。候选关系按类型分为实体关联和文本块关联两类，通过余弦相似度计算与查询的相关性。系统返回Top5文本块及Top10关系，并创新性地引入混合搜索模式——通过互惠排名融合整合语义搜索与图谱搜索优势，显著提升结果质量。





3.2.4 上下文增强机制。最终输出结构化上下文：{文本块列表，关系列表，实体列表}，为大语言模型提供远超传统RAG的多维信息。这种三维上下文架构使LLM能更深度理解问题语义与知识关联。

4 实验验证

4.1 数据集  

本研究以CCM为领域案例，数据集包含三大核心部分：基础资源语料库、CCM聊天测试集和CCM代码提案测试集。  

CCM资源语料库由550份PDF文档构成，包括SAP操作手册及代码迁移技术文档。经预处理后生成约2000个文本块（每块3000字符，含500字符重叠），作为知识图谱构建与向量表征的实验基础。  

两个测试集功能各异：CCM聊天测试集含150组代码迁移问答（如错误分析、迁移前后差异）；CCM代码提案测试集提供200组遗留代码案例，均包含迁移前后双版本对照。  

基于该语料库，我们构建的知识图谱包含3.9万节点、4.7万实体关系和6.3万实体-文本块关系，平均节点度1.52，最高达236。  

4.1.1 评估方法  
CCM聊天评估采用双轨制：  
1. 覆盖率测量：通过LLM分类器对比生成答案与标准答案，给出0（完全不匹配）、0.5（部分匹配）、1（完全匹配）三级评分  
2. RAGAS评分  
最终得分采用加权平均计算。

加权得分公式：$=\left(0.5\times\%_{0.5}+1.0\times\%_{1.0}\right)\times100\%$

此处 $\%_{0.5}$ 和 $\%_{1.0}$ 分别代表0.5分和1.0分答案的占比。

RAGAS评估体系通过三大维度综合考量：
(i) 上下文精准度——检索内容与问题的匹配比例
(ii) 答案忠实度——生成结果对检索材料的依赖程度
(iii) 响应相关性——通过生成衍生问题计算语义相似度，数值越高代表应答越精准

在CCM代码评估环节，我们启用"大语言模型作为裁判"机制，将自动生成的迁移代码与标准答案进行对比。每个测试样本包含：原始代码、参考答案，以及通过向量检索和图检索生成的两种方案。

（表1/2图示位置保持不变）

评估采用双轨制：
1. 方案对决——LLM根据贴近标准答案的程度进行二选一
2. 多维评分——从五个关键维度进行星级评定：
   • 语法合规性
   • 逻辑完备性  
   • S/4HANA适配度
   • 运行效能优化
   • 代码可读性

4.2 结果与解析

4.2.1 系统性能表现。在CCM Chat场景中，如表1和表2所示，GraphRAG的两个版本（分别采用GPT-4o三元组提取和依赖图谱建模）在上下文精准度上均比密集向量检索提升至少12%。在覆盖率指标上，两个版本的未覆盖率降低32%，而完全覆盖率提升至少19%。

特别值得注意的是，依赖图谱版GraphRAG在上下文精准度上保持了GPT-4o版94%的水准，未覆盖率表现相当，完全覆盖率达到GPT-4o版的86.6%，展现了其轻量化知识图谱构建流程的卓越性能。

代码提案效果。在CCM Code Proposal数据集上，两个GraphRAG版本在胜率和综合评分（五项指标均值）上均超越密集检索。其中依赖图谱版表现与GPT-4o版持平，证明其在检索任务中可完美替代基于大语言模型的三元组提取方案。

表3：GPT-4o版代码提案的LLM智能评估
![](images/558c99d910fdddd8260a47fa7605c3828981bd4d6c93c0db924d997c4d521c13.jpg)

表4：依赖图谱版代码提案的LLM智能评估
![](images/1fd477cb29575381d72a8b8286ae31dda31907a2d54b79e3b670f2d3ed9ab659.jpg)

典型场景分析。本方案能精准捕捉关键实体关联内容。例如在CCM对话中，针对"S/4HANA迁移后如何处理涉及VBBS表的自定义代码"的提问，密集检索完全漏检VBBS表相关内容，而GraphRAG则准确抓取了"若客户代码使用VBBS...需在VBBE创建视图..."等核心语句，展现出卓越的语义聚焦能力。

在代码提案场景中，经错误分析发现：相比GraphRAG方案，密集检索生成的迁移代码存在更多幻象内容和函数定义错误，例如会虚构出"call function 'sd vb uk read from doc multi'"等非法函数调用。

5 总结与展望  

本研究创新性地提出企业级GraphRAG系统的轻量化构建方案，通过两大核心技术突破现实场景的可扩展性瓶颈：基于高效依存解析的知识图谱构建，以及保障实时查询性能的混合子图检索。在SAP的CCM Chat和CCM Code Proposal场景中，本方案持续超越传统RAG系统，其开源依存解析器构建的知识图谱更达到媲美GPT-4o的评测表现（经LLM-as-a-Judge与RAGAS双指标验证）。  

该方案通过摆脱对大模型的知识图谱构建依赖，开辟了系统扩展的新路径。现存挑战有二：依存解析可能忽略语义隐含关系，且跨领域泛化能力有待验证。后续将通过在HotpotQA等开放基准的测试，探索方案的企业外延应用价值。  

表5：GPT-4o知识图谱构建成本分析  
![](images/1f8a47244d54b9af138d2e5a559f9a4e6e51be32ec69a09808ea93a48b55b2cd.jpg)

6 生成式AI使用说明




本文借助ChatGPT对部分表述进行了优化润色。所有核心研究内容（包括研究设计、数据分析和结果解读）均由研究人员独立完成，未使用生成式AI工具辅助。