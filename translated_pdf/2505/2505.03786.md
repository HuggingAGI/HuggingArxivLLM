小模型大智慧：15亿参数推理模型在辨别任务中力压130亿参数大模型

Md Fahim Anjum ∗ 美国加州大学旧金山分校神经病学系 旧金山94143 fahim.anjum@ucsf.edu

摘要

具备推理能力的大语言模型（LLM）为优化规划框架的候选评估开辟了新路径，但其相较传统非推理模型的优势尚待深入探索。本研究在文本转SQL任务中，基于生成器-判别器架构的LLM规划框架，对蒸馏版1.5B参数推理模型DeepSeek-R1与多款前沿非推理LLM进行对比测试。我们创新性地提出从推理思维链（CoT）输出中提取软评分的方法，实现候选方案的精细分级。核心假设认为：推理模型的判别效能优于非推理模型。实验显示，参数量大幅精简的DeepSeek-R1-1.5B，其F1值较CodeLlama-7B最高提升87%，判别准确率提高3.7%，执行准确率更超越CodeLlama-13B达3.7%。研究同时揭示：推理模型的逻辑能力存在天花板，仅增加上下文或计算资源无法持续提升判别性能。有趣的是，与非推理模型相反，推理模型更擅长判别而非生成，其生成表现甚至可能逊于小型非推理模型。本研究证实：在智能体框架中，推理模型作为判别器的价值远超生成器，这为LLM规划体系的角色优化提供了重要启示。

1 引言

规划是智能决策的核心环节。学界已投入大量精力开发高效拟人化规划方法，涵盖多阶段与多智能体框架[21,41,17,25]。随着大语言模型（LLMs）融入规划系统，基于LLM的结构化规划框架因其卓越的多步问题解决能力引发广泛关注，在各类任务中表现亮眼[14,15,43,44,51,7,21,41]。这些框架虽设计各异，但普遍遵循三阶段流程：动作序列搜索→结果预测→效用最大化选择[25,16]。具体而言，LLMs先生成候选动作（生成阶段），通过自评估或外部模型预测结果（判别阶段），最终整合输出最优方案（规划阶段）。该机制与LLMs处理数学推理、多跳问答等多步任务的模式高度吻合。传统非推理LLMs在此类框架中的表现已有详尽研究，而最新通过内部推演实现实时推理的LLMs展现出突破性性能。搭载思维链（CoT）技术的OpenAI o系列、Gemini 2.0闪思、DeepSeek-R1等推理模型，在复杂基准测试中实现逐步推理与SOTA性能，大幅超越非推理模型。尤为突出的是，DeepSeek-R1以较低训练成本达到与OpenAI模型比肩的SOTA水平，其逻辑输出在量化和蒸馏条件下仍优于Qwen等模型[49,38]。然而，关于推理模型在规划框架中的应用研究仍属凤毛麟角[38,26,3]，尤其缺乏生成-判别架构中与传统LLMs的系统性对比研究。

本文聚焦文本到SQL任务，探究DeepSeek-R1在LLM规划框架中的作用。采用1.5B蒸馏版模型，我们假设推理模型更适合担任判别器，并围绕三个核心问题展开：

1. 推理LLM作为判别器如何影响框架精度？
2. CoT计算预算与上下文增强对判别性能的影响？
3. 推理模型在生成端的表现是否优于判别？

我们系统评估了DeepSeek-R1的生成与判别能力，并与主流非推理LLMs对比。针对CoT输出非结构化导致的软分数提取难题，创新提出推理结果量化方法，实现精细判别。通过SQL查询重标注实验，从分类与排序维度测试模型判别力，分别在基础设置和包含环境验证的增强设置中评估性能。同时从词法、结构、语义三方面分析DeepSeek-R1的推理质量，并考察计算预算、模式上下文、评分方式三大因素对判别的影响。研究发现：

1. 在生成-判别框架中，1.5B版DeepSeek-R1的F1值较CodeLlama-7B提升87%，判别精度高3.7%，执行准确率优于CodeLlama-13B达3.7%；
2. 基于logit的软评分与二元判别差异不足1.5%；
3. 模型逻辑容量存在上限：上下文超过1024token后收益递减（<0.4%），而计算预算过低会导致性能骤降（准确率<2%）；
4. 尽管判别表现优异，其生成能力甚至逊于更小的非推理模型，印证"生成难于判别"的人类认知规律。

本研究首次系统对比了文本到SQL任务中推理与非推理LLMs的规划性能，创新提出推理模型的软评分判别机制，为构建高效自主系统提供了重要洞见。

2 相关研究

在生成-判别或大语言模型（LLM）规划框架中，人类和智能体通常更擅长判别而非生成任务。但West团队提出假设：LLM等生成模型的判别能力可能无法与其出色的生成能力相匹配。这一观点得到了多项研究的佐证——非推理型LLM在缺乏外部反馈时，常会将正确的自生成方案误判为错误[10,31]。Huang团队发现，自我纠正的效果高度依赖优质的外部反馈；Chen团队则证实，非推理型LLM的判别精度与整体任务表现存在显著相关性。

针对推理模型的即时计算效能，Zeng团队发现了有趣的"逆向缩放"现象：随着思维链（CoT）延长，模型准确率不升反降。数据显示，正确方案的CoT长度普遍短于错误方案，暗示过长的思维链反而会降低性能。多项研究指出，当CoT长度超出模型固有推理能力时，不仅会导致错误累积[11,4,39]，单纯增加计算资源也无法提升表现[20,33]。最新研究表明，最佳推理长度需根据模型能力与任务复杂度动态调整[40,27,2]。

不同于前人研究（或聚焦非推理型模型的规划能力，或探讨无智能体框架的CoT机制），我们的工作创新性地探索了推理模型在LLM规划框架中的作用，并系统评估了即时计算资源配置对性能的影响。

3 实验配置

3.1 任务与数据  
采用Spider数据集进行文本转SQL评估。沿袭前人研究，我们从开发集中抽取400个样本构成高效子集，按难度分级等量选取（简单/中等/困难/极难各100例）。完整开发集含1,034例，难度分布为：简单24%（248例）、中等43.1%（446例）、困难与极难合计32.9%（340例）。随机抽样方法参见文献。

3.2 语言模型




本研究采用DeepSeek-R1-Distill-Qwen-1.5B（简称DistillR1）作为核心推理模型。为对比非推理架构，我们精选了多款不同规模的开源大语言模型：包括TinyLlama-1.1B-Chat-v1.0、DeepSeek-Coder-1.3B、Stable-Code-3B，以及CodeLlama-7B和CodeLlama-13B（模型名称均省略Instruct后缀）。

3.3 大语言模型规划框架

如图1所示，我们采用生成器-判别器双模块架构：生成器LLM负责提出候选方案，判别器LLM则进行质量评估。规划模块根据评分结果对候选方案排序，并协调两模块的协作流程。下面我们将深入解析各组件在文本转SQL任务中的具体实现。

![](images/f76c6b6074a5d9f798f494e7a141671cbe7cecda986efddb242ba9209cc7be75.jpg)  

图1：本研究采用的文本转SQL任务LLM规划框架（详见文献）

3.3.1 生成器模块

通过零样本提示技术，生成器LLM将自然语言问题转化为候选SQL查询。我们以数据库表结构作为上下文，采用固定提示模板引导生成过程。对于基础模型，使用"根据数据库模式和自然语言问题生成对应SQL查询"的指令；而推理模型Distill-R1则采用"生成有效的sqlite SQL查询作答，结果需以SELECT开头"的强化指令，并配合markdown格式模板以便提取最终SQL语句（完整提示示例见附录表14-15）。

基于Hugging Face框架，我们设置max_length=300、temperature=0.2、num_return_sequences=5等超参数。当不启用规划流程（num_return_sequences=1）时，该模式称为贪婪生成。

3.3.2 判别器模块

我们将候选方案评估建模为二分类任务[12,13]，为每个候选生成质量评分。

基础模型采用直接评分法：计算模型输出"Yes"标记的softmax概率作为评分。具体通过"该SQL是否符合问题要求？"的提示语，提取关键标记概率作为评分依据（示例见附录表11）。

推理模型Distill-R1则采用创新评估流程：
1. 要求模型以JSON格式输出判断结果（键为'correct'）
2. 解析生成内容获取判断值及其logit
3. 通过softmax计算判断置信度ρ
   - 若判断为'true'则取ρ
   - 若'false'则取1-ρ
4. 缺省情况下返回-0.5基准分（完整流程见图2）

![](images/a2935752396d79cf3da553a179d687218bef8f570848a222d0013d2df30a1b01.jpg)  

图2：推理模型(Distill-R1)作为判别器的软评分获取流程

3.3.3 规划策略

采用经典的重排序机制：生成器产出候选方案→判别器独立评分→选择最高分方案输出。该策略虽简单，却在代码生成和数学推理[32,14]等领域广受认可。

实验设置两种判别模式：
1. 基础模式：直接评估候选方案
2. 增强模式：先进行SQL可执行性校验，仅对通过校验的候选评分

3.4 评估方法  

3.4.1 内在评估  

我们复用文献的预言机模拟实验数据来检验LLM的判别能力。通过评估脚本对预生成SQL查询进行重标注（模拟重排序场景），由预言机对比预测SQL与标准SQL前五条结果的表格匹配度。采用综合指标同时衡量二分类准确率与排序性能。  

3.4.2 端到端评估  

区别于静态查询集的内在评估，端到端测试聚焦LLM在规划框架中的动态表现：实时生成候选查询并排序。我们在重排序策略下，完整评估基于LLM的生成-判别全流程框架，验证其在实际决策中生成并优选查询的能力。评估沿用内在测试的400个案例，确保跨批次数据可比性。

3.5 性能指标




3.5.1 内在评估




为评估大语言模型（LLM）的判别能力，我们采用四项核心指标：成对判别准确率（PwAcc）衡量模型区分正误查询的能力[1,30]；分类宏F1（F1）从二分类角度评估模型表现；命中率@1（H@1）检验候选集首位准确率；平均倒数排名（MRR）则反映高质量结果的排序表现。





3.5.2 端到端评估




在LLM规划框架中，我们通过执行准确率（文本转SQL）、精确匹配率（对比标准查询）及F1等指标综合评估模型表现，所有计算均基于语义评估测试套件。





3.5.3 推理质量




我们通过多维度指标刻画推理质量：重复比率揭示内容冗余度；1-TTR指数反映词汇丰富性；n元组重复频率检测短语复用情况；熵值量化信息分布密度；最后通过句向量余弦相似度计算整体多样性，数值越低代表内容越丰富多元。

4 研究成

4.1 推理模型胜任判别器

我们的小型推理模型Distill-R1在智能体化LLM规划框架中展现出卓越的评估能力，性能远超传统非推理模型。

4.1.1 小模型的大能量

核心测试显示三大亮点：首先，Distill-R1在基础模式和可执行性检查下的F1分数分别领先非推理模型58%和87%（表1）。其次，其Hit@1和MRR指标仅次于CodeLlama-13B，但相较StableCode-3B等大模型仍保持4.6%和2.1%-2.6%的优势（表1）。更难得的是...

表1：LLM判别器性能对比（绿色标注为推理模型）

实战检验中，Distill-R1整体执行准确率比CodeLlama-13B高出3.7%，仅在超难题集稍逊（表2）。启用可执行性检查后，其超难题处理能力突飞猛进，准确率提升18.2%（表3）。不过精确匹配指标仍落后大模型10%-12%，显示其尚有提升空间。

表2：端到端评估成绩单（基础模式）

4.1.2 计算资源的边际效应

当测试token预算从256提升至1024时，模型判别准确率完成从<2%到峰值的飞跃。但突破1024 tokens后，每增加1000 tokens带来的提升不足0.4%（图4）。更值得注意的是，过度计算会导致模型陷入"车轱辘话"模式——重复率飙升90%，而推理深度未见增长。

图4：计算预算与模型表现的微妙关系

4.1.3 信息过载的陷阱

为提示词添加数据库schema反而适得其反：判别准确率下降4.3%，失败率暴涨215%（表4）。这表明AI和人类一样，面对信息轰炸时判断力反而会下降。

4.1.4 评分机制的玄机

放弃logits采用二元评分时，内在评估准确率骤降32.8%，但端到端测试仅微跌1.5%（表5-6）。这揭示了一个有趣现象：评分方式对实际应用的影响，可能比实验室数据小得多。

表5-6：评分方式对比实验

4.2 推理模型的生成表现




实验数据显示，推理模型Distill-R1的生成能力欠佳。以它为基准时，最小的非推理模型（TinyLlama-1.1B）表现亮眼：整体执行准确率提升56.9%，精确匹配准确率跃升87.5%，部分匹配F1分数增长49.4%（详见表7和图5）。  





![](images/4d6ed343fd0a72a0c6d4e07fba734ceda08082c39c2b4f3cdb2047f3000c707f.jpg)  





图5：大语言模型作为生成器的执行准确率对比


![](images/f7af63a872fc974bfaf77cd5878993aa56d725eef66f3e0e77770bbf6dcae452.jpg)  


表7：生成模式（贪婪算法）下的端到端评估指标，粗体标注最优结果  





更值得注意的是，非推理模型的性能与规模呈正相关。中等模型相较Distill-R1，执行准确率暴涨566.7%，精确匹配准确率飙升395%，部分匹配F1分数提升38.9%。而最大模型的表现更为惊艳，三项指标分别实现702.8%、745%和92.3%的飞跃。这一系列数据揭示了两大关键发现：其一，推理模型的生成能力甚至不及小型非推理模型；其二，在SQL生成任务中，非推理架构的规模扩展能持续带来性能突破。

5 讨论




本研究探讨了推理模型在生成器-判别器架构及LLM规划框架中的核心作用。通过采用重排序规划方法，我们在文本转SQL任务中对推理模型（Distill-R1-1.5B）与多个非推理型LLM进行了对比测试。研究发现，推理模型在LLM规划框架中扮演着关键角色，这一发现对智能体框架下的模型设计与部署具有重要指导意义。

5.1 推理小模型Distill-R1的判别性能碾压大模型

研究发现，这款具备推理能力的轻量级模型（仅1.5B参数）在LLM规划框架中展现出惊人的判别能力：不仅能精准区分查询正误，其整体执行准确率更是全面超越参数规模达8倍以上的非推理大模型。具体数据令人惊艳——在基础测试中，相比CodeLlama-7B，其配对准确率提升2.9%，F1值暴涨58%；加入执行性检查后，优势进一步扩大至3.5%和87%的惊人差距（表1）。更令人振奋的是，这个"小个子"选手甚至以3.7%的优势击败了13B参数的CodeLlama（表2），证明推理能力才是提升判别性能的关键。实验还揭示了一个商业价值点：该模型的二元判别结果与复杂logit评分差异不足1.5%，这意味着在无法获取完整logit的商业场景中，它依然能保持顶级判别水准。这些突破性发现不仅验证了推理模型在判别任务中的独特优势，更为后续性能优化指明了方向。

5.2 推理能力的天然瓶颈




研究发现，推理模型存在"计算收益天花板"现象：当测试计算资源低于临界值时，严苛的token限制会严重损害推理质量，导致准确率断崖式下跌；当token预算增至1024左右时，性能达到拐点，此后边际效益急剧递减。这表明盲目追加计算资源并不能增强推理深度。数据同时揭示：过量的token预算会引发输出冗余（图4/附录表8），出现循环论证和语境丢失问题。值得注意的是，为Distill-R1注入数据库结构信息反而适得其反（表4），不仅未能提升效果，还可能增加系统风险。这些发现与既有研究[47,39]形成三重印证：计算资源存在基础门槛、性能收益符合边际递减规律、思维链长度与准确率呈负相关。这充分说明：当前推理模型的逻辑能力存在硬性上限，单纯堆砌计算资源或扩展语境窗口已触及性能天花板。未来突破方向应当双管齐下：在优化计算规模的同时，更需要针对推理机制开展精准调优。

5.3 生成难于判别

研究发现，Distill-R1虽在判别任务中表现优异，却难以胜任生成工作——在生成高质量SQL查询时，其表现甚至不及小型非推理模型（表7和图5）。这揭示了一个有趣现象：推理模型擅长评估查询，却拙于创造查询。究其原因，自然语言转SQL需要处理可能分叉的复杂推理链（CoT），而推理模型固有的能力局限使其难以驾驭这般复杂的思维脉络。值得注意的是，这与传统认知形成鲜明对比：非推理型大语言模型通常更擅长生成而非判别[5,36,10,31]，但推理模型却呈现出与人脑相似的逆向特性。

5.4 未来方向与局限  

本研究展示了如何利用推理模型生成候选评估的软分数——尽管思维链（CoT）推理可能输出任意长度的标记，使得软分数提取颇具挑战性。基于这一方法，未来可通过软分数驱动的微调来优化模型推理能力，从而进一步提升性能。  

当前研究存在以下局限：实验仅聚焦文本转SQL场景，结论未必适用于其他领域；虽然揭示了计算预算与性能的权衡关系，但模型架构、标记限制与任务复杂度间的深层关联仍需探索；受限于算力，实验采用了轻量级推理模型（Distill-R1，15亿参数）和精简数据集。但本研究的核心价值在于为LLM规划框架中的推理机制提供了普适性洞察，这些发现对更大规模模型同样具有启示意义。

6 结论

本研究探讨了推理模型Distilled DeepSeek-R1-1.5B在文本转SQL任务的LLM规划框架中的表现。我们创新性地从其思维链输出中提取软评分用于判别分析，并系统评估了该模型作为判别器和生成器的双重能力。实验表明，DeepSeek-R1在查询判别任务上超越了许多更大的非推理模型，彰显了此类模型在LLM规划中作为判别组件的潜力。同时，研究也揭示了推理模型的内在局限：增加算力投入和上下文信息带来的边际效益会逐渐递减。值得注意的是，虽然该模型在查询评估方面表现出色，但其生成能力却不及更小型的非推理模型。尽管实验规模有限，这些发现为开发更精简高效的智能体系统指明了方向——通过战略性地将推理模型融入规划框架，实现更优的性能表现。

数据与代码资源




本研究所用代码、数据集及完整复现指南均已开源，详见：https://github.com/MD Fahim An j um/llm-planning-with-reasoning

实验设备采用市售消费级笔记本，搭载NVIDIA GeForce RTX 4080（12GB）和RTX 3070（8GB）显卡。