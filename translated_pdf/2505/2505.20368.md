标准化文档金融开放域问答：基于证据归集的层次化检索方案




Jaeyoung Choe, Jihoon Kim, Woohwan Jung 汉阳大学应用人工智能系 {cjy9100, skygl, whjung}@hanyang.ac.kr

摘要

检索增强生成（RAG）技术赋能的大型语言模型（LLM），凭借其在知识密集型任务中的卓越表现，已成为金融领域的利器。然而，标准化文件（如SEC申报材料）往往存在格式雷同的问题——重复的模板化文本、相似的表格结构等，这使得传统RAG方法容易误判近似重复内容，导致检索结果冗余，影响准确性与完整性。为此，我们创新性地提出了层次化证据检索框架HiREC。该框架通过分层检索机制，先锁定相关文档，再精准定位关键段落，配合智能证据筛选剔除无关内容，必要时还能自动生成补充查询以填补信息缺口。为验证方案效果，我们构建并开源了LOFin金融问答基准测试集，涵盖14万余份SEC文档和近1600组问答对。相关代码与数据已发布于https://github.com/deep-over/LOFin-bench-HiREC。

1 引言

大型语言模型（LLM）驱动的检索增强生成（RAG）技术（Lewis等，2020）大幅提升了知识密集型任务的性能。凭借其提升事实准确性与时效性的双重优势，该技术已在金融信息检索领域引发研究热潮（Yepes等，2024；Sarmah等，2024）——这个对信息精准度和时效性要求极高的决策场景。

以SEC年报（10-K）为代表的金融文档具有高度标准化特征：跨公司、跨年度的统一模板中，相似表格与重复叙述屡见不鲜。如图1所示，亚马逊、Meta和沃尔玛2023年的10-K报告，其表格结构宛如复制粘贴，仅数值存在差异。当被问及"2023年亚马逊与沃尔玛营业利润率差异"时，传统RAG系统往往陷入"找不同"困境，检索出大量雷同内容，导致答案失准。

为此，我们提出HiREC框架（分层检索与证据精修），其创新性体现在：
1. 分层检索：先定位相关文档，再筛选关键段落，有效规避"孪生文本"干扰（如图1所示，将检索范围精准锁定至目标公司文档）
2. 证据精修：智能过滤冗余内容，动态生成补充查询（例如当仅获取亚马逊数据时，自动补查沃尔玛数据），确保答案所需的完整证据链。

现有金融QA基准（Islam等，2023；Lai等，2024）存在明显局限：最大仅1300份文档的微型语料库，难以模拟真实金融场景。我们构建的LOFin基准具有三大突破：
- 基于标普500公司14.5万份SEC备案的大规模语料
- 包含1595个开放域QA测试案例
- 专门针对标准化文档中的"表格克隆"等现实挑战设计
整套基准已开源，助力领域研究。

实验显示，HiREC性能超越现有RAG方法至少13%，更在商用LLM+搜索引擎（如SearchGPT、Perplexity）组合中保持优势。我们的核心贡献在于：
1. 首创面向金融文档的分层检索机制，破解"千表一面"困局
2. 设计智能证据精修流程，实现"查漏补缺"自动化
3. 开源LOFin基准，为金融QA研究树立新标杆

2 研究进展

金融智能问答与RAG 金融问答领域突飞猛进，最新测评聚焦数值推理与表格解析能力。TAT-QA（Zhu等，2021）和FinQA（Chen等，2021）提供单页表格数据，DocFinQA（Reddy等，2024）与DocMath-Eval（Zhao等，2024）则拓展至多页场景。但这些封闭领域基准制约了RAG系统的应用空间。开放领域基准如Financebench（Islam等，2023）和SEC-QA（Lai等，2024）应运而生，却受限于小规模文档库与测试集不足的缺陷。

金融RAG研究同步蓬勃发展：既有专为金融设计的图算法（Barry等，2025；Sarmah等，2024），也有创新混合方案（Wang，2024），金融文档智能分块研究（Yepes等，2024）更带来关键突破。

RAG技术演进 呈现百花齐放态势（Gao等，2023；Zhang等，2025）。针对结构化文档的分层检索方案，普遍采用"文档-段落"二级处理（Ari vaz hagan等，2023；Chen等，2024）。我们的创新在于突破传统章节分割模式，实现文档级精准切分。质量优化方面，现有研究通过过滤机制提升上下文质量（Zhuang等，2024；Wang等，2024b），而我们仅凭LLM即可实现质量管控。多跳问答场景中，迭代检索通常将首轮结果纳入后续查询（Trivedi等，2022；Shao等，2023），Self-RAG（Asai等，2023）更将生成过程融入迭代。但我们的方案摒弃历史结果依赖，专注缺失信息的主动发现。

本节推出LOFin基准测试，通过扩充检索语料库与开放域问答对数量，有效突破了现有金融问答数据集的局限（详见表1）。

3.1 海量文档集构建  

为真实还原海量文档检索与问答场景，我们系统采集了美国证监会（SEC）的全套备案文件。具体包括：2001年10月至2025年4月期间标普500企业的10-K年报、10-Q季报及8-K临时报告，数据均来自SEC EDGAR系统。  

通过wkhtmltopdf工具将HTML转为PDF格式后，采用PyMuPDF库（参照Islam等人2023年方案）实现页级文本提取，并自动过滤分页不规范文件。最终建成覆盖516家上市公司、总量达145,897份报告的精品语料库。

3.2 开放域问答对构建

本节详解我们如何整合三大金融问答基准（FinQA、Finance bench和SEC-QA）构建开放域问答对。

首先对FinQA的封闭式问题进行开放域改造：剔除35个因技术原因缺失证据的测试问题后，使用GPT-4o为剩余问题注入时间范围和公司信息。例如将"2016年总运营费用？"升级为"请提供洛克希德·马丁公司2016年度总运营费用数据"，具体转换模板见附录B.2。

证据页面筛选采用双重验证机制：先通过BM25算法比对表格数值特征，再运用NLI模型4评估语义相关性。两者结果一致则采纳，否则人工校准（详见附录B.3）。

Finance bench原生支持开放域，问题直接沿用。为弥补FinQA和Finance bench在跨文档推理评估的不足，我们从SEC-QA中精选4个多文档模板，人工构建需要跨文档检索的难题及其证据链，显著提升了基准的复杂性。

经学术评审后，LOFin基准最终扩容至1,595组问答（新增205组SEC文件衍生命题），初始1,389组称为LOFin-1.4k，扩展版命名LOFin-1.6k。新增问题延续原有标注体系，重点强化多文档推理能力。基准详情见附录A，SEC-QA模板参见附录B.4。

4 层级化证据检索（HiREC）框架

本节介绍HiREC框架的运作机制。如图2所示，该框架包含两大核心模块：
1. 层级检索：采用分层策略精准抓取与问题$q$相关的文本片段$\mathcal{P}_{r}$
2. 证据提纯：对检索结果进行双重过滤与验证

![](images/e80ad9aa881b94d23c00aeba033c8ba7fded859711004991881269299b3d3f40.jpg)  

图2：HiREC框架工作流程图

证据提纯模块会智能判断文本片段的信息完备性：当信息不足时自动生成补充问题$q_{c}$启动二次检索（补充通道），信息充足时则将精炼后的文本集$\mathcal{P}_{f}$送入答案生成器（主通道）。系统在达到最大迭代次数$i_{\mathrm{max}}$时自动终止检索，并融合所有有效文本生成最终答案。具体算法实现参见算法1，各LLM模块均采用量身定制的指令模板，完整提示工程方案详见附录D。

4.1 分层检索

标准化文档采用统一模板，结构重复且内容相似，这使得精准检索相关段落颇具挑战。我们采用分层解决方案：先筛选与问题相关的文档（4.1.1）缩小范围，再精筛文档中的关键段落（4.1.2）。

4.1.1 文档检索器

文档索引。标准化文档信息量大但格式统一，单向量难以捕捉所有关键细节。为此，我们特别提取并索引区分性特征。以财务报告为例，封面页的公司名称、报告类型和财年等信息至关重要。对每个文档d∈D，先用LLM生成封面摘要d'（提示模板见附录D.1），通过双编码器预计算嵌入向量v_d=E^D(d')（Wang等，2024a），存入文档库。

三阶段检索流程：
1. 查询优化：用LLM将原始问题q转化为精炼查询q'，消除股票代码等干扰术语的影响（转换模板见附录D.2）
2. 向量检索：使用相同双编码器计算q'的向量v_q'，通过相似度评分s_q',d^D=v_q'^T v_d（Karpukhin等，2020）筛选出k_D'个候选文档
3. 精准排序：采用交叉编码器（He等，2021）重排候选文档，最终保留与问题最相关的k_D篇文档

4.1.2 段落检索器

在已筛选文档中，通过交叉编码器Cross-Encoder^P(q,p)评分，精选k_P个核心段落。这种设计既保证实时性，又充分发挥交叉编码器捕捉句间关系的优势。针对财务表格的特殊性，我们进行了专项优化：
- 问题：通用模型难以识别表格中的标题、会计期间等关键特征
- 解决方案：使用FinQA数据集微调模型，其中表格作为证据单元
- 训练方法：对每个证据表格采样n_neg个负样本，采用二元交叉熵损失函数：

L=∑[ -log(σ(q,p)) - ∑log(1-σ(q,p')) ]

其中σ表示交叉编码器的sigmoid输出，分数区间为[0,1]。

4.2 证据精修

金融问题常需跨时段或跨公司对比。即便检索到相关段落，关键信息仍可能缺失，且无关内容会干扰结果准确性（Liu等，2024；Xu等，2024）。为此，我们设计了证据精修流程：通过三重过滤机制剔除噪声数据，并在信息不足时智能发起补充检索。该体系包含：智能去噪的段落过滤器（4.2.1节）、证据完备性评估器（4.2.2节）和缺口识别问答生成器（4.2.3节），所有功能均由LLM单轮响应实现（提示模板见附录D.3）。

4.2.1 段落净化工序

从原始检索集$\mathcal{P}_{r}$中剔除无关内容，输出精炼后的段落集$\mathcal{P}_{f}$（上限$k_{P}^{\prime}$条）。系统会综合考量新增段落与历史有效段落——这一步骤直接影响LLM输出质量，任何噪声渗入都可能导致答案偏差。

4.2.2 证据完备性验证

对净化后的段落集$\mathcal{P}_{f}$进行充分性检验：达标则进入答案生成环节；若存在信息缺口，立即启动补充检索流程。

4.2.3 智能补全机制

深度扫描$\mathcal{P}_{f}$识别证据链缺失，动态生成补充查询$q_{c}$，为下一轮检索提供精准靶向。

4.3 答案生成

在答案生成阶段，系统以相关文本片段和原始问题为输入，通过智能推理得出最终答案。针对数值计算类问题，采用程序化推理（PoT）方法（Chen等，2022）；对于文本推理问题，则运用思维链（CoT）技术（Wei等，2022）。这种双轨策略尤其适合处理数据密集的金融文档，既能解析复杂表格，又能确保推理严谨。具体提示模板详见附录D.4（根据Zhao等2024年DocMath-Eval改编）。

5 实验验证

5.1 实验配置

数据集。基于第3节提出的LOFin基准测试开放域QA方法，主体实验在包含1,389组问答对的LOFin-1.4k数据集完成，更新版LOFin-1.6k结果见附录A。

根据问答形式将样本分为三类：
• 表格数值：答案直接来自表格数据或通过表格计算得出
• 文本数值：需从文本中提取并整合数字信息
• 文本解释：纯文字型答案
（具体样例与分布统计见表12）

技术实现。系统核心组件采用多组预训练模型：
- 段落检索：微调DeBERTa-v3模型（8负样本/批，128批量，3轮训练，2e-7学习率，RTX 4090显卡）
- 文档检索：E5双编码器+DeBERTa-v3重排序
- 答案生成：GPT-4o驱动
- 辅助任务（查询改写/文档摘要/证据筛选）：Qwen-2.5-7B-Instruct

框架设置最大3轮迭代，文档检索保留5份，段落检索提取5条（经过滤器限流至10条），其他参数见附录C.1。

对比方案。与当前主流RAG方法全面对标：
- 迭代式：RQ-RAG/Self-RAG/IRCoT
- 检索增强：Dense（text-embedding-3-small编码+DeBERTa重排）/Hybrid Search/HHR
- 商业参照：Perplexity AI
（所有基线均统一采用GPT-4o生成器，具体配置见附录C.2）

评估体系：
- 数值答案：允许合理近似后验证准确性
- 文本答案：GPT-4o+FAMMA提示词评估
- 检索效能：页面级召回率/精确率（规避分块差异影响）

5.2 核心结论  

表2显示，HiREC在页面召回率和答案准确率上全面超越基线模型——页面召回率较次优模型Dense至少提升10%，答案准确率领先13%，印证了该方法在标准化文档检索中的卓越性能。更惊艳的是，HiREC平均仅需检索3.7个段落，其证据筛选机制的高效性可见一斑。  

图3：HiREC与基线模型在公司/文档/页面三级错误率上的对比  

特别发现：在文本类问题中，所有模型的答案准确率均反超页面召回率，说明大语言模型具备"检索不全却答得准"的文本理解能力。但数值类问题依赖精密推理，表格类仍是公认难点。  

（注：图片描述保留原文格式，未作改写）

5.3 分析

消融实验 表3展示了HiREC各组件移除后的页面精确率、召回率及答案准确率。其中分层检索（HR）和证据整理（EC）为两大核心模块。未启用HR时相当于Dense方法与EC联用，未启用EC时则反映HR初始检索性能（kP=10）。

未微调场景下使用原始排序器以避免表格先验知识干扰。虽然性能微降，HiREC准确率仍领先Dense基线10%以上。即便Dense搭配微调排序器，其平均答案准确率仅30.55%，差距依然显著。

HR模块对提升检索精度至关重要，缺失时性能跌至谷底。值得注意的是，HR初始检索效果已优于"Dense+EC"组合。未启用EC的实验结果则印证了段落过滤器与互补问题生成器的协同效应。

图4：迭代过程中的召回率、精确率及单查询段落数（EC指证据整理）

图5：精确率-召回率曲线（横轴召回率，纵轴精确率）

EC加持下的HR系统在各项指标上全面跃升。未启用过滤器的对照实验表明：虽然互补组件能获得最高召回值，但其准确率不及完整版HiREC，原因在于未过滤的错误信息会产生干扰（Xu等，2024）。

错误类型分析 图3统计了各方法检索段落中公司信息错误的次数（以top1段落为准）。HiREC凭借精准的公司识别能力，错误率最低，实现了文档与段落检索的双重准确。

迭代优化效果 图4显示，相比初始分层检索，迭代式证据整理（EC）在提升页面召回率与精确率的同时，显著降低了单查询处理量。随着迭代推进，检索效能持续增强。

表4：成本效益对比（单元格内为输入/输出值，*表示小模型按GPT-4o计价）

检索效能 图5曲线表明，当k值在1-50区间变化时，基线方法的召回率提升伴随精确率下降。HiREC则实现双重突破，其指标全面超越基线最佳值。

成本控制 表4显示，通过在答案生成前过滤无关段落，HiREC以更少的token消耗和更低成本达成最优性能。相比IRCoT，其智能过滤与问题生成机制使迭代效率提升显著。实验证明，轻量级LLM也能高效完成证据整理任务。

5.4 多模型生成器性能对比分析




我们深入评估了HiREC框架在不同大语言模型生成器上的表现。本次测试采用DeepSeek-R1-Distill-Qwen-14B（Guo等，2025）和Qwen-2.5-7B-Instruct（Yang等，2024）等开源模型替代GPT-4o作为生成器进行对比实验。




表5数据显示，HiREC在不同规模的生成器上均保持领先的问答性能，展现出卓越的适应性。尤为亮眼的是，即便采用参数量更小的开源模型，HiREC方案仍能超越Dense基准线。其中HiREC+Deepseek-14B组合




![](images/0e7b45d7b4fc4deb3d5d65551ffed2f3316c81b81b7c8e266ddc927eb7721ad1.jpg)  


表5：多模型生成器性能对比（注：下划线标注的HiREC配置使用轻量级生成器即可超越Dense$^+$GPT-4o方案）




![](images/bf761addd69d71df650a8b17ce7ce86f4017bb170ce18fff3bc2cb55aa544749.jpg)  


表6：分数据源性能表现




相较Dense+GPT-4o方案实现了超过9%的平均准确率提升。本实验还揭示一个重要发现：在检索环节采用轻量化模型，既能维持优异性能，又可显著降低整体推理成本。

5.5 数据源性能对比




通过分析不同数据源，我们既评估了基准数据泄露风险，也验证了HiREC框架的稳健性。




表6数据显示，HiREC在各数据源均保持领先优势。值得注意的是，所有方法（含HiREC）在SECQA子集表现稍逊，因其多文档问答特性需整合多方信息。这表明LOFin基准因多文档场景更具挑战性，而基于检索证据的设计有效规避了数据泄露风险。




完整测试结果（含扩展版SEC-QA子集）详见附录。

5.6 商业LLM与搜索引擎的较量  

以SearchGPT和Perplexity为代表的商业系统，通过结合大语言模型与网络搜索来处理金融数据问题。表8显示，采用llama-3.1-sonar-large-$128k$-online模型的Perplexity和使用GPT-4o的SearchGPT，在每类40题的测试中均被我们的HiREC方案超越——尤其在数值计算方面，商业系统虽能抓取相关文献，却频繁丢失关键数据细节，导致计算精度不足。  

（注：图片描述和表格标题未作翻译处理，符合学术文献惯例；技术术语如模型名称保留原文；数值单位"$128k$"保持原格式；通过短句拆分和破折号运用提升中文节奏感）

5.7 案例研究




我们深入剖析了证据筛选机制如何高效过滤冗余信息、精准补全缺失数据，以及这些操作对最终结果的塑造作用。如表7所示，针对某问题的多轮检索与证据整理过程清晰呈现：层次检索首轮虽获取了Adobe公司2015财年营收数据，但因缺失2016财年数据仍无法作答。系统通过答案校验模块智能识别缺口，触发补充提问机制，最终成功补全2016财年关键营收信息。这一完整证据链的形成，有力印证了HiREC框架中迭代优化策略的核心价值。

6 结论

我们推出HiREC框架——一个面向标准化财务文档的智能问答系统，通过检索增强技术实现高效响应。其分层检索机制有效规避了重复模板内容的干扰，智能证据筛选系统既能过滤无关信息，又能补全缺失内容。为模拟真实开放域场景，我们创建了LOFin评测基准：涵盖14.5万份SEC文件中的1,595组问答，特别设计了超越传统财务QA的多文档关联与多跳推理题型。实验证明，HiREC在检索精度和回答准确率上全面领先现有方案，并通过智能段落选择保持成本优势。研究表明，这套框架为处理复杂财务文档的开放域问答提供了兼具扩展性与实效性的解决方案。

研究局限

本研究采用大语言模型（LLM）进行查询转换、证据筛选和答案生成，因此整体效果受限于模型性能。我们使用的Qwen 2.5 7B模型（Yang等人，2024）规模较小，与商用大模型存在差距。

实验采用的FinQA和FinanceBench均为公开数据集，预训练大模型可能已接触过相关数据。如表2所示，GPT-4o（零样本）的文本表现位列第二。

致谢




本研究由韩国卫生福利部资助的国家癌症中心（NCC）癌症防控研发计划（项目编号RS2025 02264000），以及韩国科技信息通信部（MSIT）下属信息通信技术规划与评估院（IITP）科研项目（项目编号RS-2023-00261068，轻量化多模态反钓鱼模型与隐私保护型分割学习技术研发）联合资助。