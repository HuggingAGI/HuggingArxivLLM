小型大语言模型的钓鱼邮件检测性能优化




林子杰 刘子康 范汉波  
新加坡国立大学  
lin.zijie@u.nus.edu | e1351201@u.nus.edu | hanbofan1@gmail.com  

</结果2>

摘要

大型语言模型（LLMs）在自然语言处理任务中表现卓越，钓鱼邮件检测领域也受益于此。然而当前高性能LLMs往往参数量高达数十亿，计算资源消耗惊人。为降低成本，我们探索了仅30亿参数的小型LLMs在钓鱼邮件检测中的应用潜力——这类模型可在普通GPU上运行，但检测效果欠佳。为此，我们创新性地融合了提示工程、解释增强微调和模型集成三大技术，成功将Qwen2.5-1.5B-Instruct等基线模型在Spam Assassin数据集上的准确率从0.5飙升至0.976，验证了方案的卓越成效。

关键词 钓鱼邮件检测 · 小型LLMs
</结果2>

1 引言

钓鱼邮件始终是网络安全领域的重大威胁，对个人与企业都造成严峻风险。多年来，检测技术不断演进：从早期的规则过滤和黑名单机制，到朴素贝叶斯[1]、支持向量机[2]等传统机器学习算法，再到决策树[3]等数据挖掘技术，每次突破都推动着邮件检测领域的发展。

近年来，深度学习为钓鱼检测注入了新活力。深度神经网络能自动提取邮件的高维特征[4]，研究者先后尝试了CNN[5]、RNN[6]等经典架构。随着Transformer模型[7]的崛起，其卓越的语义理解能力很快被应用于钓鱼检测——从擅长上下文理解的BERT[8]等编码器模型，到参数量暴涨的GPT[9,10]等解码器大模型，语言模型正成为检测利器。

但现有方案存在明显缺陷：高性能模型往往体积庞大。例如基于LLaMA-3.1-70b和GPT-4构建的检测系统[11]虽能达到99%准确率[12]，但动辄千亿参数[13]带来的计算成本令人却步。为此我们另辟蹊径，采用LLaMA-3.2-3B-Instruct[14]等轻量模型（约30亿参数），可在消费级GPU流畅运行。但直接使用效果不尽人意——Qwen2.5-1.5B[16]准确率仅38.8%，LLaMA-3.2-3B也仅58.7%。针对这一困境，我们开发了一套提升小模型检测性能的创新方案。

图1：小模型性能优化全流程

我们的方法环环相扣：
• 智能提示工程：通过结构化提示模板，引导模型同步输出推理链与检测结果
• 解释增强微调：突破传统微调局限，使用PT-4o-mini[17]为每封邮件生成详细分析报告作为训练素材
• 双重集成策略：创新性地融合多数表决与置信度加权两种集成方式，充分发挥模型协同效应

这套组合拳使小模型焕发大能量，在保持高效计算的同时显著提升检测精度，为实际部署提供了理想解决方案。
</结果2>

2 研究背景

钓鱼邮件与正常邮件存在本质差异。早期研究多采用基于TF-IDF或词袋模型的关键词过滤器，结合互信息提取特征。Rout团队测试了多种朴素贝叶斯分类器[18,19]，但这些基于理想假设的方法难以应对持续进化的钓鱼攻击。Drucker团队创新性地采用加权线性SVM处理真实场景中的数据失衡问题，在高维稀疏特征处理上表现亮眼[20]。Carreras团队则通过提升树模型突破传统线性模型局限，不仅准确率更高，还能灵活调整误判代价[21]。

深度学习浪潮催生技术革新。Roy团队率先将词嵌入技术引入特征提取，通过CNN/LSTM模型捕捉深层语义，检测效果远超传统方法[22]。Guo团队巧妙结合BERT的语义编码能力与经典分类器，证明预训练特征能大幅提升模型性能[23]。

当生成式大语言模型(LLM)横空出世，文本分类进入新纪元。Cunha的对比研究证实LLM相对传统模型的压倒性优势[24]。Heiding团队聚焦钓鱼检测领域[25]，发现LLM不仅能精准识别含混的欺诈意图，某些情况下甚至比人工判断更可靠。Koide团队运用GPT-4创下99.7%的检测准确率纪录[26]，其设计的提示工程不仅让模型适应多变攻击手法，还能输出可解释的推理过程，极大增强用户信任。

然而LLM的落地面临双重阻碍：数十亿参数导致的部署困难，以及高昂的API调用成本。加之微调大模型需要惊人的算力投入，我们转而探索小型LLM的潜力。研究表明，经过针对性微调的小型LLM不仅能逼近大模型性能，更在成本控制与可解释性之间取得完美平衡，堪称务实之选。
</结果2>

3 方法论</结果2>

3.1 问题定义

本研究聚焦钓鱼邮件检测问题。给定一封包含主题$S$和正文$B$的邮件$E$，采用参数为$\theta$的模型$M$进行识别，期望模型输出判定标签$L$（标识邮件是否为钓鱼邮件）：


$$
L=M(<S,B>|\theta)
$$


当采用大语言模型检测时，$L$将转换为文本形式的判定结果（"钓鱼"或"安全"）。此时还需输入提示语$P$来引导模型输出符合要求的判断：


$$
L=M(<S,B>|\theta,P)
$$

</结果2>

3.2 提示词工程

经过指令微调的大型语言模型（LLM）虽能理解人类指令，但提示词设计仍会显著影响其任务表现。我们发现，若直接要求LLM输出"钓鱼"或"安全"作为判断标签，模型往往难以严格遵循格式要求，不仅增加了结果提取难度，还影响了整体可用性。更值得注意的是，当限定仅输出单个标签时，LLM会表现出明显的判断偏好——无论输入内容如何，都会强烈倾向于某一特定标签。这很可能是因为单一标签的输出要求与LLM擅长的开放式生成特性相悖。为此，我们优化了提示策略：先让模型阐述判断依据，再用特殊符号标注最终结论。这种设计既发挥了LLM的生成优势，又能确保输出结果格式统一且易于提取。
</结果2>

3.3 解释增强微调

预训练-微调模式已被证明能显著提升大语言模型（LLM）在下游任务中的表现[8,27]。我们最初尝试直接用钓鱼邮件数据集（含主题$S$、正文$B$和标签$L$）微调小型LLM，却发现检测性能提升有限。这是因为生成式LLM虽擅长开放式文本生成，但强制其输出"钓鱼/安全"这类封闭式答案，与其预训练目标存在偏差。

图2：使用GPT-4o-mini为邮件数据添加解释说明

为此，我们创新性地将训练目标扩展为"标签+解释"的组合。如图2所示，通过GPT-4o-mini为原始邮件标签生成解释$R$，构建出包含四要素（$S$、$B$、$R$、$L$）的增强数据集。这种设计使微调任务更贴近LLM的开放式生成特性，不仅提升模型效果，还能通过解释机制减少幻觉问题，增强检测可信度。

考虑到算力限制，我们采用低秩适配（LoRA）进行高效微调[28]。其核心是将权重矩阵$W$分解为小矩阵$A$和$B$：

$$
W'=W+AB
$$

冻结原始参数$W$，仅训练低秩矩阵（$r\ll min(d,k)$）。前向计算引入可调系数$\alpha$：

$$
h=Wx+\frac{\alpha}{r}ABx
$$

这种巧妙的降维策略大幅减少了梯度存储和优化器状态所需参数，实现了内存高效的模型微调。
</结果2>

3.4 模型集成

不同大语言模型（LLM）各有所长，我们创新性地提出两种集成方案来提升钓鱼检测效果：1）置信度集成 - 根据LLM输出的词元对数概率计算置信分，择优选取最终答案；2）多数表决 - 以多数模型的共识作为判定依据。

具体实现时，模型输出的逻辑值经softmax层转换为词元概率（以logprobs形式呈现）。通过将各词元logprobs取指数后连乘，再对结果开N次方根（N为序列长度），即可得到词元概率的几何平均数，即长度归一化（LN）置信分。

多数表决机制简单高效。实验采用三款微调后的小型LLM：LLaMA-3.2-3B-Instruct、Phi-4-mini-Instruct和Qwen-2.5-1.5B-Instruct。当目标邮件的分类结果出现分歧时，我们遵循"少数服从多数"原则。

$$LN\;Conf.=\left(\prod_{i=1}^{N}\exp(logprob_{i})\right)^{1/N}$$
</结果2>

4 实验验证

本节通过系列实验验证方法的有效性。我们选用Span Assassin数据集，在包含1069封邮件的独立测试集上开展评估。实验...

表1：基础提示法的实验结果

![](images/ca2dfa41a7a3c6d90ae29edf5f090f3566b606af97aa5bb4c1041d9c6f559f24.jpg)

实验采用LLaMA-3.2-3B-Instruct（30亿参数）、Phi-4-mini-Instruct（38亿参数）和Qwen-2.5-1.5B-Instruct（15亿参数）三大模型。单张RTX 3090显卡即可完成推理和微调，通过限制序列长度有效规避显存溢出风险。实验流程依次为：基于提示工程的零样本测试→解释增强微调→模型集成实验，并通过消融实验突显训练数据解释增强带来的性能飞跃。

评估体系：采用精确率（Precision）、召回率（Recall）和F1值三大经典指标：

$$
{\mathrm{精确率}}={\frac{真阳性}{真阳性+假阳性}}
$$

$$
\mathrm{召回率}={\frac{真阳性}{真阳性+假阴性}}
$$

$$
F1=2\times{\frac{\mathrm{精确率}\times\mathrm{召回率}}{\mathrm{精确率}+\mathrm{召回率}}}
$$

（TP：真阳性，FP：假阳性，FN：假阴性）
</结果2>

4.1 基础提示工程效果评估

我们选取了LLaMA、Phi等轻量级大语言模型作为基准测试对象。相较于GPT-4等具有数千亿参数的超大模型，这些"小个子"仅有约30亿参数。实验采用提示工程引导模型：先输出推理过程，再用###标记答案。如表1所示，钓鱼邮件被标注为正样本。

研究发现：(1) 基础提示方案在轻量模型上表现欠佳，准确率不足0.7，F1值徘徊在0.5左右；(2) 模型体积直接影响性能，1.5B参数的Qwen模型准确率仅0.388，较3.8B的Phi-4-mini骤降40%。
</结果2>

4.2 解释增强微调效果分析

我们对精选的大型语言模型进行了增强微调实验。从Spam Assassin训练集中抽取1000个样本进行解释增强处理，并采用LoRA技术进行模型微调。实验将微调后的小型语言模型与朴素贝叶斯、支持向量机(SVM)、XGBoost等传统机器学习模型，以及GPT-3.5-Turbo、GPT-4o-mini和LLaMA3.1-70B-Instruct等大模型进行对比。传统方法使用Sentence-BERT的paraphrase-MiniLM-L3-v2模型生成邮件嵌入向量作为特征。详细结果见表2。

微调后的小型模型表现亮眼：LLaMA-3.2-3B-Instruct的准确率和F1值分别跃升至0.963和0.928；Phi-4-mini提升至0.968和0.944；Qwen-2.5-1.5bInstruct准确率暴涨122%。更令人惊喜的是，这些"小个子"甚至超越了参数量级更大的模型——Phi-4-mini的准确率分别领先GPT-3.5-Turbo 27.8%、LLaMA3.1-70B 21.8%、GPT-4o-mini 2.1%。虽然其性能与传统机器学习方法相当，但小型语言模型还能输出人类可读的判断依据，展现出独特优势。实验证明，经过解释增强微调的小模型在钓鱼邮件检测任务中表现卓越，部分指标甚至超越主流方案。

（表2、表3图示说明）

特别值得关注的是，这些精调后的小模型以更少的参数量实现了对大模型的超越，充分验证了我们提出的模型效率优化方法的有效性。
</结果2>

4.3 模型集成




在完成多个大语言模型的微调后，我们通过模型集成来融合不同模型的优势。实验采用置信度加权和多数表决两种集成策略（详见表3），其中置信度加权仅整合LLaMA-3.2-3B-Instruct和Phi-4-mini两个模型，而多数表决则综合了全部三个轻量级模型的表现。





数据显示，集成策略将检测准确率提升至0.975左右，F1分数分别达到0.953和0.959。这不仅增强了钓鱼邮件识别的可靠性，还提升了模型稳定性。不过相较于微调带来的显著提升，集成策略的增益空间较为有限。
</结果2>

4.4 消融实验

本节探讨解释增强数据如何提升小模型识别钓鱼邮件的性能。我们创新性地通过添加邮件分类解释来优化微调数据，使其更贴近大语言模型擅长的开放文本生成模式。为验证效果，我们对比了常规微调与解释增强微调的实验结果（见表4）。

研究发现，缺失解释的微调数据会导致性能大幅下滑：LLaMA-3.2-3B-Instruct准确率暴跌40.7%，F1分数从0.928断崖式跌至0.219；Qwen-2.5-1.5B-Instruct准确率和F1分数分别下降36.4%和26.0%；表现最稳健的Phi-4-mini也出现了15.1%准确率和27.1%F1分数的下滑。这些消融实验充分证明，解释增强能有效将钓鱼邮件检测任务从封闭预测转化为开放生成，从而显著提升微调效果。

表4：解释增强微调(EA)与常规微调效果对比

![](images/1a372caf07022fe9c148a1b7705308c5fd464e3c310a9479a2e201fd98e99827.jpg)
</结果2>

5 研究局限

本方案显著提升了小型LLM在钓鱼邮件检测中的表现，使3B规模的模型性能超越LLaMA-3.1-70B-Instruct等大模型。但受研究条件所限，仍存在以下不足：

• 数据维度：当前仅基于SpamAssassin数据集验证，需扩展更多数据集以充分验证方案普适性
• 迁移能力：未探究模型迁移性能，未来需针对小型LLM设计专项优化方案
• 成本量化：虽小型LLM推理成本优势明显，但尚未建立精确的成本效益评估体系
</结果2>

6 结论  

本研究探索了小型LLM在钓鱼邮件检测中的应用潜力。尽管直接使用小型LLM检测效果欠佳，但我们通过分阶段优化策略显著提升了其性能：首先利用提示工程规范输出格式，引导模型生成附带推理过程的格式化答案；随后采用解释增强微调技术，使小型LLM的检测能力媲美甚至超越传统机器学习方法及参数量大数十倍的LLM；最终通过模型集成实现性能再突破。研究表明，小型LLM不仅能高效完成钓鱼邮件检测，还可提供兼具高性能与可解释性的检测结果。