KG-HTC：知识图谱赋能大语言模型实现高效零样本层次文本分类

作者：Qianbo Zang a,*，Christophe Zgrzendek b，Igor Tchappi a，Afshin Khadangi a 和 Johannes Sedlmeir c

单位：a 卢森堡大学SnT跨学科中心，b 卢森堡Enovos公司，c 德国明斯特大学

摘要。层次文本分类（HTC）需要将文档精准归类到多级标签体系中。传统监督学习方法受限于标注数据稀缺，且面临标签空间庞大、分布长尾等难题。本研究创新性地提出KG-HTC框架，通过知识图谱与大语言模型（LLM）的深度融合，在分类过程中注入结构化语义信息。基于检索增强生成（RAG）技术，系统能动态提取与文本相关的知识子图，使LLM精准捕捉不同层级标签的语义特征。在WoS、DBpedia和Amazon三大开源数据集上的实验表明，该方案在严格零样本条件下显著超越基线模型，尤其在深层分类节点表现突出。这验证了结构化知识对于解决HTC标签空间复杂性和长尾分布问题的有效性。项目代码已开源：https://github.com/QianboZang/KG-HTC

1 引言

文本分类作为自然语言处理的基石任务，旨在为文本分配预定义类别。其中，分层文本分类(HTC)通过多级标签体系将文本归类到具有层级关系的分类框架中。如图1所示亚马逊产品评论案例，一条评论可被逐级归类至"健康个护→家居用品→洗碗用品"的层级路径。HTC已广泛应用于电商分类[4,26]、政务主题建模等场景。

图1. 亚马逊评论的HTC示例

然而实际应用中，HTC面临三重挑战：1) 多层级标注成本高昂，在动态场景(如电商新品上线)尤为突出；2) 标签体系规模庞大(如亚马逊评论含500+叶节点)；3) 数据呈现严重的长尾分布——我们的分析显示，亚马逊评论第三层级中15%的高频类别占据80%数据，而半数尾部类别仅占6%份额。

这些特性使得传统监督学习难以适用[11,13,24]，推动零样本学习方法的发展[2,11,25]。现有方案可分为三类：1) Halder等将分类转化为标签空间的二值判断，但需多次LLM调用；2) Bon giovanni等通过嵌入模型计算文本-标签相似度，并沿层级传播分数；3) Paletto等结合LLM生成新标签层与嵌入分类。但这些方法对深层标签效果欠佳。

本文提出KG-HTC，创新性地将知识图谱融入LLM实现HTC。具体方案：1) 将标签体系构建为DAG知识图谱；2) 通过余弦相似度筛选各层级候选标签；3) 动态检索相关子图，逆向枚举层级路径；4) 将路径转化为结构化提示输入LLM。在三个基准测试中，KG-HTC均创下新纪录，尤其在处理深层标签时性能下降幅度较前人方法减少35%以上。

主要贡献：
1. 首创知识图谱与LLM融合的HTC解决方案
2. 开发语义子图检索与结构化提示生成框架
3. 在多个数据集实现零样本SOTA性能

下文结构：第2章方法详述，第3章实验设计，第4章结果分析，第5章相关研究，第6章总结展望。

2 方法论

2.1 问题界定

大型语言模型（LLM）的零样本文本分类任务，本质上是将分类问题转化为文本生成任务。给定输入文本序列$x=(x_1,x_2,...,x_n)$（$n$为文本长度），LLM通过Top-p采样策略生成输出文本$y\sim LLM(x)$。在分类场景中，生成文本$y$可映射至预设标签集$C$中的某个预测标签$\hat{c}$。

本研究采用Paletto等人的数学框架（关键符号见表1）。分层文本分类将标签空间$C$组织为$L$层级的树状结构$C=(C^1,C^2,...,C^L)$。我们沿用的箭头符号：$\uparrow c_i^l$表示$c_i^l$的父标签，$\downarrow c_i^l$表示其子标签。所有非根层级标签$c_i^l$必须满足$\uparrow c_i^l \in C^{l-1}$的结构约束。该任务要求LLM迭代生成层级预测结果$(y^1,...,y^L)$，对应各层标签$(\hat{c}^1,...,\hat{c}^L)$，其中$\hat{c}^l \in C^l$。

表1. 符号说明
（图表示意从略）

图3. 基于亚马逊评论数据构建的多层级知识图谱可视化：红色节点（一级分类）、绿色节点（二级子类）、黄色节点（三级叶节点）通过树状结构呈现层级关系。

2.2 系统架构  

图2展示了KG-HTC的完整工作流程：  
1. 存储阶段：将所有标签分别存入图数据库和向量数据库  
2. 检索阶段：根据输入文本，从向量库获取各层级l的候选标签Q^l，同时通过验证跨层级候选标签的父子关系，从图库提取有效子图  
3. 提示构建：将子图中的路径网络转化为结构化提示，并与分类指令拼接  
4. 分类执行：采用上下文学习技术实现零样本文本分类  

![](images/9a4d39af85bef60ba7c9f54ef4523ae4001677005acad28ead15410405abd4ef.jpg)

2.3 层级标签存储方案  

首先，我们将所有标签分别存入图数据库和向量数据库。在层级文本分类任务中，标签体系可抽象为有向无环图（DAG）知识图谱，各层级标签通过树状关联关系彼此联结。通过清晰定义层级间的关联路径，大语言模型（LLM）能够结构化理解每个标签及其在分类体系中的概念边界。以图3为例，输入内容可能被归类为"洗碗"或"清洁剂"，但根据亚马逊产品评论数据集的分类体系，"清洁剂"属于"浴室洗护"的子类，其概念范畴应限定在"人体清洁用品"范围内。此时，LLM就能准确判定"洗碗"为正确分类。这种图式知识表达为LLM带来双重增益：既为文本处理构建了明确的语义导航路径，又通过优化语义消歧，在零样本场景下形成可显著提升分类精度的拓扑约束。

2.4 子图检索

研究表明，检索增强生成（RAG）框架在开放问答任务中优势显著[10,14,17]。面对层次文本分类（HTC）中标签体系庞大的核心挑战，RAG通过上下文相似性比对，从向量库动态抓取相关文档，大幅提升回答的准确性。

文献指出，大语言模型处理长文本和大规模分类任务时存在瓶颈。若将整个知识图谱直接输入模型输入：文本$x$，算法1所得子图$G$输出：层级路径集$\{P_{1},P_{2},...\}$初始化$P\leftarrow\emptyset$遍历每个叶节点$c_{i}^{L}$初始化栈$S=\{[c_{i}^{L}]\}$自底向上压入父节点至$S$最终合并$S$到$P$返回路径集$P$

易因信息过载导致性能衰减。为此，我们创新提出RAG增强框架：根据输入文本实时检索知识图谱中的语义相关子树，将其转化为上下文提示，使分类器聚焦核心层级关系，过滤无关噪声（详见2.5节）。

具体实现时，逐层计算文本嵌入与标签的余弦距离：

$$
d(x,c_{i}^{l})=1-\frac{\Psi(x)\cdot\Psi(c_{i}^{l})}{\|\Psi(x)\|\|\Psi(c_{i}^{l})\|}
$$

其中$\Psi$为嵌入函数。筛选每层相似度超过阈值$\tau_l$的候选：

$$
Q^{l}=\{c_{i}^{l}\,|\,d(x,c_{i}^{l})\leq\tau_{l}\}
$$

并通过父子关系校验层级一致性——候选标签$c_{i}^{l}$的父节点必须存在于上层候选集$Q^{l-1}$中。算法1完整呈现了该动态检索机制。

2.5 子图到提示的智能转换

给定输入文本$x$，我们先用算法1提取子图$G$。为了将知识图谱高效融入大语言模型，我们创新性地采用"图结构转路径集"策略——把每个子图序列化为从根节点到叶节点的层级路径。这种链式表达既保持了图结构特征，又完美适配大语言模型的序列输入要求。在层次分类任务中，路径长度正好对应分类体系的深度$L$。

由于大语言模型无法直接解析图数据，我们设计了巧妙的转换方案：用图中的路径作为理解推理的提示线索。通过自底向上的传播算法，系统会保留子图中所有有效的层级标签路径作为上下文提示。该算法以循环遍历的方式，从最底层的任一节点$\forall c_{i}^{L}\in C^{L}$出发，沿着父节点指针溯源至根节点（算法2），再回溯探索其他分支，确保穷尽所有合法路径组合。最终，我们会反转每条路径$P_{i}$的节点顺序，使所有输出路径$P=\{P_{1},P_{2},...\}$都保持从顶层到底层的统一方向。其中每条路径$\mathbf{\dot{P}}_{i}=(p_{i}^{1}\rightarrow p_{i}^{2}\rightarrow...\rightarrow p_{i}^{L})$都代表一个连贯的节点序列（$p_{i}^{l}\in G$且$p_{i}^{l}\in C^{l}$）。

我们创新地用"→"符号连接相邻层级的节点，将子图路径转化为结构化提示。这种设计让大语言模型在分类时能自动感知层级约束。文中的提示1展示了亚马逊评论数据集的多级标签路径实例。

2.6 层级分类方案  

我们创新性地结合检索子图的结构化上下文与分类提示模板，通过上下文学习和提示工程驱动大语言模型（LLM）推理。以提示2中的亚马逊产品评论模板为例，直观展示了这一技术路径。  

针对分层文本分类（HTC），我们设计逐层递进策略：模型先锁定首层标签，再层层深入直至最终层级。面对海量候选标签的挑战，研究表明单提示全量注入会导致性能滑坡。我们巧妙利用首层标签稀少性（评估集均≤10个），将其完整嵌入提示，既简化流程又提升精度。  

深层分类时，模型将上层预测$y^{l}$作为刚性约束——第$l+1$层候选集以$\downarrow\boldsymbol{y}^{l}$子类为核心，搭配公式2检索的$Q^{l+1}$动态补全。这种设计既能消化前层预测误差，又显著增强整体分类的稳健性与准确度（详见算法3）。

提示1：亚马逊商品评价数据集关系图谱




宠物用品 → 猫 → 猫门
宠物用品 → 狗 → 门栏
宠物用品 → 猫 → 项圈
宠物用品 → 猫 → 猫砂盆
婴儿用品 → 安全 → 防护门
婴儿用品 → 安全 → 安全背带
婴儿用品 → 安全 → 浴室防护
宠物用品 → 猫 → 喂水器
婴儿用品 → 安全 → 橱柜锁
玩具游戏 → 毛绒玩具 → 玩偶
宠物用品 → 狗 → 狗屋
婴儿用品 → 安全 → 睡姿固定器
婴儿用品 → 如厕训练 → 踏脚凳
玩具游戏 → 毛绒玩具 → 背包
宠物用品 → 猫 → 宠物推车
婴儿用品 → 装备 → 摇椅

提示2：亚马逊商品评论分类模板  

将商品评论归入以下类别之一：{类别文本}。请直接输出类别名称，勿添加引号或转义符。  

部分知识图谱如下："""  

{知识}  

此流程完整呈现了KG-HTC的工作机制。

3 实验环节

3.1 数据集  

**亚马逊产品评论（Amazon）**  
收录亚马逊平台商品评论，每条数据含标题与描述，需按三级分类体系标注（标签数分别为6、64、510）。  

**科学网（WoS）**  
聚焦科研文献，涵盖自然科学、社会科学、人文艺术等多领域数据，广泛应用于学术研究及文献分析。数据采用二级分类体系（标签数分别为7、134）。  

**DBpedia **  
基于维基百科构建的开放式知识库，通过结构化处理维基百科海量信息，形成支持跨域知识检索的复杂知识图谱。数据采用三级分类体系（标签数分别为9、70、219）。

3.2 评估指标




我们选用F1宏平均作为核心评估指标，通过计算各类别F1分数的算术均值得出。该指标赋予稀有类别同等权重，有效避免样本不均衡场景下的性能高估问题。其数学定义为：  





$$


\mathrm{F_{1}-宏平均}=\frac{1}{C}\sum_{i=1}^{C}\mathrm{F}_{1i}


$$  





式中$C$为总类别数，第$i$类的F1分数是精确率与召回率的调和均值：  





$$


\mathrm{F}_{1i}=2\times{\frac{\mathrm{精确率}_{i}\times\mathrm{召回率}_{i}}{\mathrm{精确率}_{i}+\mathrm{召回率}_{i}}}


$$  





针对大规模标签空间与长尾分布的双重挑战，我们基于算法6设计了平均衰减率指标。随着分类层级的深入，标签空间扩张与数据偏差加剧的问题可通过该指标量化：  





$$


\mathrm{衰减率}_{i}=\frac{\mathrm{F}_{1}\mathrm{宏平均}(i-1层)-\mathrm{F}_{1}\mathrm{宏平均}(i层)}{\mathrm{F}_{1}\mathrm{宏平均}(i-1层)}


$$  





$$


\mathrm{平均衰减率}={\frac{1}{L-1}}\sum_{i=2}^{L}\mathrm{衰减率}_{i}


$$

3.3 实验配置

基准对比。我们选取两类基准进行方法评估：弱基准采用LLM直接逐层分类数据点；强基准则选用第2节介绍的Z-STC和HiLA方案[2,25]，这两项研究代表了严格零样本场景下的前沿水平。

实验参数。为保持对比一致性，我们选用GPT-3.5-turbo模型，配置text-embedding-ada-002作为RAG系统的嵌入引擎。图数据库采用Ω∈O4架构，向量数据库选用ChromaDB。

全局实验设定中，GPT-3.5-turbo的温度参数和Top-p值均设为0.4，以保障输出稳定性。RAG系统的相似度阈值τl经实验调优：Dbpedia与Amazon数据集在二、三级分别保留10和40个候选标签，WoS数据集在二级保留20个候选标签。

针对LLM生成结果的随机性问题，当输出超出预设标签空间时，我们采用固定随机种子42进行标签空间采样转换，确保结果可复现。

表3显示，在错误样本中，RAG系统的Hit@K指标在二、三级分类时均出现下降。

4 研究成

4.1 核心发现

表2数据显示，KG-HTC方案在弱基线和强基线上均展现出稳定且显著的性能优势。

相较于单独使用GPT-3.5-turbo（弱基线）的零样本分类，KG-HTC实现了质的飞跃：一级分类平均提升27.1%，二三级分类更分别飙升123.1%和139.0%。这印证了知识图谱与LLM的融合能大幅提升层次分类效果，且层级越深提升越显著，尤其在处理高阶抽象信息时优势明显，成功攻克了标签空间庞大和长尾分布等难题。

图4清晰显示，在WoS和Amazon数据集上，随着分类层级加深，KG-HTC的性能衰减最小，且与三类基线的差距持续拉大。这再次验证了本方案在应对层次分类挑战时的卓越表现。

4.2 错误解析

$\operatorname{Hit}@\operatorname{K}$指标反映检索器在前K个结果中命中正确答案的概率。如第3节所述，我们对Dbpedia和Amazon数据集采用$\mathrm{Hit@10}$（二级分类）和$\mathrm{Hit@40}$（三级分类），WoS数据集则使用$\mathrm{Hit@20}$（二级分类）。表3数据显示，RAG系统在误分类样本的二、三级$\operatorname{Hit}@\operatorname{K}$指标均呈现下滑趋势。这表明系统性能下降的主因是推理时未能捕获正确子图——当检索知识与输入文本或分类任务匹配不足时，模型缺乏精准推理所需的上下文支撑，从而更易产生误判。此外，错误子图引入的噪声会进一步干扰模型的标签判别能力。这也预示着，随着信息检索技术（特别是精准检索相关领域）的发展，KG-HTC性能仍有提升空间。

表4：子图检索效果对比（FullKG方法采用全图谱检索替代RAG子图检索）

（表4配图）

表5：开源模型Qwen2-5.8b效果验证

（表5配图）

4.3 消融实验  

我们采用随机种子42，从各评估数据集中分别抽取5000个样本进行实验。  

子图检索的增效作用。实证显示，通过RAG引入知识图谱可显著增强LLM在层次文本分类（HTC）中的表现。本实验重点评估子图检索模块：移除原RAG系统的子图提取功能（其他模块保持不变），改为向LLM直接输入完整知识图谱（Full-KG方案）。  

如表4所示，除一级分类外，KG-HTC的F1-macro指标全面超越Full-KG。这是因为一级分类标签较少，完整图谱能更清晰呈现标签语义关联；但随着标签维度增加，子图检索机制可帮助LLM精准抓取关键信息，有效规避长文本输入的性能衰减。  

开源模型的适配性。将基座模型从GPT-3.5-turbo替换为Qwen2.5-8b后（表5），KG-HTC在Amazon数据集一级分类外的场景均展现出性能提升，证实该方法对开源LLM具有优秀的泛化能力。

5 相关研究

层次化文本分类。HTC任务由Sun和Lim首创，他们采用支持向量机分类器作为解决方案。随后Kowsari团队探索了深度学习方案，为分类体系各层级训练不同的深度神经网络。近年来Liu团队创新性地引入知识图谱增强技术，通过图神经网络(GraphSAGE)编码知识图谱，并与BERT文本嵌入进行联合微调，该方法目前是监督学习的标杆方案。但工业场景中，监督学习面临标注数据匮乏的困境——跨层级标注的成本往往令人望而却步。随着大语言模型性能的突破性提升[31,20,28,32]，零样本推理正在多个领域崭露头角[3,12,19,35]。

零样本HTC研究。近期三项工作与我们的严格零样本设定高度契合。Halder等人提出的任务感知表示法，将任意文本分类任务转化为二分类问题：给定文本和标签集，由大模型判断标签匹配性(输出True/False)。但面对HTC庞大的标签空间，该方法需多次迭代才能完成分类。

Bongiovanni团队开发的Z-STC框架采用"分数向上传播"(USP)机制：基于BERT、RoBERTa等预训练模型，将文档与标签映射到同一语义空间，通过余弦相似度计算关联度，并沿分类树自底向上传递分数——子标签的高相关性会提升其父节点的得分。这种层次化分数整合策略显著提升了分类性能。

Paletto等人提出的HiLA方法另辟蹊径：使用大模型为标签树的叶节点动态生成子标签。为避免直接处理完整层次结构导致的标记冲突，他们采用迭代式生成策略。结合Z-STC在新生成的深层标签上应用，HiLA成为当前严格零样本设定的最佳方案。但如第4节所示，Bongiovanni和Paletto的方法在深层标签上准确率骤降——随着分类层级加深，标签空间急剧膨胀且分布愈发偏斜。

检索增强技术。RAG能在推理时动态检索外部知识库，其图结构变体Graph RAG通过知识图谱获取关联实体，二者在开放域问答中表现亮眼[9,27]。但将这些技术应用于文本分类的研究仍属凤毛麟角。

6 结论

传统有监督的层次文本分类（HTC）方法在工业落地时面临诸多挑战。为此，我们创新性地提出了KG-HTC——一种融合知识图谱与大语言模型（LLM）的零样本HTC方案。该方案通过动态检索与文本语义相关的知识子图，并构建结构化提示模板，在严苛的零样本条件下依然实现了分类性能的显著提升。实验数据显示，KG-HTC在Amazon、WoS和Dbpedia三大基准数据集上均达到业界最优水平，尤其在深层标签分类任务中表现尤为突出。

本研究存在一个关键局限：假设标签分类体系必须完整且正确。这意味着知识图谱中的任何瑕疵都可能影响方法效果。未来我们将重点探索如何借助大语言模型，更高效地构建精准可靠的知识图谱。这些评估数据集还可用于大语言模型的微调阶段。

伦理声明




本文研究不存在伦理问题。所使用的LLM数据库及Kaggle评估数据集均开放用于学术研究。

致谢




本研究获得卢森堡国家研究基金（FNR）部分资助（项目编号14783405），并与Enovos Luxembourg S.A.合作完成。为践行开放获取承诺，作者已对相关成果采用知识共享署名4.0国际协议（CC BY 4.0）许可。