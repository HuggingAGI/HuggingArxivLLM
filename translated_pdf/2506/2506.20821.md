Multi Fin RAG：面向金融问答的优化多模态检索增强生成框架  

预印本  

作者：  
Chinmay Gondhale | Urjitkumar Patel | Fang-Chun Yeh  
机构：标普全球评级（美国纽约）  
邮箱：  
chinmay.gondhale@spglobal.com  
urjitkumar.patel@spglobal.com  
jessie.yeh@spglobal.com  

（说明：1. 框架名称保留英文原名更专业；2. 优化了作者信息排版；3. 删减冗余表述使更简洁）

摘要

财务文档（如10-K年报、10-Q季报和路演材料）往往长达数百页，包含叙述文本、结构表格和复杂图表等多种模态内容。要回答这类问题，常需跨模态联合推理，但传统大语言模型（LLM）和检索增强生成（RAG）方案受限于token容量、版式丢失和上下文碎片化。为此，我们推出Multi Fin RAG——专为金融QA打造的多模态增强框架。该框架先进行多模态提取：将表格图表批量输入轻量化的开源多模态LLM，同步生成结构化JSON数据和精炼文本摘要。这些输出与文本内容通过模态感知的相似度阈值进行智能索引，实现精准检索。独创的分级回退机制能动态切换纯文本/图文混合模式，在精简无关信息的同时完成跨模态推理。即便在消费级硬件上，Multi Fin RAG在涉及多模态推理的复杂金融QA任务中，准确率较ChatGPT-4o（免费版）显著提升19个百分点。

核心关键词  
检索增强生成（RAG）｜多模态推理｜大语言模型｜自然语言处理｜金融智能问答｜PDF文档解析｜深度学习

1 引言

当代财务报告动辄上百页，融合了密集文字、结构化表格和复杂图表。以摩根士丹利最新10-Q文件为例，这份120页的报告包含275+表格和近200张图表。对这些文件进行精准问答（QA），是风险监控、合规审查和投资决策中分析师、审计师及金融智能体的核心需求。然而，此类文档的查询处理对LLM和传统检索增强生成（RAG）系统构成双重挑战：

篇幅瓶颈：文档长度突破LLM的token上限，既推高API成本，又使端到端处理难以实现。
格式困境：表格和图表若被粗暴转为纯文本，其内在关联与数值语境将荡然无存，而这恰恰是财务QA的关键。

传统RAG虽通过片段检索缓解篇幅问题，但存在三大缺陷：
- 固定分块导致语义断裂，数值上下文支离破碎
- 将表格图表视同普通文本，牺牲结构化关系
- 静态top-k检索常返回低质片段，拉低答案精度

为此，我们推出Multi Fin RAG框架，带来三大革新：

多模态批量解析：轻量级多模态LLM处理表格图表群，输出结构化JSON与精要摘要，完整保留数值关联与视觉线索
智能语义重组：基于向量相似度融合过度分割的文本块，并通过FAISS实施模态差异化阈值检索（文本80%/图像65%），精准过滤无关内容
动态分级检索：优先匹配高相关文本；当结果不足时，自动触发"文本+表格+图像"三维检索，确保无遗漏覆盖

2 相关研究

大型语言模型（LLM）与决策流程的深度融合，催生了检索增强生成（RAG）系统的蓬勃发展，有效弥补了LLM在专业领域和动态场景中的知识短板。以10-K和8-K为代表的金融监管文件尤为特殊：篇幅冗长、多模态交织（文本/表格/图表）、语义信息分散分布，这对传统RAG系统提出了严峻挑战——它们往往难以综合多源信息进行精准作答。

开源多模态技术的突破性进展（如Meta的Llama-3.2-11BVision-Instruct、Google的Gemma和DeepSeek）让我们能够摆脱商业工具束缚，构建强大的多模态RAG管道。如今的RAG系统已从初代的简单问答框架脱胎换骨：动态检索策略、智能分块机制、内容分级组织等创新层出不穷。

其中，SELF-RAG赋予模型自省式检索优化能力；T-RAG创新采用树状实体结构进行层级检索；MoG与DRAGIN则能根据查询特征动态调整分块粒度；而Late Chunking通过延迟分块策略显著提升检索对齐效果。

在开放域问答领域，基于双编码器的密集段落检索（DPR）始终保持着标杆地位。eRAG等评估框架开创性地将检索质量与生成效果挂钩，ClashEval则专门测试模型在噪声检索下的鲁棒性。

PDFTriage研究揭示：简单将PDF转为纯文本会丢失关键版式信息，其提出的版式感知检索技术大幅提升了图表问答准确率。金融领域的Fin-RAG通过树状检索结合元数据聚类，将结构化文档的处理精度推向新高。

然而现有系统仍存在明显短板：面对需要跨模态协同推理（如同时解析文本、表格、图表）的复杂问题时力有不逮。大多数方案仅能检索相关片段，缺乏跨模态信息对齐与融合的机制。

为此，我们推出Multi Fin RAG系统：通过近似最近邻检索、模态感知过滤、分层回退策略的有机组合，实现对金融文档的精准解析。该系统创新性地保持了长篇幅PDF中文本、数据与可视化元素的对齐关系，突破了现有检索增强技术的核心瓶颈。

3 方法概述

3.1 模型与工具选型

我们采用专用模型与通用模型的组合方案，以应对金融文档的多模态处理需求：

• 表格识别：基于TableBank预训练的Ron 2 Layout模型精准提取表格结构

• 图表定位：Pdfminer的LTImage/LTFigure布局解析引擎

• 多模态摘要：选用前沿开源模型Gemma3:12B和LLama 3.2:11B，将表格图像批量转换为结构化JSON/文本摘要

• 向量嵌入：基于Sentence Transformer的BAAI/bge-base-en-v1.5模型生成文本、表格及摘要的语义向量

• 近似检索：采用FAISS的IVF-PQ索引实现高效近邻搜索

• 大模型部署：通过Ollama框架集成两款量化多模态模型：
   - Gemma3:12B：在文本/表格/图像的多模态推理中表现卓越，量化后显存降低65%（24GB→8.4GB），精度损失<10%
   - LLaMA-3.2-11B视觉版：集成图像编码器的开源模型，量化后实现单GPU流畅部署

3.2 基准框架




为验证本方案的性能优势，我们基于传统RAG流程构建了强效基线：





 •  基础配置：采用固定尺寸文本块的标准检索增强生成流程，不含语义融合功能





 •  检索机制：嵌入模型与Multi Fin RAG一致（BAAI/bge-base-en-v1.5），但仅通过FAISS IVF-PQ从固定文本块中检索，未采用分级逻辑





 •  模态处理：图表数据未经专门处理——视觉元素与表格均以原始文本形式保留或直接忽略，未进行结构化JSON转换或图像描述生成

3.3 多模态Fin RAG系统方案

3.3.1 系统概览
如图1所示，我们将每个PDF文件$F_i$智能分割为三类可检索数据块：
$$C_i = C_i^{ext} \cup C_i^{table} \cup C_i^{image}$$
其中$C_i^{ext}$是语义连贯的文本段落，$C_i^{table}$和$C_i^{image}$则是通过多模态LLM转换的表格与图像区域。所有数据块经向量化后存入FAISS近似索引。当用户发起查询$Q$时，系统会启动分级检索机制（先纯文本，后文本+表格/图像），在上下文不足时自动升级检索范围，最终由LLM生成答案。

3.3.2 语义分块与索引
我们采用以下方法确保语义完整性：

1. 句子切分：将文本分解为句子集合$S=\{s_1,...,s_n\}$
2. 滑动窗口：以窗口$w$和重叠$o$生成连续文本块
   $$B_i=\{s_i,...,s_{i+w-1}\}, i=1,1+(w-o),...$$
3. 语义边界检测：
   - 计算句子向量$e_j=E(s_j)$
   - 通过余弦距离$d_j$识别语义断点（取前5%突变点）
4. 分块优化：
   - 合并相似度>0.85的冗余块
   - 最终构建FAISS HNSW/IVF-PQ索引，支持百万级数据的亚秒检索

通过语义聚合与去重，平均减少40-60%的上下文规模，在保证质量的同时显著降低计算开销。

3.3.3 批量多模态处理
算法1详细说明了PDF解析流程：

1. 区域检测：使用Detectron2识别表格/图像区域
2. 文本处理：
   - 提取原始文本并分句
   - 执行语义分块与向量化
3. 批量解析：
   - 表格：分批次生成描述文本与JSON结构
   - 图像：批量生成摘要描述
4. 容错机制：
   - 对遗漏内容自动重试单文件解析
   - 确保100%内容覆盖率

关键技术亮点：
- 多模态提示工程提升批量处理效率
- 向量索引实现跨模态联合检索
- 自动回退机制保障处理完整性

图5：第三类问题示例

批量图像摘要处理：
• 将图表等图形区域$V$分$\lceil|V|/B\rceil$组批量处理
• 每批次$v_{b}$发送提示，要求生成3-6句摘要（忽略logo等非数据元素）
• 摘要$\{sum_{j}\}$经嵌入处理后存入图像索引$\varPi_{\mathrm{image}}$
• 缺失摘要自动转为单图处理，确保数据图形全覆盖

批处理优势：
- 分摊LLM调用成本
- 保持文件名与输出精准对应
- 存根机制确保无遗漏
- 所有嵌入数据分文本/表格/图像存入FAISS索引

3.3.4 智能检索策略
参数设置（经测试优化）：
- 文本块$n=6$
- 表格块$m=4$ 
- 图像摘要$p=3$

四步检索流程：
1. 纯文本检索：$\mathcal{T}=\{c|cos(e_Q,E(c))\geq0.7\}$，达标则直接调用LLM
2. 表格补充：取相似度Top4表格$\mathcal{T}_{\mathrm{tbl}}$
3. 图像补充：取相似度Top3图像$\mathscr{T}_{\mathrm{img}}$
4. 组合查询：合并有效结果后发起最终LLM调用

保障措施：
- 使用FAISS近似检索
- 系统提示避免AI臆测
- 全流程计时监控

3.3.5 阈值优化方案
通过测试集调优得出最优阈值：
1. 文本阈值：0.55→0.85步进测试，最终$\theta_{\text{text}}=0.70$
2. 表格/图像：固定文本阈值后双参数扫描，得$\theta_{\text{table}}=0.65$，$\theta_{\text{image}}=0.55$

选择标准：
- 最大化"相关性+准确率"综合指标
- 控制单次查询数据量

最终形成智能检索策略：
- 优先文本检索（阈值0.7）
- 不足时补充表格（0.65）/图像（0.55）
- 完美平衡精度与覆盖率

图6：第四类问题示例

4 效果评估




检索指标说明：本研究重点关注端到端问答的准确率。虽然开发过程中已记录检索模块的各项指标（如精确率、召回率等），但受篇幅所限在此不作详述，相关数据将在后续论文中专门呈现。

4.1 数据集

为开展评估，我们从多家公司收集了四类财务文件：10-Q季度报告、10-K年度报告、含EX-99.1的8-K现况报告以及DEF 14A代理声明。这些文件均通过SEC的EDGAR数据库（https://www.sec.gov/edgar/search/）获取，并借助SEC API转换为PDF格式。我们精心设计了符合难度标准和质量要求的测试问题。

为确保系统准确解析文件内容，我们设置了四类难度递增的问题：基础文本题、图像解析题、表格分析题，以及需要综合文本与图像/表格的复合推理题。具体分布如下（见表1）：
- 文本题：146道
- 图像题：42道  
- 表格题：72道
- 复合推理题：40道

表1：多金融RAG在各题型中的表现对比

4.1.1 文本题
这类问题可直接从文本中获取答案。例如根据家得宝10-Q报告所述"2024财年Q1美元贬值使净销售额增加1.06亿美元"，我们设计问题："美元贬值对当季净销售额的提振金额（百万美元）？"标准答案为"106"。所有答案均设计为数值或简明术语以确保评估准确性。

4.1.2 图像题
考查对财务图表的解析能力。如图4所示，基于摩根士丹利10-Q中的柱状图，我们提问："本季度每日95%单日风险价值(VaR)峰值区间？"正确答案"50-55"需通过识别柱状图极值得出。设计时确保答案不会在文本中重复出现。

4.1.3 表格题
测试表格数据处理能力。以摩根士丹利10-Q中的表格为例（图5），问题"截至2025/3/31的受限现金金额（百万）？"的答案"29,904"需精确定位行列交叉点。同样验证该数值不会在文本中二次出现。

4.1.4 复合推理题
最具挑战性的题型，需跨模态信息整合。例如（图6）：
1. "照明部门产品线截至2024/4/28的净销售额（百万）？"解题路径：先通过文本确认产品线归类为"装饰"，再查表得对应数值"12,344"
2. "Sasan K. Goodarzi截至2023/7/31的非合格递延补偿计划余额（美元）？"需先识别表格中"NQDCP"缩写，再定位具体数值"11,400,690"

4.2 评估策略




评估大型语言模型（LLM）框架的输出仍是一个亟待突破的研究领域。传统的"标准答案完全匹配"评估方式已难以胜任LLM结果的评判，因为确保生成答案与参考答案完全一致极具挑战性。例如，即便数据集中多数答案是简单数值，单位表述也可能存在差异——参考答案是"10亿"，而模型可能输出"1000百万"。  





流行的BERTScore评估法通过计算语义相似度来评分，但这对我们的数值型问题并不适用。毕竟，将纯数字进行语义嵌入和相似度比较缺乏实际意义。  





近期兴起的使用LLM评估生成式AI结果的方法[13,14]也面临挑战：评估模型自身存在固有偏见。虽然这种方法适合海量问答对评估，但考虑到数据集规模和资源限制，我们最终采用人工评估方案，以确保结果精准可靠，最大限度降低误判风险。

4.3 性能对决：传统方案 vs 多模态Fin RAG

4.3.1 文本类问题
表1揭示两大发现：
首先，采用多模态Fin RAG后准确率大幅跃升。以Gemma 3为例，新方案（90.4%）较传统方案（75.3%）提升15.1%，这得益于其创新的IVF/PQ FAISS索引技术，能实现亚秒级精准检索，彻底解决了传统方案检索碎片化的问题。

其次，Gemma 3全面碾压Llama模型，在文本问题上以90.4% vs 83.6%的绝对优势胜出，展现出更强的信息提炼能力。

4.3.2 图像类问题
传统方案在图像解析上彻底失灵，印证了其设计缺陷。而多模态Fin RAG架构下，Gemma 3以66.7%的准确率完胜Llama的42.9%，彰显出卓越的图像描述能力。

4.3.3 表格类问题
传统方案在表格处理上同样溃败。Gemma 3凭借出色的表格解析能力，将准确率从Llama的13.9%提升至69.4%，实现近五倍的性能飞跃。

4.3.4 图文混合类问题
在最具挑战的复合型问题上，Gemma 3以40% vs 10%的碾压优势，验证了其多模态处理实力。从传统方案的0分到新方案的40分突破，多模态Fin RAG交出了惊艳的答卷。

4.4 与ChatGPT-4o的性能对标

我们针对多种题型对比了Multi Fin RAG与ChatGPT-4o的表现。选择ChatGPT-4o作为基准，不仅因其强大的通用推理能力，更因其免费版本的高普及度，这使其成为评估我们专业领域多模态问答系统的理想参照。

![](images/851ccb72be0480a39ea97ffadb140a9cec48b1b08698f007a99349f2438498f9.jpg)  

图7：分题型准确率对比

4.4.1 文本类问题  
如图7所示，搭载Gemma 3的Multi Fin RAG准确率仅比ChatGPT-4o高出4.1%。但值得注意的是，在部分案例中，当ChatGPT-4o出现误判时，我们的系统仍能给出正确答案。例如面对以下财务陈述：

"截至2025年3月31日，公司持有至到期证券组合中98%为投资级美国机构证券......"

正确答案应为"98%"，而ChatGPT-4o却错误输出"100%"，推测是文档中多个数值干扰所致。

4.4.2 图像类问题  
在图像题型上，搭载Gemma 3的Multi Fin RAG展现出40%以上的准确率优势。如图4所示案例，正确答案区间应为"50-55美元"，但ChatGPT-4o却误读为"63-98美元"，这显然是将文件中其他无关数值当作了答案。

4.4.3 表格类问题  
处理表格数据时，我们的系统准确率领先25%以上。典型案例如图5所示：ChatGPT-4o声称"摩根士丹利受限现金为0百万美元"，但经核查该信息并未在文件中出现，说明模型可能混淆了自身训练数据与当前文档。

4.4.4 多模态问题  
在需要结合文本与图像/表格分析的复合题型中，MultiFinRAG以75.3%的准确率完胜ChatGPT-4o的56.0%。研究发现：当涉及常识性知识（如图6例2中的"NQDCP"缩写），ChatGPT-4o能正确应答；但面对专业领域的新信息（如图6例1），其表现就大打折扣。

4.5 效率与成本  

本次评估聚焦准确性而非耗时，因为处理时间高度依赖底层硬件（如算力与系统配置）。实测显示：在16GB内存的Google Colab T4 GPU环境下，MultiFinRAG+Gemma 3解析含200页PDF/200表格/150图片的金融文件，平均需25分钟。  

成本方面，基准系统与MultiFinRAG均可通过Google Colab免费版运行，实验全程零开销。作为对照组的ChatGPT4o结果同样基于免费版本生成，无额外支出。

5 讨论与未来展望

Multi Fin RAG在解析复杂金融文档时展现出卓越的效能，但仍有多项升级空间值得探索：

• 模块评估：通过系统性消融实验（如关闭批量提取或分级回退功能），精确量化各模块贡献值

• 用户反馈：当前300组QA对均经金融专家人工核验，后续将开展大规模用户研究以优化使用体验

• 智能表格处理：正在开发新型数据管道，可将CSV/Excel等异构表格标准化为轻量数据库，支持自然语言精准查询，并直接转化为RAG的结构化上下文

• 跨文档分析：针对财报对比等场景，将构建：1）支持时序关联的多文档索引 2）智能配对检索功能（如季度数据对比）3）自动化趋势图表与差异解读

• 容错增强：通过：1）多OCR引擎协同定位 2）数据一致性校验（如金额合计验证）3）微调LLM校对模块，提升低质量文档的解析准确率

• 领域扩展：方案可适配招股书、电话会议记录等多元场景，通过模块化设计应对各领域特有的版式与数据特征

• 模型优化：计划采用：1）对比学习强化检索模型 2）LoRA轻量化微调技术 3）专业金融QA数据集，持续提升系统性能

• 实时多模态：拟新增：1）无头浏览器实时抓取 2）智能表格提取（DOM解析+OCR备用方案）3）图形信息批量摘要 4）多模态数据融合检索，打造覆盖网络资讯的实时金融问答引擎

这些升级将使Multi Fin RAG从PDF处理专家进化为全能型金融分析平台——支持海量数据、趋势追踪、实时更新与智能纠错，全程通过自然语言交互实现。

6 结论

Multi Fin RAG在应对海量多模态PDF金融文件的复杂查询时表现卓越，其精准度超越ChatGPT-4o，尤其在处理含文本、表格和图像的综合问题时。该框架创新性地融合了模态感知检索机制与轻量化开源大模型，在普通硬件上即可高效运行——不仅节省了60%以上的token消耗，还显著提升了响应速度。面对高难度的多模态QA任务，其准确率突破75%，为金融大文档的智能查询提供了兼具实用性、扩展性和性价比的多模态推理方案。