MCP服务器评估报告




罗志凌，石晓蓉，林轩睿，高晋阳 2025年4月13日

执行摘要  

1. 不同MCP服务器在效能与效率上存在显著差异；与直接函数调用相比，使用MCP并未展现出明显优势。  
2. 通过优化需要由大语言模型构建的参数，可有效提升MCP服务器的运行效能。  

（说明：根据技术文档翻译规范，对术语进行了统一处理："effectiveness and efficiency"译为"效能与效率"以区分技术指标；"LLM"采用行业通用译法"大语言模型"；通过增补"运行"使第二点译文更符合中文技术报告表述习惯；保留"MCP"专业缩写确保术语一致性）

1 引言  

模型上下文协议（Model Context Protocol，MCP）[1]是一种开放协议，使AI模型能够通过标准化的服务器实现安全地与本地及远程资源交互。近几个月来，已有数千种MCP方案被提出。与此同时，OpenAI、阿里云等多个模型平台宣布在其大语言模型产品中支持MCP协议，MCP协议的爆发式应用已成为现实。  

为研究MCP服务器的效能与效率，我们选取了多个广泛使用的MCP服务器，通过MCPBench工具对其准确性、响应时间及token消耗进行了实验评估。研究聚焦于两项任务：网络搜索与数据库搜索。前者通过互联网检索回答问题，后者则从数据库中获取数据。所有MCP服务器均在受控环境中使用相同的大语言模型和提示词进行对比测试。我们重点探究以下问题：  

• 问题1：MCP服务器在实际应用中是否高效可靠？  
• 问题2：与函数调用相比，MCP是否能提供更高准确性？  
• 问题3：如何进一步提升性能？  

针对这些问题，我们提出了名为MCPBench的评估框架（开源地址：https://github.com/modelscope/MCPBench），并同步发布了网络搜索与数据库搜索的测试数据集。  

（注：根据学术文本特征，译文采用以下处理：  
1. 技术术语保留英文缩写并添加中文全称（如MCP）  
2. 长句拆分为符合中文表达习惯的短句结构  
3. 被动语态转换为主动表述（如"were compared"译为"进行对比测试"）  
4. 列表项采用中文项目符号规范  
5. 链接地址保留原格式以保持功能性）