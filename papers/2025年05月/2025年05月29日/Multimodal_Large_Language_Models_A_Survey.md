# 多模态大型语言模型综述

发布时间：2025年05月29日

`LLM理论` `人工智能` `计算机视觉`

> Multimodal Large Language Models: A Survey

# 摘要

> 多模态大型语言模型（MLLMs）已迅速超越文本生成，涵盖图像、音乐、视频、人体动作和3D对象等多种输出模态，通过在统一架构下融合语言与其他感官模态。本综述将六种主要生成模态分类，并探讨自监督学习（SSL）、专家混合模型（MoE）、基于人类反馈的强化学习（RLHF）和链式思维（CoT）提示等基础技术如何实现跨模态能力。我们分析了关键模型、架构趋势及新兴的跨模态协同效应，同时强调可转移技术和未解挑战。架构创新如变压器和扩散模型支撑了这一融合，实现跨模态迁移和模块化专业化。我们突出了协同作用的新兴模式，并指出了评估、模块化和结构化推理方面的开放挑战。本综述为MLLM发展提供统一视角，并指出了通往更通用、适应性和可解释多模态系统的路径。

> Multimodal Large Language Models (MLLMs) have rapidly evolved beyond text generation, now spanning diverse output modalities including images, music, video, human motion, and 3D objects, by integrating language with other sensory modalities under unified architectures. This survey categorises six primary generative modalities and examines how foundational techniques, namely Self-Supervised Learning (SSL), Mixture of Experts (MoE), Reinforcement Learning from Human Feedback (RLHF), and Chain-of-Thought (CoT) prompting, enable cross-modal capabilities. We analyze key models, architectural trends, and emergent cross-modal synergies, while highlighting transferable techniques and unresolved challenges. Architectural innovations like transformers and diffusion models underpin this convergence, enabling cross-modal transfer and modular specialization. We highlight emerging patterns of synergy, and identify open challenges in evaluation, modularity, and structured reasoning. This survey offers a unified perspective on MLLM development and identifies critical paths toward more general-purpose, adaptive, and interpretable multimodal systems.

[Arxiv](https://arxiv.org/abs/2506.10016)