# # ExpeTrans: LLMs Are Experiential Transfer Learners
LLMs：经验迁移的学习者。

发布时间：2025年05月29日

`LLM应用

理由：该论文探讨了如何通过自主经验迁移框架提升大型语言模型在多样化任务中的性能，属于应用层面的创新。` `机器学习`

> ExpeTrans: LLMs Are Experiential Transfer Learners

# 摘要

> 近期研究通过提示词赋予大型语言模型（LLMs）文本任务解决经验，以提升模型性能。然而，以往方法依赖大量的人力或时间来为每个任务收集经验，面对用户对LLMs多样化任务需求，这种方式难以应对。针对这一问题，我们设计了一个自主经验迁移框架，探究LLMs能否模拟人类认知智能，自主将现有源任务的经验迁移至新遇目标任务。这不仅突破了传统方法高成本的限制，更为LLMs的泛化能力开辟了新路径。实验结果表明，该框架在13个数据集上有效提升了LLMs的性能。此外，我们对框架中的各个模块进行了详细分析。

> Recent studies provide large language models (LLMs) with textual task-solving experiences via prompts to improve their performance. However, previous methods rely on substantial human labor or time to gather such experiences for each task, which is impractical given the growing variety of task types in user queries to LLMs. To address this issue, we design an autonomous experience transfer framework to explore whether LLMs can mimic human cognitive intelligence to autonomously transfer experience from existing source tasks to newly encountered target tasks. This not only allows the acquisition of experience without extensive costs of previous methods, but also offers a novel path for the generalization of LLMs. Experimental results on 13 datasets demonstrate that our framework effectively improves the performance of LLMs. Furthermore, we provide a detailed analysis of each module in the framework.

[Arxiv](https://arxiv.org/abs/2505.23191)