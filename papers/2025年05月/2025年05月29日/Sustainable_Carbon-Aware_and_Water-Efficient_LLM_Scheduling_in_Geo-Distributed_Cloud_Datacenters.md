# 可持续碳感知与节水高效的大语言模型调度在地理分布式云数据中心中的应用

发布时间：2025年05月29日

`LLM应用

LLM应用` `可持续发展` `云计算`

> Sustainable Carbon-Aware and Water-Efficient LLM Scheduling in Geo-Distributed Cloud Datacenters

# 摘要

> 近年来，ChatGPT、CoPilot和Gemini等大型语言模型（LLM）已在各领域广泛应用。尽管人们投入大量努力以降低LLM的巨额训练成本，但处理用户请求带来的环境影响日益引发关注。研究显示，LLM推理阶段的运营成本每年可能比训练成本高出25倍，且其运营阶段的碳足迹远超训练阶段。更令人担忧的是，每次20-50次的LLM推理请求就会消耗500毫升的淡水。为解决这些问题，我们提出了一种名为SLIT的框架，旨在协同优化LLM的服务质量（首次生成响应时间）、碳排放、用水量和能源成本。该框架通过基于机器学习的元启发式算法，提升LLM在跨地域分布式云数据中心托管中的可持续性。随着LLM的普及，这一框架将变得日益重要。

> In recent years, Large Language Models (LLM) such as ChatGPT, CoPilot, and Gemini have been widely adopted in different areas. As the use of LLMs continues to grow, many efforts have focused on reducing the massive training overheads of these models. But it is the environmental impact of handling user requests to LLMs that is increasingly becoming a concern. Recent studies estimate that the costs of operating LLMs in their inference phase can exceed training costs by 25x per year. As LLMs are queried incessantly, the cumulative carbon footprint for the operational phase has been shown to far exceed the footprint during the training phase. Further, estimates indicate that 500 ml of fresh water is expended for every 20-50 requests to LLMs during inference. To address these important sustainability issues with LLMs, we propose a novel framework called SLIT to co-optimize LLM quality of service (time-to-first token), carbon emissions, water usage, and energy costs. The framework utilizes a machine learning (ML) based metaheuristic to enhance the sustainability of LLM hosting across geo-distributed cloud datacenters. Such a framework will become increasingly vital as LLMs proliferate.

[Arxiv](https://arxiv.org/abs/2505.23554)