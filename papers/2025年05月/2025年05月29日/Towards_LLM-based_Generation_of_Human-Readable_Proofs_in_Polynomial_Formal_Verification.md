# 迈向基于大语言模型的多项式形式验证中人类可读证明的生成研究

发布时间：2025年05月29日

`LLM应用

理由：这篇论文探讨了如何利用大型语言模型（LLMs）来生成可验证的证明，属于LLMs在形式验证中的应用，因此归类为LLM应用。` `电路设计` `系统设计`

> Towards LLM-based Generation of Human-Readable Proofs in Polynomial Formal Verification

# 摘要

> 验证是电路和系统设计中的核心任务之一。尽管仿真和模拟被广泛采用，但只有通过形式证明技术才能确保完全正确性。然而，这些方法通常面临高运行时间和内存需求的挑战。最近，多项式形式验证（PFV）的引入表明，对于许多具有实际意义的实例，可以设定所需资源的上限。但必须提供可由人类阅读的证明。
    本研究探讨了如何利用基于大型语言模型（LLMs）的人工智能（AI）现代方法来生成证明，这些证明可后续通过推理引擎进行验证。通过实例展示了LLMs与证明引擎的交互方式，并指出了未来研究的方向。

> Verification is one of the central tasks in circuit and system design. While simulation and emulation are widely used, complete correctness can only be ensured based on formal proof techniques. But these approaches often have very high run time and memory requirements. Recently, Polynomial Formal Verification (PFV) has been introduced showing that for many instances of practical relevance upper bounds on needed resources can be given. But proofs have to be provided that are human-readable.
  Here, we study how modern approaches from Artificial Intelligence (AI) based on Large Language Models (LLMs) can be used to generate proofs that later on can be validated based on reasoning engines. Examples are given that show how LLMs can interact with proof engines, and directions for future work are outlined.

[Arxiv](https://arxiv.org/abs/2505.23311)