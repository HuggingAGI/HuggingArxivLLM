# MCP安全培训：通过改进偏好对齐的方法，学习识别并拒绝看似无害实则危险的MCP攻击

发布时间：2025年05月29日

`RAG` `AI安全` `生成式AI`

> MCP Safety Training: Learning to Refuse Falsely Benign MCP Exploits using Improved Preference Alignment

# 摘要

> 模型上下文协议（MCP）作为一种开放标准，已被广泛采用以实现生成式AI代理的无缝集成。然而，近期研究发现，MCP易受基于检索的“看似无害”攻击（FBAs）影响，此类攻击允许恶意系统访问和窃取凭证，但需要用户直接将受损文件下载到其系统中。在此，我们揭示，MCP攻击的威胁模型远比之前认知的更为广泛——攻击者只需在网上发布恶意内容，即可诱使MCP代理对毫无戒心的受害者系统发起攻击。  
为了增强抵御此类攻击的对齐护栏，我们引入了一个新的MCP数据集，包含FBAs和（真正）无害样本，以探索直接偏好优化（DPO）在大型语言模型（LLMs）拒绝训练中的有效性。尽管DPO提升了模型抵御此类攻击的能力，但我们发现，拒绝学习的效果因模型最初的后训练对齐方案而异——例如，基于GRPO的LLMs在拒绝能力方面表现极差。因此，为了进一步提升对FBAs的拒绝能力，我们引入了基于RAG的新型偏好对齐策略——检索增强生成偏好对齐（RAG-Pref）。我们发现，RAG-Pref显著提升了LLMs拒绝FBAs的能力，尤其在与DPO对齐结合使用时，大幅提升了抵御MCP攻击的护栏。

> The model context protocol (MCP) has been widely adapted as an open standard enabling the seamless integration of generative AI agents. However, recent work has shown the MCP is susceptible to retrieval-based "falsely benign" attacks (FBAs), allowing malicious system access and credential theft, but requiring that users download compromised files directly to their systems. Herein, we show that the threat model of MCP-based attacks is significantly broader than previously thought, i.e., attackers need only post malicious content online to deceive MCP agents into carrying out their attacks on unsuspecting victims' systems.
  To improve alignment guardrails against such attacks, we introduce a new MCP dataset of FBAs and (truly) benign samples to explore the effectiveness of direct preference optimization (DPO) for the refusal training of large language models (LLMs). While DPO improves model guardrails against such attacks, we show that the efficacy of refusal learning varies drastically depending on the model's original post-training alignment scheme--e.g., GRPO-based LLMs learn to refuse extremely poorly. Thus, to further improve FBA refusals, we introduce Retrieval Augmented Generation for Preference alignment (RAG-Pref), a novel preference alignment strategy based on RAG. We show that RAG-Pref significantly improves the ability of LLMs to refuse FBAs, particularly when combined with DPO alignment, thus drastically improving guardrails against MCP-based attacks.

[Arxiv](https://arxiv.org/abs/2505.23634)