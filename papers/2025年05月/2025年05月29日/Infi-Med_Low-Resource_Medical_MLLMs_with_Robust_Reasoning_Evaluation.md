# Infi-Med: 低资源医学多语言大模型与稳健推理评估

发布时间：2025年05月29日

`LLM应用` `医疗AI`

> Infi-Med: Low-Resource Medical MLLMs with Robust Reasoning Evaluation

# 摘要

> 多模态大型语言模型（MLLMs）在医疗领域展现出巨大潜力，尤其在处理复杂医学任务、支持多学科治疗（MDT）和推动个性化精准医疗方面表现突出。然而，实际应用中仍面临资源效率、诊断准确性、临床考量和伦理隐私等关键挑战。为解决这些问题，我们提出了一套名为Infi-Med的全面医疗MLLM框架，该框架具有三大创新亮点：(1) 通过构建高质量监督微调（SFT）数据集实现资源高效利用，其设计不仅适用于当前阶段，还可延伸至预训练和后训练环节；(2) 强化跨模态整合与临床任务理解的多模态推理能力；(3) 建立系统性评估体系，全面衡量模型在不同医学模态和任务类型中的表现。实验结果表明，Infi-Med在通用医学推理任务中达到当前最优（SOTA）水平，同时具备快速适应临床场景的能力。该框架通过平衡模型效果与实际运营需求，为在真实医疗环境中部署MLLM奠定了坚实基础。

> Multimodal large language models (MLLMs) have demonstrated promising prospects in healthcare, particularly for addressing complex medical tasks, supporting multidisciplinary treatment (MDT), and enabling personalized precision medicine. However, their practical deployment faces critical challenges in resource efficiency, diagnostic accuracy, clinical considerations, and ethical privacy. To address these limitations, we propose Infi-Med, a comprehensive framework for medical MLLMs that introduces three key innovations: (1) a resource-efficient approach through curating and constructing high-quality supervised fine-tuning (SFT) datasets with minimal sample requirements, with a forward-looking design that extends to both pretraining and posttraining phases; (2) enhanced multimodal reasoning capabilities for cross-modal integration and clinical task understanding; and (3) a systematic evaluation system that assesses model performance across medical modalities and task types. Our experiments demonstrate that Infi-Med achieves state-of-the-art (SOTA) performance in general medical reasoning while maintaining rapid adaptability to clinical scenarios. The framework establishes a solid foundation for deploying MLLMs in real-world healthcare settings by balancing model effectiveness with operational constraints.

[Arxiv](https://arxiv.org/abs/2505.23867)