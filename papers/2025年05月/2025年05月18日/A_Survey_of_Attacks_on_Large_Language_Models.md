# # 摘要
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年05月18日

`LLM应用` `人工智能`

> A Survey of Attacks on Large Language Models

# 摘要

> 大型语言模型（LLMs）及其代理在医疗诊断、金融分析、客户服务、机器人和自动驾驶等领域得到了广泛应用，充分展现了其强大的自然语言理解、推理和生成能力。然而，基于LLM的应用程序的广泛部署也带来了关键的安全性和可靠性风险，如恶意滥用、隐私泄露和服务中断等问题，这些问题削弱了用户的信任并威胁到社会安全。本文系统性地概述了针对LLMs及其代理的对抗攻击细节，这些攻击分为训练阶段攻击、推理阶段攻击以及可用性与完整性攻击三个阶段。针对每个阶段，我们分析了具有代表性的近期攻击方法及其防御措施。我们希望本综述能为理解LLM安全提供一个良好的教程，特别是针对LLMs的攻击。我们旨在引起人们对广泛部署的基于LLM应用程序内在风险的关注，并强调了针对不断演变的威胁制定强大缓解策略的迫切需求。

> Large language models (LLMs) and LLM-based agents have been widely deployed in a wide range of applications in the real world, including healthcare diagnostics, financial analysis, customer support, robotics, and autonomous driving, expanding their powerful capability of understanding, reasoning, and generating natural languages. However, the wide deployment of LLM-based applications exposes critical security and reliability risks, such as the potential for malicious misuse, privacy leakage, and service disruption that weaken user trust and undermine societal safety. This paper provides a systematic overview of the details of adversarial attacks targeting both LLMs and LLM-based agents. These attacks are organized into three phases in LLMs: Training-Phase Attacks, Inference-Phase Attacks, and Availability & Integrity Attacks. For each phase, we analyze the details of representative and recently introduced attack methods along with their corresponding defenses. We hope our survey will provide a good tutorial and a comprehensive understanding of LLM security, especially for attacks on LLMs. We desire to raise attention to the risks inherent in widely deployed LLM-based applications and highlight the urgent need for robust mitigation strategies for evolving threats.

[Arxiv](https://arxiv.org/abs/2505.12567)