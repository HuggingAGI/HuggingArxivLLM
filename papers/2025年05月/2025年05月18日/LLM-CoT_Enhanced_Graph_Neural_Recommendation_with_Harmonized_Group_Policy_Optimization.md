# LLM-CoT 增强的图神经推荐系统，通过协调的组策略优化提升性能

发布时间：2025年05月18日

`LLM应用` `电子商务` `推荐系统`

> LLM-CoT Enhanced Graph Neural Recommendation with Harmonized Group Policy Optimization

# 摘要

> 图神经网络 (GNNs) 通过建模交互关系，显著推动了推荐系统的发展。然而，现有基于图的推荐系统存在以下问题：它们依赖稀疏的 ID 特征，未能充分利用文本信息，导致表示中的信息密度较低。此外，图对比学习面临两个主要挑战：随机负采样可能引入虚假负样本，而固定温度系数无法适应不同节点的异质性。更重要的是，当前结合大型语言模型 (LLMs) 增强推荐的研究尚未充分利用其链式推理 (Chain-of-Thought, CoT) 能力来指导表示学习。

为了解决上述问题，我们提出了 LGHRec（LLM-CoT 增强的图神经推荐框架，结合协调的组策略优化）。该框架通过利用 LLM 的 CoT 推理能力生成语义 ID，显著丰富了推理过程，从而提升了表示的信息密度和语义质量。此外，我们设计了一种强化学习算法——协调的组策略优化 (HGPO)，用于优化对比学习中的负采样策略和温度系数。这种方法不仅增强了长尾推荐性能，还确保了不同组之间的优化一致性。

在三个数据集上的实验结果表明，LGHRec 通过 LLM 的 CoT 推理生成的语义 ID 显著提高了表示质量，并通过 HGPO 有效提升了对比学习效果。我们的方法在多个基准模型上表现更优。代码可在以下链接获取：https://anonymous.4open.science/r/LLM-Rec。


> Graph neural networks (GNNs) have advanced recommender systems by modeling interaction relationships. However, existing graph-based recommenders rely on sparse ID features and do not fully exploit textual information, resulting in low information density within representations. Furthermore, graph contrastive learning faces challenges. Random negative sampling can introduce false negative samples, while fixed temperature coefficients cannot adapt to the heterogeneity of different nodes. In addition, current efforts to enhance recommendations with large language models (LLMs) have not fully utilized their Chain-of-Thought (CoT) reasoning capabilities to guide representation learning. To address these limitations, we introduces LGHRec (LLM-CoT Enhanced Graph Neural Recommendation with Harmonized Group Policy Optimization). This framework leverages the CoT reasoning ability of LLMs to generate semantic IDs, enriching reasoning processes and improving information density and semantic quality of representations. Moreover, we design a reinforcement learning algorithm, Harmonized Group Policy Optimization (HGPO), to optimize negative sampling strategies and temperature coefficients in contrastive learning. This approach enhances long-tail recommendation performance and ensures optimization consistency across different groups. Experimental results on three datasets demonstrate that LGHRec improves representation quality through semantic IDs generated by LLM's CoT reasoning and effectively boosts contrastive learning with HGPO. Our method outperforms several baseline models. The code is available at: https://anonymous.4open.science/r/LLM-Rec.

[Arxiv](https://arxiv.org/abs/2505.12396)