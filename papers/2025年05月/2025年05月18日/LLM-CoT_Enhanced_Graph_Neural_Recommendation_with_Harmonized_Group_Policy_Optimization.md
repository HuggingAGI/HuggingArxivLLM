# 基于LLM链式推理的图神经推荐与和谐群体策略优化

发布时间：2025年05月18日

`LLM应用` `推荐系统`

> LLM-CoT Enhanced Graph Neural Recommendation with Harmonized Group Policy Optimization

# 摘要

> 图神经网络（GNNs）推动了推荐系统的发展，但现有基于图的推荐系统存在信息密度低、对比学习挑战多等问题。我们提出了LGHRec框架，结合LLMs的链式思维（CoT）推理能力生成语义ID，提升表示质量。同时，设计了协同组策略优化（HGPO）算法优化对比学习，提升长尾推荐性能。实验表明，LGHRec在多个数据集上表现优异。代码已开源。


> Graph neural networks (GNNs) have advanced recommender systems by modeling interaction relationships. However, existing graph-based recommenders rely on sparse ID features and do not fully exploit textual information, resulting in low information density within representations. Furthermore, graph contrastive learning faces challenges. Random negative sampling can introduce false negative samples, while fixed temperature coefficients cannot adapt to the heterogeneity of different nodes. In addition, current efforts to enhance recommendations with large language models (LLMs) have not fully utilized their Chain-of-Thought (CoT) reasoning capabilities to guide representation learning. To address these limitations, we introduces LGHRec (LLM-CoT Enhanced Graph Neural Recommendation with Harmonized Group Policy Optimization). This framework leverages the CoT reasoning ability of LLMs to generate semantic IDs, enriching reasoning processes and improving information density and semantic quality of representations. Moreover, we design a reinforcement learning algorithm, Harmonized Group Policy Optimization (HGPO), to optimize negative sampling strategies and temperature coefficients in contrastive learning. This approach enhances long-tail recommendation performance and ensures optimization consistency across different groups. Experimental results on three datasets demonstrate that LGHRec improves representation quality through semantic IDs generated by LLM's CoT reasoning and effectively boosts contrastive learning with HGPO. Our method outperforms several baseline models. The code is available at: https://anonymous.4open.science/r/LLM-Rec.

[Arxiv](https://arxiv.org/abs/2505.12396)