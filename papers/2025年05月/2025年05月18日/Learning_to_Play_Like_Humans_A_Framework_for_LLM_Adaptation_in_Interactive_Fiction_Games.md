# 像人类一样玩游戏，LLM也能学会！本文为交互式小说游戏中的LLM适配提供一个全新的框架。

发布时间：2025年05月18日

`LLM应用` `人工智能`

> Learning to Play Like Humans: A Framework for LLM Adaptation in Interactive Fiction Games

# 摘要

> 互动小说游戏（IF games）是通过自然语言指令与游戏互动的独特形式。近期，人工智能代理在决策机制研究领域的突破性进展，重新点燃了人们对互动小说游戏（IF games）这一领域的兴趣。然而，现有方法过分关注任务特定的性能指标，忽视了对叙事背景和游戏逻辑的人类般理解。为此，我们提出了一种以认知科学为启发的框架，旨在系统性地引导大型语言模型（LLMs）学习和玩转互动小说游戏。我们的**L**earning to **P**lay **L**ike **H**umans（LPLH）框架整合了三个关键模块：（1）构建结构化地图以捕捉空间与叙事关系，（2）学习动作指令以识别语境合适的命令，（3）通过反馈驱动的经验分析来逐步优化决策过程。通过将基于LLMs的代理行为与叙事意图及常识约束相协调，LPLH超越了纯粹的探索性策略，呈现了更具可解释性、更贴近人类表现的游戏机制。这一方法借鉴了认知科学原理，更贴近人类玩家在叙事世界中阅读、理解和回应的方式。因此，LPLH重新定义了互动小说游戏的挑战，将其视为基于LLMs的代理学习问题，为在复杂文本环境中实现稳健、情境感知的游戏开辟了新的路径。

> Interactive Fiction games (IF games) are where players interact through natural language commands. While recent advances in Artificial Intelligence agents have reignited interest in IF games as a domain for studying decision-making, existing approaches prioritize task-specific performance metrics over human-like comprehension of narrative context and gameplay logic. This work presents a cognitively inspired framework that guides Large Language Models (LLMs) to learn and play IF games systematically. Our proposed **L**earning to **P**lay **L**ike **H**umans (LPLH) framework integrates three key components: (1) structured map building to capture spatial and narrative relationships, (2) action learning to identify context-appropriate commands, and (3) feedback-driven experience analysis to refine decision-making over time. By aligning LLMs-based agents' behavior with narrative intent and commonsense constraints, LPLH moves beyond purely exploratory strategies to deliver more interpretable, human-like performance. Crucially, this approach draws on cognitive science principles to more closely simulate how human players read, interpret, and respond within narrative worlds. As a result, LPLH reframes the IF games challenge as a learning problem for LLMs-based agents, offering a new path toward robust, context-aware gameplay in complex text-based environments.

[Arxiv](https://arxiv.org/abs/2505.12439)