# SEAR: 分析 AR-LLM 驱动社会工程学行为的多模态数据集

发布时间：2025年05月30日

`LLM应用` `增强现实` `社会工程`

> SEAR: A Multimodal Dataset for Analyzing AR-LLM-Driven Social Engineering Behaviors

# 摘要

> SEAR 数据集是一个创新的多模态资源，专注于研究通过增强现实（AR）与多模态大型语言模型（LLMs）策划的社会工程（SE）攻击这一新兴威胁。该数据集记录了60名参与者在模拟的对抗场景（如会议、课堂和 networking 活动）中的180次标注对话。它整合了同步捕获的 AR 视觉/音频线索（如面部表情、语调）、环境背景以及精选的社交媒体资料，并包含信任评分和易受攻击性评估等主观指标。研究发现，SEAR 在引发合规行为（如 93.3% 的钓鱼链接点击率和 85% 的电话接听率）以及劫持信任（76.7% 的交互后信任激增）方面表现出惊人效果。该数据集为 AR 驱动的 SE 攻击检测、防御框架设计以及多模态对抗性操纵机制的研究提供了支持。严格的伦理保障措施，包括匿名化和 IRB 审查，确保了数据集的负责任使用。SEAR 数据集现已在 https://github.com/INSLabCN/SEAR-Dataset 上开放获取。

> The SEAR Dataset is a novel multimodal resource designed to study the emerging threat of social engineering (SE) attacks orchestrated through augmented reality (AR) and multimodal large language models (LLMs). This dataset captures 180 annotated conversations across 60 participants in simulated adversarial scenarios, including meetings, classes and networking events. It comprises synchronized AR-captured visual/audio cues (e.g., facial expressions, vocal tones), environmental context, and curated social media profiles, alongside subjective metrics such as trust ratings and susceptibility assessments. Key findings reveal SEAR's alarming efficacy in eliciting compliance (e.g., 93.3% phishing link clicks, 85% call acceptance) and hijacking trust (76.7% post-interaction trust surge). The dataset supports research in detecting AR-driven SE attacks, designing defensive frameworks, and understanding multimodal adversarial manipulation. Rigorous ethical safeguards, including anonymization and IRB compliance, ensure responsible use. The SEAR dataset is available at https://github.com/INSLabCN/SEAR-Dataset.

[Arxiv](https://arxiv.org/abs/2505.24458)