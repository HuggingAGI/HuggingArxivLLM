# MedArabiQ：评估大型语言模型在阿拉伯语医疗任务上的表现

发布时间：2025年05月06日

`LLM应用` `基准测试`

> MedArabiQ: Benchmarking Large Language Models on Arabic Medical Tasks

# 摘要

> 大型语言模型（LLMs）在医疗领域的广泛应用中展现出巨大潜力。然而，由于缺乏高质量的领域特定数据集和基准测试，LLMs在阿拉伯语医学领域的效果尚未得到充分探索。本研究介绍了MedArabiQ，一个包含七个阿拉伯语医学任务的新型基准数据集，涵盖多个专业领域，并包括多项选择题、填空题和患者-医生问答等多种题型。我们首先利用过去的医学考试和公开可用的数据集构建了该数据集。随后，我们引入了不同的修改来评估LLMs的多种能力，包括偏见缓解。我们使用了五种最先进的开源和专有LLMs进行了全面评估，包括GPT-4o、Claude 3.5-Sonnet和Gemini 1.5。我们的研究结果强调了创建涵盖不同语言的新高质量基准的必要性，以确保LLMs在医疗领域的公平部署和可扩展性。通过建立这一基准并公开数据集，我们为未来的研究奠定了基础，旨在评估和提升LLMs的多语言能力，以实现医疗领域中生成式AI的公平应用。

> Large Language Models (LLMs) have demonstrated significant promise for various applications in healthcare. However, their efficacy in the Arabic medical domain remains unexplored due to the lack of high-quality domain-specific datasets and benchmarks. This study introduces MedArabiQ, a novel benchmark dataset consisting of seven Arabic medical tasks, covering multiple specialties and including multiple choice questions, fill-in-the-blank, and patient-doctor question answering. We first constructed the dataset using past medical exams and publicly available datasets. We then introduced different modifications to evaluate various LLM capabilities, including bias mitigation. We conducted an extensive evaluation with five state-of-the-art open-source and proprietary LLMs, including GPT-4o, Claude 3.5-Sonnet, and Gemini 1.5. Our findings highlight the need for the creation of new high-quality benchmarks that span different languages to ensure fair deployment and scalability of LLMs in healthcare. By establishing this benchmark and releasing the dataset, we provide a foundation for future research aimed at evaluating and enhancing the multilingual capabilities of LLMs for the equitable use of generative AI in healthcare.

[Arxiv](https://arxiv.org/abs/2505.03427)