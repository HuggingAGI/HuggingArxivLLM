# 基于相对危险系数的大型语言模型伦理与安全差距比较分析

发布时间：2025年05月06日

`LLM应用

理由：这篇论文探讨了大型语言模型（LLMs）在伦理方面的表现及其潜在危害，属于对LLM应用的伦理和社会影响分析，因此归类为LLM应用。` `人工智能`

> A Comparative Analysis of Ethical and Safety Gaps in LLMs using Relative Danger Coefficient

# 摘要

> 近年来，人工智能（AI）和大型语言模型（LLMs）飞速发展，在自然语言理解和生成领域展现出了非凡的能力。然而，这些技术突破也引发了一系列关键的伦理问题，涉及安全、潜在滥用、歧视以及对社会的整体影响。本文对包括全新DeepSeek-V3（带推理和不带推理版本）、多种GPT变体（4o、3.5 Turbo、4 Turbo、o1/o3 mini）以及Gemini（1.5闪存、2.0闪存和2.0闪存增强版）在内的各类AI模型的伦理表现进行了深入比较分析。本文特别强调了在高风险场景中实施人工监督的重要性，并提出了一个用于衡量大型语言模型危害的新指标——相对危险系数（RDC）。

> Artificial Intelligence (AI) and Large Language Models (LLMs) have rapidly evolved in recent years, showcasing remarkable capabilities in natural language understanding and generation. However, these advancements also raise critical ethical questions regarding safety, potential misuse, discrimination and overall societal impact. This article provides a comparative analysis of the ethical performance of various AI models, including the brand new DeepSeek-V3(R1 with reasoning and without), various GPT variants (4o, 3.5 Turbo, 4 Turbo, o1/o3 mini) and Gemini (1.5 flash, 2.0 flash and 2.0 flash exp) and highlights the need for robust human oversight, especially in situations with high stakes. Furthermore, we present a new metric for calculating harm in LLMs called Relative Danger Coefficient (RDC).

[Arxiv](https://arxiv.org/abs/2505.04654)