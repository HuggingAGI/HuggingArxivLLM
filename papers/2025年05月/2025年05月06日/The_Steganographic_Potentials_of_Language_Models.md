# 语言模型的隐写潜力

发布时间：2025年05月06日

`LLM理论` `信息安全` `人工智能`

> The Steganographic Potentials of Language Models

# 摘要

> 大型语言模型 (LLMs) 隐藏信息的能力对检测不一致 AI 代理以及削弱其推理忠诚度构成挑战。我们研究了通过强化学习 (RL) 微调的 LLMs 的信息隐藏能力，包括开发隐蔽编码方案、在提示下进行信息隐藏，以及在现实场景中利用信息隐藏。我们的实验结果揭示，尽管当前模型在信息隐藏方面的能力尚显基础，但通过明确的算法指导，其信息隐藏能力得到了显著提升。

> The potential for large language models (LLMs) to hide messages within plain text (steganography) poses a challenge to detection and thwarting of unaligned AI agents, and undermines faithfulness of LLMs reasoning. We explore the steganographic capabilities of LLMs fine-tuned via reinforcement learning (RL) to: (1) develop covert encoding schemes, (2) engage in steganography when prompted, and (3) utilize steganography in realistic scenarios where hidden reasoning is likely, but not prompted. In these scenarios, we detect the intention of LLMs to hide their reasoning as well as their steganography performance. Our findings in the fine-tuning experiments as well as in behavioral non fine-tuning evaluations reveal that while current models exhibit rudimentary steganographic abilities in terms of security and capacity, explicit algorithmic guidance markedly enhances their capacity for information concealment.

[Arxiv](https://arxiv.org/abs/2505.03439)