# Alpha Excel 基准测试

发布时间：2025年05月06日

`LLM应用` `金融建模` `商业应用`

> Alpha Excel Benchmark

# 摘要

> 本研究提出了一种新颖的基准测试，利用金融建模世界杯（FMWC）Excel竞赛中的挑战来评估大型语言模型（LLMs）。我们开发了一种方法，将113个现有FMWC挑战转换为可程序化评估的JSON格式，并通过该数据集比较了多个领先LLM的表现。研究发现，不同挑战类别中模型表现存在显著差异，模型在模式识别任务中表现出色，但在复杂数值推理方面则面临挑战。该基准测试提供了一个标准化框架，用于评估LLM在现实业务任务中的能力，而非抽象的学术问题。这项研究为AI基准领域贡献了一个有意义的评估指标——全球15亿每日使用Microsoft Excel用户的熟练程度，从而弥合了学术AI基准与实际商业应用之间的差距。

> This study presents a novel benchmark for evaluating Large Language Models (LLMs) using challenges derived from the Financial Modeling World Cup (FMWC) Excel competitions. We introduce a methodology for converting 113 existing FMWC challenges into programmatically evaluable JSON formats and use this dataset to compare the performance of several leading LLMs. Our findings demonstrate significant variations in performance across different challenge categories, with models showing specific strengths in pattern recognition tasks but struggling with complex numerical reasoning. The benchmark provides a standardized framework for assessing LLM capabilities in realistic business-oriented tasks rather than abstract academic problems. This research contributes to the growing field of AI benchmarking by establishing proficiency among the 1.5 billion people who daily use Microsoft Excel as a meaningful evaluation metric that bridges the gap between academic AI benchmarks and practical business applications.

[Arxiv](https://arxiv.org/abs/2505.04110)