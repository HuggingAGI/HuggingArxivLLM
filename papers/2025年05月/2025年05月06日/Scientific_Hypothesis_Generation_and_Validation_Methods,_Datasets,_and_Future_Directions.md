# 科学假设生成与验证：方法、数据集与未来方向

发布时间：2025年05月06日

`LLM应用` `科学发现` `跨学科`

> Scientific Hypothesis Generation and Validation: Methods, Datasets, and Future Directions

# 摘要

> 大型语言模型 (LLMs) 正在改变科学假设生成与验证的方式，实现了信息合成、潜在关系发现和推理增强。本研究综述系统性地概述了基于 LLM 的方法，包括符号框架、生成模型、混合系统及多智能体架构。我们探讨了检索增强生成、知识图谱补全、模拟、因果推断及工具辅助推理等技术，强调了可解释性、新颖性及领域对齐之间的权衡。我们对比了早期符号发现系统（如 BACON、KEKADA）与现代 LLM 管道，后者通过微调、检索及符号 grounding 等方式实现了上下文学习与领域适配。在验证方面，我们回顾了模拟、人机协作、因果建模及不确定性量化等方法，强调了开放世界情境下的迭代评估。本综述涵盖了生物医学、材料科学、环境科学及社会科学等领域的数据集，并介绍了 AHTech 和 CSKG-600 等新资源。最后，我们提出了发展路线图，强调了新颖性感知生成、多模态-符号融合、人机协同系统及伦理保障的重要性，定位 LLM 为基于原则且可扩展的科学发现工具。


> Large Language Models (LLMs) are transforming scientific hypothesis generation and validation by enabling information synthesis, latent relationship discovery, and reasoning augmentation. This survey provides a structured overview of LLM-driven approaches, including symbolic frameworks, generative models, hybrid systems, and multi-agent architectures. We examine techniques such as retrieval-augmented generation, knowledge-graph completion, simulation, causal inference, and tool-assisted reasoning, highlighting trade-offs in interpretability, novelty, and domain alignment. We contrast early symbolic discovery systems (e.g., BACON, KEKADA) with modern LLM pipelines that leverage in-context learning and domain adaptation via fine-tuning, retrieval, and symbolic grounding. For validation, we review simulation, human-AI collaboration, causal modeling, and uncertainty quantification, emphasizing iterative assessment in open-world contexts. The survey maps datasets across biomedicine, materials science, environmental science, and social science, introducing new resources like AHTech and CSKG-600. Finally, we outline a roadmap emphasizing novelty-aware generation, multimodal-symbolic integration, human-in-the-loop systems, and ethical safeguards, positioning LLMs as agents for principled, scalable scientific discovery.

[Arxiv](https://arxiv.org/abs/2505.04651)