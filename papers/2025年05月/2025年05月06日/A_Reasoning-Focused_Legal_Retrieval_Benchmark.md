# # 聚焦推理的法律检索评测基准

发布时间：2025年05月06日

`RAG` `问答系统`

> A Reasoning-Focused Legal Retrieval Benchmark

# 摘要

> 随着法律界对大型语言模型（LLMs）在各类法律应用中的探索日益深入，法律AI开发者已转向检索增强的LLMs（RAG系统）以提升系统性能和稳定性。然而，开发专业RAG系统面临一个重大挑战：缺乏能够全面反映法律检索和下游法律问答复杂性的现实基准。为解决这一难题，我们推出了两个全新的法律RAG基准：律师资格考试问答（Bar Exam QA）和住房法规问答（Housing Statute QA）。这些任务模拟了现实中的法律研究场景，并通过类似法律研究的标注流程精心打造而成。我们详细介绍了这些基准的构建过程，并评估了现有检索管道的表现。研究结果表明，法律RAG仍是一项充满挑战的应用领域，这为未来的研究指明了方向。

> As the legal community increasingly examines the use of large language models (LLMs) for various legal applications, legal AI developers have turned to retrieval-augmented LLMs ("RAG" systems) to improve system performance and robustness. An obstacle to the development of specialized RAG systems is the lack of realistic legal RAG benchmarks which capture the complexity of both legal retrieval and downstream legal question-answering. To address this, we introduce two novel legal RAG benchmarks: Bar Exam QA and Housing Statute QA. Our tasks correspond to real-world legal research tasks, and were produced through annotation processes which resemble legal research. We describe the construction of these benchmarks and the performance of existing retriever pipelines. Our results suggest that legal RAG remains a challenging application, thus motivating future research.

[Arxiv](https://arxiv.org/abs/2505.03970)