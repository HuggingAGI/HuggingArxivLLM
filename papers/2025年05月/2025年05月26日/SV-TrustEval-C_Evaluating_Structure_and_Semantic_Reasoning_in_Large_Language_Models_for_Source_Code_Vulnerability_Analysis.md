# SV-TrustEval-C：针对源代码漏洞分析的大型语言模型结构与语义推理能力评估。

发布时间：2025年05月26日

`LLM应用` `软件工程` `信息安全`

> SV-TrustEval-C: Evaluating Structure and Semantic Reasoning in Large Language Models for Source Code Vulnerability Analysis

# 摘要

> 随着大型语言模型（LLMs）在代码理解和生成领域的不断进步，准确评估其在源代码漏洞分析中的可靠性变得愈发重要。尽管已有研究探讨了LLMs在漏洞检测与修复等任务中的能力，但它们往往忽视了结构和语义推理对于可信漏洞分析的关键作用。为此，我们提出了SV-TrustEval-C，一个专注于评估LLMs在C语言代码漏洞分析中能力的基准，通过以下两个核心维度：结构推理——评估模型在不同数据和控制流复杂性下识别代码元素间关系的能力；语义推理——考察模型在代码结构和语义受到扰动时的逻辑一致性。研究结果表明，当前LLMs在理解复杂代码关系方面仍有显著不足，其漏洞分析更多依赖模式匹配，而非可靠的逻辑推理。这些发现不仅验证了SV-TrustEval-C基准的有效性，还突出了在真实世界漏洞分析任务中提升LLMs推理能力与可信度的关键方向。我们的初始基准数据集现已公开。

> As Large Language Models (LLMs) evolve in understanding and generating code, accurately evaluating their reliability in analyzing source code vulnerabilities becomes increasingly vital. While studies have examined LLM capabilities in tasks like vulnerability detection and repair, they often overlook the importance of both structure and semantic reasoning crucial for trustworthy vulnerability analysis. To address this gap, we introduce SV-TrustEval-C, a benchmark designed to evaluate LLMs' abilities for vulnerability analysis of code written in the C programming language through two key dimensions: structure reasoning - assessing how models identify relationships between code elements under varying data and control flow complexities; and semantic reasoning - examining their logical consistency in scenarios where code is structurally and semantically perturbed. Our results show that current LLMs are far from satisfactory in understanding complex code relationships and that their vulnerability analyses rely more on pattern matching than on robust logical reasoning. These findings underscore the effectiveness of the SV-TrustEval-C benchmark and highlight critical areas for enhancing the reasoning capabilities and trustworthiness of LLMs in real-world vulnerability analysis tasks. Our initial benchmark dataset is publicly available.

[Arxiv](https://arxiv.org/abs/2505.20630)