# # 超越关键词：评估大型语言模型在分类微妙 ableism 方面的能力

发布时间：2025年05月26日

`LLM应用` `人力资源` `内容审核`

> Beyond Keywords: Evaluating Large Language Model Classification of Nuanced Ableism

# 摘要

> 大型语言模型（LLMs）在简历筛选和内容审核等决策任务中发挥越来越重要的作用，它们有能力放大或抑制某些观点。虽然之前的研究已经发现LLMs存在与残疾相关的偏见，但它们如何理解ableism或在文本中识别其行为仍是个谜。我们测试了四个LLMs识别针对自闭症个体的微妙ableism的能力。研究发现，尽管这些模型能够识别与自闭症相关的语言，但常常忽略了其中的有害或冒犯性含义。进一步的比较分析显示，LLMs倾向于依赖表面关键词匹配，容易误解上下文，而人类标注者则会综合考虑上下文、说话者身份和潜在影响。有趣的是，LLMs和人类在标注方案上达成一致，这表明二元分类足以评估LLMs的表现，这一发现与先前涉及人类标注者的相关研究结果一致。

> Large language models (LLMs) are increasingly used in decision-making tasks like résumé screening and content moderation, giving them the power to amplify or suppress certain perspectives. While previous research has identified disability-related biases in LLMs, little is known about how they conceptualize ableism or detect it in text. We evaluate the ability of four LLMs to identify nuanced ableism directed at autistic individuals. We examine the gap between their understanding of relevant terminology and their effectiveness in recognizing ableist content in context. Our results reveal that LLMs can identify autism-related language but often miss harmful or offensive connotations. Further, we conduct a qualitative comparison of human and LLM explanations. We find that LLMs tend to rely on surface-level keyword matching, leading to context misinterpretations, in contrast to human annotators who consider context, speaker identity, and potential impact. On the other hand, both LLMs and humans agree on the annotation scheme, suggesting that a binary classification is adequate for evaluating LLM performance, which is consistent with findings from prior studies involving human annotators.

[Arxiv](https://arxiv.org/abs/2505.20500)