# 发生了什么变化？借助多模态大语言模型检测与评估基于指令的图像编辑

发布时间：2025年05月26日

`LLM应用` `图像处理`

> What Changed? Detecting and Evaluating Instruction-Guided Image Edits with Multimodal Large Language Models

# 摘要

> 基于指令的图像编辑模型为生成任务提供了更多个性化可能。然而，对其结果的恰当评估充满挑战，现有指标在与人类判断的一致性和可解释性方面均显不足。为解决这一难题，我们推出DICE（差异一致性评估器），一个专注于检测原始图像与编辑后图像之间局部差异，并评估这些差异与修改请求相关性的模型。DICE由差异检测器和一致性评估器两大核心组件构成，均基于自回归多模态大型语言模型（MLLM），并通过自监督学习、从 inpainting 网络的知识蒸馏及全监督策略进行训练。通过大量实验，我们在提出的框架内评估了pipeline的每个环节，并对比了不同 MLLM 的表现。结果表明，DICE能够有效识别一致的编辑，对不同编辑模型生成的图像进行准确评估，与人类判断高度相关。我们现已公开发布源代码、模型和数据集。

> Instruction-based image editing models offer increased personalization opportunities in generative tasks. However, properly evaluating their results is challenging, and most of the existing metrics lag in terms of alignment with human judgment and explainability. To tackle these issues, we introduce DICE (DIfference Coherence Estimator), a model designed to detect localized differences between the original and the edited image and to assess their relevance to the given modification request. DICE consists of two key components: a difference detector and a coherence estimator, both built on an autoregressive Multimodal Large Language Model (MLLM) and trained using a strategy that leverages self-supervision, distillation from inpainting networks, and full supervision. Through extensive experiments, we evaluate each stage of our pipeline, comparing different MLLMs within the proposed framework. We demonstrate that DICE effectively identifies coherent edits, effectively evaluating images generated by different editing models with a strong correlation with human judgment. We publicly release our source code, models, and data.

[Arxiv](https://arxiv.org/abs/2505.20405)