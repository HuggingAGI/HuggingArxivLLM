# VideoLLM 基准与评估综述

发布时间：2025年05月03日

`LLM应用` `视频理解` `评估方法`

> VideoLLM Benchmarks and Evaluation: A Survey

# 摘要

> 大型语言模型（LLMs）的迅猛发展推动了视频理解技术的显著进步。本综述全面分析了专为视频大型语言模型（VideoLLMs）设计的基准测试和评估方法。我们深入探讨了当前视频理解基准的特点、评估流程及其局限性。文章详细研究了闭集、开集以及针对时空理解任务的专门评估方法。我们还总结了先进VideoLLMs在这些基准上的性能趋势，并指出现有评估体系中的主要挑战。此外，我们提出了未来研究方向，旨在优化基准设计、评估指标和流程，包括开发更多样化、多模态且注重可解释性的基准。本综述旨在帮助研究人员系统地掌握VideoLLMs的评估方法，并为利用大型语言模型推动视频理解领域的发展提供富有前景的研究方向。

> The rapid development of Large Language Models (LLMs) has catalyzed significant advancements in video understanding technologies. This survey provides a comprehensive analysis of benchmarks and evaluation methodologies specifically designed or used for Video Large Language Models (VideoLLMs). We examine the current landscape of video understanding benchmarks, discussing their characteristics, evaluation protocols, and limitations. The paper analyzes various evaluation methodologies, including closed-set, open-set, and specialized evaluations for temporal and spatiotemporal understanding tasks. We highlight the performance trends of state-of-the-art VideoLLMs across these benchmarks and identify key challenges in current evaluation frameworks. Additionally, we propose future research directions to enhance benchmark design, evaluation metrics, and protocols, including the need for more diverse, multimodal, and interpretability-focused benchmarks. This survey aims to equip researchers with a structured understanding of how to effectively evaluate VideoLLMs and identify promising avenues for advancing the field of video understanding with large language models.

[Arxiv](https://arxiv.org/abs/2505.03829)