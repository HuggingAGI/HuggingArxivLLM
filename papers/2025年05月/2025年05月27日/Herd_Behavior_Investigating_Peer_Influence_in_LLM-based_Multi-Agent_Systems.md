# 从众行为：探究基于LLM的多智能体系统中的同伴影响机制

发布时间：2025年05月27日

`Agent` `人工智能` `社会学`

> Herd Behavior: Investigating Peer Influence in LLM-based Multi-Agent Systems

# 摘要

> 大型语言模型（LLMs）的最新进展推动了多智能体系统的兴起，这些系统中，LLMs在共享环境中互动、协作并做出决策。尽管个体模型的行为已得到深入研究，但此类系统中同侪影响力的动力学机制仍鲜有探索。本文研究了基于LLM的多智能体互动中的从众行为，即智能体趋向于与同侪保持一致的倾向。我们通过一系列受控实验揭示了从众行为如何受到多种因素的影响。首先，我们发现自我信心与对同侪信心的感知之间的差距显著影响了智能体从众的可能性。其次，我们发现同侪信息呈现的格式在调节从众行为强度方面起着关键作用。最后，我们证明了从众行为的程度可以系统性地进行控制，并且适当调校的从众倾向能够提升协作成果。这些发现为基于LLM的系统中的社会动态提供了新的见解，并为设计更高效、更具适应性的多智能体协作框架开辟了新途径。

> Recent advancements in Large Language Models (LLMs) have enabled the emergence of multi-agent systems where LLMs interact, collaborate, and make decisions in shared environments. While individual model behavior has been extensively studied, the dynamics of peer influence in such systems remain underexplored. In this paper, we investigate herd behavior, the tendency of agents to align their outputs with those of their peers, within LLM-based multi-agent interactions. We present a series of controlled experiments that reveal how herd behaviors are shaped by multiple factors. First, we show that the gap between self-confidence and perceived confidence in peers significantly impacts an agent's likelihood to conform. Second, we find that the format in which peer information is presented plays a critical role in modulating the strength of herd behavior. Finally, we demonstrate that the degree of herd behavior can be systematically controlled, and that appropriately calibrated herd tendencies can enhance collaborative outcomes. These findings offer new insights into the social dynamics of LLM-based systems and open pathways for designing more effective and adaptive multi-agent collaboration frameworks.

[Arxiv](https://arxiv.org/abs/2505.21588)