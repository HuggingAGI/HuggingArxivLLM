# 稳健假设生成：LLM 驱动的语言偏差在归纳逻辑编程中的应用

发布时间：2025年05月27日

`Agent` `人工智能` `认知科学`

> Robust Hypothesis Generation: LLM-Automated Language Bias for Inductive Logic Programming

# 摘要

> 在开放环境中实现健壮假设的自动化生成对AI认知至关重要。我们提出了一种全新框架，将基于大型语言模型（LLMs）的多智能体系统与归纳逻辑编程（ILP）相结合。系统中的LLM智能体能够从原始文本数据中自主定义结构化的符号词汇（谓词）和关系模板，即\emph{语言偏置}。这一自动化符号接地过程（语言偏置的构建），传统上是ILP中依赖专家知识的瓶颈，随后指导文本转化为事实，供ILP求解器进行归纳学习，从而获得可解释的规则。这种方法克服了传统ILP对预定义符号结构的依赖以及纯LLM方法对噪声的敏感性。在多样化的挑战性场景中进行的大量实验验证了该方法的优越性能，为自动化、可解释且可验证的假设生成开辟了新的道路。

> Automating robust hypothesis generation in open environments is pivotal for AI cognition. We introduce a novel framework integrating a multi-agent system, powered by Large Language Models (LLMs), with Inductive Logic Programming (ILP). Our system's LLM agents autonomously define a structured symbolic vocabulary (predicates) and relational templates , i.e., \emph{language bias} directly from raw textual data. This automated symbolic grounding (the construction of the language bias), traditionally an expert-driven bottleneck for ILP, then guides the transformation of text into facts for an ILP solver, which inductively learns interpretable rules. This approach overcomes traditional ILP's reliance on predefined symbolic structures and the noise-sensitivity of pure LLM methods. Extensive experiments in diverse, challenging scenarios validate superior performance, paving a new path for automated, explainable, and verifiable hypothesis generation.

[Arxiv](https://arxiv.org/abs/2505.21486)