# # **MSA 在 SemEval-2025 任务3中**：多语言幻觉检测的高质量弱标注与大语言模型集成验证方案

发布时间：2025年05月27日

`LLM应用` `幻觉检测` `多语言处理`

> MSA at SemEval-2025 Task 3: High Quality Weak Labeling and LLM Ensemble Verification for Multilingual Hallucination Detection

# 摘要

> 本论文描述了我们对SemEval-2025任务3的提交：Mu-SHROOM，一个多语言共享任务，专注于幻觉和相关可观察过度生成错误。该任务旨在检测由指令微调的大型语言模型（LLMs）生成的文本中跨多种语言的幻觉片段。我们的方法结合了任务特定提示工程与LLM集成验证机制：主模型负责提取幻觉片段，三个独立的LLMs通过基于概率的投票判定其有效性。此框架模拟了共享任务验证和测试数据中使用的人类标注工作流程。此外，我们还采用了模糊匹配技术优化片段对齐。最终，我们的系统在阿拉伯语和巴斯克语中排名第一，在德语、瑞典语和芬兰语中排名第二，在捷克语、波斯语和法语中排名第三。

> This paper describes our submission for SemEval-2025 Task 3: Mu-SHROOM, the Multilingual Shared-task on Hallucinations and Related Observable Overgeneration Mistakes. The task involves detecting hallucinated spans in text generated by instruction-tuned Large Language Models (LLMs) across multiple languages. Our approach combines task-specific prompt engineering with an LLM ensemble verification mechanism, where a primary model extracts hallucination spans and three independent LLMs adjudicate their validity through probability-based voting. This framework simulates the human annotation workflow used in the shared task validation and test data. Additionally, fuzzy matching refines span alignment. Our system ranked 1st in Arabic and Basque, 2nd in German, Swedish, and Finnish, and 3rd in Czech, Farsi, and French.

[Arxiv](https://arxiv.org/abs/2505.20880)