# 从推理到学习：大型语言模型在假设发现与规则学习中的研究综述

发布时间：2025年05月27日

`LLM理论`

> From Reasoning to Learning: A Survey on Hypothesis Discovery and Rule Learning with Large Language Models

# 摘要

> 自大型语言模型（LLMs）诞生以来，研究重点一直放在提升其遵循指令和演绎推理的能力上，但这些模型是否真的能够发现新知识，仍是一个待解之谜。随着对人工通用智能（AGI）的追求，我们需要的不仅是能执行命令或检索信息的模型，更需要能通过提出新假设和新理论来学习、推理并创造新知识的模型，从而深化我们对世界的理解。

本研究以皮尔士的 abduction、deduction 和 induction 框架为指导，系统审视了基于 LLM 的假设发现。我们整合了现有研究，涵盖了假设生成、应用和验证，既总结了关键进展，也指出了研究空白。通过整合这些研究线索，我们揭示了 LLMs 如何可能从单纯的“信息执行者”转变为真正的创新引擎，从而有可能推动研究、科学和现实问题解决的变革。

> Since the advent of Large Language Models (LLMs), efforts have largely focused on improving their instruction-following and deductive reasoning abilities, leaving open the question of whether these models can truly discover new knowledge. In pursuit of artificial general intelligence (AGI), there is a growing need for models that not only execute commands or retrieve information but also learn, reason, and generate new knowledge by formulating novel hypotheses and theories that deepen our understanding of the world. Guided by Peirce's framework of abduction, deduction, and induction, this survey offers a structured lens to examine LLM-based hypothesis discovery. We synthesize existing work in hypothesis generation, application, and validation, identifying both key achievements and critical gaps. By unifying these threads, we illuminate how LLMs might evolve from mere ``information executors'' into engines of genuine innovation, potentially transforming research, science, and real-world problem solving.

[Arxiv](https://arxiv.org/abs/2505.21935)