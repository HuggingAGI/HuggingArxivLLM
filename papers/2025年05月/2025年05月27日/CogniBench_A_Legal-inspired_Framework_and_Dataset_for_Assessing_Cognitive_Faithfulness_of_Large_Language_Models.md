# CogniBench：一个法律启发式框架和数据集，用于评测大型语言模型的认知忠诚度

发布时间：2025年05月27日

`LLM应用` `法律科技`

> CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models

# 摘要

> 大型语言模型 (LLM) 生成的未经支持的声明被称为 Faithfulness hallucination。由于现有基准测试缺乏统一的评估标准，它们仅包含对源材料进行改写的"事实性陈述"，而未标注基于上下文进行推理的"认知性陈述"，这使得对认知性陈述的一致性评估和优化变得困难。受立法领域对证据评估方式的启发，我们设计了一个严谨的框架来评估认知性陈述的不同可信度水平，并创建了一个基准数据集，从中揭示了有价值的统计信息。我们设计了一个标注流水线，以便为不同的 LLM 自动生成更大规模的基准测试，最终得到的 CogniBench-L 数据集可用于训练准确的认知性幻觉检测模型。我们已在 https://github.com/FUTUREEEEEE/CogniBench 发布了我们的模型和数据集。

> Faithfulness hallucination are claims generated by a Large Language Model (LLM) not supported by contexts provided to the LLM. Lacking assessment standard, existing benchmarks only contain "factual statements" that rephrase source materials without marking "cognitive statements" that make inference from the given context, making the consistency evaluation and optimization of cognitive statements difficult. Inspired by how an evidence is assessed in the legislative domain, we design a rigorous framework to assess different levels of faithfulness of cognitive statements and create a benchmark dataset where we reveal insightful statistics. We design an annotation pipeline to create larger benchmarks for different LLMs automatically, and the resulting larger-scale CogniBench-L dataset can be used to train accurate cognitive hallucination detection model. We release our model and dataset at: https://github.com/FUTUREEEEEE/CogniBench

[Arxiv](https://arxiv.org/abs/2505.20767)