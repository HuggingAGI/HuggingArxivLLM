# 伦理模拟：LLM辩论小组在医疗困境中的应用

发布时间：2025年05月27日

`LLM应用` `伦理学`

> Simulating Ethics: Using LLM Debate Panels to Model Deliberation on Medical Dilemmas

# 摘要

> 本文介绍了ADEPT系统，它利用大型语言模型（LLM）人格模拟多视角伦理辩论。ADEPT组织由“AI人格”组成的小组，每个小组代表不同的伦理框架或利益相关者视角（如义务论者、功利主义者或残疾权利倡导者），以探讨复杂的道德问题。通过一个关于如何为有限数量的呼吸机优先分配患者的模拟场景展示了其应用，该场景灵感来源于现实世界中分配稀缺医疗资源的挑战。进行了两场辩论，每场包含六个人格，它们之间的唯一区别在于所代表的道德观点：一场包括一位天主教生物伦理学家和一位关怀理论家，另一场则由一位基于规则的康德主义哲学家和一位法律顾问取代。两组最终都支持同一政策——一种兼顾临床需求和公平性的加权抽奖系统，并且避免了撤下呼吸机以重新分配的行为。然而，每组通过不同的论点线得出这一结论，且当义务和权利相关的观点加入后，它们的投票联盟发生了变化。对辩论记录的分析表明，成员的变化重新将注意力转向了道德伤害、法律风险和公众信任，进而改变了四个持续存在的小组成员的最终立场。这项研究提供了三个贡献：(i) 一个透明且可复制的工作流程，用于运行和分析生物伦理学中多智能体AI辩论；(ii) 证据表明，即使在事实输入保持不变的情况下，此类小组中包含的不同道德视角也会实质上改变结果；(iii) 对此类AI中介方法在伦理审议和政策制定中的影响和未来方向的分析。

> This paper introduces ADEPT, a system using Large Language Model (LLM) personas to simulate multi-perspective ethical debates. ADEPT assembles panels of 'AI personas', each embodying a distinct ethical framework or stakeholder perspective (like a deontologist, consequentialist, or disability rights advocate), to deliberate on complex moral issues. Its application is demonstrated through a scenario about prioritizing patients for a limited number of ventilators inspired by real-world challenges in allocating scarce medical resources. Two debates, each with six LLM personas, were conducted; they only differed in the moral viewpoints represented: one included a Catholic bioethicist and a care theorist, the other substituted a rule-based Kantian philosopher and a legal adviser. Both panels ultimately favoured the same policy -- a lottery system weighted for clinical need and fairness, crucially avoiding the withdrawal of ventilators for reallocation. However, each panel reached that conclusion through different lines of argument, and their voting coalitions shifted once duty- and rights-based voices were present. Examination of the debate transcripts shows that the altered membership redirected attention toward moral injury, legal risk and public trust, which in turn changed four continuing personas' final positions. The work offers three contributions: (i) a transparent, replicable workflow for running and analysing multi-agent AI debates in bioethics; (ii) evidence that the moral perspectives included in such panels can materially change the outcome even when the factual inputs remain constant; and (iii) an analysis of the implications and future directions for such AI-mediated approaches to ethical deliberation and policy.

[Arxiv](https://arxiv.org/abs/2505.21112)