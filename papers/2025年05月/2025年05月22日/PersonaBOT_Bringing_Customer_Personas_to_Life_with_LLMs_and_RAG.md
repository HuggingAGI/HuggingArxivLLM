# PersonaBOT：通过大型语言模型 (LLMs) 和检索增强生成 (RAG) 活力呈现客户画像

发布时间：2025年05月22日

`RAG` `市场营销` `客户画像`

> PersonaBOT: Bringing Customer Personas to Life with LLMs and RAG

# 摘要

> 大型语言模型（LLMs）的引入彻底改变了自然语言处理（NLP）应用，使客户画像分析更加智能化。在沃尔沃建筑设备（VCE），传统的客户画像创建主要依赖于耗时且难以扩展的定性方法。本文旨在通过生成合成客户画像并将其整合到检索增强生成（RAG）聊天机器人中，支持业务流程中的决策制定。为此，我们首先开发了一个集成经过验证的客户画像的基于画像的RAG聊天机器人。随后，我们采用少样本（Few-Shot）和思维链（CoT）提示技术生成合成画像，并通过麦肯马尔检验（McNemar's test）从完整性、相关性和一致性三个维度进行评估。最后，我们将合成画像和额外的客户群体信息整合到聊天机器人的知识库中，以评估其在响应准确性和实际效用方面的提升。研究发现，少样本提示技术在生成更完整的客户画像方面表现更优，而思维链技术在响应时间和令牌使用效率方面更具优势。在增强知识库后，聊天机器人的平均准确性评分从10分制的5.88提升至6.42，且81.82%的参与者认为更新后的系统在商业环境中具有实用价值。

> The introduction of Large Language Models (LLMs) has significantly transformed Natural Language Processing (NLP) applications by enabling more advanced analysis of customer personas. At Volvo Construction Equipment (VCE), customer personas have traditionally been developed through qualitative methods, which are time-consuming and lack scalability. The main objective of this paper is to generate synthetic customer personas and integrate them into a Retrieval-Augmented Generation (RAG) chatbot to support decision-making in business processes. To this end, we first focus on developing a persona-based RAG chatbot integrated with verified personas. Next, synthetic personas are generated using Few-Shot and Chain-of-Thought (CoT) prompting techniques and evaluated based on completeness, relevance, and consistency using McNemar's test. In the final step, the chatbot's knowledge base is augmented with synthetic personas and additional segment information to assess improvements in response accuracy and practical utility. Key findings indicate that Few-Shot prompting outperformed CoT in generating more complete personas, while CoT demonstrated greater efficiency in terms of response time and token usage. After augmenting the knowledge base, the average accuracy rating of the chatbot increased from 5.88 to 6.42 on a 10-point scale, and 81.82% of participants found the updated system useful in business contexts.

[Arxiv](https://arxiv.org/abs/2505.17156)