# # 摘要
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年05月22日

`LLM应用` `金融分析`

> Towards Competent AI for Fundamental Analysis in Finance: A Benchmark Dataset and Evaluation

# 摘要

> 生成式AI，特别是大型语言模型（LLMs），正在逐步改变金融行业，通过自动化任务和解析复杂金融信息。其中，自动生成基本面分析报告是一个极具潜力的应用，对投资决策、风险评估和企业并购至关重要。尽管LLMs能通过单一提示生成这些报告，但其准确性风险较高。分析失误可能导致投资失误、监管问题及信任危机。现有金融基准主要评估LLMs回答问题的能力，却未能反映其在生成财务分析报告等实际任务中的表现。本文提出FinAR-Bench，专注于财务报表分析这一基本面分析的核心能力。为使评估更精准可靠，我们将任务分解为三个步骤：提取关键信息、计算财务指标和逻辑推理。这种结构化方法可客观评估LLMs在各步骤的表现。我们的研究清晰揭示了LLMs在基本面分析中的优势与局限，并为在现实金融环境中评估其性能提供了实用方法。

> Generative AI, particularly large language models (LLMs), is beginning to transform the financial industry by automating tasks and helping to make sense of complex financial information. One especially promising use case is the automatic creation of fundamental analysis reports, which are essential for making informed investment decisions, evaluating credit risks, guiding corporate mergers, etc. While LLMs attempt to generate these reports from a single prompt, the risks of inaccuracy are significant. Poor analysis can lead to misguided investments, regulatory issues, and loss of trust. Existing financial benchmarks mainly evaluate how well LLMs answer financial questions but do not reflect performance in real-world tasks like generating financial analysis reports. In this paper, we propose FinAR-Bench, a solid benchmark dataset focusing on financial statement analysis, a core competence of fundamental analysis. To make the evaluation more precise and reliable, we break this task into three measurable steps: extracting key information, calculating financial indicators, and applying logical reasoning. This structured approach allows us to objectively assess how well LLMs perform each step of the process. Our findings offer a clear understanding of LLMs current strengths and limitations in fundamental analysis and provide a more practical way to benchmark their performance in real-world financial settings.

[Arxiv](https://arxiv.org/abs/2506.07315)