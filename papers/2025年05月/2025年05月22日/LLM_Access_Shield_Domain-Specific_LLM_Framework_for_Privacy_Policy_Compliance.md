# # LLM 访问防护盾：为特定领域设计且满足隐私政策合规要求的 LLM 框架

发布时间：2025年05月22日

`LLM应用

理由：论文讨论了大型语言模型在实际应用中的安全问题，并提出了一种安全框架来缓解这些风险，这属于LLM的应用层面。` `数据隐私`

> LLM Access Shield: Domain-Specific LLM Framework for Privacy Policy Compliance

# 摘要

> 大型语言模型 (LLMs) 凭借生成类人文本和适应专业任务的能力，正广泛应用于金融、教育和治理等领域。然而，其广泛应用引发了关于数据隐私和安全的关键担忧，特别是敏感数据暴露的风险。

    本文提出了一种安全框架，旨在强制执行策略合规并缓解 LLM 交互中的安全风险。我们的方法创新性地引入了以下三个关键特性：(i) 基于 LLM 的策略执行：通过可定制机制增强对敏感数据的领域特定检测。 (ii) 动态策略定制：在用户与 LLM 的交互过程中实时适应和执行策略，确保符合不断变化的安全要求。 (iii) 敏感数据匿名化：采用格式保留加密技术，在保护敏感信息的同时保持上下文完整性。实验结果表明，该框架不仅有效缓解了安全风险，还保持了 LLM 驱动任务的功能准确性。

> Large language models (LLMs) are increasingly applied in fields such as finance, education, and governance due to their ability to generate human-like text and adapt to specialized tasks. However, their widespread adoption raises critical concerns about data privacy and security, including the risk of sensitive data exposure.
  In this paper, we propose a security framework to enforce policy compliance and mitigate risks in LLM interactions. Our approach introduces three key innovations: (i) LLM-based policy enforcement: a customizable mechanism that enhances domain-specific detection of sensitive data. (ii) Dynamic policy customization: real-time policy adaptation and enforcement during user-LLM interactions to ensure compliance with evolving security requirements. (iii) Sensitive data anonymization: a format-preserving encryption technique that protects sensitive information while maintaining contextual integrity. Experimental results demonstrate that our framework effectively mitigates security risks while preserving the functional accuracy of LLM-driven tasks.

[Arxiv](https://arxiv.org/abs/2505.17145)