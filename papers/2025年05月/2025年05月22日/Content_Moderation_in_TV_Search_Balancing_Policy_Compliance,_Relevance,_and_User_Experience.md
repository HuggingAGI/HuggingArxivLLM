# 电视搜索中的内容审核：平衡政策合规、内容相关性与用户体验

发布时间：2025年05月22日

`LLM应用

理由：这篇论文探讨了如何应用大型语言模型（LLMs）来监控和优化搜索系统，以提升内容审核和用户体验。具体来说，它引入了基于LLM的额外监控层，用于标记不适当或不相关内容，并通过反馈优化搜索模型的检索机制。这些应用属于LLM在实际任务中的具体应用，因此归类为LLM应用。` `娱乐平台`

> Content Moderation in TV Search: Balancing Policy Compliance, Relevance, and User Experience

# 摘要

> 海量用户依赖搜索功能在娱乐平台发现和探索内容。现代搜索系统结合候选生成和排序机制，其中先进方法利用深度学习和基于LLM的技术来检索、生成和分类搜索结果。尽管有这些进步，搜索算法仍可能因模型不可预测性、元数据错误或设计缺陷而显示不适当或不相关内容。这些问题可能与产品目标和用户期望不符，损害用户体验和业务成果。在本研究中，我们引入基于大型语言模型（LLMs）的额外监控层，以提升内容审核。此层可标记用户无意搜索的内容。此方法作为产品质量保证的基准，收集的反馈用于优化搜索模型的初始检索机制，确保更安全可靠的用户体验。

> Millions of people rely on search functionality to find and explore content on entertainment platforms. Modern search systems use a combination of candidate generation and ranking approaches, with advanced methods leveraging deep learning and LLM-based techniques to retrieve, generate, and categorize search results. Despite these advancements, search algorithms can still surface inappropriate or irrelevant content due to factors like model unpredictability, metadata errors, or overlooked design flaws. Such issues can misalign with product goals and user expectations, potentially harming user trust and business outcomes. In this work, we introduce an additional monitoring layer using Large Language Models (LLMs) to enhance content moderation. This additional layer flags content if the user did not intend to search for it. This approach serves as a baseline for product quality assurance, with collected feedback used to refine the initial retrieval mechanisms of the search model, ensuring a safer and more reliable user experience.

[Arxiv](https://arxiv.org/abs/2505.17207)