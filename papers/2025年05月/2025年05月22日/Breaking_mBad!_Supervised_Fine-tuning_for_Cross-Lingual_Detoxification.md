# 击败 mBad！监督微调技术助力跨语言毒性内容过滤

发布时间：2025年05月22日

`LLM应用` `内容安全`

> Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification

# 摘要

> 随着大规模语言模型 (LLMs) 在全球应用中的普及，如何确保其在不同语言环境中无毒性成为一个关键挑战。我们提出了一种名为 "跨语言净化" 的创新方法，通过缓解毒性，使净化能力能够在不同书写家族的高低资源语言之间实现迁移。我们通过 504 种广泛的实验设置深入分析了跨语言净化的效果，特别是在数据有限的跨分布场景下毒性减少的表现。同时，我们还研究了毒性缓解措施对非毒性任务上模型性能的影响，揭示了安全性与知识保留之间的权衡关系。我们的代码和数据集已在 https://github.com/himanshubeniwal/Breaking-mBad 上公开发布，欢迎访问获取。

> As large language models (LLMs) become increasingly prevalent in global applications, ensuring that they are toxicity-free across diverse linguistic contexts remains a critical challenge. We explore "Cross-lingual Detoxification", a cross-lingual paradigm that mitigates toxicity, enabling detoxification capabilities to transfer between high and low-resource languages across different script families. We analyze cross-lingual detoxification's effectiveness through 504 extensive settings to evaluate toxicity reduction in cross-distribution settings with limited data and investigate how mitigation impacts model performance on non-toxic tasks, revealing trade-offs between safety and knowledge preservation. Our code and dataset are publicly available at https://github.com/himanshubeniwal/Breaking-mBad.

[Arxiv](https://arxiv.org/abs/2505.16722)