# 神经符号AI推理：探索智能的新维度

发布时间：2025年05月22日

`LLM理论` `人工智能` `神经符号系统`

> Reasoning in Neurosymbolic AI

# 摘要

> 神经网络中的知识表示与推理一直是研究热点，神经符号人工智能（AI）致力于实现推理与学习的有机结合。本章介绍了一种基于能量的神经符号AI系统，能够对任意命题逻辑公式进行形式化表示与推理，将数据学习与逻辑推理相结合。我们首先分析了神经符号AI在由大型语言模型（LLMs）主导的AI领域中的定位，指出了LLMs在数据效率、公平性和安全性方面的重要挑战，并探讨了神经符号推理系统如何通过形式化推理能力解决这些问题。我们还详细讨论了特定能量系统对逻辑的表示，包括使用受限玻尔兹曼机（RBM）对逻辑推理与能量最小化对应关系的经验评估。通过与符号系统、神经网络和神经符号系统的比较，我们对从数据和知识中学习进行了经验评估。本章以易于理解的方式呈现了研究结果，旨在重新激发将神经网络作为大规模并行模型用于逻辑推理的研究，并推动深度网络中推理与学习的有机结合。我们以讨论神经符号AI在更广泛的正式推理和人工智能责任框架中的重要性作为结尾，探讨了神经符号AI在解决深度学习可靠性问题方面所面临的挑战。

> Knowledge representation and reasoning in neural networks have been a long-standing endeavor which has attracted much attention recently. The principled integration of reasoning and learning in neural networks is a main objective of the area of neurosymbolic Artificial Intelligence (AI). In this chapter, a simple energy-based neurosymbolic AI system is described that can represent and reason formally about any propositional logic formula. This creates a powerful combination of learning from data and knowledge and logical reasoning. We start by positioning neurosymbolic AI in the context of the current AI landscape that is unsurprisingly dominated by Large Language Models (LLMs). We identify important challenges of data efficiency, fairness and safety of LLMs that might be addressed by neurosymbolic reasoning systems with formal reasoning capabilities. We then discuss the representation of logic by the specific energy-based system, including illustrative examples and empirical evaluation of the correspondence between logical reasoning and energy minimization using Restricted Boltzmann Machines (RBM). Learning from data and knowledge is also evaluated empirically and compared with a symbolic, neural and a neurosymbolic system. Results reported in this chapter in an accessible way are expected to reignite the research on the use of neural networks as massively-parallel models for logical reasoning and promote the principled integration of reasoning and learning in deep networks. We conclude the chapter with a discussion of the importance of positioning neurosymbolic AI within a broader framework of formal reasoning and accountability in AI, discussing the challenges for neurosynbolic AI to tackle the various known problems of reliability of deep learning.

[Arxiv](https://arxiv.org/abs/2505.20313)