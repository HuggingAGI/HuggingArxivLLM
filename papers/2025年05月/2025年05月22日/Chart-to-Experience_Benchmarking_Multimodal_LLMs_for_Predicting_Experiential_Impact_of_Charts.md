# Chart-to-Experience: 评估多模态大型语言模型预测图表体验效果的能力

发布时间：2025年05月22日

`LLM应用` `数据科学`

> Chart-to-Experience: Benchmarking Multimodal LLMs for Predicting Experiential Impact of Charts

# 摘要

> 多模态大型语言模型（MLLMs）在视觉理解领域取得了显著进展，为预测图表的感知与情感影响提供了巨大机遇。然而，这也引发了一些担忧，因为许多LLMs的应用基于从少量示例中过度概括的假设，缺乏对其性能和效果的充分验证。我们引入了Chart-to-Experience，这是一个包含36个图表的基准数据集，由众包工作者对其对七个体验因素的影响进行了评估。利用该数据集作为真实依据，我们评估了当前最先进的MLLMs在两项任务中的能力：直接预测和图表的两两比较。我们的研究结果表明，MLLMs在评估单个图表时不如人类评估者敏感，但在两两比较任务中表现出准确且可靠的能力。

> The field of Multimodal Large Language Models (MLLMs) has made remarkable progress in visual understanding tasks, presenting a vast opportunity to predict the perceptual and emotional impact of charts. However, it also raises concerns, as many applications of LLMs are based on overgeneralized assumptions from a few examples, lacking sufficient validation of their performance and effectiveness. We introduce Chart-to-Experience, a benchmark dataset comprising 36 charts, evaluated by crowdsourced workers for their impact on seven experiential factors. Using the dataset as ground truth, we evaluated capabilities of state-of-the-art MLLMs on two tasks: direct prediction and pairwise comparison of charts. Our findings imply that MLLMs are not as sensitive as human evaluators when assessing individual charts, but are accurate and reliable in pairwise comparisons.

[Arxiv](https://arxiv.org/abs/2505.17374)