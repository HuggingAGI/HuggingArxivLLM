# GPT是编辑，而非作者：LLMs在学术预印本中的风格印记

发布时间：2025年05月22日

`LLM应用` `文本分析`

> GPT Editors, Not Authors: The Stylistic Footprint of LLMs in Academic Preprints

# 摘要

> 2022年末，大型语言模型（LLMs）的蓬勃发展对学术写作造成了深远影响，不仅威胁到学术可信度，还引发了机构层面的不确定性。我们试图探究LLMs在生成批判性文本中的应用程度，而非仅仅用于编辑（如检查语法错误或不当措辞）。在研究中，我们通过调整PELT阈值并结合贝叶斯分类器，分析了arXiv论文的风格分段，该分类器基于GPT再生文本进行训练。研究发现，LLMs生成的语言与风格分段无显著关联，这表明作者在使用LLMs时风格统一，从而有效降低了幻觉被引入学术预印本的风险。

> The proliferation of Large Language Models (LLMs) in late 2022 has impacted academic writing, threatening credibility, and causing institutional uncertainty. We seek to determine the degree to which LLMs are used to generate critical text as opposed to being used for editing, such as checking for grammar errors or inappropriate phrasing. In our study, we analyze arXiv papers for stylistic segmentation, which we measure by varying a PELT threshold against a Bayesian classifier trained on GPT-regenerated text. We find that LLM-attributed language is not predictive of stylistic segmentation, suggesting that when authors use LLMs, they do so uniformly, reducing the risk of hallucinations being introduced into academic preprints.

[Arxiv](https://arxiv.org/abs/2505.17327)