# # 对话对齐与上下文中的人工智能
上下文驱动的对话对齐与人工智能

发布时间：2025年05月28日

`LLM应用` `人工智能`

> Conversational Alignment with Artificial Intelligence in Context

# 摘要

> 开发基于大型语言模型的复杂人工智能 (AI) 对话代理引发了一系列重要问题，涉及人类规范、价值观、实践与 AI 设计和性能之间的关系。本文深入探讨 AI 代理如何在对话中与人类交流规范和实践保持一致，特别是在处理上下文和共同 ground 方面，并提出了一种新的评估框架，以分析开发者的设计选择。首先，我们从哲学和语言学关于对话语用学的文献中汲取灵感，阐述了实现对话一致性的核心目标，即我们提出的 CONTEXT-ALIGN 框架。随后，我们指出，当前大型语言模型 (LLM) 的架构、约束和优势可能从根本上限制了实现完全对话一致性的可能性。

> The development of sophisticated artificial intelligence (AI) conversational agents based on large language models raises important questions about the relationship between human norms, values, and practices and AI design and performance. This article explores what it means for AI agents to be conversationally aligned to human communicative norms and practices for handling context and common ground and proposes a new framework for evaluating developers' design choices. We begin by drawing on the philosophical and linguistic literature on conversational pragmatics to motivate a set of desiderata, which we call the CONTEXT-ALIGN framework, for conversational alignment with human communicative practices. We then suggest that current large language model (LLM) architectures, constraints, and affordances may impose fundamental limitations on achieving full conversational alignment.

[Arxiv](https://arxiv.org/abs/2505.22907)