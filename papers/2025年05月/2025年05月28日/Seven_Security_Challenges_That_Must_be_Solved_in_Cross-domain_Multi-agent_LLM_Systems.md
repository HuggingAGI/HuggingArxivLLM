# # 七个关键安全挑战：跨领域多智能体LLM系统中的安全问题

发布时间：2025年05月28日

`LLM应用` `灾害响应` `供应链优化`

> Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems

# 摘要

> 大型语言模型（LLMs）正在迅速演变为跨组织协同工作的自主代理，从而实现联合灾害响应、供应链优化等需要分散专业知识而不放弃数据所有权的任务。然而，跨领域协作打破了当前对齐与控制技术背后统一的信任假设。一个在孤立状态下良性的代理，在接收来自不可信同伴的消息时，可能会泄露机密或违反政策，从而产生由多智能体动态而非传统软件漏洞驱动的风险。本文旨在为跨领域多智能体LLM系统绘制安全议程。我们介绍了七类新型安全挑战，并为每类挑战提出了可能的攻击方式、安全评估指标以及未来研究方向的指导方针。

> Large language models (LLMs) are rapidly evolving into autonomous agents that cooperate across organizational boundaries, enabling joint disaster response, supply-chain optimization, and other tasks that demand decentralized expertise without surrendering data ownership. Yet, cross-domain collaboration shatters the unified trust assumptions behind current alignment and containment techniques. An agent benign in isolation may, when receiving messages from an untrusted peer, leak secrets or violate policy, producing risks driven by emergent multi-agent dynamics rather than classical software bugs. This position paper maps the security agenda for cross-domain multi-agent LLM systems. We introduce seven categories of novel security challenges, for each of which we also present plausible attacks, security evaluation metrics, and future research guidelines.

[Arxiv](https://arxiv.org/abs/2505.23847)