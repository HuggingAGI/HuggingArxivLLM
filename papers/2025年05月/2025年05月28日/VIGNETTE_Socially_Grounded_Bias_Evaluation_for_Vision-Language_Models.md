# # VIGNETTE：视觉-语言模型的社会背景偏见评估

发布时间：2025年05月28日

`其他` `社会学` `计算机视觉`

> VIGNETTE: Socially Grounded Bias Evaluation for Vision-Language Models

# 摘要

> 尽管大型语言模型（LLMs）中的偏见已得到广泛研究，但视觉语言模型（VLMs）中的类似问题却相对较少受到关注。现有的VLM偏见研究大多集中在肖像式图像和性别职业关联上，忽视了更广泛、更复杂的社会刻板印象及其潜在危害。本研究引入了VIGNETTE，这是一个包含3000多万张图像的大型VQA基准测试，通过涵盖事实性、感知、刻板印象和决策四个方向的问答框架，评估VLMs中的偏见。除了狭窄聚焦的研究，我们还评估了VLMs在情境化设置中对身份的解释，揭示了模型如何进行特质和能力假设以及表现出歧视模式。借鉴社会心理学，我们探讨了VLMs如何将视觉身份线索与特质和角色推理联系起来，通过偏见选择编码社会层级。我们的发现揭示了微妙的、多方面的以及令人惊讶的刻板印象模式，为理解VLMs如何从输入中构建社会意义提供了见解。

> While bias in large language models (LLMs) is well-studied, similar concerns in vision-language models (VLMs) have received comparatively less attention. Existing VLM bias studies often focus on portrait-style images and gender-occupation associations, overlooking broader and more complex social stereotypes and their implied harm. This work introduces VIGNETTE, a large-scale VQA benchmark with 30M+ images for evaluating bias in VLMs through a question-answering framework spanning four directions: factuality, perception, stereotyping, and decision making. Beyond narrowly-centered studies, we assess how VLMs interpret identities in contextualized settings, revealing how models make trait and capability assumptions and exhibit patterns of discrimination. Drawing from social psychology, we examine how VLMs connect visual identity cues to trait and role-based inferences, encoding social hierarchies, through biased selections. Our findings uncover subtle, multifaceted, and surprising stereotypical patterns, offering insights into how VLMs construct social meaning from inputs.

[Arxiv](https://arxiv.org/abs/2505.22897)