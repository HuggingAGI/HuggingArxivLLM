# 多轮不完全信息侧向驱动推理任务中的评估幻觉现象

发布时间：2025年05月28日

`LLM应用` `模型评估`

> Evaluation Hallucination in Multi-Round Incomplete Information Lateral-Driven Reasoning Tasks

# 摘要

> 多轮不完全信息任务是考验大型语言模型（LLMs）侧向思维能力的重要方式。目前，研究主要依赖多个基准和自动化评估指标来进行能力评估。然而，我们的研究发现现有方法存在显著局限性，它们常常产生误导性结果，未能揭示关键问题，例如走捷径行为、僵化的模式以及任务过早终止。这些问题不仅掩盖了LLMs的真实推理能力，还严重削弱了评估的可靠性。为此，我们提出了一套改进的评估标准，包括推理路径检查、多样化评估指标以及与人类表现的比较分析，以期更全面地评估LLMs的能力。

> Multi-round incomplete information tasks are crucial for evaluating the lateral thinking capabilities of large language models (LLMs). Currently, research primarily relies on multiple benchmarks and automated evaluation metrics to assess these abilities. However, our study reveals novel insights into the limitations of existing methods, as they often yield misleading results that fail to uncover key issues, such as shortcut-taking behaviors, rigid patterns, and premature task termination. These issues obscure the true reasoning capabilities of LLMs and undermine the reliability of evaluations. To address these limitations, we propose a refined set of evaluation standards, including inspection of reasoning paths, diversified assessment metrics, and comparative analyses with human performance.

[Arxiv](https://arxiv.org/abs/2505.23843)