# # 摘要
追踪AI模型行为使用条款的合规性，亟需新工具

发布时间：2025年05月28日

`其他

摘要讨论了AI模型的开源共享、许可证的使用以及如何负责任地使用AI，属于法律和伦理层面的内容，不属于Agent、RAG、LLM应用或LLM理论。因此，归类为其他。` `AI领域`

> New Tools are Needed for Tracking Adherence to AI Model Behavioral Use Clauses

# 摘要

> 基础模型正在深刻改变 AI 领域。得益于巨额研发投入、海量数字训练数据以及可随数据和算力扩展的架构，我们见证了具备强大能力的模型的诞生。开源共享对科学进步和商业发展至关重要。然而，为应对 AI 被疏忽或恶意使用的风险，人们设计了多种限制技术风险的机制。如今，越来越多常用模型家族（如 Llama、Gemma、Deepseek）和众多小型项目开始采用包含行为使用条款和可接受使用政策的许可证。我们开发并部署了一个定制 AI 许可证生成器，以简化许可证创建过程。通过该工具，我们对 300 多份定制许可证进行了定量和定性分析。与此同时，我们还分析了 HuggingFace 模型库中的 170 万份模型许可证。结果显示，这些许可证的采用率正在上升，人们对支持其创建的工具越来越感兴趣，且在条款配置上逐渐形成共识。本文认为，开发用于跟踪许可证采用情况和遵守情况的工具是自然而然的下一步，也是确保这些许可证达到预期效果、促进负责任使用所迫切需要的。

> Foundation models have had a transformative impact on AI. A combination of large investments in research and development, growing sources of digital data for training, and architectures that scale with data and compute has led to models with powerful capabilities. Releasing assets is fundamental to scientific advancement and commercial enterprise. However, concerns over negligent or malicious uses of AI have led to the design of mechanisms to limit the risks of the technology. The result has been a proliferation of licenses with behavioral-use clauses and acceptable-use-policies that are increasingly being adopted by commonly used families of models (Llama, Gemma, Deepseek) and a myriad of smaller projects. We created and deployed a custom AI licenses generator to facilitate license creation and have quantitatively and qualitatively analyzed over 300 customized licenses created with this tool. Alongside this we analyzed 1.7 million models licenses on the HuggingFace model hub. Our results show increasing adoption of these licenses, interest in tools that support their creation and a convergence on common clause configurations. In this paper we take the position that tools for tracking adoption of, and adherence to, these licenses is the natural next step and urgently needed in order to ensure they have the desired impact of ensuring responsible use.

[Arxiv](https://arxiv.org/abs/2505.22287)