# 约翰尼收到信息了吗？评估日常用户的网络安全提示

发布时间：2025年05月28日

`LLM应用

摘要中提到的研究主要涉及大型语言模型在网络安全警报生成和评估中的应用，属于LLM的实际应用领域。` `网络安全` `用户体验`

> Does Johnny Get the Message? Evaluating Cybersecurity Notifications for Everyday Users

# 摘要

> 随着网络设备在日常生活中的普及，不仅网络安全专家，普通用户也从防火墙、漏洞扫描器和入侵检测系统等安全应用中获益。近期研究利用大型语言模型（LLMs）将简短、专业的安全警报改写为更直观的语言，并建议可执行的应对措施，帮助普通用户理解并适当应对安全风险。然而，如何有效向用户解释这些警报仍是一个开放性问题。LLM的输出也可能产生幻觉、不一致或误导性内容。在此项研究中，我们引入了“以人为核心的网络安全警报评估框架”（HCSAEF）。HCSAEF评估由LLM生成的网络安全通知，支持研究人员比较针对普通用户的各类通知、改进它们，或分析不同LLMs在解释网络安全问题方面的能力。我们通过三个实际案例展示了HCSAEF的应用，这些案例使我们能够量化提示设计、模型选择和输出一致性的影响。我们的研究发现表明，HCSAEF能够有效区分生成通知在直观性、紧迫性和准确性等方面的差异。

> Due to the increasing presence of networked devices in everyday life, not only cybersecurity specialists but also end users benefit from security applications such as firewalls, vulnerability scanners, and intrusion detection systems. Recent approaches use large language models (LLMs) to rewrite brief, technical security alerts into intuitive language and suggest actionable measures, helping everyday users understand and respond appropriately to security risks. However, it remains an open question how well such alerts are explained to users. LLM outputs can also be hallucinated, inconsistent, or misleading. In this work, we introduce the Human-Centered Security Alert Evaluation Framework (HCSAEF). HCSAEF assesses LLM-generated cybersecurity notifications to support researchers who want to compare notifications generated for everyday users, improve them, or analyze the capabilities of different LLMs in explaining cybersecurity issues. We demonstrate HCSAEF through three use cases, which allow us to quantify the impact of prompt design, model selection, and output consistency. Our findings indicate that HCSAEF effectively differentiates generated notifications along dimensions such as intuitiveness, urgency, and correctness.

[Arxiv](https://arxiv.org/abs/2505.22435)