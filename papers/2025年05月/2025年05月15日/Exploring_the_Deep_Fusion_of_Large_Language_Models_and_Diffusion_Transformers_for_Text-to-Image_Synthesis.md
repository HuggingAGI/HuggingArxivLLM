# 探索大型语言模型与扩散式变换器的深度融合在文本到图像生成中的应用

发布时间：2025年05月15日

`LLM应用` `人工智能` `多模态生成`

> Exploring the Deep Fusion of Large Language Models and Diffusion Transformers for Text-to-Image Synthesis

# 摘要

> 本文并非介绍新方法，而是聚焦于近期文本到图像合成领域的重要研究方向——大型语言模型（LLMs）与扩散式变压器（DiTs）在多模态生成中的深度融合这一重要但尚未深入探索的设计空间。此前研究大多关注整体系统性能，缺乏与替代方法的详细对比，关键设计细节和训练配方也往往秘而不宣。这些研究空白让我们对这一方法的实际潜力充满疑问。为填补这些空白，我们针对文本到图像生成任务开展了一项实证研究，通过与现有基线模型进行受控对比，深入分析关键设计选择，并提供一套清晰可复现的大规模训练配方。我们希望这项研究能够为未来多模态生成领域的研究提供有意义的数据参考和实用指导方针。

> This paper does not describe a new method; instead, it provides a thorough exploration of an important yet understudied design space related to recent advances in text-to-image synthesis -- specifically, the deep fusion of large language models (LLMs) and diffusion transformers (DiTs) for multi-modal generation. Previous studies mainly focused on overall system performance rather than detailed comparisons with alternative methods, and key design details and training recipes were often left undisclosed. These gaps create uncertainty about the real potential of this approach. To fill these gaps, we conduct an empirical study on text-to-image generation, performing controlled comparisons with established baselines, analyzing important design choices, and providing a clear, reproducible recipe for training at scale. We hope this work offers meaningful data points and practical guidelines for future research in multi-modal generation.

[Arxiv](https://arxiv.org/abs/2505.10046)