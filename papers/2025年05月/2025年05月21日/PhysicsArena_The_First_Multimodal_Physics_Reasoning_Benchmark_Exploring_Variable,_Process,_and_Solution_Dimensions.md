# 物理竞技场：首个探索变量、过程与解法维度的多模态物理推理基准测试

发布时间：2025年05月21日

`LLM应用` `物理推理` `多模态`

> PhysicsArena: The First Multimodal Physics Reasoning Benchmark Exploring Variable, Process, and Solution Dimensions

# 摘要

> 多模态大型语言模型（MLLMs）在多种推理任务中表现突出，但其在复杂物理推理领域的应用仍有待深入探索。物理推理具有独特挑战，需要基于物理条件进行推理，并对多模态信息进行解读。现有的物理推理基准存在局限，往往仅关注纯文本输入或单一问题解决，忽视了变量识别和过程构建等关键中间步骤。为解决这些局限，我们推出了PhysicsArena——首个专注于多模态物理推理的基准测试平台。该平台旨在全面评估MLLMs在变量识别、物理过程构建和解决方案推导三大关键维度的能力，为评估和提升MLLMs的多模态物理推理能力提供一个全面的平台。

> Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in diverse reasoning tasks, yet their application to complex physics reasoning remains underexplored. Physics reasoning presents unique challenges, requiring grounding in physical conditions and the interpretation of multimodal information. Current physics benchmarks are limited, often focusing on text-only inputs or solely on problem-solving, thereby overlooking the critical intermediate steps of variable identification and process formulation. To address these limitations, we introduce PhysicsArena, the first multimodal physics reasoning benchmark designed to holistically evaluate MLLMs across three critical dimensions: variable identification, physical process formulation, and solution derivation. PhysicsArena aims to provide a comprehensive platform for assessing and advancing the multimodal physics reasoning abilities of MLLMs.

[Arxiv](https://arxiv.org/abs/2505.15472)