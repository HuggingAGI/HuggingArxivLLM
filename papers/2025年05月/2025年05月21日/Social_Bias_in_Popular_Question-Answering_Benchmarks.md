# # 流行问答基准中的社会偏见

发布时间：2025年05月21日

`LLM应用` `社会学`

> Social Bias in Popular Question-Answering Benchmarks

# 摘要

> 问答（QA）和阅读理解（RC）基准测试是评估大型语言模型（LLMs）知识检索与再现能力的重要工具。然而，我们发现目前流行的 QA 和 RC 基准测试存在偏见，未能以具有代表性的形式涵盖关于不同人口统计或地区的各种问题，这可能是因为这些基准的创建者缺乏多样性。通过对 30 篇基准论文进行定性内容分析，以及对 20 个相应数据集进行定量分析，我们发现大多数基准论文未能提供有关参与创建的利益相关者（尤其是标注者）的足够信息。值得注意的是，仅有一篇论文明确报告了为解决社会代表性问题所采取的措施。数据分析还揭示了在百科知识、常识和学术基准中广泛存在的性别、宗教和地理偏见。因此，我们需要更加透明和关注偏见的 QA 和 RC 基准创建实践，以促进更公平的 LLMs 开发。

> Question-answering (QA) and reading comprehension (RC) benchmarks are essential for assessing the capabilities of large language models (LLMs) in retrieving and reproducing knowledge. However, we demonstrate that popular QA and RC benchmarks are biased and do not cover questions about different demographics or regions in a representative way, potentially due to a lack of diversity of those involved in their creation. We perform a qualitative content analysis of 30 benchmark papers and a quantitative analysis of 20 respective benchmark datasets to learn (1) who is involved in the benchmark creation, (2) how social bias is addressed or prevented, and (3) whether the demographics of the creators and annotators correspond to particular biases in the content. Most analyzed benchmark papers provided insufficient information regarding the stakeholders involved in benchmark creation, particularly the annotators. Notably, just one of the benchmark papers explicitly reported measures taken to address social representation issues. Moreover, the data analysis revealed gender, religion, and geographic biases across a wide range of encyclopedic, commonsense, and scholarly benchmarks. More transparent and bias-aware QA and RC benchmark creation practices are needed to facilitate better scrutiny and incentivize the development of fairer LLMs.

[Arxiv](https://arxiv.org/abs/2505.15553)