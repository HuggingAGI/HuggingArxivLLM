# 配置上下文学习示例以释放多语言大型语言模型情感感知能力的实证研究

发布时间：2025年05月21日

`LLM应用` `人工智能` `情感分析`

> An Empirical Study on Configuring In-Context Learning Demonstrations for Unleashing MLLMs' Sentimental Perception Capability

# 摘要

> 多模态大型语言模型 (MLLMs) 的突破性进展使多种多模态任务得以在零样本范式下轻松应对，这一范式通过规避模型微调成本，成为实际应用中的主流趋势。然而，作为通向通用人工智能的重要挑战，多模态情感分析 (MSA) 却未能享受这一便利。零样本范式在 MSA 任务上的表现不尽如人意，这引发了关于 MLLMs 是否能像监督模型一样出色感知情感的质疑。通过将零样本范式扩展至 In-Context Learning (ICL)，并对演示配置进行深入研究，我们证实了 MLLMs 确实具备这种能力。具体而言，我们全面研究并优化了涵盖演示检索、呈现和分布的三个关键因素。同时，发现了一种 MLLMs 内在的情感预测偏差，并成功加以抑制。通过这三个因素策略的相互配合，相较于零样本范式，我们在六个 MSA 数据集上平均准确率提高了 15.9%；相较于随机 ICL 基线，提高了 11.2%。

> The advancements in Multimodal Large Language Models (MLLMs) have enabled various multimodal tasks to be addressed under a zero-shot paradigm. This paradigm sidesteps the cost of model fine-tuning, emerging as a dominant trend in practical application. Nevertheless, Multimodal Sentiment Analysis (MSA), a pivotal challenge in the quest for general artificial intelligence, fails to accommodate this convenience. The zero-shot paradigm exhibits undesirable performance on MSA, casting doubt on whether MLLMs can perceive sentiments as competent as supervised models. By extending the zero-shot paradigm to In-Context Learning (ICL) and conducting an in-depth study on configuring demonstrations, we validate that MLLMs indeed possess such capability. Specifically, three key factors that cover demonstrations' retrieval, presentation, and distribution are comprehensively investigated and optimized. A sentimental predictive bias inherent in MLLMs is also discovered and later effectively counteracted. By complementing each other, the devised strategies for three factors result in average accuracy improvements of 15.9% on six MSA datasets against the zero-shot paradigm and 11.2% against the random ICL baseline.

[Arxiv](https://arxiv.org/abs/2505.16193)