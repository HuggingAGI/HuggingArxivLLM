# # Set-LLM：无序集合型大语言模型

发布时间：2025年05月21日

`LLM理论` `模型优化`

> Set-LLM: A Permutation-Invariant LLM

# 摘要

> 尽管大型语言模型（LLMs）在众多应用中展现出令人惊叹的能力，但它们的稳健性仍然是一个关键问题。本文聚焦于LLMs的一个特定漏洞：顺序敏感性。这一问题不仅体现在LLMs在面对多项选择时的顺序偏见（例如倾向于选择第一个选项），还表现在当选项重新排序时，LLMs往往给出不同答案的倾向。这种情形的应用场景不仅限于传统的多项选择题回答，还扩展到将LLMs用作AI管道中的自动化评估器，比较不同模型生成的输出。我们引入了Set-LLM，这是一种针对预训练LLMs的全新架构适应方案，能够处理混合集合文本输入，并保证排列不变性。这种适应方案引入了一种新的注意力掩码和专门针对集合设计的新位置编码。我们不仅提供了不变性的理论证明，还通过实验表明，Set-LLM可以有效训练，实现与原模型相当或更优的性能，同时保持原模型的运行时间，彻底消除顺序敏感性。

> While large language models (LLMs) demonstrate impressive capabilities across numerous applications, their robustness remains a critical concern. This paper is motivated by a specific vulnerability: the order sensitivity of LLMs. This vulnerability manifests itself as the order bias observed when LLMs decide between possible options (for example, a preference for the first option) and the tendency of LLMs to provide different answers when options are reordered. The use cases for this scenario extend beyond the classical case of multiple-choice question answering to the use of LLMs as automated evaluators in AI pipelines, comparing output generated by different models. We introduce Set-LLM, a novel architectural adaptation for pretrained LLMs that enables the processing of mixed set-text inputs with permutation invariance guarantees. The adaptations involve a new attention mask and new positional encodings specifically designed for sets. We provide a theoretical proof of invariance and demonstrate through experiments that Set-LLM can be trained effectively, achieving comparable or improved performance and maintaining the runtime of the original model, while eliminating order sensitivity.

[Arxiv](https://arxiv.org/abs/2505.15433)