# # 开放权重 LLM 时代的网络风险缓解：政策空白与技术现实

发布时间：2025年05月21日

`LLM应用` `人工智能` `网络安全`

> Mitigating Cyber Risk in the Age of Open-Weight LLMs: Policy Gaps and Technical Realities

# 摘要

> 开放权重的通用人工智能（GPAI）模型虽具有显著优势，但也带来了重大网络安全风险。这在MITRE的OCCULT评估中，通过DeepSeek-R1等模型的进攻能力得到了体现。这些公开可用的模型赋予了更广泛的参与者自动化和扩大网络攻击的能力，挑战了传统的防御范式和监管方法。本文分析了由开放权重AI发布所放大的特定威胁，包括加速恶意软件开发和增强社会工程等。我们对现行法规进行了批判性评估，特别是欧盟《人工智能法案》和GPAI行为准则，发现由于开放分发固有的控制权丧失，存在重大漏洞，导致许多标准的安全缓解措施失效。我们提出了一条前进的道路，重点在于评估和控制特定高风险功能，而不是整个模型，倡导对开放权重系统进行务实的政策解释，促进防御性AI创新，并推动国际在标准和网络威胁情报（CTI）共享方面的合作，以确保安全，同时不过度抑制开放技术进步。

> Open-weight general-purpose AI (GPAI) models offer significant benefits but also introduce substantial cybersecurity risks, as demonstrated by the offensive capabilities of models like DeepSeek-R1 in evaluations such as MITRE's OCCULT. These publicly available models empower a wider range of actors to automate and scale cyberattacks, challenging traditional defence paradigms and regulatory approaches. This paper analyzes the specific threats -- including accelerated malware development and enhanced social engineering -- magnified by open-weight AI release. We critically assess current regulations, notably the EU AI Act and the GPAI Code of Practice, identifying significant gaps stemming from the loss of control inherent in open distribution, which renders many standard security mitigations ineffective. We propose a path forward focusing on evaluating and controlling specific high-risk capabilities rather than entire models, advocating for pragmatic policy interpretations for open-weight systems, promoting defensive AI innovation, and fostering international collaboration on standards and cyber threat intelligence (CTI) sharing to ensure security without unduly stifling open technological progress.

[Arxiv](https://arxiv.org/abs/2505.17109)