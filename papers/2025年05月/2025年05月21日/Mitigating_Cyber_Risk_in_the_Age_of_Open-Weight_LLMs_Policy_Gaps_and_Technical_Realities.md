# 开放权重大语言模型时代应对网络风险：政策空白与技术挑战

发布时间：2025年05月21日

`其他` `网络安全` `人工智能`

> Mitigating Cyber Risk in the Age of Open-Weight LLMs: Policy Gaps and Technical Realities

# 摘要

> 开源权重的通用人工智能（GPAI）模型虽优势显著，但也带来了重大网络安全风险。如DeepSeek-R1等模型在MITRE的OCCULT评估中展现出的强大攻击能力便印证了这一观点。这些公开的AI模型赋予了更多行动者自动化和扩大网络攻击的能力，对传统的防御模式和监管方法提出了挑战。

本文重点分析了开源权重发布所放大的特定威胁，包括恶意软件开发的加速和社交工程能力的显著增强。通过对现有法规的批判性评估，特别是欧盟《人工智能法案》和GPAI《行为准则》，我们发现这些法规存在重大漏洞。由于开源发布本质上导致的控制权丧失，许多标准的安全缓解措施因此失效。

我们提出了一条以评估和控制特定高风险功能为核心的发展道路。主张对开源系统采取务实的政策解释，推动防御性AI创新，并促进国际在标准制定和网络威胁情报（CTI）共享方面的合作。这不仅有助于确保安全，还能避免扼杀开放技术的进步。

> Open-weight general-purpose AI (GPAI) models offer significant benefits but also introduce substantial cybersecurity risks, as demonstrated by the offensive capabilities of models like DeepSeek-R1 in evaluations such as MITRE's OCCULT. These publicly available models empower a wider range of actors to automate and scale cyberattacks, challenging traditional defence paradigms and regulatory approaches. This paper analyzes the specific threats -- including accelerated malware development and enhanced social engineering -- magnified by open-weight AI release. We critically assess current regulations, notably the EU AI Act and the GPAI Code of Practice, identifying significant gaps stemming from the loss of control inherent in open distribution, which renders many standard security mitigations ineffective. We propose a path forward focusing on evaluating and controlling specific high-risk capabilities rather than entire models, advocating for pragmatic policy interpretations for open-weight systems, promoting defensive AI innovation, and fostering international collaboration on standards and cyber threat intelligence (CTI) sharing to ensure security without unduly stifling open technological progress.

[Arxiv](https://arxiv.org/abs/2505.17109)