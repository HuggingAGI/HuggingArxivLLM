# EduBench: 一个全面的基准测试数据集，专为在多样化教育场景中评估大型语言模型而设计。

发布时间：2025年05月21日

`LLM应用`

> EduBench: A Comprehensive Benchmarking Dataset for Evaluating Large Language Models in Diverse Educational Scenarios

# 摘要

> 随着大型语言模型的不断发展，其在教育领域的应用潜力尚未得到充分挖掘和优化。本文针对这一现状，推出了首个专为教育场景设计的多样化基准测试，整合了涵盖9大主要场景和超过4,000个独特教育背景的合成数据。为了实现全面的评估，我们提出了一套多维度的评估指标，涵盖了与教师和学生均相关的12个关键方面。此外，我们通过人工标注确保了模型生成的评估结果的有效性。值得注意的是，我们在构建的数据集上成功训练了一个相对小型的模型，并在测试集中达到了与当前最先进的大型模型（如Deepseek V3、Qwen Max）相当的性能水平。总体而言，本研究为教育导向型语言模型的开发与评估提供了坚实的基础。代码和数据已发布于GitHub：https://github.com/ybai-nlp/EduBench.

> As large language models continue to advance, their application in educational contexts remains underexplored and under-optimized. In this paper, we address this gap by introducing the first diverse benchmark tailored for educational scenarios, incorporating synthetic data containing 9 major scenarios and over 4,000 distinct educational contexts. To enable comprehensive assessment, we propose a set of multi-dimensional evaluation metrics that cover 12 critical aspects relevant to both teachers and students. We further apply human annotation to ensure the effectiveness of the model-generated evaluation responses. Additionally, we succeed to train a relatively small-scale model on our constructed dataset and demonstrate that it can achieve performance comparable to state-of-the-art large models (e.g., Deepseek V3, Qwen Max) on the test set. Overall, this work provides a practical foundation for the development and evaluation of education-oriented language models. Code and data are released at https://github.com/ybai-nlp/EduBench.

[Arxiv](https://arxiv.org/abs/2505.16160)