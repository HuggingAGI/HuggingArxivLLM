# 大型语言模型能否胜任在线意见挖掘这一角色？

发布时间：2025年05月21日

`LLM应用

理由：这篇论文主要探讨了大型语言模型（LLMs）在在线观点挖掘中的应用，介绍了基准测试OOMB的构建和评估协议，分析了模型在复杂在线环境中的表现。论文的重点在于评估和应用LLMs进行观点挖掘，属于LLM的应用领域。` `市场营销`

> Can Large Language Models be Effective Online Opinion Miners?

# 摘要

> 用户生成的在线内容激增为洞察客户偏好和市场趋势提供了丰富见解。然而，这些内容的高度多样化、复杂性和语境丰富性对传统观点挖掘方法提出了巨大挑战。为此，我们引入了在线观点挖掘基准（OOMB），这是一个全新的数据集和评估协议，旨在评估大型语言模型（LLMs）在多样且复杂的在线环境中有效挖掘观点的能力。

OOMB提供了广泛的（实体、特征、观点）元组标注和全面的观点中心摘要，突出了每个内容中的关键观点主题，从而能够评估模型的提取和抽象能力。通过我们的基准测试，我们全面分析了哪些方面仍然具有挑战性以及LLMs在哪些方面表现出适应性，以探索它们是否能够有效地作为现实在线场景中的观点挖掘工具。

这项研究为基于LLM的观点挖掘奠定了基础，并讨论了该领域未来研究的方向。

> The surge of user-generated online content presents a wealth of insights into customer preferences and market trends. However, the highly diverse, complex, and context-rich nature of such contents poses significant challenges to traditional opinion mining approaches. To address this, we introduce Online Opinion Mining Benchmark (OOMB), a novel dataset and evaluation protocol designed to assess the ability of large language models (LLMs) to mine opinions effectively from diverse and intricate online environments. OOMB provides extensive (entity, feature, opinion) tuple annotations and a comprehensive opinion-centric summary that highlights key opinion topics within each content, thereby enabling the evaluation of both the extractive and abstractive capabilities of models. Through our proposed benchmark, we conduct a comprehensive analysis of which aspects remain challenging and where LLMs exhibit adaptability, to explore whether they can effectively serve as opinion miners in realistic online scenarios. This study lays the foundation for LLM-based opinion mining and discusses directions for future research in this field.

[Arxiv](https://arxiv.org/abs/2505.15695)