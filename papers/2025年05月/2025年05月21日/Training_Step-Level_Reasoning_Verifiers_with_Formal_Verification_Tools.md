# 使用形式化验证工具训练步骤级别的推理验证器

发布时间：2025年05月21日

`LLM应用` `数学推理` `形式验证`

> Training Step-Level Reasoning Verifiers with Formal Verification Tools

# 摘要

> 过程奖励模型（PRMs）能够为大型语言模型（LLMs）生成的推理过程提供逐步反馈，正逐渐受到越来越多的关注。然而，目前仍存在两个关键的研究空白：为训练收集准确的分步错误标签通常需要耗费大量的人工标注成本，且现有的PRMs仅限于数学推理问题。针对这些空白，本文旨在解决自动数据集创建以及将PRMs泛化到多种推理任务的挑战。为实现这一目标，我们提出了FoVer，一种利用形式化验证工具（如Z3用于形式逻辑，Isabelle用于定理证明）自动标注分步错误标签来训练PRMs的方法。通过这种方法，我们无需人工标注即可合成一个训练数据集，其中包含了形式逻辑和定理证明任务中对LLM响应的错误标签。尽管这种数据合成仅适用于与形式验证兼容的任务，但我们在实验中发现，基于我们数据集训练的LLM-based PRMs展现出跨任务的泛化能力，能够在多种推理任务中提升验证效果。具体而言，通过FoVer训练的PRMs显著优于基于原始LLMs的基线PRMs，并在ProcessBench上的分步验证和涵盖MATH、AIME、ANLI、MMLU和BBH等12个推理基准测试的Best-of-K性能方面，与基于人工标注或更强模型标注的最先进的PRMs相比，取得了具有竞争力甚至更优的结果。数据集、模型和代码可在https://github.com/psunlpgroup/FoVer获取。

> Process Reward Models (PRMs), which provide step-by-step feedback on the reasoning generated by Large Language Models (LLMs), are receiving increasing attention. However, two key research gaps remain: collecting accurate step-level error labels for training typically requires costly human annotation, and existing PRMs are limited to math reasoning problems. In response to these gaps, this paper aims to address the challenges of automatic dataset creation and the generalization of PRMs to diverse reasoning tasks. To achieve this goal, we propose FoVer, an approach for training PRMs on step-level error labels automatically annotated by formal verification tools, such as Z3 for formal logic and Isabelle for theorem proof, which provide automatic and accurate verification for symbolic tasks. Using this approach, we synthesize a training dataset with error labels on LLM responses for formal logic and theorem proof tasks without human annotation. Although this data synthesis is feasible only for tasks compatible with formal verification, we observe that LLM-based PRMs trained on our dataset exhibit cross-task generalization, improving verification across diverse reasoning tasks. Specifically, PRMs trained with FoVer significantly outperform baseline PRMs based on the original LLMs and achieve competitive or superior results compared to state-of-the-art PRMs trained on labels annotated by humans or stronger models, as measured by step-level verification on ProcessBench and Best-of-K performance across 12 reasoning benchmarks, including MATH, AIME, ANLI, MMLU, and BBH. The datasets, models, and code are provided at https://github.com/psunlpgroup/FoVer.

[Arxiv](https://arxiv.org/abs/2505.15960)