# 从Token到思维：LLMs与人类如何在压缩与意义之间进行交换

发布时间：2025年05月21日

`LLM理论` `语言模型` `认知科学`

> From Tokens to Thoughts: How LLMs and Humans Trade Compression for Meaning

# 摘要

> 人类通过语义压缩将知识组织成紧凑的类别，例如知更鸟和蓝鸟同属鸟类，而大多数鸟类都能飞翔。这种分类方式在表达的精确性和表示的简洁性之间找到了平衡。虽然大型语言模型（LLMs）展现了卓越的语言能力，但它们的内部表示是否像人类一样在压缩与语义保真度之间取得平衡，仍是一个未解之谜。我们提出了一种基于速率失真理论和信息瓶颈原则的新信息论框架，用于定量比较这些策略。通过对多样化LLMs的标记嵌入与经典人类分类基准的分析，我们发现了一些关键差异。LLMs能够形成与人类判断一致的广泛概念类别，但在捕捉对人类理解至关重要的细微语义差别方面表现不足。更值得注意的是，LLMs倾向于进行激进的统计压缩，而人类概念系统则更注重适应性的细微差别和语境的丰富性，即使这会降低压缩效率。这些发现揭示了当前AI与人类认知架构之间的关键差异，为开发具有更符合人类概念表示的LLMs提供了重要启示。

> Humans organize knowledge into compact categories through semantic compression by mapping diverse instances to abstract representations while preserving meaning (e.g., robin and blue jay are both birds; most birds can fly). These concepts reflect a trade-off between expressive fidelity and representational simplicity. Large Language Models (LLMs) demonstrate remarkable linguistic abilities, yet whether their internal representations strike a human-like trade-off between compression and semantic fidelity is unclear. We introduce a novel information-theoretic framework, drawing from Rate-Distortion Theory and the Information Bottleneck principle, to quantitatively compare these strategies. Analyzing token embeddings from a diverse suite of LLMs against seminal human categorization benchmarks, we uncover key divergences. While LLMs form broad conceptual categories that align with human judgment, they struggle to capture the fine-grained semantic distinctions crucial for human understanding. More fundamentally, LLMs demonstrate a strong bias towards aggressive statistical compression, whereas human conceptual systems appear to prioritize adaptive nuance and contextual richness, even if this results in lower compressional efficiency by our measures. These findings illuminate critical differences between current AI and human cognitive architectures, guiding pathways toward LLMs with more human-aligned conceptual representations.

[Arxiv](https://arxiv.org/abs/2505.17117)