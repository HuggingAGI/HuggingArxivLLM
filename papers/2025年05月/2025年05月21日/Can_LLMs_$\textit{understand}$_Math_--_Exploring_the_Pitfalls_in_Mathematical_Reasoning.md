# 大型语言模型真的能理解数学吗？——解析数学推理中的潜在问题

发布时间：2025年05月21日

`LLM理论` `数学推理` `评估框架`

> Can LLMs $\textit{understand}$ Math? -- Exploring the Pitfalls in Mathematical Reasoning

# 摘要

> 大型语言模型（LLMs）在自然语言任务中表现优异，但数学推理，尤其是精确的多步骤逻辑推理，仍具挑战性。现有评估框架仅依据最终答案的准确性评判性能，忽略了推理过程中的问题。本研究采用新型评估框架，深入探讨这些局限性。我们提出了MAPLE分数，通过综合考量错误率、冗余性和有效性，全面量化推理偏差。

> Large language models (LLMs) demonstrate considerable potential in various natural language tasks but face significant challenges in mathematical reasoning, particularly in executing precise, multi-step logic. However, current evaluation frameworks judge their performance solely based on accuracy, which only accounts for the final answer. This study explores these pitfalls by employing a novel evaluation framework. We propose an evaluation metric called the MAPLE score, which holistically quantifies reasoning misalignment by integrating error rates, redundancy, and validity.

[Arxiv](https://arxiv.org/abs/2505.15623)