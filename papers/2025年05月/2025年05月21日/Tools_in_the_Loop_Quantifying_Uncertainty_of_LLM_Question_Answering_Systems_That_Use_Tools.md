# 工具在循环中：量化使用工具的大型语言模型问答系统的不确定性

发布时间：2025年05月21日

`LLM应用

理由：这篇论文探讨了大型语言模型（LLMs）在工具调用场景中的应用，特别是如何通过不确定性建模框架来提升系统在实际应用中的可信度。论文提出了一种新的方法来量化LLM和外部工具的不确定性，适用于需要外部信息检索的场景，如增强型检索生成（RAG）系统。虽然提到了RAG系统，但论文的核心是关于LLM的应用和不确定性建模，因此归类为LLM应用。` `大型语言模型` `工具调用`

> Tools in the Loop: Quantifying Uncertainty of LLM Question Answering Systems That Use Tools

# 摘要

> # 现代大型语言模型的工具调用与不确定性建模框架

现代大型语言模型（LLMs）在处理某些任务时，常常需要借助外部工具（如机器学习分类器或知识检索系统），以弥补其预训练知识的不足，从而提供准确的答案。这种将LLMs与外部工具相结合的方式，虽然扩展了模型的应用范围，但也带来了一个关键挑战：如何评估联合系统生成响应的可信度。

在高风险应用场景（如医疗决策）中，必须同时评估LLM生成文本的不确定性和外部工具输出的不确定性，以确保最终响应的可靠性。然而，现有的不确定性量化方法并未充分考虑工具调用场景中的复杂性，其中LLM和外部工具都会对整个系统的不确定性产生影响。

在本研究中，我们提出了一种全新的框架，用于建模工具调用场景下的LLMs，通过综合考虑LLM和外部工具的预测不确定性，实现对整体不确定性的量化。我们对现有基于token序列的不确定性量化方法进行了扩展，并提出了高效的近似算法，使不确定性计算在实际应用中更具可行性。

我们通过两个基于知名机器学习数据集构建的合成问答数据集，对我们的框架进行了评估，这些数据集需要通过工具调用来获得准确答案。此外，我们将方法应用于增强型检索生成（RAG）系统，并通过概念验证实验，展示了我们的不确定性指标在需要外部信息检索场景中的有效性。

实验结果表明，我们的框架有效提升了基于LLM系统在实际应用中的可信度，特别是在LLM内部知识不足且需要调用外部工具的情况下。

> Modern Large Language Models (LLMs) often require external tools, such as machine learning classifiers or knowledge retrieval systems, to provide accurate answers in domains where their pre-trained knowledge is insufficient. This integration of LLMs with external tools expands their utility but also introduces a critical challenge: determining the trustworthiness of responses generated by the combined system. In high-stakes applications, such as medical decision-making, it is essential to assess the uncertainty of both the LLM's generated text and the tool's output to ensure the reliability of the final response. However, existing uncertainty quantification methods do not account for the tool-calling scenario, where both the LLM and external tool contribute to the overall system's uncertainty. In this work, we present a novel framework for modeling tool-calling LLMs that quantifies uncertainty by jointly considering the predictive uncertainty of the LLM and the external tool. We extend previous methods for uncertainty quantification over token sequences to this setting and propose efficient approximations that make uncertainty computation practical for real-world applications. We evaluate our framework on two new synthetic QA datasets, derived from well-known machine learning datasets, which require tool-calling for accurate answers. Additionally, we apply our method to retrieval-augmented generation (RAG) systems and conduct a proof-of-concept experiment demonstrating the effectiveness of our uncertainty metrics in scenarios where external information retrieval is needed. Our results show that the framework is effective in enhancing trust in LLM-based systems, especially in cases where the LLM's internal knowledge is insufficient and external tools are required.

[Arxiv](https://arxiv.org/abs/2505.16113)