# 从模板到自然语言：指令微调的大型语言模型在空间推理任务中的泛化挑战

发布时间：2025年05月20日

`LLM应用` `机器人` `自动化`

> From Templates to Natural Language: Generalization Challenges in Instruction-Tuned LLMs for Spatial Reasoning

# 摘要

> 指令微调的大型语言模型 (LLMs) 在多种任务中表现强劲，但将这种能力从合成指令泛化到真实的人类编写指令仍具挑战性。本研究聚焦于空间定位任务中的泛化难题，即模型如何理解和转换指令以构建物体在 2.5D 网格中的排列。我们仅使用合成指令对 LLMs 进行微调，并在包含合成与人类编写指令的基准数据集上评估其性能。结果显示，模型在简单任务中表现良好，但在复杂任务中性能显著下降。我们对指令泛化的差距进行了详细分析。


> Instruction-tuned large language models (LLMs) have shown strong performance on a variety of tasks; however, generalizing from synthetic to human-authored instructions in grounded environments remains a challenge for them. In this work, we study generalization challenges in spatial grounding tasks where models interpret and translate instructions for building object arrangements on a $2.5$D grid. We fine-tune LLMs using only synthetic instructions and evaluate their performance on a benchmark dataset containing both synthetic and human-written instructions. Our results reveal that while models generalize well on simple tasks, their performance degrades significantly on more complex tasks. We present a detailed error analysis of the gaps in instruction generalization.

[Arxiv](https://arxiv.org/abs/2505.14425)