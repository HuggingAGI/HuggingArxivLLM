# 因果VL基准：大型视觉-语言模型中的视觉因果推理基准测试

发布时间：2025年05月20日

`LLM应用` `因果推理`

> CausalVLBench: Benchmarking Visual Causal Reasoning in Large Vision-Language Models

# 摘要

> 大型语言模型（LLMs）凭借其卓越的上下文学习能力，在语言任务中表现出色。通过引入视觉输入，大型视觉-语言模型（LVLMs）在图像识别和视觉问答（VQA）等领域也取得了显著成果。尽管LLMs在因果推理任务中的应用备受关注，但关于LVLMs在视觉因果推理方面的能力研究却较为匮乏。为此，我们推出一个全面的因果推理基准——CausalVLBench，专注于评估多模态上下文学习中的LVLMs表现。该基准包含三个核心任务：因果结构推断、干预目标预测及反事实预测。通过在三个因果表征学习数据集上的实证研究，我们全面评估了当前主流开源LVLMs的因果推理能力，揭示了其优缺点。我们期待这一基准能够指出现有视觉-语言模型的局限性，并为提升LVLMs的视觉因果推理能力开辟新的研究方向与范式。

> Large language models (LLMs) have shown remarkable ability in various language tasks, especially with their emergent in-context learning capability. Extending LLMs to incorporate visual inputs, large vision-language models (LVLMs) have shown impressive performance in tasks such as recognition and visual question answering (VQA). Despite increasing interest in the utility of LLMs in causal reasoning tasks such as causal discovery and counterfactual reasoning, there has been relatively little work showcasing the abilities of LVLMs on visual causal reasoning tasks. We take this opportunity to formally introduce a comprehensive causal reasoning benchmark for multi-modal in-context learning from LVLMs. Our CausalVLBench encompasses three representative tasks: causal structure inference, intervention target prediction, and counterfactual prediction. We evaluate the ability of state-of-the-art open-source LVLMs on our causal reasoning tasks across three causal representation learning datasets and demonstrate their fundamental strengths and weaknesses. We hope that our benchmark elucidates the drawbacks of existing vision-language models and motivates new directions and paradigms in improving the visual causal reasoning abilities of LVLMs.

[Arxiv](https://arxiv.org/abs/2506.11034)