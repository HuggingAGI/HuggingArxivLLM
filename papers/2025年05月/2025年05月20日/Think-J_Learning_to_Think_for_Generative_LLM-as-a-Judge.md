# Think-J：让生成式大语言模型学会思考与评判

发布时间：2025年05月20日

`LLM理论`

> Think-J: Learning to Think for Generative LLM-as-a-Judge

# 摘要

> LLM-as-a-Judge 是指对大型语言模型 (LLMs) 生成的响应进行自动偏好建模，这对 LLM 评估和奖励建模至关重要。尽管生成型 LLM 在各类任务中表现突出，但其作为 LLM-Judge 的能力仍有待提升。本研究提出 Think-J，通过学习思考来优化生成型 LLM-as-a-Judge。我们首先利用少量精选数据开发了具备基础判断思维能力的模型，随后基于强化学习 (RL) 进一步优化判断思维轨迹。我们分别提出了基于离线和在线 RL 的两种优化方法：离线 RL 需训练批评模型构建正反例，而在线方法则采用基于规则的奖励反馈。实验结果表明，我们的方法显著提升了生成型 LLM-Judge 的评估能力，超越了传统生成型和分类器基线，且无需额外人工标注。

> LLM-as-a-Judge refers to the automatic modeling of preferences for responses generated by Large Language Models (LLMs), which is of significant importance for both LLM evaluation and reward modeling. Although generative LLMs have made substantial progress in various tasks, their performance as LLM-Judge still falls short of expectations. In this work, we propose Think-J, which improves generative LLM-as-a-Judge by learning how to think. We first utilized a small amount of curated data to develop the model with initial judgment thinking capabilities. Subsequently, we optimize the judgment thinking traces based on reinforcement learning (RL). We propose two methods for judgment thinking optimization, based on offline and online RL, respectively. The offline RL requires training a critic model to construct positive and negative examples for learning. The online method defines rule-based reward as feedback for optimization. Experimental results showed that our approach can significantly enhance the evaluation capability of generative LLM-Judge, surpassing both generative and classifier-based LLM-Judge without requiring extra human annotations.

[Arxiv](https://arxiv.org/abs/2505.14268)