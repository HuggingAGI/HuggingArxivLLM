# MedBrowseComp: 医疗深度研究与计算机使用基准测试

发布时间：2025年05月20日

`LLM应用` `知识图谱`

> MedBrowseComp: Benchmarking Medical Deep Research and Computer Use

# 摘要

> 大型语言模型（LLMs）在临床实践中被寄予厚望成为决策支持工具，但安全的临床推理需要在严格的准确性要求下整合异质化的知识库——包括试验、原始研究、监管文件和成本数据。现有的评估方法往往依赖于合成提示，将任务简化为单跳事实查询，或将推理与开放生成混为一谈，导致其实际效用尚不明确。为填补这一空白，我们推出了MedBrowseComp——首个系统测试智能体从实时、领域特定知识库中可靠检索和综合多跳医学事实能力的基准。MedBrowseComp包含超过1000个由人工精选的问题，这些问题模拟了临床场景，其中从业者必须协调碎片化或相互矛盾的信息以得出最新的结论。将MedBrowseComp应用于前沿的智能体系统揭示了性能不足，低至10%，这暴露了当前LLM能力与临床环境中所需严谨性之间的关键差距。因此，MedBrowseComp不仅为可靠医疗信息检索提供了一个明确的测试平台，还为未来模型和工具链的升级设定了具体目标。访问我们的项目页面了解更多：https://moreirap12.github.io/mbc-browse-app/

> Large language models (LLMs) are increasingly envisioned as decision-support tools in clinical practice, yet safe clinical reasoning demands integrating heterogeneous knowledge bases -- trials, primary studies, regulatory documents, and cost data -- under strict accuracy constraints. Existing evaluations often rely on synthetic prompts, reduce the task to single-hop factoid queries, or conflate reasoning with open-ended generation, leaving their real-world utility unclear. To close this gap, we present MedBrowseComp, the first benchmark that systematically tests an agent's ability to reliably retrieve and synthesize multi-hop medical facts from live, domain-specific knowledge bases. MedBrowseComp contains more than 1,000 human-curated questions that mirror clinical scenarios where practitioners must reconcile fragmented or conflicting information to reach an up-to-date conclusion. Applying MedBrowseComp to frontier agentic systems reveals performance shortfalls as low as ten percent, exposing a critical gap between current LLM capabilities and the rigor demanded in clinical settings. MedBrowseComp therefore offers a clear testbed for reliable medical information seeking and sets concrete goals for future model and toolchain upgrades. You can visit our project page at: https://moreirap12.github.io/mbc-browse-app/

[Arxiv](https://arxiv.org/abs/2505.14963)