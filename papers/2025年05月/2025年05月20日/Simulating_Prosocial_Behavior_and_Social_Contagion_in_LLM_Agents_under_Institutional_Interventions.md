# 在机构干预下，仿真LLM智能体的亲社会行为与社会传染

发布时间：2025年05月20日

`LLM应用` `社会科学` `人工智能`

> Simulating Prosocial Behavior and Social Contagion in LLM Agents under Institutional Interventions

# 摘要

> 随着大型语言模型（LLMs）越来越多地作为自主代理在社交情境中发挥作用，理解它们的亲社会行为能力变得至关重要。我们提出了ProSim框架，用于研究LLM代理在不同社会和制度条件下如何产生、适应和削弱亲社会行为。该框架由个体模拟、场景模拟、交互模拟和干预模拟四个部分组成。我们通过三项逐步研究来评估亲社会行为的一致性。首先，LLM代理能够在各种场景中表现出稳定且情境敏感的亲社会行为，并在规范性政策干预下调整响应。其次，代理会参与基于公平的第三方惩罚，并对不平等程度和执行成本的变化做出系统性反应。最后，政策导致的不平等会抑制亲社会行为，通过社会网络传播，并受到代理对不公平感知的影响。这些发现为评估社会一致性和在代理驱动社会中建模机构动态奠定了基础。

> As large language models (LLMs) increasingly serve as autonomous agents in social contexts, understanding their capacity for prosocial behavior becomes essential. We present ProSim, a simulation framework designed to examine how prosocial behavior emerges, adapts, and erodes in LLM-based agents under diverse social and institutional conditions. The framework comprises four components: individual simulation, scenario simulation, interaction simulation, and intervention simulation. We conduct three progressive studies to evaluate prosocial alignment. First, we show that LLM agents can demonstrate stable and context-sensitive prosocial behavior across diverse scenarios and adapt their responses under normative policy interventions. Second, we find that agents engage in fairness-based third-party punishment and respond systematically to variations in inequity magnitude and enforcement cost. Third, we show that policy-induced inequities suppress prosocial behavior, propagate through social networks, and are mediated by agents' perceptions of unfairness. These findings lay the groundwork for evaluating social alignment and modeling institutional dynamics in agent-driven societies.

[Arxiv](https://arxiv.org/abs/2505.15857)