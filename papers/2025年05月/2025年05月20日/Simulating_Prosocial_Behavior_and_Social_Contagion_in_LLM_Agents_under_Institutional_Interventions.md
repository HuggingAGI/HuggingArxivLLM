# 机构干预下LLM智能体中的亲社会行为与社会传染模拟

发布时间：2025年05月20日

`Agent` `社会模拟` `代理行为`

> Simulating Prosocial Behavior and Social Contagion in LLM Agents under Institutional Interventions

# 摘要

> 随着大型语言模型 (LLMs) 在社会环境中越来越多地作为自主代理，理解它们的亲社会行为能力变得至关重要。为此，我们提出了 ProSim，一个模拟框架，用于研究 LLM 基础代理在多样化的社会和制度环境中，亲社会行为如何出现、适应和消退。该框架由四个关键部分组成：个体模拟、场景模拟、交互模拟和干预模拟。

我们通过三项逐步研究来评估亲社会一致性。首先，我们发现 LLM 代理能够稳定地在多种场景中展示情境敏感的亲社会行为，并且在规范性政策干预下能够灵活调整其响应。其次，我们发现代理能够进行基于公平的第三方惩罚，并且系统地回应不平等程度和执行成本的变化。第三，我们发现政策引发的不平等不仅会抑制亲社会行为，还会通过社会网络传播，并且这种抑制作用受代理对不公平感知的中介作用。

这些研究发现为评估社会一致性和在代理驱动社会中建模机构动力学奠定了重要基础。

> As large language models (LLMs) increasingly serve as autonomous agents in social contexts, understanding their capacity for prosocial behavior becomes essential. We present ProSim, a simulation framework designed to examine how prosocial behavior emerges, adapts, and erodes in LLM-based agents under diverse social and institutional conditions. The framework comprises four components: individual simulation, scenario simulation, interaction simulation, and intervention simulation. We conduct three progressive studies to evaluate prosocial alignment. First, we show that LLM agents can demonstrate stable and context-sensitive prosocial behavior across diverse scenarios and adapt their responses under normative policy interventions. Second, we find that agents engage in fairness-based third-party punishment and respond systematically to variations in inequity magnitude and enforcement cost. Third, we show that policy-induced inequities suppress prosocial behavior, propagate through social networks, and are mediated by agents' perceptions of unfairness. These findings lay the groundwork for evaluating social alignment and modeling institutional dynamics in agent-driven societies.

[Arxiv](https://arxiv.org/abs/2505.15857)