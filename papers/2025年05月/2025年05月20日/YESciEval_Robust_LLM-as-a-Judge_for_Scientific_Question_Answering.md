# YESciEval：用于科学问答的 robust LLM 评判系统

发布时间：2025年05月20日

`LLM应用` `搜索引擎` `计算机科学`

> YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering

# 摘要

> 大型语言模型（LLMs）正在改变现代搜索引擎的科学问答能力，但其评估的可靠性仍待深入研究。我们推出开源框架YESciEval，通过结合细粒度评分标准评估与强化学习，有效减少LLM评估中的乐观偏见。我们发布了涵盖多学科的问答数据集，包括对抗变体，并提供了多个LLM的评估结果。无需依赖专有模型或人工反馈，我们的方法实现了高效且免费的评估方案。这项研究不仅提升了LLM作为评估工具的可靠性，更推动了AI对齐目标的实现，为科学探究和通用人工智能发展奠定了坚实基础。

> Large Language Models (LLMs) drive scientific question-answering on modern search engines, yet their evaluation robustness remains underexplored. We introduce YESciEval, an open-source framework that combines fine-grained rubric-based assessment with reinforcement learning to mitigate optimism bias in LLM evaluators. We release multidisciplinary scienceQ&A datasets, including adversarial variants, with evaluation scores from multiple LLMs. Independent of proprietary models and human feedback, our approach enables scalable, cost-free evaluation. By advancing reliable LLM-as-a-judge models, this work supports AI alignment and fosters robust, transparent evaluation essential for scientific inquiry and artificial general intelligence.

[Arxiv](https://arxiv.org/abs/2505.14279)