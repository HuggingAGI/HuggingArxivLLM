# # 激励包容性贡献的模型共享市场机制

发布时间：2025年05月05日

`其他` `人工智能` `分布式计算`

> Incentivizing Inclusive Contributions in Model Sharing Markets

# 摘要

> 数据是训练当代AI模型的基石，但目前，有价值的公共数据将在未来几年内面临耗尽的风险，这促使全球目光转向了海量分散的私人数据。然而，原始数据的隐私敏感性以及缺乏有效的激励机制，限制了这些宝贵数据的充分利用。针对这一问题，本文提出了一种名为激励型个性化联邦学习（iPFL）的解决方案。通过构建基于博弈论的激励机制，iPFL能够激励具有不同目标的数据持有者，在保护隐私的前提下，协同训练个性化模型。具体而言，iPFL通过解决基于图的训练优化问题，构建了一个模型共享市场。理论分析表明，iPFL具备个体理性与真实报告两大关键激励属性。在涵盖大型语言模型指令遵循任务等11个AI任务的实证研究中，iPFL不仅在经济效用方面表现最优，其模型性能也优于或与现有方法持平。我们相信，iPFL将为未来基于分散式私人数据的AI模型训练提供一种高效且各方满意的解决方案。

> While data plays a crucial role in training contemporary AI models, it is acknowledged that valuable public data will be exhausted in a few years, directing the world's attention towards the massive decentralized private data. However, the privacy-sensitive nature of raw data and lack of incentive mechanism prevent these valuable data from being fully exploited. Addressing these challenges, this paper proposes inclusive and incentivized personalized federated learning (iPFL), which incentivizes data holders with diverse purposes to collaboratively train personalized models without revealing raw data. iPFL constructs a model-sharing market by solving a graph-based training optimization and incorporates an incentive mechanism based on game theory principles. Theoretical analysis shows that iPFL adheres to two key incentive properties: individual rationality and truthfulness. Empirical studies on eleven AI tasks (e.g., large language models' instruction-following tasks) demonstrate that iPFL consistently achieves the highest economic utility, and better or comparable model performance compared to baseline methods. We anticipate that our iPFL can serve as a valuable technique for boosting future AI models on decentralized private data while making everyone satisfied.

[Arxiv](https://arxiv.org/abs/2505.02462)