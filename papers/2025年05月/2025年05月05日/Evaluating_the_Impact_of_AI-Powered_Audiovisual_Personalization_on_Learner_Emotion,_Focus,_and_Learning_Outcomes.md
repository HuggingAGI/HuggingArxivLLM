# # 研究AI驱动的视听个性化技术对学习者情感状态、专注程度以及学习成果的影响

发布时间：2025年05月05日

`LLM应用

理由：这篇论文探讨了大型语言模型在教育技术中的应用，特别是在生成个性化多感官学习环境方面的潜力。它利用LLMs的能力来创建沉浸式学习场景，旨在减少分心并增强情绪稳定性，属于LLM的实际应用。` `生成技术`

> Evaluating the Impact of AI-Powered Audiovisual Personalization on Learner Emotion, Focus, and Learning Outcomes

# 摘要

> 独立学习者在无结构或易分心的环境中常常难以保持专注并进行情绪调节。虽然有些人依靠环境辅助工具（如音乐、ASMR或视觉背景）来支持注意力集中，但这些工具很少被整合到统一的、以学习者为中心的系统中。现有教育技术主要关注内容适配和反馈，忽视了学习所处的情感和感官环境。大型语言模型已展示出强大的多模态能力，包括生成和适应文本、音频和视觉内容的能力，但教育研究尚未充分探索其在创建个性化视听学习环境方面的潜力。为解决这一空白，我们推出了一款由AI驱动的系统，利用LLMs生成个性化的多感官学习环境。用户可选择或生成定制的视觉主题（如抽象与现实，静态与动态）和听觉元素（如白噪音、环境ASMR、熟悉与新颖的声音），以创建沉浸式学习场景，旨在减少分心并增强情绪稳定性。我们的研究主要探讨个性化视听元素的组合如何影响学习者认知负荷和参与度。本研究采用混合方法设计，结合生物计量指标和绩效结果，评估由LLM驱动的感官个性化效果。研究结果旨在推动情感响应型教育技术的发展，并将多模态LLMs的应用扩展到自我导向学习的感官维度。

> Independent learners often struggle with sustaining focus and emotional regulation in unstructured or distracting settings. Although some rely on ambient aids such as music, ASMR, or visual backgrounds to support concentration, these tools are rarely integrated into cohesive, learner-centered systems. Moreover, existing educational technologies focus primarily on content adaptation and feedback, overlooking the emotional and sensory context in which learning takes place. Large language models have demonstrated powerful multimodal capabilities including the ability to generate and adapt text, audio, and visual content. Educational research has yet to fully explore their potential in creating personalized audiovisual learning environments. To address this gap, we introduce an AI-powered system that uses LLMs to generate personalized multisensory study environments. Users select or generate customized visual themes (e.g., abstract vs. realistic, static vs. animated) and auditory elements (e.g., white noise, ambient ASMR, familiar vs. novel sounds) to create immersive settings aimed at reducing distraction and enhancing emotional stability. Our primary research question investigates how combinations of personalized audiovisual elements affect learner cognitive load and engagement. Using a mixed-methods design that incorporates biometric measures and performance outcomes, this study evaluates the effectiveness of LLM-driven sensory personalization. The findings aim to advance emotionally responsive educational technologies and extend the application of multimodal LLMs into the sensory dimension of self-directed learning.

[Arxiv](https://arxiv.org/abs/2505.03033)