# 34个LLM在材料科学与化学中的应用案例：探索自动化、智能体、智能助手和加速科学发现的未来

发布时间：2025年05月05日

`LLM应用` `材料科学`

> 34 Examples of LLM Applications in Materials Science and Chemistry: Towards Automation, Assistants, Agents, and Accelerated Scientific Discovery

# 摘要

> 大型语言模型（LLMs）正在深刻改变材料科学与化学研究的面貌，推动了分子性质预测、材料设计、科学自动化、知识提取等领域的突破。最新研究显示，新一代LLMs不仅能整合结构化与非结构化数据，还能辅助假设生成，优化研究流程。为探索LLMs在研究全流程中的潜力，我们回顾了第二届全球材料科学与化学领域大型语言模型应用黑客马拉松的34个项目。这些项目覆盖了七大核心领域：分子与材料性质预测、设计、自动化与界面创新、科学交流与教育、数据管理、假设生成与评估，以及从文献中提取知识与推理。这些案例生动展示了LLMs作为多功能预测工具和领域专属工具快速开发平台的潜力。值得注意的是，通过增强推理能力、扩充训练数据和引入新技术，开源与专有LLMs在低数据环境和跨学科研究中的表现尤为突出。随着LLMs的持续演进，其在科学工作流程中的应用既带来了新机遇，也提出了新挑战，需要我们不断探索、优化和深入研究，以应对可靠性、可解释性和可重复性等关键问题。

> Large Language Models (LLMs) are reshaping many aspects of materials science and chemistry research, enabling advances in molecular property prediction, materials design, scientific automation, knowledge extraction, and more. Recent developments demonstrate that the latest class of models are able to integrate structured and unstructured data, assist in hypothesis generation, and streamline research workflows. To explore the frontier of LLM capabilities across the research lifecycle, we review applications of LLMs through 34 total projects developed during the second annual Large Language Model Hackathon for Applications in Materials Science and Chemistry, a global hybrid event. These projects spanned seven key research areas: (1) molecular and material property prediction, (2) molecular and material design, (3) automation and novel interfaces, (4) scientific communication and education, (5) research data management and automation, (6) hypothesis generation and evaluation, and (7) knowledge extraction and reasoning from the scientific literature. Collectively, these applications illustrate how LLMs serve as versatile predictive models, platforms for rapid prototyping of domain-specific tools, and much more. In particular, improvements in both open source and proprietary LLM performance through the addition of reasoning, additional training data, and new techniques have expanded effectiveness, particularly in low-data environments and interdisciplinary research. As LLMs continue to improve, their integration into scientific workflows presents both new opportunities and new challenges, requiring ongoing exploration, continued refinement, and further research to address reliability, interpretability, and reproducibility.

[Arxiv](https://arxiv.org/abs/2505.03049)