# # Tevatron 2.0：跨规模、语言与模态的统一文档检索工具包

发布时间：2025年05月05日

`LLM应用` `信息检索` `工具开发`

> Tevatron 2.0: Unified Document Retrieval Toolkit across Scale, Language, and Modality

# 摘要

> 大型语言模型（LLMs）的最新进展激发了对十亿规模检索模型的兴趣，这些模型在各类检索任务和语言中展现了强大的泛化能力。同时，大型视觉语言模型的进步也为多模态检索开辟了新的机遇。为此，我们更新了Tevatron工具包，引入了一个统一的流水线，使研究人员能够探索不同规模、多语言以及多模态的检索器模型。这篇演示论文重点介绍了该工具包的关键特性，通过支持神经检索器的高效训练、推理和评估，架起学术界与工业界的桥梁。我们展示了一个统一的稠密检索器，在跨语言和跨模态任务中表现优异，并开展了一项跨模态零样本研究，以凸显其研究潜力。此外，我们发布了OmniEmbed，据我们所知，这是首个整合文本、图像文档、视频和音频检索的嵌入模型，为未来研究提供了基准。


> Recent advancements in large language models (LLMs) have driven interest in billion-scale retrieval models with strong generalization across retrieval tasks and languages. Additionally, progress in large vision-language models has created new opportunities for multimodal retrieval. In response, we have updated the Tevatron toolkit, introducing a unified pipeline that enables researchers to explore retriever models at different scales, across multiple languages, and with various modalities. This demo paper highlights the toolkit's key features, bridging academia and industry by supporting efficient training, inference, and evaluation of neural retrievers. We showcase a unified dense retriever achieving strong multilingual and multimodal effectiveness, and conduct a cross-modality zero-shot study to demonstrate its research potential. Alongside, we release OmniEmbed, to the best of our knowledge, the first embedding model that unifies text, image document, video, and audio retrieval, serving as a baseline for future research.

[Arxiv](https://arxiv.org/abs/2505.02466)