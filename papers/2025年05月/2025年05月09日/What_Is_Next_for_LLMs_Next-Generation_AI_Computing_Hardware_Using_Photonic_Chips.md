# LLMs的下一步发展是什么？下一代AI计算硬件：光子芯片驱动的AI未来

发布时间：2025年05月09日

`LLM理论` `光子计算` `AI硬件`

> What Is Next for LLMs? Next-Generation AI Computing Hardware Using Photonic Chips

# 摘要

> 大型语言模型（LLMs）正在迅速突破当代计算硬件的极限。例如，训练GPT-3估计消耗了约1300兆瓦时的电力，而未来模型可能需要城市规模（千兆瓦级）的电力预算。这些需求促使我们探索超越传统冯·诺伊曼架构的计算范式。

本文综述了针对下一代生成式AI计算优化的新兴光子硬件。我们讨论了集成光子神经网络架构（例如，马赫-曾德尔干涉仪网格、激光器、波长复用微环谐振器），这些架构能够执行超快速矩阵运算。我们还探讨了有前途的替代神经形态设备，包括脉冲神经网络电路和混合自旋-光子突触，这些设备将记忆和处理功能相结合。我们回顾了将二维材料（如石墨烯、TMDCs）集成到硅光子平台上，用于可调制解调器和片上突触元件。

我们在此背景下分析了基于Transformer的LLM架构（自我注意层和前馈层），并识别了将动态矩阵乘法映射到这些新颖硬件基底的战略和挑战。然后，我们解构了主流LLM（如ChatGPT、DeepSeek和LLaMA）的机制，强调了它们在架构上的相似性和差异性。我们综合了最新的组件、算法和集成方法，突出了将此类系统扩展到 mega-scale LLM 模型的关键进展和开放问题。

我们发现，光子计算系统在吞吐量和能效方面可能比电子处理器高出几个数量级，但需要在内存、特别是长上下文窗口和长令牌序列以及超大数据集的存储方面取得突破。

> Large language models (LLMs) are rapidly pushing the limits of contemporary computing hardware. For example, training GPT-3 has been estimated to consume around 1300 MWh of electricity, and projections suggest future models may require city-scale (gigawatt) power budgets. These demands motivate exploration of computing paradigms beyond conventional von Neumann architectures. This review surveys emerging photonic hardware optimized for next-generation generative AI computing. We discuss integrated photonic neural network architectures (e.g., Mach-Zehnder interferometer meshes, lasers, wavelength-multiplexed microring resonators) that perform ultrafast matrix operations. We also examine promising alternative neuromorphic devices, including spiking neural network circuits and hybrid spintronic-photonic synapses, which combine memory and processing. The integration of two-dimensional materials (graphene, TMDCs) into silicon photonic platforms is reviewed for tunable modulators and on-chip synaptic elements. Transformer-based LLM architectures (self-attention and feed-forward layers) are analyzed in this context, identifying strategies and challenges for mapping dynamic matrix multiplications onto these novel hardware substrates. We then dissect the mechanisms of mainstream LLMs, such as ChatGPT, DeepSeek, and LLaMA, highlighting their architectural similarities and differences. We synthesize state-of-the-art components, algorithms, and integration methods, highlighting key advances and open issues in scaling such systems to mega-sized LLM models. We find that photonic computing systems could potentially surpass electronic processors by orders of magnitude in throughput and energy efficiency, but require breakthroughs in memory, especially for long-context windows and long token sequences, and in storage of ultra-large datasets.

[Arxiv](https://arxiv.org/abs/2505.05794)