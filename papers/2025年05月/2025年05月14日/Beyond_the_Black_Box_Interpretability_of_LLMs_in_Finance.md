# 金融领域大型语言模型的可解释性：超越黑箱

发布时间：2025年05月14日

`LLM应用

摘要中详细讨论了大型语言模型（LLMs）在金融服务领域的多种应用，包括报告生成、聊天机器人、情感分析等，并探讨了这些应用在金融监管环境下的挑战和解决方案。虽然提到了机制可解释性，但其重点在于如何在实际金融场景中应用LLMs，以及如何通过可解释性技术来满足监管需求。因此，这篇论文属于LLM应用类别。` `金融服务`

> Beyond the Black Box: Interpretability of LLMs in Finance

# 摘要

> 大型语言模型（LLMs）在金融服务领域的各项任务中展现出了卓越的能力，包括报告生成、聊天机器人、情感分析、合规监管、投资建议、财务知识检索和总结等。然而，其内在的复杂性和缺乏透明度带来了重大挑战，尤其是在高度监管的金融行业中，可解释性、公平性和问责制至关重要。本文是首个在金融领域通过机制可解释性来理解和利用LLMs内部工作原理的研究，旨在满足对AI系统透明度和控制力的迫切需求。机制可解释性是通过逆向工程LLMs的内部工作原理来理解其行为的最直观和透明的方式。通过剖析这些模型中的激活和电路，它提供了特定特征或组件如何影响预测的洞察——使我们不仅能够观察，还能修改模型行为。本文探讨了机制可解释性的理论方面，并通过一系列金融应用场景和实验展示了其实际相关性，包括在交易策略、情感分析、偏见和幻觉检测中的应用。尽管尚未被广泛应用，但随着LLMs采用率的提高，机制可解释性预计将变得越来越重要。先进的可解释性工具可以确保AI系统保持道德性、透明性，并与不断演变的金融法规保持一致。本文特别关注这些技术如何帮助满足监管和合规需求的可解释性要求——既满足当前需求，又预见到全球金融监管机构的未来期望。

> Large Language Models (LLMs) exhibit remarkable capabilities across a spectrum of tasks in financial services, including report generation, chatbots, sentiment analysis, regulatory compliance, investment advisory, financial knowledge retrieval, and summarization. However, their intrinsic complexity and lack of transparency pose significant challenges, especially in the highly regulated financial sector, where interpretability, fairness, and accountability are critical. As far as we are aware, this paper presents the first application in the finance domain of understanding and utilizing the inner workings of LLMs through mechanistic interpretability, addressing the pressing need for transparency and control in AI systems. Mechanistic interpretability is the most intuitive and transparent way to understand LLM behavior by reverse-engineering their internal workings. By dissecting the activations and circuits within these models, it provides insights into how specific features or components influence predictions - making it possible not only to observe but also to modify model behavior. In this paper, we explore the theoretical aspects of mechanistic interpretability and demonstrate its practical relevance through a range of financial use cases and experiments, including applications in trading strategies, sentiment analysis, bias, and hallucination detection. While not yet widely adopted, mechanistic interpretability is expected to become increasingly vital as adoption of LLMs increases. Advanced interpretability tools can ensure AI systems remain ethical, transparent, and aligned with evolving financial regulations. In this paper, we have put special emphasis on how these techniques can help unlock interpretability requirements for regulatory and compliance purposes - addressing both current needs and anticipating future expectations from financial regulators globally.

[Arxiv](https://arxiv.org/abs/2505.24650)