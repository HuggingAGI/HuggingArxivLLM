# 窥探大型语言模型的金融世界：解析其可解释性

发布时间：2025年05月14日

`LLM应用`

> Beyond the Black Box: Interpretability of LLMs in Finance

# 摘要

> 大型语言模型（LLMs）在金融服务的多个领域中展现出卓越的能力，包括报告生成、聊天机器人、情感分析、合规监管、投资建议、金融知识检索和总结等。然而，它们的复杂性和缺乏透明度在金融领域带来了重大挑战，尤其是在可解释性、公平性和问责制至关重要的情况下。据我们所知，本文首次在金融领域通过机制可解释性来理解和利用LLMs的内部工作原理，以解决AI系统中对透明度和控制的迫切需求。机制可解释性是通过逆向工程理解LLM行为的最直观、最透明的方式。通过分解模型中的激活和电路，它揭示了特定特征或组件如何影响预测，不仅能够观察，还能修改模型行为。本文不仅探讨了机制可解释性的理论方面，还通过一系列金融应用场景和实验展示了其实际相关性，包括在交易策略、情感分析、偏见检测和幻觉检测中的应用。尽管尚未被广泛应用，随着LLMs的采用增加，机制可解释性预计将变得越来越重要。先进的可解释性工具可以确保AI系统保持道德、透明，并与不断发展的金融法规保持一致。本文特别强调了这些技术如何帮助满足监管和合规目的下的可解释性要求，既满足当前需求，又预见到全球金融监管机构的未来期望。

> Large Language Models (LLMs) exhibit remarkable capabilities across a spectrum of tasks in financial services, including report generation, chatbots, sentiment analysis, regulatory compliance, investment advisory, financial knowledge retrieval, and summarization. However, their intrinsic complexity and lack of transparency pose significant challenges, especially in the highly regulated financial sector, where interpretability, fairness, and accountability are critical. As far as we are aware, this paper presents the first application in the finance domain of understanding and utilizing the inner workings of LLMs through mechanistic interpretability, addressing the pressing need for transparency and control in AI systems. Mechanistic interpretability is the most intuitive and transparent way to understand LLM behavior by reverse-engineering their internal workings. By dissecting the activations and circuits within these models, it provides insights into how specific features or components influence predictions - making it possible not only to observe but also to modify model behavior. In this paper, we explore the theoretical aspects of mechanistic interpretability and demonstrate its practical relevance through a range of financial use cases and experiments, including applications in trading strategies, sentiment analysis, bias, and hallucination detection. While not yet widely adopted, mechanistic interpretability is expected to become increasingly vital as adoption of LLMs increases. Advanced interpretability tools can ensure AI systems remain ethical, transparent, and aligned with evolving financial regulations. In this paper, we have put special emphasis on how these techniques can help unlock interpretability requirements for regulatory and compliance purposes - addressing both current needs and anticipating future expectations from financial regulators globally.

[Arxiv](https://arxiv.org/abs/2505.24650)