# # 摘要
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年05月14日

`LLM应用` `决策科学` `人工智能`

> Comparing Exploration-Exploitation Strategies of LLMs and Humans: Insights from Standard Multi-armed Bandit Tasks

# 摘要

> LLMs在复杂序列决策任务中越来越常被用来模拟或自动化人类行为。一个自然的问题是，LLMs是否能像人类一样做出决策，并达到相当（甚至更优）的性能？本研究聚焦于探索与利用（E&E）的权衡这一动态决策中的核心问题。我们采用认知科学和精神病学领域中的典型多臂老虎机（MAB）任务，对LLMs、人类和MAB算法的E&E策略展开比较研究。通过可解释的选择模型，我们捕捉不同决策主体的E&E策略，并深入研究显式推理——无论是通过提示策略还是增强推理的模型——如何影响LLMs的决策过程。研究发现，推理能力使LLMs展现出更接近人类的决策行为，表现为随机探索与有目标探索的结合。在简单的静态任务中，具备推理能力的LLMs与人类的随机和有目标探索水平相当。然而，在复杂、非静态的环境中，尽管LLMs在某些情况下能达到与人类相似的遗憾值，但它们在有效有目标探索方面的适应性仍逊色于人类。这些发现不仅揭示了LLMs作为人类行为模拟器和自动化决策工具的潜力，也指出了其局限性，为未来研究提供了改进方向。

> Large language models (LLMs) are increasingly used to simulate or automate human behavior in complex sequential decision-making tasks. A natural question is then whether LLMs exhibit similar decision-making behavior to humans, and can achieve comparable (or superior) performance. In this work, we focus on the exploration-exploitation (E&E) tradeoff, a fundamental aspect of dynamic decision-making under uncertainty. We employ canonical multi-armed bandit (MAB) tasks introduced in the cognitive science and psychiatry literature to conduct a comparative study of the E&E strategies of LLMs, humans, and MAB algorithms. We use interpretable choice models to capture the E&E strategies of the agents and investigate how explicit reasoning, through both prompting strategies and reasoning-enhanced models, shapes LLM decision-making. We find that reasoning shifts LLMs toward more human-like behavior, characterized by a mix of random and directed exploration. In simple stationary tasks, reasoning-enabled LLMs exhibit similar levels of random and directed exploration compared to humans. However, in more complex, non-stationary environments, LLMs struggle to match human adaptability, particularly in effective directed exploration, despite achieving similar regret in certain scenarios. Our findings highlight both the promise and limits of LLMs as simulators of human behavior and tools for automated decision-making and point to potential areas of improvements.

[Arxiv](https://arxiv.org/abs/2505.09901)