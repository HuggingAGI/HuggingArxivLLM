# 大型语言模型伦理基准：评估大型语言模型道德推理能力的三维评估体系

发布时间：2025年05月01日

`LLM理论` `伦理AI` `AI评估`

> LLM Ethics Benchmark: A Three-Dimensional Assessment System for Evaluating Moral Reasoning in Large Language Models

# 摘要

> 本研究提出了一种全新的框架，用于系统性评估大型语言模型（LLMs）在融入关键社会领域时的道德推理能力。现有评估方法在精准度上存在不足，难以有效评估AI系统在复杂伦理决策中的表现，导致问责机制出现显著缺口。我们的框架通过量化与人类伦理标准的契合度来应对这一挑战，具体从三个维度展开：基础道德原则、推理稳健性以及在多样场景中的价值一致性。这种方法能够精准识别LLMs在伦理方面的优势与不足，从而推动针对性改进，并实现与社会价值观的更深度对齐。为了促进透明度和伦理AI开发领域的协作进步，我们公开发布了基准数据集和评估代码库，详情请访问https://github.com/ The-Responsible-AI-Initiative/LLM_Ethics_Benchmark.git。

> This study establishes a novel framework for systematically evaluating the moral reasoning capabilities of large language models (LLMs) as they increasingly integrate into critical societal domains. Current assessment methodologies lack the precision needed to evaluate nuanced ethical decision-making in AI systems, creating significant accountability gaps. Our framework addresses this challenge by quantifying alignment with human ethical standards through three dimensions: foundational moral principles, reasoning robustness, and value consistency across diverse scenarios. This approach enables precise identification of ethical strengths and weaknesses in LLMs, facilitating targeted improvements and stronger alignment with societal values. To promote transparency and collaborative advancement in ethical AI development, we are publicly releasing both our benchmark datasets and evaluation codebase at https://github.com/ The-Responsible-AI-Initiative/LLM_Ethics_Benchmark.git.

[Arxiv](https://arxiv.org/abs/2505.00853)