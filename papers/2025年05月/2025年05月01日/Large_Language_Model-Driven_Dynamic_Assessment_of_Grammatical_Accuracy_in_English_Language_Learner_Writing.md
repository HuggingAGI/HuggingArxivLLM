# 基于大型语言模型的英语学习者写作语法准确性动态评估

发布时间：2025年05月01日

`LLM应用` `语言学习`

> Large Language Model-Driven Dynamic Assessment of Grammatical Accuracy in English Language Learner Writing

# 摘要

> 本研究旨在探索大型语言模型（LLMs）在动态评估（DA）中的扩展潜力。为此，我们开发了DynaWrite——一个模块化、基于微服务的语法辅导应用程序，支持多种LLMs为英语学习者提供动态反馈。初步测试了21个LLMs后发现，GPT-4o和神经聊天模型在语言学习课堂中扩展DA方面最具潜力。进一步测试表明，尽管两者在识别语法错误方面表现相当，但GPT-4o在动态评估质量上更胜一筹，能够生成清晰、一致且逐步明确的提示。通过详细性能测试，GPT-4o的实时响应能力和系统稳定性也得到了验证，展现出足够的速度和稳定性。本研究证实，LLMs可用于扩展动态评估，使其能够服务于比传统师生设置更大的群体。

> This study investigates the potential for Large Language Models (LLMs) to scale-up Dynamic Assessment (DA). To facilitate such an investigation, we first developed DynaWrite-a modular, microservices-based grammatical tutoring application which supports multiple LLMs to generate dynamic feedback to learners of English. Initial testing of 21 LLMs, revealed GPT-4o and neural chat to have the most potential to scale-up DA in the language learning classroom. Further testing of these two candidates found both models performed similarly in their ability to accurately identify grammatical errors in user sentences. However, GPT-4o consistently outperformed neural chat in the quality of its DA by generating clear, consistent, and progressively explicit hints. Real-time responsiveness and system stability were also confirmed through detailed performance testing, with GPT-4o exhibiting sufficient speed and stability. This study shows that LLMs can be used to scale-up dynamic assessment and thus enable dynamic assessment to be delivered to larger groups than possible in traditional teacher-learner settings.

[Arxiv](https://arxiv.org/abs/2505.00931)