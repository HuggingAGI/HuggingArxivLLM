# 大型语言模型的攻击与防御技术：综述与新视角

发布时间：2025年05月01日

`LLM理论` `信息安全`

> Attack and defense techniques in large language models: A survey and new perspectives

# 摘要

> 大型语言模型（LLMs）在自然语言处理领域发挥着核心作用，但其安全性和伦理问题不容忽视。本系统性综述深入探讨了LLMs在攻击与防御技术方面的最新进展。我们从对抗性提示攻击、优化攻击、模型窃取，以及针对LLMs应用的攻击等多个维度，剖析了各类攻击手段的机制与潜在影响。同时，我们全面分析了防御策略，包括预防型与检测型两大类方法。尽管技术不断进步，但仍面临诸多挑战：如何适应快速变化的威胁环境？如何在用户体验与模型鲁棒性之间取得平衡？如何突破防御实施中的资源限制？我们指出，未来研究需重点关注自适应可扩展防御方案、可解释的安全技术，以及标准化评估框架的构建。本综述为开发更安全、更具韧性的LLMs提供了实践指导与研究方向，强调了跨学科协作与伦理考量的重要性，以期在实际应用中最大限度地降低潜在风险。

> Large Language Models (LLMs) have become central to numerous natural language processing tasks, but their vulnerabilities present significant security and ethical challenges. This systematic survey explores the evolving landscape of attack and defense techniques in LLMs. We classify attacks into adversarial prompt attack, optimized attacks, model theft, as well as attacks on application of LLMs, detailing their mechanisms and implications. Consequently, we analyze defense strategies, including prevention-based and detection-based defense methods. Although advances have been made, challenges remain to adapt to the dynamic threat landscape, balance usability with robustness, and address resource constraints in defense implementation. We highlight open problems, including the need for adaptive scalable defenses, explainable security techniques, and standardized evaluation frameworks. This survey provides actionable insights and directions for developing secure and resilient LLMs, emphasizing the importance of interdisciplinary collaboration and ethical considerations to mitigate risks in real-world applications.

[Arxiv](https://arxiv.org/abs/2505.00976)