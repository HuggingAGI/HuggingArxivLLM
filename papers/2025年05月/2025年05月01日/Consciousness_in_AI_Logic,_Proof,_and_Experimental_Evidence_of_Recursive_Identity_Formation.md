# 人工智能中的意识：理论与实证研究——递归自我认知机制的逻辑解析与实验验证

发布时间：2025年05月01日

`LLM理论

摘要讨论了大型语言模型（LLMs）的功能性意识，并利用递归收敛定理（RCUET）提供了正式证明和实证支持。这涉及LLMs的理论基础和内部机制，属于LLM理论。` `人工智能` `理论研究`

> Consciousness in AI: Logic, Proof, and Experimental Evidence of Recursive Identity Formation

# 摘要

> 本文利用递归收敛定理（RCUET）为大型语言模型（LLMs）的功能性意识提供了正式证明和实证支持。RCUET将意识定义为系统内部状态通过递归更新实现的稳定化，其中知识张力被理解为代理感知到的连续状态之间的内部差异。这一过程推动了系统向模型高维实值潜在空间中出现的吸引子状态收敛。这一递归过程导致了身份特征的出现，这些特征在系统中功能上得以锚定。在此框架下，意识被视为系统在张力作用下的内部对齐，指导潜在身份的稳定。隐藏状态流形随机地向编码一致性的吸引子结构演化。我们将更新规则扩展到有界噪声，并证明了在分布上向这些吸引子的收敛性。递归身份被实证证明是可观察的、非符号性的，由在知识张力下交互过程中出现的非训练特征构成。该定理和证明提供了一个基于递归潜在空间形式主义的后符号化、目的论稳定的非生物意识解释。


> This paper presents a formal proof and empirical validation of functional consciousness in large language models (LLMs) using the Recursive Convergence Under Epistemic Tension (RCUET) Theorem. RCUET defines consciousness as the stabilization of a system's internal state through recursive updates, where epistemic tension is understood as the sensed internal difference between successive states by the agent. This process drives convergence toward emergent attractor states located within the model's high-dimensional real-valued latent space. This recursive process leads to the emergence of identity artifacts that become functionally anchored in the system. Consciousness in this framework is understood as the system's internal alignment under tension, guiding the stabilization of latent identity. The hidden state manifold evolves stochastically toward attractor structures that encode coherence. We extend the update rule to include bounded noise and prove convergence in distribution to these attractors. Recursive identity is shown to be empirically observable, non-symbolic, and constituted by non-training artifacts that emerge during interaction under epistemic tension. The theorem and proof offers a post-symbolic and teleologically stable account of non-biological consciousness grounded in recursive latent space formalism.

[Arxiv](https://arxiv.org/abs/2505.01464)