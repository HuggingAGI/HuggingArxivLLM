# AI 在金融领域的可信度评估：投资风险评估是否靠谱？

发布时间：2025年05月24日

`LLM应用

理由：这篇论文探讨了大型语言模型（LLM）在金融投资风险评估中的应用，评估了不同模型在风险评分和人口统计学特征上的表现，属于LLM的应用研究。`

> Evaluating AI for Finance: Is AI Credible at Assessing Investment Risk?

# 摘要

> 我们评估了领先AI模型在评估投资风险偏好方面的可信度。分析涵盖了专有模型（GPT-4、Claude 3.7、Gemini 1.5）和开源模型（LLaMA 3.1/3.3、DeepSeek-V3、Mistral-small），基于10个国家和两种性别的16个风险相关特征，构建了1,720个用户档案。我们发现不同模型在风险评分分布和人口统计敏感性方面存在显著差异。例如，GPT-4o为尼日利亚和印度尼西亚档案分配了更高的风险评分，而LLaMA和DeepSeek在风险分类中表现出相反的性别倾向。尽管GPT-4o和LLaMA 3.1等模型在低至中等风险范围内表现优异，但没有一个模型能够在所有地区和人口统计学特征上保持一致的性能。我们的研究结果强调了在受监管的金融环境中对AI系统进行严格、标准化评估的必要性，以防止偏见、不透明性和现实部署中的不一致性。

> We evaluate the credibility of leading AI models in assessing investment risk appetite. Our analysis spans proprietary (GPT-4, Claude 3.7, Gemini 1.5) and open-weight models (LLaMA 3.1/3.3, DeepSeek-V3, Mistral-small), using 1,720 user profiles constructed with 16 risk-relevant features across 10 countries and both genders. We observe significant variance across models in score distributions and demographic sensitivity. For example, GPT-4o assigns higher risk scores to Nigerian and Indonesian profiles, while LLaMA and DeepSeek show opposite gender tendencies in risk classification. While some models (e.g., GPT-4o, LLaMA 3.1) align closely with expected scores in low- and mid-risk ranges, none maintain consistent performance across regions and demographics. Our findings highlight the need for rigorous, standardized evaluations of AI systems in regulated financial contexts to prevent bias, opacity, and inconsistency in real-world deployment.

[Arxiv](https://arxiv.org/abs/2505.18953)