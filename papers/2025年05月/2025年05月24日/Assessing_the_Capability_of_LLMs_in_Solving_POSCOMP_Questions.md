# 大型语言模型在解答POSCOMP问题上的能力评估

发布时间：2025年05月24日

`LLM应用` `计算机科学` `教育评估`

> Assessing the Capability of LLMs in Solving POSCOMP Questions

# 摘要

> 大型语言模型（LLMs）的最新进展极大地拓展了人工智能在自然语言处理领域的应用能力。然而，这些模型在计算机科学等专业领域中的表现仍相对未被探索，这使得研究它们的实际应用潜力和指导未来发展变得尤为重要。巴西计算机学会（SBC）推广的研究生入学考试——POSCOMP，是一项极具挑战性的基准测试。本研究旨在探讨LLMs是否能够达到或超越人类在POSCOMP考试中的表现。我们首先评估了四款LLMs——ChatGPT-4、Gemini 1.0 Advanced、Claude 3 Sonnet和Le Chat Mistral Large——在2022和2023年POSCOMP考试中的表现。评估重点在于测试模型处理考试中典型复杂问题的能力。结果显示，LLMs在文本类问题上的表现显著优于图像解读任务。在2022年的考试中，ChatGPT-4以57题正确（共69题）的成绩领先，紧随其后的是Gemini 1.0 Advanced（49题）、Le Chat Mistral（48题）和Claude 3 Sonnet（44题）。2023年的考试中也观察到了类似的趋势。值得注意的是，ChatGPT-4在2023年的考试中表现最为出色，甚至超过了所有参加该次考试的学生。尽管LLMs，特别是ChatGPT-4，在文本类任务上展现出巨大潜力，但图像解读仍是一个待解决的难题。鉴于LLMs的快速发展，我们进一步扩展分析，纳入了近期推出的o1、Gemini 2.5 Pro、Claude 3.7 Sonnet和o3-mini-high等模型，并在2022至2024年的POSCOMP考试中对其进行了评估。这些最新模型展现了更进一步的改进，且在三年的考试中始终超越了人类参与者的平均水平和顶尖表现。

> Recent advancements in Large Language Models (LLMs) have significantly expanded the capabilities of artificial intelligence in natural language processing tasks. Despite this progress, their performance in specialized domains such as computer science remains relatively unexplored. Understanding the proficiency of LLMs in these domains is critical for evaluating their practical utility and guiding future developments. The POSCOMP, a prestigious Brazilian examination used for graduate admissions in computer science promoted by the Brazlian Computer Society (SBC), provides a challenging benchmark. This study investigates whether LLMs can match or surpass human performance on the POSCOMP exam. Four LLMs - ChatGPT-4, Gemini 1.0 Advanced, Claude 3 Sonnet, and Le Chat Mistral Large - were initially evaluated on the 2022 and 2023 POSCOMP exams. The assessments measured the models' proficiency in handling complex questions typical of the exam. LLM performance was notably better on text-based questions than on image interpretation tasks. In the 2022 exam, ChatGPT-4 led with 57 correct answers out of 69 questions, followed by Gemini 1.0 Advanced (49), Le Chat Mistral (48), and Claude 3 Sonnet (44). Similar trends were observed in the 2023 exam. ChatGPT-4 achieved the highest performance, surpassing all students who took the POSCOMP 2023 exam. LLMs, particularly ChatGPT-4, show promise in text-based tasks on the POSCOMP exam, although image interpretation remains a challenge. Given the rapid evolution of LLMs, we expanded our analysis to include more recent models - o1, Gemini 2.5 Pro, Claude 3.7 Sonnet, and o3-mini-high - evaluated on the 2022-2024 POSCOMP exams. These newer models demonstrate further improvements and consistently surpass both the average and top-performing human participants across all three years.

[Arxiv](https://arxiv.org/abs/2505.20338)