# CEFR引导的大型语言模型在互动式西班牙语辅导中的对齐偏移现象。

发布时间：2025年05月13日

`LLM应用` `人工智能`

> Alignment Drift in CEFR-prompted LLMs for Interactive Spanish Tutoring

# 摘要

> 本文探讨了大型语言模型（LLMs）在第二语言学习中作为自适应导师的应用潜力，特别关注系统提示是否能可靠地限制模型输出，使其仅生成符合学生水平的文本。我们使用参数规模从7B到12B的开源LLMs，模拟完整的西班牙语师生对话。对话生成通过让LLM在导师和学生角色之间交替，并分别维护聊天记录来实现。我们利用导师模型的输出，评估基于CEFR的提示在控制三个熟练度级别（A1、B1、C1）的文本难度方面的有效性。研究发现，虽然系统提示可用于约束模型输出，但仅靠提示在持续的长期交互场景中过于脆弱，我们将其称为对齐漂移现象。这些结果为LLMs作为个性化、与熟练度相匹配的自适应导师的可行性提供了见解，并为在没有人类参与者的情况下对模型性能进行低成本、可扩展的评估提供了一种方法。

> This paper investigates the potentials of Large Language Models (LLMs) as adaptive tutors in the context of second-language learning. In particular, we evaluate whether system prompting can reliably constrain LLMs to generate only text appropriate to the student's competence level. We simulate full teacher-student dialogues in Spanish using instruction-tuned, open-source LLMs ranging in size from 7B to 12B parameters. Dialogues are generated by having an LLM alternate between tutor and student roles with separate chat histories. The output from the tutor model is then used to evaluate the effectiveness of CEFR-based prompting to control text difficulty across three proficiency levels (A1, B1, C1). Our findings suggest that while system prompting can be used to constrain model outputs, prompting alone is too brittle for sustained, long-term interactional contexts - a phenomenon we term alignment drift. Our results provide insights into the feasibility of LLMs for personalized, proficiency-aligned adaptive tutors and provide a scalable method for low-cost evaluation of model performance without human participants.

[Arxiv](https://arxiv.org/abs/2505.08351)