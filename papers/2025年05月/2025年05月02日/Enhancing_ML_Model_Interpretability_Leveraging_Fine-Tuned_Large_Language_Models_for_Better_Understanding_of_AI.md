# 提升机器学习模型的可解释性：借助微调后的大型语言模型深入理解人工智能

发布时间：2025年05月02日

`LLM应用` `人工智能`

> Enhancing ML Model Interpretability: Leveraging Fine-Tuned Large Language Models for Better Understanding of AI

# 摘要

> 随着机器学习（ML）模型的黑箱特性日益明显，可解释的人工智能（XAI）在各个领域的应用势头强劲。与此同时，大型语言模型（LLMs）在理解人类语言和复杂模式方面的能力显著提升。我们结合XAI与LLMs，提出了一种通过交互式聊天机器人解释XAI的新型参考架构。以电池状态（SoH）预测为例，我们在多个评估和演示轮次中验证了该架构的设计。评估结果表明，该原型显著提升了机器学习的可解释性，尤其对XAI经验较少的用户效果显著。

> Across various sectors applications of eXplainableAI (XAI) gained momentum as the increasing black-boxedness of prevailing Machine Learning (ML) models became apparent. In parallel, Large Language Models (LLMs) significantly developed in their abilities to understand human language and complex patterns. By combining both, this paper presents a novel reference architecture for the interpretation of XAI through an interactive chatbot powered by a fine-tuned LLM. We instantiate the reference architecture in the context of State-of-Health (SoH) prediction for batteries and validate its design in multiple evaluation and demonstration rounds. The evaluation indicates that the implemented prototype enhances the human interpretability of ML, especially for users with less experience with XAI.

[Arxiv](https://arxiv.org/abs/2505.02859)