# 视频片段引发的高维情感结构在人类与多模态大型语言模型（LLMs）之间的对应关系研究

发布时间：2025年05月19日

`LLM应用` `情感分析` `人工智能`

> Correspondence of high-dimensional emotion structures elicited by video clips between humans and Multimodal LLMs

# 摘要

> 最近研究表明，人类情感具有高维且复杂的结构特征。要全面理解这种复杂性，传统模型可能力有未逮，因此我们需要探索新的方法。我们研究了快速发展的多模态大型语言模型（MLLMs）在捕捉高维复杂情感结构方面的表现，包括其优势与不足。具体而言，我们将参与者观看视频时的自我报告情感评分与模型生成的估计（如Gemini或GPT）进行了对比。我们的评估不仅关注单个视频层面，还从考虑视频间关系的情感结构层面进行了深入分析。在情感结构的简单相关性层面，结果显示人类与模型推断的情感结构具有高度相似性。为了进一步探讨这种相似性是源于单个条目层面还是粗略分类层面，我们采用了Gromov Wasserstein最优传输方法。研究发现，尽管在严格的单个条目层面上模型表现有限，但在引发相似情感的视频类别层面上，模型表现优异，表明其能够在分类层面上有效推断人类情感体验。综上所述，当前先进的MLLMs在分类层面上能够较好地捕捉复杂高维情感结构，但在单个条目层面上仍存在明显局限性。

> Recent studies have revealed that human emotions exhibit a high-dimensional, complex structure. A full capturing of this complexity requires new approaches, as conventional models that disregard high dimensionality risk overlooking key nuances of human emotions. Here, we examined the extent to which the latest generation of rapidly evolving Multimodal Large Language Models (MLLMs) capture these high-dimensional, intricate emotion structures, including capabilities and limitations. Specifically, we compared self-reported emotion ratings from participants watching videos with model-generated estimates (e.g., Gemini or GPT). We evaluated performance not only at the individual video level but also from emotion structures that account for inter-video relationships. At the level of simple correlation between emotion structures, our results demonstrated strong similarity between human and model-inferred emotion structures. To further explore whether the similarity between humans and models is at the signle item level or the coarse-categorical level, we applied Gromov Wasserstein Optimal Transport. We found that although performance was not necessarily high at the strict, single-item level, performance across video categories that elicit similar emotions was substantial, indicating that the model could infer human emotional experiences at the category level. Our results suggest that current state-of-the-art MLLMs broadly capture the complex high-dimensional emotion structures at the category level, as well as their apparent limitations in accurately capturing entire structures at the single-item level.

[Arxiv](https://arxiv.org/abs/2505.12746)