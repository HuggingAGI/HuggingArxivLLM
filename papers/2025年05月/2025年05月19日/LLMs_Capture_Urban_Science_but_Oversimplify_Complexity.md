# 大型语言模型成功捕捉到了城市科学的精髓，却也过分简化了其中的复杂性。

发布时间：2025年05月19日

`LLM应用` `城市科学`

> LLMs Capture Urban Science but Oversimplify Complexity

# 摘要

> 大型语言模型（LLMs）在科学推理和数据生成任务中的应用日益广泛，但其与城市科学的实证和理论结构之间的契合度尚不明确。本文介绍AI4US（人工智能应用于城市科学），一个系统评估五种前沿LLMs（ChatGPT、DeepSeek、Claude、Gemini和ChatGLM）的框架。通过生成城市数据并测试其与实证分布及三大基础理论（城市规模法则、城市距离衰减和城市活力）的一致性，发现LLMs能够以较高精度再现核心理论模式（平均R2值为0.804（规模）和0.988（衰减）），并初步展现了模拟非正式化概念（如城市活力）的能力。然而，生成数据存在关键局限：与真实数据相比多样性不足且过于理想化；理论拟合参数存在系统性偏差（如低估规模指数和衰减率）；提示工程改进有限。这些发现表明，尽管LLMs为基于理论的城市分析提供了有前景的工具，但它们尚未完全捕捉现实世界的复杂性，凸显了提升契合度和评估的必要性。


> Large language models (LLMs) are increasingly used in scientific reasoning and data generation tasks, yet their alignment with empirical and theoretical structures in urban science remains unclear. Here, this study introduces AI4US (Artificial Intelligence for Urban Science), a framework to systematically evaluate five state-of-the-art LLMs (ChatGPT, DeepSeek, Claude, Gemini, and ChatGLM) by generating urban data and testing its fidelity against empirical distributions and three foundational theories: urban scaling laws, urban distance decay, and urban vitality. LLMs reproduce core theoretical patterns with notable accuracy (average R2 = 0.804 for scaling; 0.988 for decay), and exhibit preliminary capacity to simulate less formalized constructs such as urban vitality. However, generated data exhibit crucial limitations: poor diversity and idealization compared to real data; systematic deviations in fitted theoretical parameters (e.g., underestimated scaling exponents and decay rates); and limited improvement from prompt engineering. These findings suggest that while LLMs offer a promising tool for theory-informed urban analysis, they fall short of capturing real-world complexity, underscoring the need for improved alignment and evaluation.

[Arxiv](https://arxiv.org/abs/2505.13803)