# # 摘要
大型语言模型正在捕捉城市科学，但对复杂性进行了过度简化。

发布时间：2025年05月19日

`LLM应用` `城市科学` `城市规划`

> LLMs Capture Urban Science but Oversimplify Complexity

# 摘要

> 大型语言模型（LLMs）在科学推理和数据生成领域应用广泛，但其与城市科学的实证和理论结构是否对齐仍不明朗。本文提出AI4US框架，系统评估了五款前沿LLMs（ChatGPT、DeepSeek、Claude、Gemini和ChatGLM），通过生成城市数据并验证其与实证分布及三大理论（城市规模法则、距离衰减法则、城市活力）的契合度。LLMs在复制核心理论模式上表现优异（规模法则R²平均达0.804，衰减法则R²平均达0.988），并初步具备模拟城市活力等非正式化概念的能力。然而，生成数据存在三大局限：与真实数据相比，多样性和现实性不足；理论参数拟合时出现系统性偏差（如低估规模指数和衰减速率）；提示工程优化效果有限。这些发现表明，尽管LLMs为基于理论的城市分析提供了有力工具，但其捕捉现实复杂性的能力仍有待提升，亟需加强模型的对齐性和评估工作。

> Large language models (LLMs) are increasingly used in scientific reasoning and data generation tasks, yet their alignment with empirical and theoretical structures in urban science remains unclear. Here, this study introduces AI4US (Artificial Intelligence for Urban Science), a framework to systematically evaluate five state-of-the-art LLMs (ChatGPT, DeepSeek, Claude, Gemini, and ChatGLM) by generating urban data and testing its fidelity against empirical distributions and three foundational theories: urban scaling laws, urban distance decay, and urban vitality. LLMs reproduce core theoretical patterns with notable accuracy (average R2 = 0.804 for scaling; 0.988 for decay), and exhibit preliminary capacity to simulate less formalized constructs such as urban vitality. However, generated data exhibit crucial limitations: poor diversity and idealization compared to real data; systematic deviations in fitted theoretical parameters (e.g., underestimated scaling exponents and decay rates); and limited improvement from prompt engineering. These findings suggest that while LLMs offer a promising tool for theory-informed urban analysis, they fall short of capturing real-world complexity, underscoring the need for improved alignment and evaluation.

[Arxiv](https://arxiv.org/abs/2505.13803)