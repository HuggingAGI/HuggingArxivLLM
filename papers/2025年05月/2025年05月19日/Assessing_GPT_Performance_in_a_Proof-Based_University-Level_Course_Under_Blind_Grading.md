# 基于盲评的 GPT 在证明课程中的表现评估

发布时间：2025年05月19日

`LLM应用` `高等教育`

> Assessing GPT Performance in a Proof-Based University-Level Course Under Blind Grading

# 摘要

> 随着大型语言模型 (LLMs) 的发展，它们在高等教育中的作用，特别是在自由回答问题解决方面，值得深入研究。本研究在大学算法课程中，评估了 GPT-4o 和 o1-preview 在现实教育条件下的表现。助教对匿名的 GPT 生成的考试答案进行评分，而评分者并不知道这些答案的来源。我们的分析同时考察了粗粒度性能（分数）和细粒度推理质量（错误模式）。结果显示，GPT-4o 表现不佳，未能达到及格线，而 o1-preview 的表现明显更好，超过了及格分数，甚至在某些练习中超过了学生的中位数。然而，两个模型都存在缺乏依据的主张和误导性论点的问题。这些发现强调了在教育中制定稳健评估策略和 AI 意识的评分政策的必要性。

> As large language models (LLMs) advance, their role in higher education, particularly in free-response problem-solving, requires careful examination. This study assesses the performance of GPT-4o and o1-preview under realistic educational conditions in an undergraduate algorithms course. Anonymous GPT-generated solutions to take-home exams were graded by teaching assistants unaware of their origin. Our analysis examines both coarse-grained performance (scores) and fine-grained reasoning quality (error patterns). Results show that GPT-4o consistently struggles, failing to reach the passing threshold, while o1-preview performs significantly better, surpassing the passing score and even exceeding the student median in certain exercises. However, both models exhibit issues with unjustified claims and misleading arguments. These findings highlight the need for robust assessment strategies and AI-aware grading policies in education.

[Arxiv](https://arxiv.org/abs/2505.13664)