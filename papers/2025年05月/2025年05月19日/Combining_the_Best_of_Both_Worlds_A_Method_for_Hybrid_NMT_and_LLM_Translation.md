# 融汇双优：混合 NMT 与 LLM 的翻译新方法

发布时间：2025年05月19日

`LLM应用` `机器翻译`

> Combining the Best of Both Worlds: A Method for Hybrid NMT and LLM Translation

# 摘要

> 大型语言模型（LLM）在机器翻译等下游任务中表现优异，但在实际应用中面临计算成本高和延迟大的问题。经评估，LLM译文通常与神经机器翻译（NMT）相当，仅在特定场景下各有千秋。因此，将NMT与LLM结合使用，并仅在必要时启用LLM，是一种更优的解决方案。我们提出了一种基于源句特征的决策方法，并通过多语言实验验证，证明了该方法能在减少LLM使用的同时保持翻译质量。

> Large language model (LLM) shows promising performances in a variety of downstream tasks, such as machine translation (MT). However, using LLMs for translation suffers from high computational costs and significant latency. Based on our evaluation, in most cases, translations using LLMs are comparable to that generated by neural machine translation (NMT) systems. Only in particular scenarios, LLM and NMT models show respective advantages. As a result, integrating NMT and LLM for translation and using LLM only when necessary seems to be a sound solution. A scheduling policy that optimizes translation result while ensuring fast speed and as little LLM usage as possible is thereby required. We compare several scheduling policies and propose a novel and straightforward decider that leverages source sentence features. We conduct extensive experiments on multilingual test sets and the result shows that we can achieve optimal translation performance with minimal LLM usage, demonstrating effectiveness of our decider.

[Arxiv](https://arxiv.org/abs/2505.13554)