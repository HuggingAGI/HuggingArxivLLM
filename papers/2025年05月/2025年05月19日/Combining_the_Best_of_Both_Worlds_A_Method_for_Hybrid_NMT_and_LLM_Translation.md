# 融合双方优势：一种结合NMT与LLM的混合翻译方法

发布时间：2025年05月19日

`LLM应用` `机器翻译`

> Combining the Best of Both Worlds: A Method for Hybrid NMT and LLM Translation

# 摘要

> 大型语言模型（LLM）在机器翻译等下游任务中表现优异，但其高计算成本和显著延迟问题不容忽视。经评估，LLM译文在大多数情况下可与神经机器翻译（NMT）系统相媲美，但在特定场景下，两者各具优势。因此，将NMT与LLM结合使用，并仅在必要时启用LLM，是一种明智的选择。为此，我们提出了一种全新的调度策略，旨在优化翻译质量的同时，确保快速响应和尽可能减少LLM的使用。通过在多语言测试集上的大量实验，我们验证了该策略的有效性：在极低的LLM使用率下，仍可实现最优的翻译性能。

> Large language model (LLM) shows promising performances in a variety of downstream tasks, such as machine translation (MT). However, using LLMs for translation suffers from high computational costs and significant latency. Based on our evaluation, in most cases, translations using LLMs are comparable to that generated by neural machine translation (NMT) systems. Only in particular scenarios, LLM and NMT models show respective advantages. As a result, integrating NMT and LLM for translation and using LLM only when necessary seems to be a sound solution. A scheduling policy that optimizes translation result while ensuring fast speed and as little LLM usage as possible is thereby required. We compare several scheduling policies and propose a novel and straightforward decider that leverages source sentence features. We conduct extensive experiments on multilingual test sets and the result shows that we can achieve optimal translation performance with minimal LLM usage, demonstrating effectiveness of our decider.

[Arxiv](https://arxiv.org/abs/2505.13554)