# 框架输入，框架输出：大型语言模型生成的新闻标题比人类更具偏见吗？

发布时间：2025年05月08日

`LLM应用` `新闻学`

> Frame In, Frame Out: Do LLMs Generate More Biased News Headlines than Humans?

# 摘要

> 媒体中的框架效应通过有选择地突出某些细节而弱化其他信息，对公众认知产生重要影响。随着大型语言模型在自动新闻和内容创作中的兴起，人们日益担忧这些系统可能引入甚至放大与人类作者相比的框架偏差。本文探讨了框架效应在预训练和微调后的大型语言模型生成新闻内容中的表现。我们的分析发现，特别是在政治和社会敏感语境下，LLMs的框架效应往往比人类作者更为显著。此外，我们观察到不同模型架构在框架倾向上的显著差异，某些模型表现出明显更高的偏见。这些发现凸显了制定有效的后训练缓解策略和更严格的评估框架的必要性，以确保自动化新闻内容能够坚持平衡报道的标准。


> Framing in media critically shapes public perception by selectively emphasizing some details while downplaying others. With the rise of large language models in automated news and content creation, there is growing concern that these systems may introduce or even amplify framing biases compared to human authors. In this paper, we explore how framing manifests in both out-of-the-box and fine-tuned LLM-generated news content. Our analysis reveals that, particularly in politically and socially sensitive contexts, LLMs tend to exhibit more pronounced framing than their human counterparts. In addition, we observe significant variation in framing tendencies across different model architectures, with some models displaying notably higher biases. These findings point to the need for effective post-training mitigation strategies and tighter evaluation frameworks to ensure that automated news content upholds the standards of balanced reporting.

[Arxiv](https://arxiv.org/abs/2505.05406)