# 基于大型语言模型的隐私保护用户行为分析：有限数据下的隐私偏好研究

发布时间：2025年05月08日

`LLM应用` `隐私保护` `用户行为分析`

> User Behavior Analysis in Privacy Protection with Large Language Models: A Study on Privacy Preferences with Limited Data

# 摘要

> 大型语言模型（LLMs）的广泛应用使得用户隐私保护成为一个重要研究课题。现有隐私偏好建模方法通常依赖大规模数据，在数据受限环境下难以有效分析隐私偏好。本研究探索了LLMs在数据受限场景下分析隐私相关用户行为的能力，并提出一种结合小样本学习和隐私计算的方法来建模用户隐私偏好。研究采用匿名化隐私设置数据、调查反馈和模拟数据，对比了传统方法与LLM方法的性能。实验结果表明，即使数据有限，LLMs显著提升了隐私偏好建模的准确性。此外，引入差分隐私和联邦学习进一步降低了数据暴露风险。本研究为LLMs在隐私保护中的应用提供了新视角，并为隐私计算和用户行为分析的理论发展提供了支持。

> With the widespread application of large language models (LLMs), user privacy protection has become a significant research topic. Existing privacy preference modeling methods often rely on large-scale user data, making effective privacy preference analysis challenging in data-limited environments. This study explores how LLMs can analyze user behavior related to privacy protection in scenarios with limited data and proposes a method that integrates Few-shot Learning and Privacy Computing to model user privacy preferences. The research utilizes anonymized user privacy settings data, survey responses, and simulated data, comparing the performance of traditional modeling approaches with LLM-based methods. Experimental results demonstrate that, even with limited data, LLMs significantly improve the accuracy of privacy preference modeling. Additionally, incorporating Differential Privacy and Federated Learning further reduces the risk of user data exposure. The findings provide new insights into the application of LLMs in privacy protection and offer theoretical support for advancing privacy computing and user behavior analysis.

[Arxiv](https://arxiv.org/abs/2505.06305)