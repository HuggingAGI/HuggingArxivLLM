# 我们如何设计提示：概念融合的奥秘、神经动力学机制与提示引发的动态转变

发布时间：2025年05月16日

`LLM理论` `神经科学` `认知科学`

> The Way We Prompt: Conceptual Blending, Neural Dynamics, and Prompt-Induced Transitions in LLMs

# 摘要

> # 大型语言模型（LLMs）的行为与神经科学的启发

受神经科学启发的大型语言模型（LLMs）展现出令人觉得具有个性和智能的行为，然而这些现象背后的机制仍是个谜。本研究将概念整合理论（CBT）转化为实验框架，通过基于提示词的方法揭示LLMs如何融合与压缩意义。通过对提示词诱导的转换（PIT）和幻觉（PIH）的系统性探索，我们发现了人工与生物认知之间结构上的异同。我们的研究方法融合了语言学、神经科学与实证AI研究，证明了人与AI的合作可以成为未来认知科学的原型。本工作不仅将提示工程视为技术工具，更将其作为一种探索意义深层结构的科学方法。

> Large language models (LLMs), inspired by neuroscience, exhibit behaviors that often evoke a sense of personality and intelligence-yet the mechanisms behind these effects remain elusive. Here, we operationalize Conceptual Blending Theory (CBT) as an experimental framework, using prompt-based methods to reveal how LLMs blend and compress meaning. By systematically investigating Prompt-Induced Transitions (PIT) and Prompt-Induced Hallucinations (PIH), we uncover structural parallels and divergences between artificial and biological cognition. Our approach bridges linguistics, neuroscience, and empirical AI research, demonstrating that human-AI collaboration can serve as a living prototype for the future of cognitive science. This work proposes prompt engineering not just as a technical tool, but as a scientific method for probing the deep structure of meaning itself.

[Arxiv](https://arxiv.org/abs/2505.10948)