# # 摘要  
    最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年05月16日

`LLM应用` `知识产权`

> Towards Better Evaluation for Generated Patent Claims

# 摘要

> 专利声明界定了发明的保护范围和法律边界，起草这些声明通常需要专业专利律师的 expertise，这对许多小型企业而言是一道较高的准入门槛。为了解决这一难题，研究人员探索了利用大型语言模型 (LLMs) 自动化专利声明生成的可能性。然而，现有研究发现自动化评估指标与人类专家评估之间存在不一致。为填补这一空白，我们推出了首个全面的专利声明评估基准——Patent-CE。该基准包含由专利专家标注的比较声明评估，重点考察特征完整性、概念清晰度、术语一致性、逻辑连贯性和整体质量五个关键标准。此外，我们还提出了专为专利声明设计的新型多维评估方法 PatClaimEval。实验结果表明，在所有测试指标中，PatClaimEval 在所有评估标准上与人类专家评估的相关性最高。这项研究为更准确地评估自动化专利声明生成系统奠定了基础。

> Patent claims define the scope of protection and establish the legal boundaries of an invention. Drafting these claims is a complex and time-consuming process that usually requires the expertise of skilled patent attorneys, which can form a large access barrier for many small enterprises. To solve these challenges, researchers have investigated the use of large language models (LLMs) for automating patent claim generation. However, existing studies highlight inconsistencies between automated evaluation metrics and human expert assessments. To bridge this gap, we introduce Patent-CE, the first comprehensive benchmark for evaluating patent claims. Patent-CE includes comparative claim evaluations annotated by patent experts, focusing on five key criteria: feature completeness, conceptual clarity, terminology consistency, logical linkage, and overall quality. Additionally, we propose PatClaimEval, a novel multi-dimensional evaluation method specifically designed for patent claims. Our experiments demonstrate that PatClaimEval achieves the highest correlation with human expert evaluations across all assessment criteria among all tested metrics. This research provides the groundwork for more accurate evaluations of automated patent claim generation systems.

[Arxiv](https://arxiv.org/abs/2505.11095)