# OntoURL：评估大型语言模型在符号本体理解、推理与学习能力的基准测试

发布时间：2025年05月16日

`LLM理论` `知识表示` `知识工程`

> OntoURL: A Benchmark for Evaluating Large Language Models on Symbolic Ontological Understanding, Reasoning and Learning

# 摘要

> 大型语言模型（LLMs）在多种自然语言处理任务中表现卓越，但它们在处理结构化符号知识方面的能力仍有待深入挖掘。为了弥补这一研究空白，我们提出了一个LLMs本体能力的分类体系，并推出了OntoURL——首个全面的基准测试，旨在系统评估LLMs在处理本体（即通过概念、关系和实例形式化表示的领域知识）方面的熟练程度。基于此分类体系，OntoURL从理解、推理和学习三个维度进行了系统评估，涵盖了15个不同任务，涉及8个领域40个本体的58,981个问题。通过对20个开源LLMs的实验，我们发现不同模型在任务和领域上的性能存在显著差异。当前的LLMs在理解本体知识方面表现出色，但在推理和学习任务中仍存在明显不足。这些研究结果不仅揭示了LLMs在处理符号知识方面的能力局限，还确立了OntoURL作为推进LLMs与正式知识表示整合的关键基准。

> Large language models (LLMs) have demonstrated remarkable capabilities across a range of natural language processing tasks, yet their ability to process structured symbolic knowledge remains underexplored. To address this gap, we propose a taxonomy of LLMs' ontological capabilities and introduce OntoURL, the first comprehensive benchmark designed to systematically evaluate LLMs' proficiency in handling ontologies -- formal, symbolic representations of domain knowledge through concepts, relationships, and instances. Based on the proposed taxonomy, OntoURL systematically assesses three dimensions: understanding, reasoning, and learning through 15 distinct tasks comprising 58,981 questions derived from 40 ontologies across 8 domains. Experiments with 20 open-source LLMs reveal significant performance differences across models, tasks, and domains, with current LLMs showing proficiency in understanding ontological knowledge but substantial weaknesses in reasoning and learning tasks. These findings highlight fundamental limitations in LLMs' capability to process symbolic knowledge and establish OntoURL as a critical benchmark for advancing the integration of LLMs with formal knowledge representations.

[Arxiv](https://arxiv.org/abs/2505.11031)