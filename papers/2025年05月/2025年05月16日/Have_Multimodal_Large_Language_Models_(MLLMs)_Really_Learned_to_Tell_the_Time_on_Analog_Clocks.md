# 多模态大语言模型（MLLMs）真的掌握了读取模拟时钟时间的能力了吗？

发布时间：2025年05月16日

`LLM应用` `图像处理` `时间识别`

> Have Multimodal Large Language Models (MLLMs) Really Learned to Tell the Time on Analog Clocks?

# 摘要

> 多模态大型语言模型 (MLLMs) 虽然能够解答图片相关的复杂问题，但在识别模拟时钟的时间上却表现不佳。这可能是因为它们的训练数据中缺少不同时间的时钟图像。本研究采用最新的 MLLMs 之一：GPT-4.1，深入探讨这一问题，旨在揭示 MLLMs 无法准确报时的原因，并评估微调是否能有效解决这一问题。研究结果表明，模型在阅读模拟时钟时间方面取得了一定进展。然而，它们是否真正掌握了这一技能，还是仅仅识别了训练数据中的模式？通过不同类型的时钟测试，我们揭示了 MLLMs 在抽象思维和泛化能力上的局限性。

> Multimodal Large Language Models which can answer complex questions on an image struggle to tell the time on analog clocks. This is probably due to the lack of images with clocks at different times in their training set. In this work we explore this issue with one of the latest MLLMs: GPT-4.1 to understand why MLLMs fail to tell the time and whether fine-tuning can solve the problem. The results show how models are making progress in reading the time on analog clocks. But have they really learned to do it, or have they only learned patterns in their training datasets? In this work we put the models to the test with different clocks to illustrate the limitations of MLLMs to abstract and generalize.

[Arxiv](https://arxiv.org/abs/2505.10862)