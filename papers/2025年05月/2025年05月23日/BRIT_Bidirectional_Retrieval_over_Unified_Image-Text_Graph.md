# BRIT：统一图文图上的双向检索

发布时间：2025年05月23日

`RAG` `多模态` `问答系统`

> BRIT: Bidirectional Retrieval over Unified Image-Text Graph

# 摘要

> 检索增强生成（RAG）技术在提升大型语言模型生成质量方面展现出巨大潜力。虽然现有研究主要致力于优化基于文本查询的RAG性能，但针对包含文本与图像的多模态文档的RAG研究仍显不足，尤其是在微调方法失效的场景下。本文提出了一种创新的多模态RAG框架——BRIT，该框架能将文档中的文本-图像关联整合到一个统一的多模态图中，并根据查询需求检索特定子图中的文本和图像。通过遍历图中的图像到文本和文本到图像的双重路径，BRIT不仅能检索直接相关的图像和文本，还能进一步获取解答复杂跨模态多跳问题的关联内容。为了评估BRIT的效果，我们专门设计了一个用于多模态问答任务的测试集MM-RAG，该测试集要求理解文本-图像关系。通过全面的实验，我们验证了BRIT的优越性，凸显了其在多模态文档上处理跨模态问题的能力。

> Retrieval-Augmented Generation (RAG) has emerged as a promising technique to enhance the quality and relevance of responses generated by large language models. While recent advancements have mainly focused on improving RAG for text-based queries, RAG on multi-modal documents containing both texts and images has not been fully explored. Especially when fine-tuning does not work. This paper proposes BRIT, a novel multi-modal RAG framework that effectively unifies various text-image connections in the document into a multi-modal graph and retrieves the texts and images as a query-specific sub-graph. By traversing both image-to-text and text-to-image paths in the graph, BRIT retrieve not only directly query-relevant images and texts but also further relevant contents to answering complex cross-modal multi-hop questions. To evaluate the effectiveness of BRIT, we introduce MM-RAG test set specifically designed for multi-modal question answering tasks that require to understand the text-image relations. Our comprehensive experiments demonstrate the superiority of BRIT, highlighting its ability to handle cross-modal questions on the multi-modal documents.

[Arxiv](https://arxiv.org/abs/2505.18450)