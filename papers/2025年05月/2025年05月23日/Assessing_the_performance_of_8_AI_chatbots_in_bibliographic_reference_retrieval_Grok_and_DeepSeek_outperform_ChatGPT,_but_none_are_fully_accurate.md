# 评估8个AI聊天机器人在文献参考检索中的表现：Grok和DeepSeek的表现优于ChatGPT，但目前尚无完全准确的解决方案

发布时间：2025年05月23日

`LLM应用` `信息质量`

> Assessing the performance of 8 AI chatbots in bibliographic reference retrieval: Grok and DeepSeek outperform ChatGPT, but none are fully accurate

# 摘要

> 本研究评估了八款生成式 AI 聊天机器人（ChatGPT、Claude、Copilot、DeepSeek、Gemini、Grok、Le Chat 和 Perplexity）在免费版本中，于学术环境中生成引用的表现。研究在健康、工程、实验科学、社会科学和人文学科五大领域，基于标准化提示评估了 400 个引用。每个引用从作者、年份、标题、来源、位置、文档类型、出版年份和错误数量八个维度进行评估。结果显示，仅有 26.5% 的引用完全正确，33.8% 部分正确，39.8% 存在错误或完全编造。Grok 和 DeepSeek 是唯一未生成虚假引用的聊天机器人，而 Copilot、Perplexity 和 Claude 的幻觉率最高。此外，聊天机器人更倾向于生成书籍引用而非期刊文章，尽管后者编造率更高。多个模型（特别是 DeepSeek、Grok、Gemini 和 ChatGPT）提供的来源间存在高度重叠。这些发现揭示了当前 AI 模型的结构性限制，突显了学生无批判使用 AI 的风险，并强调了在高等教育中加强信息和批判性素养的重要性，以确保 AI 工具的负责任使用。

> This study analyzes the performance of eight generative artificial intelligence chatbots -- ChatGPT, Claude, Copilot, DeepSeek, Gemini, Grok, Le Chat, and Perplexity -- in their free versions, in the task of generating academic bibliographic references within the university context. A total of 400 references were evaluated across the five major areas of knowledge (Health, Engineering, Experimental Sciences, Social Sciences, and Humanities), based on a standardized prompt. Each reference was assessed according to five key components (authorship, year, title, source, and location), along with document type, publication age, and error count. The results show that only 26.5% of the references were fully correct, 33.8% partially correct, and 39.8% were either erroneous or entirely fabricated. Grok and DeepSeek stood out as the only chatbots that did not generate false references, while Copilot, Perplexity, and Claude exhibited the highest hallucination rates. Furthermore, the chatbots showed a greater tendency to generate book references over journal articles, although the latter had a significantly higher fabrication rate. A high degree of overlap was also detected among the sources provided by several models, particularly between DeepSeek, Grok, Gemini, and ChatGPT. These findings reveal structural limitations in current AI models, highlight the risks of uncritical use by students, and underscore the need to strengthen information and critical literacy regarding the use of AI tools in higher education.

[Arxiv](https://arxiv.org/abs/2505.18059)