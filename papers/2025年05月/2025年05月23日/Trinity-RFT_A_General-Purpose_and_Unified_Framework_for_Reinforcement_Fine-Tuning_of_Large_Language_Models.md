# Trinity-RFT：大型语言模型强化微调的通用统一框架

发布时间：2025年05月23日

`LLM理论` `人工智能` `机器学习` `软件工程`

> Trinity-RFT: A General-Purpose and Unified Framework for Reinforcement Fine-Tuning of Large Language Models

# 摘要

> Trinity-RFT 是一个专为大型语言模型强化微调（RFT）打造的通用、灵活且可扩展框架。其解耦设计包含三大核心要素：（1）统一支持同步/异步、在线/离线及策略内/策略外模式的 RFT 核心；（2）高效且稳健的代理-环境交互无缝集成；（3）专为 RFT 优化的系统化数据管道。Trinity-RFT 能轻松适应各类应用场景，为探索先进强化学习范式提供统一平台。本技术报告全面介绍 Trinity-RFT 的愿景、特性、设计与实现，并附有丰富实例，充分展示该框架的实用价值与用户友好性。

> Trinity-RFT is a general-purpose, flexible and scalable framework designed for reinforcement fine-tuning (RFT) of large language models. It is built with a decoupled design, consisting of (1) an RFT-core that unifies and generalizes synchronous/asynchronous, on-policy/off-policy, and online/offline modes of RFT, (2) seamless integration for agent-environment interaction with high efficiency and robustness, and (3) systematic data pipelines optimized for RFT. Trinity-RFT can be easily adapted for diverse application scenarios, and serves as a unified platform for exploring advanced reinforcement learning paradigms. This technical report outlines the vision, features, design and implementations of Trinity-RFT, accompanied by extensive examples demonstrating the utility and user-friendliness of the proposed framework.

[Arxiv](https://arxiv.org/abs/2505.17826)