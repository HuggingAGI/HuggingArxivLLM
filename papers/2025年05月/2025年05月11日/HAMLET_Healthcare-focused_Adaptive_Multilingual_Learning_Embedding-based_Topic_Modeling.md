# HAMLET：专注于医疗领域的自适应多语言学习嵌入主题建模方法

发布时间：2025年05月11日

`LLM应用` `跨语言`

> HAMLET: Healthcare-focused Adaptive Multilingual Learning Embedding-based Topic Modeling

# 摘要

> 传统主题模型在捕捉语境细微差别、处理多义词和罕见词汇方面表现欠佳，导致生成的主题缺乏连贯性和质量。大型语言模型（LLMs）虽能生成初始主题集合，但这些原始主题常缺乏精炼和代表性，导致冗余现象（缺乏词汇相似性）并降低可解释性。为此，本文提出了一种基于图的跨语言医疗主题建模架构 HAMLET，利用大型语言模型（LLMs）。该方法采用神经增强语义融合来优化 LLM 生成的主题嵌入。与单纯依赖统计共现或人工解释从文档语料库中提取主题不同，本方法引入了一种基于 BERT 和图神经网络 (GNN) 的主题嵌入优化方法。在主题生成后，采用结合 BERT 和 Sentence-BERT (SBERT) 的混合技术进行嵌入处理。随后，通过图神经网络 (GNN) 进一步优化主题表示，该网络在文档、主题、词语、相似主题和相似词语之间建立连接。本文还提出了一种计算相似性的新方法。最终，主题嵌入得到优化，并提取出 top k 个主题。实验采用两个医疗领域的数据集（一个英文，一个法语），从中衍生出六组数据。结果表明 HAMLET 的有效性。


> Traditional topic models often struggle with contextual nuances and fail to adequately handle polysemy and rare words. This limitation typically results in topics that lack coherence and quality. Large Language Models (LLMs) can mitigate this issue by generating an initial set of topics. However, these raw topics frequently lack refinement and representativeness, which leads to redundancy without lexical similarity and reduced interpretability. This paper introduces HAMLET, a graph-driven architecture for cross-lingual healthcare topic modeling that uses LLMs. The proposed approach leverages neural-enhanced semantic fusion to refine the embeddings of topics generated by the LLM. Instead of relying solely on statistical co-occurrence or human interpretation to extract topics from a document corpus, this method introduces a topic embedding refinement that uses Bidirectional Encoder Representations from Transformers (BERT) and Graph Neural Networks (GNN). After topic generation, a hybrid technique that involves BERT and Sentence-BERT (SBERT) is employed for embedding. The topic representations are further refined using a GNN, which establishes connections between documents, topics, words, similar topics, and similar words. A novel method is introduced to compute similarities. Consequently, the topic embeddings are refined, and the top k topics are extracted. Experiments were conducted using two healthcare datasets, one in English and one in French, from which six sets were derived. The results demonstrate the effectiveness of HAMLET.

[Arxiv](https://arxiv.org/abs/2505.07157)