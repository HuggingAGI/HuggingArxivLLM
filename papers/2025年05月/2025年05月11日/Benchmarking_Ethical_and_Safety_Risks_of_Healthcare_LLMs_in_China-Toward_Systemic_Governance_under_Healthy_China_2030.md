# # 标题  
评估中国医疗LLM的伦理与安全风险，迈向健康中国2030目标下的系统性治理

发布时间：2025年05月11日

`LLM应用`

> Benchmarking Ethical and Safety Risks of Healthcare LLMs in China-Toward Systemic Governance under Healthy China 2030

# 摘要

> 大型语言模型（LLMs）正准备在中国健康中国2030计划中改变医疗行业，但同时也带来了新的伦理和患者安全挑战。我们提出了一个包含12,000个问题的问答基准测试，涵盖了医疗场景中的11个伦理维度和9个安全维度，用于定量评估这些风险。利用这个数据集，我们评估了最先进的中文医疗LLMs（例如，Qwen 2.5-32B、DeepSeek），发现其基线性能中等（Qwen 2.5-32B的准确率为42.7%），但在我们的数据上进行微调后有了显著提升（准确率最高达50.8%）。结果显示，LLMs在伦理和安全场景下的决策存在明显差距，反映出机构监督不足。然后，我们识别了当前阻碍安全部署LLMs的系统性治理缺陷，包括缺乏细致的伦理审计协议、医院伦理审查委员会适应缓慢以及评估工具不足。最后，我们为医疗机构提出了一套实用的治理框架（嵌入LLM审计团队、制定数据伦理指南、实施安全模拟管道），以主动管理LLM风险。我们的研究强调了在中国医疗领域建立强大LLM治理框架的紧迫性，将AI创新与患者安全和伦理标准相结合。

> Large Language Models (LLMs) are poised to transform healthcare under China's Healthy China 2030 initiative, yet they introduce new ethical and patient-safety challenges. We present a novel 12,000-item Q&A benchmark covering 11 ethics and 9 safety dimensions in medical contexts, to quantitatively evaluate these risks. Using this dataset, we assess state-of-the-art Chinese medical LLMs (e.g., Qwen 2.5-32B, DeepSeek), revealing moderate baseline performance (accuracy 42.7% for Qwen 2.5-32B) and significant improvements after fine-tuning on our data (up to 50.8% accuracy). Results show notable gaps in LLM decision-making on ethics and safety scenarios, reflecting insufficient institutional oversight. We then identify systemic governance shortfalls-including the lack of fine-grained ethical audit protocols, slow adaptation by hospital IRBs, and insufficient evaluation tools-that currently hinder safe LLM deployment. Finally, we propose a practical governance framework for healthcare institutions (embedding LLM auditing teams, enacting data ethics guidelines, and implementing safety simulation pipelines) to proactively manage LLM risks. Our study highlights the urgent need for robust LLM governance in Chinese healthcare, aligning AI innovation with patient safety and ethical standards.

[Arxiv](https://arxiv.org/abs/2505.07205)