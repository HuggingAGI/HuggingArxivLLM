# DriveSOTIF: 借助多模态大型语言模型提升感知 SOTIF 能力

发布时间：2025年05月11日

`LLM应用` `自动驾驶` `交通安全`

> DriveSOTIF: Advancing Perception SOTIF Through Multimodal Large Language Models

# 摘要

> 人类驾驶员凭借空间因果智能，能够感知驾驶场景、预测潜在危险并本能反应，从而在时空维度与三维世界互动。然而，自动驾驶汽车缺乏这些能力，导致在复杂多变的驾驶条件下有效管理与感知相关的预期功能安全 (SOTIF) 风险方面面临挑战。为填补这一空白，我们提出了一种基于定制数据集微调多模态语言模型 (MLLMs) 的方法，专门用于捕捉与感知相关的 SOTIF 场景。模型基准测试表明，这一量身定制的数据集显著提升了模型理解和应对复杂驾驶情况的能力。实际案例研究显示，该方法能够正确处理即使是人类驾驶员也可能棘手的挑战性场景。实时性能测试进一步表明，这些模型有望在实时驾驶环境中高效运行。这种方法，连同数据集生成管道，为提升自动驾驶系统在识别、认知、预测和应对 SOTIF 相关风险方面的能力展现出巨大潜力。数据集和相关信息可访问：https://github.com/s95huang/DriveSOTIF.git

> Human drivers naturally possess the ability to perceive driving scenarios, predict potential hazards, and react instinctively due to their spatial and causal intelligence, which allows them to perceive, understand, predict, and interact with the 3D world both spatially and temporally. Autonomous vehicles, however, lack these capabilities, leading to challenges in effectively managing perception-related Safety of the Intended Functionality (SOTIF) risks, particularly in complex and unpredictable driving conditions. To address this gap, we propose an approach that fine-tunes multimodal language models (MLLMs) on a customized dataset specifically designed to capture perception-related SOTIF scenarios. Model benchmarking demonstrates that this tailored dataset enables the models to better understand and respond to these complex driving situations. Additionally, in real-world case studies, the proposed method correctly handles challenging scenarios that even human drivers may find difficult. Real-time performance tests further indicate the potential for the models to operate efficiently in live driving environments. This approach, along with the dataset generation pipeline, shows significant promise for improving the identification, cognition, prediction, and reaction to SOTIF-related risks in autonomous driving systems. The dataset and information are available: https://github.com/s95huang/DriveSOTIF.git

[Arxiv](https://arxiv.org/abs/2505.07084)