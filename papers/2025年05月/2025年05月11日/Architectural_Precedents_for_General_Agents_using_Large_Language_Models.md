# 使用大型语言模型的通用代理架构先例

发布时间：2025年05月11日

`Agent` `人工智能` `认知科学`

> Architectural Precedents for General Agents using Large Language Models

# 摘要

> 人工智能（AI）与人工通用智能（AGI）的目标之一是识别并理解实现通用智能所需的特定机制与表示方法。这一目标通常通过专注于架构的研究来实现，AI/AGI领域已探索了多种认知架构。然而，不同研究团队甚至不同研究传统在某种程度上独立地识别出在现有架构中表现出来的相似或共同的过程和表示模式，或认知设计模式。如今，利用大型语言模型（LLMs）的AI系统提供了一种相对较新的机制与表示方法的组合，可用于探索通用智能的可能性。本文总结了在各种预变形AI架构中出现的一些反复出现的认知设计模式，并探讨了这些模式在使用LLMs的系统中如何显现，特别是在推理和交互式（“智能体”）用例中。通过研究和应用这些反复出现的模式，我们可以预测当前智能体LLM系统中的差距或不足，并确定未来研究的主题，以利用LLMs和其他生成基础模型实现通用智能。

> One goal of AI (and AGI) is to identify and understand specific mechanisms and representations sufficient for general intelligence. Often, this work manifests in research focused on architectures and many cognitive architectures have been explored in AI/AGI. However, different research groups and even different research traditions have somewhat independently identified similar/common patterns of processes and representations or cognitive design patterns that are manifest in existing architectures. Today, AI systems exploiting large language models (LLMs) offer a relatively new combination of mechanism and representation available for exploring the possibilities of general intelligence. In this paper, we summarize a few recurring cognitive design patterns that have appeared in various pre-transformer AI architectures. We then explore how these patterns are evident in systems using LLMs, especially for reasoning and interactive ("agentic") use cases. By examining and applying these recurring patterns, we can also predict gaps or deficiencies in today's Agentic LLM Systems and identify likely subjects of future research towards general intelligence using LLMs and other generative foundation models.

[Arxiv](https://arxiv.org/abs/2505.07087)