# 生成式 AI 代理能否像人类一样行为？实验室市场实验提供了有力证据

发布时间：2025年05月12日

`Agent` `行为模拟`

> Can Generative AI agents behave like humans? Evidence from laboratory market experiments

# 摘要

> 我们研究了大型语言模型（LLMs）在经济市场实验中模拟人类行为的可能性。与以往研究不同，我们关注的是 LLM 智能体之间的动态反馈：每个 LLM 的决策不仅影响当前的市场价格，还会进一步影响其他 LLM 在下一步的决策。我们将 LLM 的行为与实验室环境中观察到的市场动态进行对比，并评估其与人类参与者行为的一致性。研究发现，LLMs 并不严格遵循理性预期，而是表现出有界理性，与人类参与者类似。通过提供一个最小的上下文窗口（记忆前三步），并结合高变异性设置来捕捉响应差异，LLMs 能够复制人类实验中观察到的广泛趋势，例如正负反馈市场的区别。然而，在细粒度层面，LLMs 的行为异质性仍低于人类。这些结果表明，LLMs 作为模拟经济情境中现实人类行为的工具具有潜力，但未来仍需进一步研究以提高其准确性并增加行为多样性。

> We explore the potential of Large Language Models (LLMs) to replicate human behavior in economic market experiments. Compared to previous studies, we focus on dynamic feedback between LLM agents: the decisions of each LLM impact the market price at the current step, and so affect the decisions of the other LLMs at the next step. We compare LLM behavior to market dynamics observed in laboratory settings and assess their alignment with human participants' behavior. Our findings indicate that LLMs do not adhere strictly to rational expectations, displaying instead bounded rationality, similarly to human participants. Providing a minimal context window i.e. memory of three previous time steps, combined with a high variability setting capturing response heterogeneity, allows LLMs to replicate broad trends seen in human experiments, such as the distinction between positive and negative feedback markets. However, differences remain at a granular level--LLMs exhibit less heterogeneity in behavior than humans. These results suggest that LLMs hold promise as tools for simulating realistic human behavior in economic contexts, though further research is needed to refine their accuracy and increase behavioral diversity.

[Arxiv](https://arxiv.org/abs/2505.07457)