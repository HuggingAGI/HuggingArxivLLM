# 评估大型语言模型在真实世界工程任务中的表现

发布时间：2025年05月12日

`LLM应用` `产品设计`

> Evaluating Large Language Models for Real-World Engineering Tasks

# 摘要

> 大型语言模型（LLMs）不仅在日常活动中具有变革性，而且在工程任务中也表现出巨大潜力。然而，当前对LLMs在工程领域的评估存在两大关键缺陷：(i) 过于依赖简化的使用场景，这些场景往往改编自考试材料，容易验证正确性；(ii) 采用即兴设计的场景，未能充分涵盖关键工程能力。因此，LLMs在复杂真实世界工程问题上的评估仍鲜有探索。本文通过引入一个精选数据库填补这一空白，该数据库包含100多个问题，源自真实、以生产为导向的工程场景，系统设计覆盖产品设计、预测和诊断等核心能力。利用此数据集，我们评估了四个先进的LLMs，包括基于云和本地托管的实例，系统性研究其在复杂工程任务中的表现。我们的结果显示，LLMs在基本时序和结构推理上表现出色，但在抽象推理、形式建模和语境敏感的工程逻辑方面则面临显著挑战。

> Large Language Models (LLMs) are transformative not only for daily activities but also for engineering tasks. However, current evaluations of LLMs in engineering exhibit two critical shortcomings: (i) the reliance on simplified use cases, often adapted from examination materials where correctness is easily verifiable, and (ii) the use of ad hoc scenarios that insufficiently capture critical engineering competencies. Consequently, the assessment of LLMs on complex, real-world engineering problems remains largely unexplored. This paper addresses this gap by introducing a curated database comprising over 100 questions derived from authentic, production-oriented engineering scenarios, systematically designed to cover core competencies such as product design, prognosis, and diagnosis. Using this dataset, we evaluate four state-of-the-art LLMs, including both cloud-based and locally hosted instances, to systematically investigate their performance on complex engineering tasks. Our results show that LLMs demonstrate strengths in basic temporal and structural reasoning but struggle significantly with abstract reasoning, formal modeling, and context-sensitive engineering logic.

[Arxiv](https://arxiv.org/abs/2505.13484)