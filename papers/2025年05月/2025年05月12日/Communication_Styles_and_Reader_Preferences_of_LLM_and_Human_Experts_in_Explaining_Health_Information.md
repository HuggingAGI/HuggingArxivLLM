# 大型语言模型（LLM）与人类专家在解释健康信息时的沟通风格及读者偏好

发布时间：2025年05月12日

`LLM应用` `健康传播`

> Communication Styles and Reader Preferences of LLM and Human Experts in Explaining Health Information

# 摘要

> 大型语言模型（LLMs）在信息协助领域的广泛应用，促使我们深入探讨其与人类沟通风格和价值观的契合度。本研究聚焦于健康信息核查这一关键领域，旨在应对纠正观念和建立信任的挑战。尽管近期研究揭示了LLMs在健康传播中的潜力，但LLMs与人类专家之间的风格差异及其对读者感知的影响仍待进一步探索。为此，我们从信息、发送者和接收者三个核心维度，评估了LLMs的沟通风格及其与人类解释的差异。通过整理权威事实核查机构提供的1498条健康 misinformation 解释，并生成LLM对不准确健康信息的回应，我们基于健康传播理论，从信息语言特征、发送者劝说策略以及接收者价值契合三个维度进行了深入分析。通过99名参与者的盲评，我们进一步评估了人类感知。研究发现，LLM生成的文章在劝说策略、确定性表达以及与社会价值观和道德基础的契合度方面得分显著较低。然而，人类评估结果显示，超过60%的受访者更倾向于选择LLM文章，因其在清晰度、完整性和说服力方面表现突出。尽管在传统事实核查和健康传播质量指标上得分较低，但LLMs的结构化信息呈现方式展现出更强的读者吸引力。


> With the wide adoption of large language models (LLMs) in information assistance, it is essential to examine their alignment with human communication styles and values. We situate this study within the context of fact-checking health information, given the critical challenge of rectifying conceptions and building trust. Recent studies have explored the potential of LLM for health communication, but style differences between LLMs and human experts and associated reader perceptions remain under-explored. In this light, our study evaluates the communication styles of LLMs, focusing on how their explanations differ from those of humans in three core components of health communication: information, sender, and receiver. We compiled a dataset of 1498 health misinformation explanations from authoritative fact-checking organizations and generated LLM responses to inaccurate health information. Drawing from health communication theory, we evaluate communication styles across three key dimensions of information linguistic features, sender persuasive strategies, and receiver value alignments. We further assessed human perceptions through a blinded evaluation with 99 participants. Our findings reveal that LLM-generated articles showed significantly lower scores in persuasive strategies, certainty expressions, and alignment with social values and moral foundations. However, human evaluation demonstrated a strong preference for LLM content, with over 60% responses favoring LLM articles for clarity, completeness, and persuasiveness. Our results suggest that LLMs' structured approach to presenting information may be more effective at engaging readers despite scoring lower on traditional measures of quality in fact-checking and health communication.

[Arxiv](https://arxiv.org/abs/2505.08143)