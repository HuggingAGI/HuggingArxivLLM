# 大型模型左倾：大型语言模型的政治偏见随参数数量增加而增强

发布时间：2025年05月07日

`LLM应用` `政治学`

> Large Means Left: Political Bias in Large Language Models Increases with Their Number of Parameters

# 摘要

> 人工智能的普及促使我们需要仔细评估其固有偏见，以缓解这些偏见对用户的影响。大型语言模型（LLMs）被许多人用作各种话题的主要信息来源，但它们经常出现事实错误、捏造数据（幻觉）或呈现偏见，使用户接触到错误信息并影响他们的观点。教育用户了解这些风险是负责任使用的关键，因为偏见与幻觉不同，无法通过数据验证捕捉。

我们通过Wahl-O-Mat评分量化了 popular LLMs 在最近德国联邦议院投票中的政治偏见。这一指标衡量个人政治观点与德国政党的立场的契合度。我们比较了各模型的契合度得分，以识别影响其政治偏好的因素。通过此分析，我们发现了一种倾向于左翼政党的偏见，尤其在较大的LLMs中最为明显。此外，我们发现与模型交流的语言会影响其政治观点。同时，我们还分析了模型来源和发布日期的影响，并将结果与最近联邦议院投票的结果进行了比较。

我们的研究结果表明，LLMs容易表现出政治偏见。大型企业，拥有开发LLMs的资源，无论有意还是无意，都有责任控制这些偏见，因为它们可能影响每位选民的决策过程，并在更大范围内塑造公众舆论。

> With the increasing prevalence of artificial intelligence, careful evaluation of inherent biases needs to be conducted to form the basis for alleviating the effects these predispositions can have on users. Large language models (LLMs) are predominantly used by many as a primary source of information for various topics. LLMs frequently make factual errors, fabricate data (hallucinations), or present biases, exposing users to misinformation and influencing opinions. Educating users on their risks is key to responsible use, as bias, unlike hallucinations, cannot be caught through data verification. We quantify the political bias of popular LLMs in the context of the recent vote of the German Bundestag using the score produced by the Wahl-O-Mat. This metric measures the alignment between an individual's political views and the positions of German political parties. We compare the models' alignment scores to identify factors influencing their political preferences. Doing so, we discover a bias toward left-leaning parties, most dominant in larger LLMs. Also, we find that the language we use to communicate with the models affects their political views. Additionally, we analyze the influence of a model's origin and release date and compare the results to the outcome of the recent vote of the Bundestag. Our results imply that LLMs are prone to exhibiting political bias. Large corporations with the necessary means to develop LLMs, thus, knowingly or unknowingly, have a responsibility to contain these biases, as they can influence each voter's decision-making process and inform public opinion in general and at scale.

[Arxiv](https://arxiv.org/abs/2505.04393)