# 探索通往多模态通才之路：通用基准与通用水平

发布时间：2025年05月07日

`LLM理论

摘要讨论了多模态大型语言模型的评估框架和能力分析，属于理论探讨和模型评估的范畴。` `人工智能`

> On Path to Multimodal Generalist: General-Level and General-Bench

# 摘要

> 多模态大型语言模型（MLLM）正迎来迅猛发展，这一进程由大型语言模型（LLMs）的先进能力推动。与早期专注于单一任务的模型不同，现有的MLLM正逐步向多模态通用模型范式演进。最初，这些模型仅限于理解多种模态，如今已发展到不仅能理解还能跨模态生成。它们的能力从粗粒度的多模态理解扩展至细粒度，从支持有限的模态到任意模态。尽管已有许多基准测试用于评估MLLM，但一个关键问题浮现：我们能否简单地认为跨任务的更高性能意味着更强的MLLM能力，使我们更接近人类水平的人工智能？我们主张，答案并非表面上那样显而易见。本项目推出General-Level，这是一个评估框架，定义了MLLM性能和通用性的5个等级，提供了一种比较MLLM的方法，并衡量现有系统向更稳健的多模态通用模型发展，最终迈向AGI的进程。框架的核心是Synergy概念，它衡量模型在理解和生成、以及跨多种模态时是否保持一致的能力。为了支持这一评估，我们推出了General-Bench，它涵盖了更广泛的技能、模态、格式和能力，包括超过700个任务和325,800个实例。涉及100多个现有先进MLLM的评估结果揭示了通用模型的能力排名，突显了实现真正AI的挑战。我们期望该项目为下一代多模态基础模型的研究铺平道路，提供一个强大的基础设施，以加速AGI的实现。项目页面：https://generalist.top/

> The Multimodal Large Language Model (MLLM) is currently experiencing rapid growth, driven by the advanced capabilities of LLMs. Unlike earlier specialists, existing MLLMs are evolving towards a Multimodal Generalist paradigm. Initially limited to understanding multiple modalities, these models have advanced to not only comprehend but also generate across modalities. Their capabilities have expanded from coarse-grained to fine-grained multimodal understanding and from supporting limited modalities to arbitrary ones. While many benchmarks exist to assess MLLMs, a critical question arises: Can we simply assume that higher performance across tasks indicates a stronger MLLM capability, bringing us closer to human-level AI? We argue that the answer is not as straightforward as it seems. This project introduces General-Level, an evaluation framework that defines 5-scale levels of MLLM performance and generality, offering a methodology to compare MLLMs and gauge the progress of existing systems towards more robust multimodal generalists and, ultimately, towards AGI. At the core of the framework is the concept of Synergy, which measures whether models maintain consistent capabilities across comprehension and generation, and across multiple modalities. To support this evaluation, we present General-Bench, which encompasses a broader spectrum of skills, modalities, formats, and capabilities, including over 700 tasks and 325,800 instances. The evaluation results that involve over 100 existing state-of-the-art MLLMs uncover the capability rankings of generalists, highlighting the challenges in reaching genuine AI. We expect this project to pave the way for future research on next-generation multimodal foundation models, providing a robust infrastructure to accelerate the realization of AGI. Project page: https://generalist.top/

[Arxiv](https://arxiv.org/abs/2505.04620)