# RAP-SM：基于影子模型的鲁棒对抗提示方法，用于大型语言模型的版权验证

发布时间：2025年05月07日

`LLM理论` `知识产权保护` `模型指纹`

> RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models

# 摘要

> 大型语言模型（LLMs）的最新进展凸显了通过稳健指纹识别技术保护知识产权的重要性。传统指纹验证方法通常专注于单个模型，致力于提升其指纹的稳健性。然而，这些方法难以捕捉多个相关模型间的内在共性。本文提出了一种名为RAP-SM（基于影子模型的稳健对抗提示）的全新框架，用于提取整个LLM系列的公共指纹。实验结果表明，RAP-SM不仅能够有效捕捉不同模型间的内在共性，还展现出强大的对抗鲁棒性。这一发现为可扩展的指纹验证提供了宝贵的研究方向，为防范LLMs时代潜在的模型泄露风险提供了增强保护。

> Recent advances in large language models (LLMs) have underscored the importance of safeguarding intellectual property rights through robust fingerprinting techniques. Traditional fingerprint verification approaches typically focus on a single model, seeking to improve the robustness of its fingerprint.However, these single-model methods often struggle to capture intrinsic commonalities across multiple related models. In this paper, we propose RAP-SM (Robust Adversarial Prompt via Shadow Models), a novel framework that extracts a public fingerprint for an entire series of LLMs. Experimental results demonstrate that RAP-SM effectively captures the intrinsic commonalities among different models while exhibiting strong adversarial robustness. Our findings suggest that RAP-SM presents a valuable avenue for scalable fingerprint verification, offering enhanced protection against potential model breaches in the era of increasingly prevalent LLMs.

[Arxiv](https://arxiv.org/abs/2505.06304)