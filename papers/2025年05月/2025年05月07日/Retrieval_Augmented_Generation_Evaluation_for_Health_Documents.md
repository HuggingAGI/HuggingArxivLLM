# 医疗文档上检索增强生成的评估

发布时间：2025年05月07日

`RAG` `文档处理`

> Retrieval Augmented Generation Evaluation for Health Documents

# 摘要

> 在医疗文档和科学论文处理中安全、可靠地使用大型语言模型（LLM）能够显著帮助临床医生、科学家和政策制定者克服信息过载问题，并在特定时刻专注于最关键的信息。检索增强生成（RAG）是一种有前景的方法，可以在提升大型语言模型潜力的同时增强其输出结果的准确性。本报告评估了此类方法在健康领域不同类型的文档自动知识合成中的潜力与不足。为此，报告描述了：(1) 一个内部开发的概念验证管道，名为RAGEv（检索增强生成评估），该管道采用最先进的实践方法，为医疗文档和科学论文提供安全、可信的分析；(2) 一组用于基于LLM的文档检索和生成的评估工具；(3) 一个名为RAGEv-Bench的基准数据集，用于验证结果的准确性和真实性。报告结论指出，谨慎实施RAG技术可以有效减少大部分在健康领域文档处理中使用LLM时的常见问题，并在简短的Yes/No答案和长篇答案上均获得极高分数。将其纳入日常政策支持任务工作的潜力巨大，但需要进一步努力以获得一致且可信的工具。

> Safe and trustworthy use of Large Language Models (LLM) in the processing of healthcare documents and scientific papers could substantially help clinicians, scientists and policymakers in overcoming information overload and focusing on the most relevant information at a given moment. Retrieval Augmented Generation (RAG) is a promising method to leverage the potential of LLMs while enhancing the accuracy of their outcomes. This report assesses the potentials and shortcomings of such approaches in the automatic knowledge synthesis of different types of documents in the health domain. To this end, it describes: (1) an internally developed proof of concept pipeline that employs state-of-the-art practices to deliver safe and trustable analysis for healthcare documents and scientific papers called RAGEv (Retrieval Augmented Generation Evaluation); (2) a set of evaluation tools for LLM-based document retrieval and generation; (3) a benchmark dataset to verify the accuracy and veracity of the results called RAGEv-Bench. It concludes that careful implementations of RAG techniques could minimize most of the common problems in the use of LLMs for document processing in the health domain, obtaining very high scores both on short yes/no answers and long answers. There is a high potential for incorporating it into the day-to-day work of policy support tasks, but additional efforts are required to obtain a consistent and trustworthy tool.

[Arxiv](https://arxiv.org/abs/2505.04680)