# 可控的聊天机器人：通过偏好驱动的激活引导实现个性化大型语言模型

发布时间：2025年05月07日

`LLM应用` `人工智能` `人机交互`

> Steerable Chatbots: Personalizing LLMs with Preference-Based Activation Steering

# 摘要

> 大型语言模型（LLMs）在作为个人AI助手方面的能力不断提升，输出与用户潜在偏好相匹配的独特定制化、个性化响应的能力对于提升用户满意度和留存至关重要。然而，未经训练的普通用户往往难以向AI助手传达其潜在偏好。为了解决这一问题，我们利用激活引导技术，在推理过程中引导LLMs与可解释的偏好维度保持一致。与需要更长用户历史记录的记忆型个性化方法不同，引导方法极为轻量，用户可以通过线性强度因子轻松控制。我们将引导技术嵌入三种不同的交互式聊天机器人界面，并进行了一项被试内用户研究（n=14），以探究终端用户如何偏好个性化他们的对话。结果显示，基于偏好的引导方法能够有效对齐现实世界对话与隐藏的用户偏好，并进一步揭示了围绕控制、可用性和透明度的多样化价值观如何引导用户偏好不同的界面。

> As large language models (LLMs) improve in their capacity to serve as personal AI assistants, their ability to output uniquely tailored, personalized responses that align with the soft preferences of their users is essential for enhancing user satisfaction and retention. However, untrained lay users have poor prompt specification abilities and often struggle with conveying their latent preferences to AI assistants. To address this, we leverage activation steering to guide LLMs to align with interpretable preference dimensions during inference. In contrast to memory-based personalization methods that require longer user history, steering is extremely lightweight and can be easily controlled by the user via an linear strength factor. We embed steering into three different interactive chatbot interfaces and conduct a within-subjects user study (n=14) to investigate how end users prefer to personalize their conversations. The results demonstrate the effectiveness of preference-based steering for aligning real-world conversations with hidden user preferences, and highlight further insights on how diverse values around control, usability, and transparency lead users to prefer different interfaces.

[Arxiv](https://arxiv.org/abs/2505.04260)