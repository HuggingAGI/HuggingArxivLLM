# 多模态指涉分割综述

发布时间：2025年07月31日

`其他` `计算机视觉` `多模态`

> Multimodal Referring Segmentation: A Survey

# 摘要

> 多模态指代分割旨在根据文本或音频格式的指代表达，在图像、视频和3D场景等视觉场景中精确分割目标对象。这一技术在基于用户指令实现精准物体感知的实际应用中具有重要作用。过去十年间，得益于卷积神经网络、变压器和大型语言模型的突破性进展，多模态感知能力得到了显著提升，推动了多模态社区对这一任务的广泛关注。本文对多模态指代分割进行了全面综述。首先，我们介绍了该领域的背景，包括问题定义和常用数据集。接着，我们总结了指代分割的统一元架构，并详细回顾了在图像、视频和3D场景这三大主要视觉场景中的代表性方法。此外，我们探讨了针对现实世界复杂性问题的广义指代表达（GREx）方法，以及相关任务和实际应用场景。本文还提供了在标准基准上的广泛性能比较。我们持续跟踪相关研究进展，欢迎访问https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation获取最新动态。


> Multimodal referring segmentation aims to segment target objects in visual scenes, such as images, videos, and 3D scenes, based on referring expressions in text or audio format. This task plays a crucial role in practical applications requiring accurate object perception based on user instructions. Over the past decade, it has gained significant attention in the multimodal community, driven by advances in convolutional neural networks, transformers, and large language models, all of which have substantially improved multimodal perception capabilities. This paper provides a comprehensive survey of multimodal referring segmentation. We begin by introducing this field's background, including problem definitions and commonly used datasets. Next, we summarize a unified meta architecture for referring segmentation and review representative methods across three primary visual scenes, including images, videos, and 3D scenes. We further discuss Generalized Referring Expression (GREx) methods to address the challenges of real-world complexity, along with related tasks and practical applications. Extensive performance comparisons on standard benchmarks are also provided. We continually track related works at https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation.

[Arxiv](https://arxiv.org/abs/2508.00265)