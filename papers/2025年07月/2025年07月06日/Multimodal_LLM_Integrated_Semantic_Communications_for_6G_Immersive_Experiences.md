# 面向6G沉浸式体验的多模态大型语言模型集成语义通信

发布时间：2025年07月06日

`LLM应用` `通信技术` `增强现实`

> Multimodal LLM Integrated Semantic Communications for 6G Immersive Experiences

# 摘要

> 6G网络将带来革命性的沉浸式通信体验，包括增强现实（AR）、虚拟现实（VR）和全息通信。这些应用对高维多模态数据的实时传输与智能处理提出了极高要求，而这对资源有限的无线通信系统来说极具挑战。此外，准确理解环境、上下文和用户意图是实现高效任务相关内容传递的关键。本文提出了一种名为MLLM-SC的新型多模态大语言模型集成语义通信框架，充分利用预训练基础模型的推理和生成能力，实现上下文感知和任务导向的无线通信。MLLM-SC采用设备-边缘协作架构。在边缘端，MLLM增强的语义引导模块通过分析多模态输入、用户意图和信道条件，生成语义关键信息优先的注意力图。同时，框架设计并优化了语义感知编码器和资源自适应语义解码器，能够利用语义引导实现自适应带宽分配和高质量内容重构或生成。针对AR/VR应用的视觉问答和扩散驱动图像生成的大量案例研究证实了MLLM-SC框架的有效性。

> 6G networks promise revolutionary immersive communication experiences including augmented reality (AR), virtual reality (VR), and holographic communications. These applications demand high-dimensional multimodal data transmission and intelligent data processing in real-time, which is extremely challenging over resource-limited wireless communication systems. Moreover, a joint understanding of the environment, context, and user intent is essential to deliver task-relevant content effectively. This article presents a novel multimodal large language model (MLLM) integrated semantic communications framework, termed MLLM-SC, which fully leverages reasoning and generative capabilities of pre-trained foundation models for context-aware and task-oriented wireless communication. The MLLM-SC framework adopts a device-edge collaborative architecture. At the edge, MLLM-empowered semantic guidance module analyzes multimodal inputs, user intents, and channel conditions to generate importance-aware attention maps prioritizing semantically critical information. An importance-aware semantic encoder and a resource-adaptive semantic decoder are jointly designed and optimized, which can utilize the semantic guidance for adaptive bandwidth allocation and high-quality content reconstruction or generation. Extensive case studies on visual question answering for AR/VR applications and diffusion-driven image generation validate the effectiveness of MLLM-SC.

[Arxiv](https://arxiv.org/abs/2507.04621)