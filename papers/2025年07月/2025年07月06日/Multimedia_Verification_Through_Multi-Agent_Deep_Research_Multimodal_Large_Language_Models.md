# 通过多智能体深度研究，利用多模态大型语言模型实现的多媒体验证

发布时间：2025年07月06日

`Agent` `信息验证` `多媒体`

> Multimedia Verification Through Multi-Agent Deep Research Multimodal Large Language Models

# 摘要

> # 摘要
本文介绍了我们对ACMMM25 - 多媒体验证大挑战的参赛作品。我们开发了一个多智能体验证系统，结合多模态大型语言模型（MLLMs）与专用工具，用于检测多媒体虚假信息。系统通过六个阶段运行：原始数据处理、规划、信息提取、深度研究、证据收集和报告生成。核心深度研究代理使用反向图像搜索、元数据分析、事实核查数据库和新闻处理工具，提取空间、时间、归属和动机背景。我们在一个复杂多媒体数据集上展示了方法，系统成功验证内容真实性，提取精确地理位置和时间信息，并追踪跨平台来源归属，有效应对现实世界中的多媒体验证挑战。


> This paper presents our submission to the ACMMM25 - Grand Challenge on Multimedia Verification. We developed a multi-agent verification system that combines Multimodal Large Language Models (MLLMs) with specialized verification tools to detect multimedia misinformation. Our system operates through six stages: raw data processing, planning, information extraction, deep research, evidence collection, and report generation. The core Deep Researcher Agent employs four tools: reverse image search, metadata analysis, fact-checking databases, and verified news processing that extracts spatial, temporal, attribution, and motivational context. We demonstrate our approach on a challenge dataset sample involving complex multimedia content. Our system successfully verified content authenticity, extracted precise geolocation and timing information, and traced source attribution across multiple platforms, effectively addressing real-world multimedia verification scenarios.

[Arxiv](https://arxiv.org/abs/2507.04410)