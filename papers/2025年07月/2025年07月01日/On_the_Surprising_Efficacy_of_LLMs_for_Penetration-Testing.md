# # 令人意外的LLMs渗透测试有效性
大型语言模型（LLMs）在渗透测试中的意外有效性

发布时间：2025年07月01日

`LLM应用` `网络安全`

> On the Surprising Efficacy of LLMs for Penetration-Testing

# 摘要

> 本文深入探讨了大型语言模型（LLMs）在渗透测试中令人瞩目的有效性。文章回顾了LLMs的发展历程及其日益增强的能力，使其成为复杂渗透测试任务的理想工具。从学术研究到工业应用，LLMs已在多种进攻性安全任务中展现出广泛应用，并贯穿网络攻击链的各个阶段。值得注意的是，恶意行为者对LLMs的采用也引发了技术双重用途的安全挑战。

LLMs在渗透测试中的成功得益于三大关键因素：其一，渗透测试对模式匹配的依赖与LLMs的核心优势高度契合；其二，LLMs在动态环境中处理不确定性的卓越能力；其三，通过LLM供应商获取优质预训练模型的高效途径。

当前基于LLMs的渗透测试可分为交互式“氛围破解”与全自动系统两大类。文章深入探讨了阻碍其广泛应用与安全部署的多重障碍，包括模型可靠性、安全性、成本控制、隐私保护、问责机制及伦理问题。这些分析为未来研究方向及AI与安全领域的保障措施开发提供了重要参考。

> This paper presents a critical examination of the surprising efficacy of Large Language Models (LLMs) in penetration testing. The paper thoroughly reviews the evolution of LLMs and their rapidly expanding capabilities which render them increasingly suitable for complex penetration testing operations. It systematically details the historical adoption of LLMs in both academic research and industry, showcasing their application across various offensive security tasks and covering broader phases of the cyber kill chain. Crucially, the analysis also extends to the observed adoption of LLMs by malicious actors, underscoring the inherent dual-use challenge of this technology within the security landscape.
  The unexpected effectiveness of LLMs in this context is elucidated by several key factors: the strong alignment between penetration testing's reliance on pattern-matching and LLMs' core strengths, their inherent capacity to manage uncertainty in dynamic environments, and cost-effective access to competent pre-trained models through LLM providers.
  The current landscape of LLM-aided penetration testing is categorized into interactive 'vibe-hacking' and the emergence of fully autonomous systems. The paper identifies and discusses significant obstacles impeding wider adoption and safe deployment. These include critical issues concerning model reliability and stability, paramount safety and security concerns, substantial monetary and ecological costs, implications for privacy and digital sovereignty, complex questions of accountability, and profound ethical dilemmas. This comprehensive review and analysis provides a foundation for discussion on future research directions and the development of robust safeguards at the intersection of AI and security.

[Arxiv](https://arxiv.org/abs/2507.00829)