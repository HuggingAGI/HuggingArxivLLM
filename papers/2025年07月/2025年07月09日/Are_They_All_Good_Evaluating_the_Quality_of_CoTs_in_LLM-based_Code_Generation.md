# # 它们质量如何？一探LLM代码生成中的CoT质量：全面评估

发布时间：2025年07月09日

`LLM应用` `软件开发`

> Are They All Good? Evaluating the Quality of CoTs in LLM-based Code Generation

# 摘要

> 大型语言模型（LLMs）在代码生成方面表现出了令人印象深刻的性能，尤其是在结合链式思维（CoT）提示技术时。它们通过将需求分解为中间推理步骤，指导LLMs像人类程序员一样编写代码。然而，这些推理步骤的质量直接影响生成代码的正确性和可靠性。本文通过分析两个广泛使用的代码生成基准上的1023个失败代码样本，深入探讨了LLMs生成不满意链式思维的外部和内部原因。我们还通过分析210个链式思维-代码对，并通过提示LLMs来完善不满意的链式思维，评估了它们对代码生成性能的影响。研究发现：（1）外部因素（53.60%）如需求不明确和缺乏上下文是主要问题，而内部因素（40.10%）则源于LLMs对提示的误解。（2）即使链式思维正确，18.5%的代码仍因指令遵循问题出错；同时，11.90%的正确代码却配对了有缺陷的链式思维。（3）通过完善低质量链式思维，LLMs的性能可以显著提升。这些发现揭示了基于链式思维的代码生成中的关键挑战，并为提升LLMs推理和可靠性提供了重要方向。

> Large language models (LLMs) have demonstrated impressive performance in code generation, particularly when augmented with chain-of-thought (CoT) prompting techniques. They break down requirements into intermediate reasoning steps, which act as design rationales to guide LLMs in writing code like human programmers. Thus, the quality of these steps is crucial for ensuring the correctness and reliability of the generated code. However, little is known about the quality of CoT generated by LLMs. To what extent can we trust the thoughts generated by LLMs? How good are they? This paper empirically explores the external and internal factors of why LLMs generate unsatisfactory CoTs by analyzing 1,023 failed code samples on two widely used code generation benchmarks. We also evaluate their impact on code generation performance by analyzing 210 CoT-code pairs and refining the unsatisfied CoTs by prompting LLMs. Our study reveals three key findings: (1) External factors (53.60%), such as unclear requirements and lack of context, mainly affect CoT quality, while internal factors (40.10%) stem from LLMs' misunderstanding prompts. (2) Even when CoTs are correct, 18.5% of the generated code contains errors due to instruction-following issues; conversely, 11.90% of correct code is paired with flawed CoTs. (3) Refining low-quality CoTs is feasible, i.e., LLMs improve when given detailed problem descriptions. These findings highlight key challenges in CoT-based code generation and suggest directions for improving LLM reasoning and reliability.

[Arxiv](https://arxiv.org/abs/2507.06980)