# 生物医学图像分析中的可解释AI研究进展：一项全面综述

发布时间：2025年07月09日

`其他` `生物医学` `可解释人工智能`

> Explainable Artificial Intelligence in Biomedical Image Analysis: A Comprehensive Survey

# 摘要

> 可解释的人工智能（XAI）在生物医学图像分析领域越来越重要，它有助于提升深度学习模型的透明性、信任度和临床应用。虽然已有不少综述对XAI技术进行了回顾，但它们往往忽视了模态感知的视角，未能充分反映多模态和视觉-语言范式中的最新进展，且缺乏实用指导。本综述通过全面而结构化的XAI方法整合，专门针对生物医学图像分析，填补了这一空白。我们系统性地对XAI方法进行了分类，深入分析了它们在生物医学背景下的基本原理、优势和局限性。提出了一种以模态为中心的分类框架，将XAI方法与特定的成像类型相结合，突出了不同模态下的独特可解释性挑战。我们还深入探讨了多模态学习和视觉-语言模型在可解释生物医学AI中的新兴作用，这一领域在以往研究中鲜有涉及。此外，本综述总结了常用的评估指标和开源框架，并对当前面临的挑战和未来发展方向进行了批判性讨论。本综述为推动生物医学图像分析中的可解释深度学习提供了及时且深入的理论基础，为相关研究和应用提供了重要参考.

> Explainable artificial intelligence (XAI) has become increasingly important in biomedical image analysis to promote transparency, trust, and clinical adoption of DL models. While several surveys have reviewed XAI techniques, they often lack a modality-aware perspective, overlook recent advances in multimodal and vision-language paradigms, and provide limited practical guidance. This survey addresses this gap through a comprehensive and structured synthesis of XAI methods tailored to biomedical image analysis.We systematically categorize XAI methods, analyzing their underlying principles, strengths, and limitations within biomedical contexts. A modality-centered taxonomy is proposed to align XAI methods with specific imaging types, highlighting the distinct interpretability challenges across modalities. We further examine the emerging role of multimodal learning and vision-language models in explainable biomedical AI, a topic largely underexplored in previous work. Our contributions also include a summary of widely used evaluation metrics and open-source frameworks, along with a critical discussion of persistent challenges and future directions. This survey offers a timely and in-depth foundation for advancing interpretable DL in biomedical image analysis.

[Arxiv](https://arxiv.org/abs/2507.07148)