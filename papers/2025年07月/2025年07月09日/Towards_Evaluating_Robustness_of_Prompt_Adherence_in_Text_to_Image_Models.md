# 文本到图像模型中提示遵循的稳健性评估

发布时间：2025年07月09日

`LLM应用` `图像生成` `图像处理`

> Towards Evaluating Robustness of Prompt Adherence in Text to Image Models

# 摘要

> 近年来，大型语言模型的突破性进展令人瞩目，不仅展示了其强大的能力，还拓展了其在多个领域的应用。随着研究的深入，人们开始关注这些模型在实际应用中的可靠性和有效性。然而，与传统的文本处理模型相比，多模态LLMs和文本到图像模型虽然发展迅速，但其可靠性仍需进一步验证，原因在于对其性能和鲁棒性的研究尚不充分。本文致力于构建一个全面的文本到图像模型评估框架，重点关注这些模型对输入提示的遵循程度。为此，我们开发了一个新型数据集，用于评估模型在生成符合输入文本提示中指定变体因素的图像时的鲁棒性。我们的研究对象包括三种Stable Diffusion模型变体（Stable Diffusion 3 Medium、Stable Diffusion 3.5 Large和Stable Diffusion 3.5 Large Turbo），以及两种Janus模型变体（Janus Pro 1B和Janus Pro 7B）。我们设计了一条创新的评估管道，首先利用gpt-4o模型生成真实图像的文本描述，随后将这些描述输入文本到图像模型生成人工图像。接着，我们将生成的图像再次通过gpt-4o模型，使用相同的系统提示，比较前后两次生成的描述差异。实验结果表明，这些模型在生成仅包含两个变体因素（如简单几何形状及其位置）的二值图像时表现不佳。此外，通过在我们的数据集上预训练的变分自编码器（VAE），我们发现这些模型难以生成符合输入数据分布的图像。

> The advancements in the domain of LLMs in recent years have surprised many, showcasing their remarkable capabilities and diverse applications. Their potential applications in various real-world scenarios have led to significant research on their reliability and effectiveness. On the other hand, multimodal LLMs and Text-to-Image models have only recently gained prominence, especially when compared to text-only LLMs. Their reliability remains constrained due to insufficient research on assessing their performance and robustness. This paper aims to establish a comprehensive evaluation framework for Text-to-Image models, concentrating particularly on their adherence to prompts. We created a novel dataset that aimed to assess the robustness of these models in generating images that conform to the specified factors of variation in the input text prompts. Our evaluation studies present findings on three variants of Stable Diffusion models: Stable Diffusion 3 Medium, Stable Diffusion 3.5 Large, and Stable Diffusion 3.5 Large Turbo, and two variants of Janus models: Janus Pro 1B and Janus Pro 7B. We introduce a pipeline that leverages text descriptions generated by the gpt-4o model for our ground-truth images, which are then used to generate artificial images by passing these descriptions to the Text-to-Image models. We then pass these generated images again through gpt-4o using the same system prompt and compare the variation between the two descriptions. Our results reveal that these models struggle to create simple binary images with only two factors of variation: a simple geometric shape and its location. We also show, using pre-trained VAEs on our dataset, that they fail to generate images that follow our input dataset distribution.

[Arxiv](https://arxiv.org/abs/2507.08039)