# # 预训练语言模型在通用文本嵌入中的作用研究综述

发布时间：2025年07月28日

`其他` `人工智能`

> On The Role of Pretrained Language Models in General-Purpose Text Embeddings: A Survey

# 摘要

> 文本嵌入在自然语言处理（NLP）领域日益受到研究者的关注，其应用范围涵盖检索、分类、聚类、双语文本挖掘和摘要等任务。随着预训练语言模型（PLMs）的崛起，通用文本嵌入（GPTE）凭借其生成丰富且可迁移表示的能力获得了广泛关注。GPTE的基本架构通常利用PLMs生成密集的文本表示，并通过在大规模成对数据集上进行对比学习进行优化。本文综述了PLMs时代下GPTE的发展全貌，重点分析了PLMs在其发展中的关键作用。

首先，我们探讨了GPTE的基础架构，并阐述了PLMs在其中的核心功能，包括嵌入提取、表达能力增强、训练策略、学习目标和数据构建。随后，我们深入介绍了PLMs支持的高级功能，如多语言支持、多模态整合、代码理解和特定场景的适应。最后，我们展望了GPTE未来的发展方向，这些方向超越了传统的改进目标，包括排名整合、安全性考虑、偏见缓解、结构信息的纳入以及嵌入的认知扩展。

这篇综述旨在为希望深入了解GPTE当前发展状况及其未来潜力的研究者提供有价值的参考，无论您是刚入门的新手还是经验丰富的专家。


> Text embeddings have attracted growing interest due to their effectiveness across a wide range of natural language processing (NLP) tasks, such as retrieval, classification, clustering, bitext mining, and summarization. With the emergence of pretrained language models (PLMs), general-purpose text embeddings (GPTE) have gained significant traction for their ability to produce rich, transferable representations. The general architecture of GPTE typically leverages PLMs to derive dense text representations, which are then optimized through contrastive learning on large-scale pairwise datasets. In this survey, we provide a comprehensive overview of GPTE in the era of PLMs, focusing on the roles PLMs play in driving its development. We first examine the fundamental architecture and describe the basic roles of PLMs in GPTE, i.e., embedding extraction, expressivity enhancement, training strategies, learning objectives, and data construction. Then, we describe advanced roles enabled by PLMs, such as multilingual support, multimodal integration, code understanding, and scenario-specific adaptation. Finally, we highlight potential future research directions that move beyond traditional improvement goals, including ranking integration, safety considerations, bias mitigation, structural information incorporation, and the cognitive extension of embeddings. This survey aims to serve as a valuable reference for both newcomers and established researchers seeking to understand the current state and future potential of GPTE.

[Arxiv](https://arxiv.org/abs/2507.20783)