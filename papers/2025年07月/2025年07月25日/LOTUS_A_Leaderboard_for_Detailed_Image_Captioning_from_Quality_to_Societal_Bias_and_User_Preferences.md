# LOTUS：一个涵盖质量、社会偏见与用户偏好的详细图像描述任务排行榜

发布时间：2025年07月25日

`LLM应用

理由：这篇论文讨论了大规模视觉-语言模型（LVLMs）在图像描述任务中的应用，并提出了一个评估排行榜，涉及描述质量、风险和社会偏见等多个维度。它关注的是模型的实际应用和评估方法，属于应用层面。` `图像描述` `计算机视觉` `社会责任`

> LOTUS: A Leaderboard for Detailed Image Captioning from Quality to Societal Bias and User Preferences

# 摘要

> 大规模视觉-语言模型 (LVLMs) 已经彻底改变了图像描述任务，从简单的 captions 迈向了更详细的描述。我们推出 LOTUS 评估排行榜，填补现有评估体系的三大空白：标准化评估标准的缺失、偏见感知评估的不足以及用户偏好考量的缺乏。LOTUS 从描述质量（如与图像的对齐度、描述的丰富性）、风险（如 hallucination）以及社会偏见（如性别偏见）等多个维度进行全面评估，同时支持偏好导向的评估，通过定制化标准满足不同用户的偏好需求。通过对近期 LVLMs 的深入分析，我们发现没有单一模型能够在所有评估维度上都表现优异，而描述的详细程度与偏见风险之间存在显著相关性。偏好导向的评估结果表明，选择最优模型需结合用户的实际需求和优先级。

> Large Vision-Language Models (LVLMs) have transformed image captioning, shifting from concise captions to detailed descriptions. We introduce LOTUS, a leaderboard for evaluating detailed captions, addressing three main gaps in existing evaluations: lack of standardized criteria, bias-aware assessments, and user preference considerations. LOTUS comprehensively evaluates various aspects, including caption quality (e.g., alignment, descriptiveness), risks (\eg, hallucination), and societal biases (e.g., gender bias) while enabling preference-oriented evaluations by tailoring criteria to diverse user preferences. Our analysis of recent LVLMs reveals no single model excels across all criteria, while correlations emerge between caption detail and bias risks. Preference-oriented evaluations demonstrate that optimal model selection depends on user priorities.

[Arxiv](https://arxiv.org/abs/2507.19362)