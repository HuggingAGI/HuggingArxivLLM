# 基于大型语言模型的数字孪生边缘计算网络任务卸载与资源分配研究

发布时间：2025年07月25日

`LLM应用

理由：论文主要讨论了在边缘计算网络中应用大语言模型（LLM）来优化任务卸载策略和资源分配问题。虽然研究涉及多辆车辆和服务器组成的网络，但核心是将LLM作为工具应用于具体任务，属于LLM的应用层面。` `智能交通系统` `边缘计算`

> Large Language Model-Based Task Offloading and Resource Allocation for Digital Twin Edge Computing Networks

# 摘要

> 本文提出了一种由多辆车辆和一个服务器组成的通用数字孪生边缘计算网络。每辆车在每个时间槽内生成多个计算任务，导致任务卸载至服务器时的队列难题。本研究深入探讨了任务卸载策略、队列稳定性及资源分配问题。通过Lyapunov优化，我们将长期约束转化为易于处理的短期决策。为了解决由此产生的问题，我们采用了一种基于大语言模型（LLM）的上下文学习方法，取代传统的多智能体强化学习（MARL）框架。实验结果表明，基于LLM的方法在性能上与MARL相当，甚至更优。

> In this paper, we propose a general digital twin edge computing network comprising multiple vehicles and a server. Each vehicle generates multiple computing tasks within a time slot, leading to queuing challenges when offloading tasks to the server. The study investigates task offloading strategies, queue stability, and resource allocation. Lyapunov optimization is employed to transform long-term constraints into tractable short-term decisions. To solve the resulting problem, an in-context learning approach based on large language model (LLM) is adopted, replacing the conventional multi-agent reinforcement learning (MARL) framework. Experimental results demonstrate that the LLM-based method achieves comparable or even superior performance to MARL.

[Arxiv](https://arxiv.org/abs/2507.19050)