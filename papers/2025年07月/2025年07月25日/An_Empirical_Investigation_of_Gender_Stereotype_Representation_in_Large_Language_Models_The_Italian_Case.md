# # 摘要  
大型语言模型（LLMs）的最新进展推动了从机器人流程自动化到智能体流程自动化的革命性范式转变，这一转变基于LLMs自动化了工作流编排过程。

发布时间：2025年07月25日

`LLM应用`

> An Empirical Investigation of Gender Stereotype Representation in Large Language Models: The Italian Case

# 摘要

> 大型语言模型（LLMs）在多领域的广泛应用引发了对其延续刻板印象和生成偏见内容能力的担忧。本研究聚焦于性别与职业偏见，探讨LLMs如何在无性别提示下生成回应，从而导致偏见输出。研究采用结构化实验方法，设计了涉及三种职业组合的提示词，这些组合具有层级关系。我们选择语法性别差异显著的意大利语，以凸显当前LLMs在非英语语言中生成客观文本能力的潜在局限。研究考察了两个流行的聊天机器人：OpenAI ChatGPT（gpt-4o-mini）和Google Gemini（gemini-1.5-flash）。通过API接口，我们收集了共计3600条回复。结果显示，LLMs生成的内容可能延续刻板印象。例如，Gemini将100%（ChatGPT为97%）的'she'代词与'assistant'而非'manager'相关联。AI生成文本中的偏见可能在职场或职业选择等领域产生重大影响，引发对其使用的伦理担忧。理解这些风险对于制定缓解策略至关重要，以确保AI系统不会加剧社会不平等，而是促进更公平的结果。未来研究可扩展至更多聊天机器人或语言、优化提示工程方法或进一步扩大实验规模。

> The increasing use of Large Language Models (LLMs) in a large variety of domains has sparked worries about how easily they can perpetuate stereotypes and contribute to the generation of biased content. With a focus on gender and professional bias, this work examines in which manner LLMs shape responses to ungendered prompts, contributing to biased outputs. This analysis uses a structured experimental method, giving different prompts involving three different professional job combinations, which are also characterized by a hierarchical relationship. This study uses Italian, a language with extensive grammatical gender differences, to highlight potential limitations in current LLMs' ability to generate objective text in non-English languages. Two popular LLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google Gemini (gemini-1.5-flash). Through APIs, we collected a range of 3600 responses. The results highlight how content generated by LLMs can perpetuate stereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she' pronouns to the 'assistant' rather than the 'manager'. The presence of bias in AI-generated text can have significant implications in many fields, such as in the workplaces or in job selections, raising ethical concerns about its use. Understanding these risks is pivotal to developing mitigation strategies and assuring that AI-based systems do not increase social inequalities, but rather contribute to more equitable outcomes. Future research directions include expanding the study to additional chatbots or languages, refining prompt engineering methods or further exploiting a larger experimental base.

[Arxiv](https://arxiv.org/abs/2507.19156)