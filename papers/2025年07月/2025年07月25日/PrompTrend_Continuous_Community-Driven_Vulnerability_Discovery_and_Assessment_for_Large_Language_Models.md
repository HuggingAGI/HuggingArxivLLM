# PrompTrend：针对大型语言模型的持续社区驱动漏洞发现与评估。

发布时间：2025年07月25日

`LLM应用` `人工智能安全` `网络安全`

> PrompTrend: Continuous Community-Driven Vulnerability Discovery and Assessment for Large Language Models

# 摘要

> 传统的静态基准测试无法有效捕捉通过社区在线实验浮现的大型语言模型（LLM）漏洞。为此，我们提出了PrompTrend系统，该系统通过跨平台收集漏洞数据，并结合多维度评分进行评估，构建了一个支持大规模监控的架构。通过对2025年1月至5月期间从在线社区收集的198个漏洞进行横截面分析，并在九个商用模型上进行测试，我们发现：先进功能与某些架构中的漏洞增加存在显著关联，心理攻击在效果上远超技术漏洞利用，而平台动态则显著影响攻击效果，并呈现出可测量的模型特定模式。PrompTrend漏洞评估框架实现了78%的分类准确率，同时揭示了有限的跨模型迁移能力，这表明要实现有效的LLM安全防护，需要建立超越传统周期性评估的全面社会技术监测体系。我们的研究结果挑战了能力提升会增强安全性的假设，并将社区驱动的心理操控确立为当前语言模型的主要威胁向量。

> Static benchmarks fail to capture LLM vulnerabilities emerging through community experimentation in online forums. We present PrompTrend, a system that collects vulnerability data across platforms and evaluates them using multidimensional scoring, with an architecture designed for scalable monitoring. Cross-sectional analysis of 198 vulnerabilities collected from online communities over a five-month period (January-May 2025) and tested on nine commercial models reveals that advanced capabilities correlate with increased vulnerability in some architectures, psychological attacks significantly outperform technical exploits, and platform dynamics shape attack effectiveness with measurable model-specific patterns. The PrompTrend Vulnerability Assessment Framework achieves 78% classification accuracy while revealing limited cross-model transferability, demonstrating that effective LLM security requires comprehensive socio-technical monitoring beyond traditional periodic assessment. Our findings challenge the assumption that capability advancement improves security and establish community-driven psychological manipulation as the dominant threat vector for current language models.

[Arxiv](https://arxiv.org/abs/2507.19185)