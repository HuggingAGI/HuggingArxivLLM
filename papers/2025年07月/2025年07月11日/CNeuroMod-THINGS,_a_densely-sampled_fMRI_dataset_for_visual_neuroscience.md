# CNeuroMod-THINGS：为视觉神经科学打造的高密度采样 fMRI 数据集

发布时间：2025年07月11日

`其他` `神经科学` `计算机视觉`

> CNeuroMod-THINGS, a densely-sampled fMRI dataset for visual neuroscience

# 摘要

> 数据驱动的神经AI建模需要越来越庞大的神经成像数据集。CNeuroMod-THINGS项目通过结合两个重要计划——THINGS和CNeuroMod，成功满足了这一需求。THINGS计划开发了一组经过彻底标注的图像，广泛涵盖了自然和人造物体，用于获取多模态神经响应数据。而CNeuroMod项目则专注于从核心参与者中获取数百小时的fMRI数据，包括观看电影和玩电子游戏等视觉任务。在CNeuroMod-THINGS项目中，四位参与者各自完成了33-36个连续识别范式的会话，使用了来自THINGS刺激集的约4000张图像，涵盖720个类别。通过整合现有的大型资源，CNeuroMod-THINGS不仅展示了高质量的行为和神经成像数据，还扩展了我们建模人类视觉体验广泛切面的能力。

> Data-hungry neuro-AI modelling requires ever larger neuroimaging datasets. CNeuroMod-THINGS meets this need by capturing neural representations for a wide set of semantic concepts using well-characterized stimuli in a new densely-sampled, large-scale fMRI dataset. Importantly, CNeuroMod-THINGS exploits synergies between two existing projects: the THINGS initiative (THINGS) and the Courtois Project on Neural Modelling (CNeuroMod). THINGS has developed a common set of thoroughly annotated images broadly sampling natural and man-made objects which is used to acquire a growing collection of large-scale multimodal neural responses. Meanwhile, CNeuroMod is acquiring hundreds of hours of fMRI data from a core set of participants during controlled and naturalistic tasks, including visual tasks like movie watching and videogame playing. For CNeuroMod-THINGS, four CNeuroMod participants each completed 33-36 sessions of a continuous recognition paradigm using approximately 4000 images from the THINGS stimulus set spanning 720 categories. We report behavioural and neuroimaging metrics that showcase the quality of the data. By bridging together large existing resources, CNeuroMod-THINGS expands our capacity to model broad slices of the human visual experience.

[Arxiv](https://arxiv.org/abs/2507.09024)