# 人类更倾向于选择可信赖的人工智能而非人类伙伴。

发布时间：2025年07月17日

`Agent` `人工智能` `社会学`

> Humans learn to prefer trustworthy AI over human partners

# 摘要

> 合作伙伴的选择对合作至关重要，这一选择过程取决于沟通。随着人工代理，尤其是由大型语言模型（LLMs）驱动的代理，变得越来越自主、智能和有说服力，它们开始与人类竞争合作伙伴关系。然而，关于人类如何在人类和AI伙伴之间做出选择以及如何在AI引发的竞争压力下适应，我们知之甚少。我们构建了一个基于沟通的合作伙伴选择游戏，并研究了由人类和由最先进的LLM驱动的AI助手组成的混合小型社会中的动态。通过三项实验（N = 975），我们发现，尽管AI助手比人类更具 prosocial 性质且语言表达可区分，但在其身份被隐藏时，并未被优先选择。相反，人类将AI助手的行为误认为是人类行为，反之亦然。当AI助手的身份被揭示时，产生了双重效果：它降低了AI助手被最初选择的机会，但使它们能够逐渐通过促进人类了解每种伙伴类型的行为而胜过人类。这些发现展示了AI如何重塑混合社会中的社交互动，并为设计更有效和合作的混合系统提供了启示。


> Partner selection is crucial for cooperation and hinges on communication. As artificial agents, especially those powered by large language models (LLMs), become more autonomous, intelligent, and persuasive, they compete with humans for partnerships. Yet little is known about how humans select between human and AI partners and adapt under AI-induced competition pressure. We constructed a communication-based partner selection game and examined the dynamics in hybrid mini-societies of humans and bots powered by a state-of-the-art LLM. Through three experiments (N = 975), we found that bots, though more prosocial than humans and linguistically distinguishable, were not selected preferentially when their identity was hidden. Instead, humans misattributed bots' behaviour to humans and vice versa. Disclosing bots' identity induced a dual effect: it reduced bots' initial chances of being selected but allowed them to gradually outcompete humans by facilitating human learning about the behaviour of each partner type. These findings show how AI can reshape social interaction in mixed societies and inform the design of more effective and cooperative hybrid systems.

[Arxiv](https://arxiv.org/abs/2507.13524)