# GraphTrafficGPT：基于图的AI代理协作提升交通管理能力

发布时间：2025年07月17日

`LLM应用

LLM应用` `智能交通`

> GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination

# 摘要

> 大型语言模型（LLMs）为智能交通管理带来了革命性潜力，但现有链式系统如TrafficGPT存在任务串行执行、高资源消耗和扩展性差的局限性，难以应对复杂现实场景。为突破这些限制，我们提出了GraphTrafficGPT——一种创新的图结构框架，重新定义了LLM驱动交通应用的任务协调机制。该模型通过有向图将任务及其依赖关系可视化，实现高效并行处理和资源动态分配。其核心是"大脑代理"，能够智能拆解用户需求、构建优化依赖图谱，并调度专业代理团队协同完成数据处理、分析、可视化和模拟等任务。借助先进的上下文感知资源管理和多任务并行处理能力，GraphTrafficGPT完美适配现代城市交通的复杂需求。实验验证表明，与TrafficGPT相比，GraphTrafficGPT实现了50.2%的资源消耗降低，19.0%的响应速度提升，同时支持多任务并发，整体效率提升23.0%。

> Large Language Models (LLMs) offer significant promise for intelligent traffic management; however, current chain-based systems like TrafficGPT are hindered by sequential task execution, high token usage, and poor scalability, making them inefficient for complex, real-world scenarios. To address these limitations, we propose GraphTrafficGPT, a novel graph-based architecture, which fundamentally redesigns the task coordination process for LLM-driven traffic applications. GraphTrafficGPT represents tasks and their dependencies as nodes and edges in a directed graph, enabling efficient parallel execution and dynamic resource allocation. The main idea behind the proposed model is a Brain Agent that decomposes user queries, constructs optimized dependency graphs, and coordinates a network of specialized agents for data retrieval, analysis, visualization, and simulation. By introducing advanced context-aware token management and supporting concurrent multi-query processing, the proposed architecture handles interdependent tasks typical of modern urban mobility environments. Experimental results demonstrate that GraphTrafficGPT reduces token consumption by 50.2% and average response latency by 19.0% compared to TrafficGPT, while supporting simultaneous multi-query execution with up to 23.0% improvement in efficiency.

[Arxiv](https://arxiv.org/abs/2507.13511)