# TalentCLEF 2025 概述：技能与职位名称的智能解析，助力人才资本管理

发布时间：2025年07月17日

`LLM应用` `人力资源管理` `人才管理`

> Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management

# 摘要

> 自然语言处理和大型语言模型的进步正在推动人力资源管理领域的重大变革。越来越多的企业对基于语言技术的智能系统感兴趣，用于人才获取、技能提升策略和 workforce planning。然而，这些技术的采用和进展在很大程度上依赖于可靠和公平的模型的开发，这些模型需要在公共数据和开放基准上进行适当的评估，而到目前为止，这些在该领域还不可用。

  为了解决这一差距，我们介绍了TalentCLEF 2025，这是第一个专注于技能和职位智能的评估活动。该实验室包括两个任务：任务A - 多语言职位匹配，涵盖英语、西班牙语、德语和中文；任务B - 基于职位的技能预测，使用英语。两个语料库都是从真实的职位申请中构建的，经过仔细的匿名化处理，并进行了人工标注，以反映现实世界劳动力市场数据的复杂性和多样性，包括语言变体和性别标记的表达。

  评估包括单语和跨语言场景，并涵盖了对性别偏见的评估。

  TalentCLEF吸引了76个注册团队，提交了超过280次。大多数系统依赖于基于多语言编码器模型的信息检索技术，这些模型通过对比学习进行了微调，其中几个系统还集成了大型语言模型用于数据增强或重新排序。结果显示，训练策略的影响比模型大小本身更大。TalentCLEF提供了该领域的第一个公开基准，并鼓励开发强大、公平且可转移的语言技术，用于劳动力市场。

> Advances in natural language processing and large language models are driving a major transformation in Human Capital Management, with a growing interest in building smart systems based on language technologies for talent acquisition, upskilling strategies, and workforce planning. However, the adoption and progress of these technologies critically depend on the development of reliable and fair models, properly evaluated on public data and open benchmarks, which have so far been unavailable in this domain.
  To address this gap, we present TalentCLEF 2025, the first evaluation campaign focused on skill and job title intelligence. The lab consists of two tasks: Task A - Multilingual Job Title Matching, covering English, Spanish, German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English. Both corpora were built from real job applications, carefully anonymized, and manually annotated to reflect the complexity and diversity of real-world labor market data, including linguistic variability and gender-marked expressions.
  The evaluations included monolingual and cross-lingual scenarios and covered the evaluation of gender bias.
  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most systems relied on information retrieval techniques built with multilingual encoder-based models fine-tuned with contrastive learning, and several of them incorporated large language models for data augmentation or re-ranking. The results show that the training strategies have a larger effect than the size of the model alone. TalentCLEF provides the first public benchmark in this field and encourages the development of robust, fair, and transferable language technologies for the labor market.

[Arxiv](https://arxiv.org/abs/2507.13275)