# 融合大型语言模型与化学片段空间的协作框架：助力药物先导设计的相互启发

发布时间：2025年07月17日

`LLM应用` `药物设计`

> A Collaborative Framework Integrating Large Language Model and Chemical Fragment Space: Mutual Inspiration for Lead Design

# 摘要

> 在计算机辅助药物设计领域，组合优化算法通过系统性探索化学空间来设计与目标蛋白具有高亲和力的先导化合物，发挥着关键作用。然而，现有方法在整合领域知识方面存在固有挑战，这限制了它们在识别具有新颖且有效结合模式的先导化合物方面的性能。我们提出的AutoLeadDesign框架，巧妙地利用大型语言模型中编码的广泛领域知识（以化学片段为基础），实现了对广阔化学空间的高效探索。综合实验结果表明，AutoLeadDesign在性能上显著优于现有方法。特别是在针对两种临床相关靶点（PRMT5和SARS-CoV-2 PLpro）的实证先导设计案例中，AutoLeadDesign展示了其卓越的从头生成先导化合物的能力，其设计效果可与专家水平相媲美。结构分析进一步证实了这些化合物具有机制验证的抑制模式。通过追踪设计过程，我们发现AutoLeadDesign与传统的基于片段的药物设计具有相似的机制，这种设计传统上依赖专家决策，这进一步揭示了其成功的原因。总体而言，AutoLeadDesign为先导化合物设计提供了一种高效的方法，暗示了其在药物设计中的潜在应用价值。

> Combinatorial optimization algorithm is essential in computer-aided drug design by progressively exploring chemical space to design lead compounds with high affinity to target protein. However current methods face inherent challenges in integrating domain knowledge, limiting their performance in identifying lead compounds with novel and valid binding mode. Here, we propose AutoLeadDesign, a lead compounds design framework that inspires extensive domain knowledge encoded in large language models with chemical fragments to progressively implement efficient exploration of vast chemical space. The comprehensive experiments indicate that AutoLeadDesign outperforms baseline methods. Significantly, empirical lead design campaigns targeting two clinically relevant targets (PRMT5 and SARS-CoV-2 PLpro) demonstrate AutoLeadDesign's competence in de novo generation of lead compounds achieving expert-competitive design efficacy. Structural analysis further confirms their mechanism-validated inhibitory patterns. By tracing the process of design, we find that AutoLeadDesign shares analogous mechanisms with fragment-based drug design which traditionally rely on the expert decision-making, further revealing why it works. Overall, AutoLeadDesign offers an efficient approach for lead compounds design, suggesting its potential utility in drug design.

[Arxiv](https://arxiv.org/abs/2507.13580)