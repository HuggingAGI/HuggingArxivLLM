# 生成式能量竞技场（GEA）：将能量意识融入大型语言模型（LLM）的人类评估

发布时间：2025年07月17日

`LLM应用

理由：这篇论文探讨了大型语言模型的评估方法以及能源消耗对模型选择的影响，属于模型应用层面的研究。` `模型评估` `能源效率`

> The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations

# 摘要

> 大型语言模型的评估涉及多种方法，其中最常见的是通过自动化基准测试让模型回答多选题。然而，这种方法的局限性在于与人类的相关性较差。另一种方法是让人类直接评估模型，但随着模型数量的激增，这变得不切实际且昂贵。于是，公共平台如LM Arena应运而生，用户可自由评估模型并排名。如今，模型的能源消耗日益重要，因此我们提出了GEA（生成能量竞技场），一个在评估中纳入能源信息的平台。初步结果显示，当用户了解能源消耗时，更倾向于选择小型节能模型。这表明，复杂模型的额外成本和能源消耗未必能提升回答质量，从而不值得采用。

> The evaluation of large language models is a complex task, in which several approaches have been proposed. The most common is the use of automated benchmarks in which LLMs have to answer multiple-choice questions of different topics. However, this method has certain limitations, being the most concerning, the poor correlation with the humans. An alternative approach, is to have humans evaluate the LLMs. This poses scalability issues as there is a large and growing number of models to evaluate making it impractical (and costly) to run traditional studies based on recruiting a number of evaluators and having them rank the responses of the models. An alternative approach is the use of public arenas, such as the popular LM arena, on which any user can freely evaluate models on any question and rank the responses of two models. The results are then elaborated into a model ranking. An increasingly important aspect of LLMs is their energy consumption and, therefore, evaluating how energy awareness influences the decisions of humans in selecting a model is of interest. In this paper, we present GEA, the Generative Energy Arena, an arena that incorporates information on the energy consumption of the model in the evaluation process. Preliminary results obtained with GEA are also presented, showing that for most questions, when users are aware of the energy consumption, they favor smaller and more energy efficient models. This suggests that for most user interactions, the extra cost and energy incurred by the more complex and top-performing models do not provide an increase in the perceived quality of the responses that justifies their use.

[Arxiv](https://arxiv.org/abs/2507.13302)