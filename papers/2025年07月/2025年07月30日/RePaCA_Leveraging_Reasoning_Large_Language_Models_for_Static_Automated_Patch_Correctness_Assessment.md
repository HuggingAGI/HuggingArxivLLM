# RePaCA：借助推理型大型语言模型实现静态自动补丁正确性评估

发布时间：2025年07月30日

`LLM应用` `软件工程` `程序修复`

> RePaCA: Leveraging Reasoning Large Language Models for Static Automated Patch Correctness Assessment

# 摘要

> 自动程序修复（APR）旨在无需人工干预自动修正软件漏洞。然而，现有工具往往生成满足测试用例却未修复根本原因的补丁，这类补丁被称为过拟合补丁。为了解决这一问题，我们提出了自动补丁正确性评估（APCA），它通过静态方法分析代码差异，无需额外信息即可识别过拟合补丁。当前静态技术在可靠性、灵活性和透明度方面存在局限。为此，我们开发了RePaCA，这是一种基于大型语言模型（LLMs）的新型静态APCA技术，专门用于思考任务。我们的模型同时接收有缺陷和修复后的代码片段，生成一条推理链，分析代码差异，推断补丁如何解决根本原因，并最终进行二元分类：正确或过拟合。为了提升推理能力，我们使用带有组相对策略优化算法的强化学习对LLM进行微调。在标准的Defects4J测试中，我们的方法达到了83.1%的准确率和84.8%的F1值。此外，我们在不同数据集上的训练展示了更优的泛化能力，超越了现有领先技术。这种推理能力还为补丁评估提供了增强的可解释性。这些结果凸显了微调后具有推理能力的LLMs在提升静态APCA的准确性、泛化能力和可解释性方面的巨大潜力。

> Automated Program Repair (APR) seeks to automatically correct software bugs without requiring human intervention. However, existing tools tend to generate patches that satisfy test cases without fixing the underlying bug, those are known as overfitting patches. To address this issue, Automated Patch Correctness Assessment (APCA) attempts to identify overfitting patches generated by APR tools. It can be solved as a static approach, meaning that no additional information is needed beyond the original and fixed code snippets. Current static techniques often struggle with reliability, flexibility and transparency. To address these issues, we introduce RePaCA, a novel static APCA technique that leverages Large Language Models (LLMs) specialized in thinking tasks. Our model is prompted with both buggy and fixed code snippets and guided to generate a Chain of Thought that analyses code differences, reasons about how the patch addresses the root cause, and ultimately provides a binary classification: correct or overfitting. To enhance these reasoning capabilities for the APCA task specifically, the LLM is finetuned using Reinforcement Learning with the Group Relative Policy Optimization algorithm. When evaluated on a standard Defects4J-derived test, our approach achieves state-of-the-art performance, with 83.1% accuracy and an 84.8% F1-score. Furthermore, our model demonstrates superior generalization capabilities when trained on different datasets, outperforming the leading technique. This reasoning capability also provides enhanced explainability for the patch assessment. These findings underscore the considerable promise of finetuned, reasoning LLMs to advance static APCA by enhancing accuracy, generalization, and explainability.

[Arxiv](https://arxiv.org/abs/2507.22580)