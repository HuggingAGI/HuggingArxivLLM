# 什么是“抽象推理者”？重新审视大型语言模型的实验与论证

发布时间：2025年07月30日

`LLM理论` `人工智能`

> What is an "Abstract Reasoner"? Revisiting Experiments and Arguments about Large Language Models

# 摘要

> 最近有研究认为大型语言模型（LLMs）并不是“抽象推理者”，他们以LLMs在多种具有挑战性的任务上较差的零样本表现作为证据。我们重新审视这些实验，以更细致地探讨这一观点。首先，我们表明尽管LLMs确实在零样本设置下表现不佳，但即使是微调输入编码部分的一小部分参数，也能实现近乎完美的性能。然而，我们同时也表明这种微调并不一定能够跨数据集迁移。我们从这一系列实证结果出发，重新开启关于“抽象推理者”意味着什么，以及为什么LLMs是否符合这一标准至关重要的讨论。

> Recent work has argued that large language models (LLMs) are not "abstract reasoners", citing their poor zero-shot performance on a variety of challenging tasks as evidence. We revisit these experiments in order to add nuance to the claim. First, we show that while LLMs indeed perform poorly in a zero-shot setting, even tuning a small subset of parameters for input encoding can enable near-perfect performance. However, we also show that this finetuning does not necessarily transfer across datasets. We take this collection of empirical results as an invitation to (re-)open the discussion of what it means to be an "abstract reasoner", and why it matters whether LLMs fit the bill.

[Arxiv](https://arxiv.org/abs/2507.22457)