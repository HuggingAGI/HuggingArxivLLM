# # 多智能体大语言模型协作中的策略性沟通与语言偏见

发布时间：2025年07月30日

`Agent` `人工智能` `多智能体系统`

> Strategic Communication and Language Bias in Multi-Agent LLM Coordination

# 摘要

> 基于大型语言模型（LLM）的智能体在多智能体场景中广泛应用，这些场景中协调至关重要但并非始终有保障。先前研究表明，用于构建战略场景的语言可能会影响合作行为。本文探讨是否允许智能体进行沟通会放大这些由语言驱动的效果。我们借助FAIRGAME框架，模拟了不同语言和模型下的一次性和重复性游戏，分别考察有沟通和无沟通的情况。实验采用GPT-4o和Llama 4 Maverick两款先进LLM开展，结果表明沟通显著影响智能体行为，但其影响因语言、个性和游戏结构而异。这些发现凸显了沟通在促进协调与强化偏见中的双重作用。

> Large Language Model (LLM)-based agents are increasingly deployed in multi-agent scenarios where coordination is crucial but not always assured. Previous studies indicate that the language used to frame strategic scenarios can influence cooperative behavior. This paper explores whether allowing agents to communicate amplifies these language-driven effects. Leveraging the FAIRGAME framework, we simulate one-shot and repeated games across different languages and models, both with and without communication. Our experiments, conducted with two advanced LLMs, GPT-4o and Llama 4 Maverick, reveal that communication significantly influences agent behavior, though its impact varies by language, personality, and game structure. These findings underscore the dual role of communication in fostering coordination and reinforcing biases.

[Arxiv](https://arxiv.org/abs/2508.00032)