# 突破刚性AI：迈向自然的人机协作，助力术中智能辅助

发布时间：2025年07月30日

`Agent` `机器人`

> Beyond Rigid AI: Towards Natural Human-Machine Symbiosis for Interoperative Surgical Assistance

# 摘要

> 新兴的外科数据科学和机器人解决方案，特别是那些旨在提供现场协助的方案，需要自然的人机界面来释放其在提供自适应和直观辅助方面的潜力。当代AI驱动的解决方案本质上仍然 rigid，灵活性有限，并且限制了在动态外科环境中自然的人机交互。这些解决方案严重依赖于大量任务特定的预训练、固定的物体类别以及明确的手动提示。本研究介绍了一种新型感知代理，它结合了语音集成提示工程大型语言模型（LLMs）、任意分割模型（SAM）以及任意点跟踪基础模型，以实现实时术中辅助中的更自然人机交互。通过引入记忆库以及两种新型机制来分割未见元素，感知代理能够通过直观交互灵活地分割手术场景中的已知和未知元素。此外，该代理能够记住新元素以备未来手术使用，这标志着外科手术中人机共生迈出了重要一步。通过在公共数据集上的定量分析，我们展示了我们的代理性能与需要大量手动提示策略相当。定性分析中，我们在一个自定义整理的数据集中展示了代理在分割新元素（如器械、假体移植物和纱布）方面的灵活性。通过提供自然的人机交互并克服 rigidity，我们的感知代理有望将基于AI的实时动态手术环境辅助更接近现实。

> Emerging surgical data science and robotics solutions, especially those designed to provide assistance in situ, require natural human-machine interfaces to fully unlock their potential in providing adaptive and intuitive aid. Contemporary AI-driven solutions remain inherently rigid, offering limited flexibility and restricting natural human-machine interaction in dynamic surgical environments. These solutions rely heavily on extensive task-specific pre-training, fixed object categories, and explicit manual-prompting. This work introduces a novel Perception Agent that leverages speech-integrated prompt-engineered large language models (LLMs), segment anything model (SAM), and any-point tracking foundation models to enable a more natural human-machine interaction in real-time intraoperative surgical assistance. Incorporating a memory repository and two novel mechanisms for segmenting unseen elements, Perception Agent offers the flexibility to segment both known and unseen elements in the surgical scene through intuitive interaction. Incorporating the ability to memorize novel elements for use in future surgeries, this work takes a marked step towards human-machine symbiosis in surgical procedures. Through quantitative analysis on a public dataset, we show that the performance of our agent is on par with considerably more labor-intensive manual-prompting strategies. Qualitatively, we show the flexibility of our agent in segmenting novel elements (instruments, phantom grafts, and gauze) in a custom-curated dataset. By offering natural human-machine interaction and overcoming rigidity, our Perception Agent potentially brings AI-based real-time assistance in dynamic surgical environments closer to reality.

[Arxiv](https://arxiv.org/abs/2507.23088)