# # SAEL：智能合约漏洞检测的自适应专家混合大语言模型方案

发布时间：2025年07月30日

`LLM应用` `区块链安全` `智能合约漏洞检测`

> SAEL: Leveraging Large Language Models with Adaptive Mixture-of-Experts for Smart Contract Vulnerability Detection

# 摘要

> 随着区块链安全问题日益增多，智能合约漏洞检测已成为研究热点。现有漏洞检测方法各有局限性：静态分析方法在复杂场景下表现吃力，而基于专用预训练模型的方法虽然在特定数据集上表现出色，但泛化能力有限。相比之下，通用大型语言模型（LLMs）展现出引人注目的新漏洞模式适应能力，尽管在特定漏洞类型上不如专用模型，但它们生成的解释能够提供细致入微的代码理解信息，有助于提升检测性能。

> With the increasing security issues in blockchain, smart contract vulnerability detection has become a research focus. Existing vulnerability detection methods have their limitations: 1) Static analysis methods struggle with complex scenarios. 2) Methods based on specialized pre-trained models perform well on specific datasets but have limited generalization capabilities. In contrast, general-purpose Large Language Models (LLMs) demonstrate impressive ability in adapting to new vulnerability patterns. However, they often underperform on specific vulnerability types compared to methods based on specialized pre-trained models. We also observe that explanations generated by general-purpose LLMs can provide fine-grained code understanding information, contributing to improved detection performance.
  Inspired by these observations, we propose SAEL, an LLM-based framework for smart contract vulnerability detection. We first design targeted prompts to guide LLMs in identifying vulnerabilities and generating explanations, which serve as prediction features. Next, we apply prompt-tuning on CodeT5 and T5 to process contract code and explanations, enhancing task-specific performance. To combine the strengths of each approach, we introduce an Adaptive Mixture-of-Experts architecture. This dynamically adjusts feature weights via a Gating Network, which selects relevant features using TopK filtering and Softmax normalization, and incorporates a Multi-Head Self-Attention mechanism to enhance cross-feature relationships. This design enables effective integration of LLM predictions, explanation features, and code features through gradient optimization. The loss function jointly considers both independent feature performance and overall weighted predictions. Experiments show that SAEL outperforms existing methods across various vulnerabilities.

[Arxiv](https://arxiv.org/abs/2507.22371)