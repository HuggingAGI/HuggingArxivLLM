# # 摘要
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年07月03日

`LLM应用` `科学研究` `同行评审`

> Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers

# 摘要

> 同行评审是科学研究的基石，但海量出版物的激增给这一需要专业知识的过程带来了巨大挑战。尽管LLMs在科学任务中展现出巨大潜力，但其在协助同行评审，尤其是识别论文局限性方面的潜力仍未得到充分研究。我们提出了一个全面的科学局限性类型分类体系，重点聚焦于人工智能领域。基于此分类体系，我们推出了LimitGen，这是首个全面评估LLMs支持早期反馈并辅助人类同行评审能力的基准测试。我们的基准测试包含两个子集：LimitGen-Syn（一个通过精心设计的高质量论文可控扰动生成的合成数据集）和LimitGen-Human（一个真实人类编写的局限性集合）。为了提升LLM系统识别局限性的能力，我们引入了文献检索功能，这是将局限性识别植根于先前科学发现的必要手段。我们的方法显著增强了LLM系统生成研究论文局限性能力，使其能够提供更具建设性的反馈。


> Peer review is fundamental to scientific research, but the growing volume of publications has intensified the challenges of this expertise-intensive process. While LLMs show promise in various scientific tasks, their potential to assist with peer review, particularly in identifying paper limitations, remains understudied. We first present a comprehensive taxonomy of limitation types in scientific research, with a focus on AI. Guided by this taxonomy, for studying limitations, we present LimitGen, the first comprehensive benchmark for evaluating LLMs' capability to support early-stage feedback and complement human peer review. Our benchmark consists of two subsets: LimitGen-Syn, a synthetic dataset carefully created through controlled perturbations of high-quality papers, and LimitGen-Human, a collection of real human-written limitations. To improve the ability of LLM systems to identify limitations, we augment them with literature retrieval, which is essential for grounding identifying limitations in prior scientific findings. Our approach enhances the capabilities of LLM systems to generate limitations in research papers, enabling them to provide more concrete and constructive feedback.

[Arxiv](https://arxiv.org/abs/2507.02694)