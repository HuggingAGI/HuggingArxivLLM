# # **谁该道歉？用户偏好与大型语言模型聊天机器人中的机械式、共情式及解释性道歉**

发布时间：2025年07月03日

`LLM应用

摘要讨论了大型语言模型驱动的聊天机器人如何通过有效的道歉来修复错误，以维护用户信任和满意度。研究涉及用户对不同道歉类型的偏好，属于LLM在实际应用中的优化和策略设计，因此归类为LLM应用。` `人工智能` `人机交互`

> Who's Sorry Now: User Preferences Among Rote, Empathic, and Explanatory Apologies from LLM Chatbots

# 摘要

> 随着大型语言模型（LLMs）驱动的聊天机器人在日常场景中越来越普及，它们通过有效的道歉来修复错误的能力对于维护用户信任和满意度至关重要。在一项针对Prolific平台上的工作者（N=162）的预注册研究中，我们探讨了用户对三种类型道歉（程式化、解释性、共情性）的偏好，这些道歉是在回应三类常见的LLM错误（偏见、无根据的捏造、事实性错误）时发出的。我们设计了一个配对实验，参与者评估了聊天机器人的回应，这些回应包括一个初始错误、随后的道歉以及解决方案。总体而言，解释性道歉更受欢迎，但这一偏好因情境和用户而异。在偏见场景中，共情性道歉更受青睐，因为它们承认了情感影响；而对于幻觉（尽管被视为严重问题），并未出现明确的偏好，这反映了用户的不确定性。我们的研究结果揭示了AI系统中有效道歉的复杂性。我们讨论了未来系统必须应对的关键见解，如个性化和校准，以切实修复信任。

> As chatbots driven by large language models (LLMs) are increasingly deployed in everyday contexts, their ability to recover from errors through effective apologies is critical to maintaining user trust and satisfaction. In a preregistered study with Prolific workers (N=162), we examine user preferences for three types of apologies (rote, explanatory, and empathic) issued in response to three categories of common LLM mistakes (bias, unfounded fabrication, and factual errors). We designed a pairwise experiment in which participants evaluated chatbot responses consisting of an initial error, a subsequent apology, and a resolution. Explanatory apologies were generally preferred, but this varied by context and user. In the bias scenario, empathic apologies were favored for acknowledging emotional impact, while hallucinations, though seen as serious, elicited no clear preference, reflecting user uncertainty. Our findings show the complexity of effective apology in AI systems. We discuss key insights such as personalization and calibration that future systems must navigate to meaningfully repair trust.

[Arxiv](https://arxiv.org/abs/2507.02745)