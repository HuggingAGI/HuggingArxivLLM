# Coling-UniA 参与 SciVQA 2025：面向多模态大型语言模型的少样本示例检索与置信度驱动集成

发布时间：2025年07月03日

`LLM应用` `计算机视觉`

> Coling-UniA at SciVQA 2025: Few-Shot Example Retrieval and Confidence-Informed Ensembling for Multimodal Large Language Models

# 摘要

> 本文介绍了我们在 SciVQA 2025 科学视觉问答共享任务中的系统方案。该系统采用多模态大语言模型的集成架构，并结合多种少样本示例检索策略。模型选择及设置会根据图表类型和问题特点进行调整。此外，系统会根据模型的置信度评分来确定最终答案。在盲测评估中，我们的系统在七支参赛队伍中排名第三，ROUGE-1、ROUGE-L 和 BERTS 的平均 F1 得分为 85.12。我们的代码已开源发布。

> This paper describes our system for the SciVQA 2025 Shared Task on Scientific Visual Question Answering. Our system employs an ensemble of two Multimodal Large Language Models and various few-shot example retrieval strategies. The model and few-shot setting are selected based on the figure and question type. We also select answers based on the models' confidence levels. On the blind test data, our system ranks third out of seven with an average F1 score of 85.12 across ROUGE-1, ROUGE-L, and BERTS. Our code is publicly available.

[Arxiv](https://arxiv.org/abs/2507.02357)