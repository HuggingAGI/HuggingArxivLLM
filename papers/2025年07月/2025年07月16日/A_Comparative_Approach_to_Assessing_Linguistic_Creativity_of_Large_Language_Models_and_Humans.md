# 大型语言模型与人类语言创造力的对比研究

发布时间：2025年07月16日

`LLM应用` `测试评估`

> A Comparative Approach to Assessing Linguistic Creativity of Large Language Models and Humans

# 摘要

> 本文介绍了一项针对人类和大型语言模型（LLMs）的通用语言创造力测试。测试包含多种任务，旨在评估其根据词形变化（派生与合成）和隐喻性语言使用生成新词与短语的能力。我们对24名人类和同等数量的LLMs进行了测试，并使用OCSAI工具根据原创性、扩展性和灵活性三个标准自动评估了答案。结果显示，LLMs不仅在所有评估标准上超越人类，还在八项任务中的六项表现更优。计算个体答案独特性后发现，人类与LLMs之间存在细微差异。最后，通过简要手动分析数据集，我们发现人类更倾向于E（扩展）型创造力，而LLMs则偏好F（固定）型创造力。

> The following paper introduces a general linguistic creativity test for humans and Large Language Models (LLMs). The test consists of various tasks aimed at assessing their ability to generate new original words and phrases based on word formation processes (derivation and compounding) and on metaphorical language use. We administered the test to 24 humans and to an equal number of LLMs, and we automatically evaluated their answers using OCSAI tool for three criteria: Originality, Elaboration, and Flexibility. The results show that LLMs not only outperformed humans in all the assessed criteria, but did better in six out of the eight test tasks. We then computed the uniqueness of the individual answers, which showed some minor differences between humans and LLMs. Finally, we performed a short manual analysis of the dataset, which revealed that humans are more inclined towards E(extending)-creativity, while LLMs favor F(ixed)-creativity.

[Arxiv](https://arxiv.org/abs/2507.12039)