# 大型语言模型中的理解和说服之间只有一线之隔

发布时间：2025年07月02日

`LLM理论` `对话系统` `人工智能`

> The Thin Line Between Comprehension and Persuasion in LLMs

# 摘要

> 大型语言模型（LLMs）在对话领域堪称卓越，能够保持高水平且富有说服力的交流。它们正迅速被部署为聊天机器人和评估者，尤其在同行评审和心理健康应用等敏感领域。然而，关于其推理能力的不一致报告，使得对LLMs对话理解能力的深入研究变得尤为重要。

本研究首先评估了LLMs在维护辩论方面的能力——这是人类交流中最纯粹但也最复杂的沟通形式之一。我们进一步探讨了这种能力与其对对话内容理解之间的关系，即它们对对话结构和语用背景的掌握程度。研究发现，LLMs能够维持连贯且有说服力的辩论，常常改变参与者和观众的信念。然而，当测试其对对话深层结构的理解时，LLMs的表现却显得力不从心。

我们的研究结果揭示了LLMs作为评估者能力的局限性，这些局限性与其对上下文理解能力的不足密切相关。从更广泛的论证理论领域来看，我们提出：如果一个智能体能够令人信服地维持对话，那么它不必真正理解讨论的内容。因此，对语用背景和连贯性的建模并非实现有效性的首要任务。

> Large language models (LLMs) are excellent at maintaining high-level, convincing dialogues. They are being fast deployed as chatbots and evaluators in sensitive areas, such as peer review and mental health applications. This, along with the disparate accounts on their reasoning capabilities, calls for a closer examination of LLMs and their comprehension of dialogue. In this work we begin by evaluating LLMs' ability to maintain a debate--one of the purest yet most complex forms of human communication. Then we measure how this capability relates to their understanding of what is being talked about, namely, their comprehension of dialogical structures and the pragmatic context. We find that LLMs are capable of maintaining coherent, persuasive debates, often swaying the beliefs of participants and audiences alike. We also note that awareness or suspicion of AI involvement encourage people to be more critical of the arguments made. When polling LLMs on their comprehension of deeper structures of dialogue, however, they cannot demonstrate said understanding. Our findings tie the shortcomings of LLMs-as-evaluators to their (in)ability to understand the context. More broadly, for the field of argumentation theory we posit that, if an agent can convincingly maintain a dialogue, it is not necessary for it to know what it is talking about. Hence, the modelling of pragmatic context and coherence are secondary to effectiveness.

[Arxiv](https://arxiv.org/abs/2507.01936)