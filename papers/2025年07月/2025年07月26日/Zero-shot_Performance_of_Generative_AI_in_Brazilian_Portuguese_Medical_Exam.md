# 生成式AI在巴西葡萄牙语医学考试中的零样本性能表现

发布时间：2025年07月26日

`LLM应用` `人工智能`

> Zero-shot Performance of Generative AI in Brazilian Portuguese Medical Exam

# 摘要

> 人工智能 (AI) 正在通过提升诊断精准度、优化医疗流程和实现个性化治疗方案，为医疗行业带来革命性变革。大型语言模型 (LLMs) 和多模态大型语言模型 (MLLMs) 在自然语言处理和医疗领域取得了显著突破。然而，目前对这些模型的评估大多局限于英语环境，可能导致不同语言使用场景下的性能偏差。

    本研究评估了六种 LLMs（包括 GPT-4.0 Turbo、LLaMA-3-8B、LLaMA-3-70B 等）和四种 MLLMs（如 Claude-3.5-Sonnet 和 Claude-3-Opus）在解答巴西葡萄牙语医学考试问题时的表现，这些试题来自南美洲最大的医疗综合体 —— 圣保罗大学医学院临床医院 (HCFMUSP) 的 residency 入学考试。研究通过准确性、响应速度和解释连贯性三个维度，将模型表现与人类考生进行了对比分析。

    研究结果显示，Claude-3.5-Sonnet 和 Claude-3-Opus 等模型在准确性上已接近人类水平，但在需要图像解读的多模态问题上仍存在明显差距。此外，本研究揭示了语言使用中的显著差异，凸显了对非英语医疗 AI 应用进行针对性优化和数据增强的迫切需求。

    本研究结果强调，在不同语言环境和临床场景中对生成式 AI 进行全面评估至关重要，以确保其在医疗领域得到公平可靠的运用。未来研究方向应包括优化训练方法、提升多模态推理能力，以及推动 AI 在真实医疗场景中的实际应用。

> Artificial intelligence (AI) has shown the potential to revolutionize healthcare by improving diagnostic accuracy, optimizing workflows, and personalizing treatment plans. Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) have achieved notable advancements in natural language processing and medical applications. However, the evaluation of these models has focused predominantly on the English language, leading to potential biases in their performance across different languages.
  This study investigates the capability of six LLMs (GPT-4.0 Turbo, LLaMA-3-8B, LLaMA-3-70B, Mixtral 8x7B Instruct, Titan Text G1-Express, and Command R+) and four MLLMs (Claude-3.5-Sonnet, Claude-3-Opus, Claude-3-Sonnet, and Claude-3-Haiku) to answer questions written in Brazilian spoken portuguese from the medical residency entrance exam of the Hospital das Clínicas da Faculdade de Medicina da Universidade de São Paulo (HCFMUSP) - the largest health complex in South America. The performance of the models was benchmarked against human candidates, analyzing accuracy, processing time, and coherence of the generated explanations.
  The results show that while some models, particularly Claude-3.5-Sonnet and Claude-3-Opus, achieved accuracy levels comparable to human candidates, performance gaps persist, particularly in multimodal questions requiring image interpretation. Furthermore, the study highlights language disparities, emphasizing the need for further fine-tuning and data set augmentation for non-English medical AI applications.
  Our findings reinforce the importance of evaluating generative AI in various linguistic and clinical settings to ensure a fair and reliable deployment in healthcare. Future research should explore improved training methodologies, improved multimodal reasoning, and real-world clinical integration of AI-driven medical assistance.

[Arxiv](https://arxiv.org/abs/2507.19885)