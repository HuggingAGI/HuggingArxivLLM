# OpenFActScore: 基于开源的文本生成事实性原子级评估

发布时间：2025年07月08日

`LLM应用` `开源技术`

> OpenFActScore: Open-Source Atomic Evaluation of Factuality in Text Generation

# 摘要

> 我们很高兴推出 OpenFActScore，这是一个开源的 FActScore 框架实现，用于评估大语言模型生成文本的事实准确性。FActScore 通过原子事实生成（AFG）提取个体事实声明，并利用原子事实验证（AFV）将这些声明与可信知识库进行比对，从而评估长文本的事实准确性。与依赖闭源商业模型（如 InstructGPT 和 ChatGPT）的原始 FActScore 不同，OpenFActScore 支持使用任何与 Hugging Face 兼容的模型进行 AFG 和 AFV。我们详细介绍了实现的技术细节，重点突出了支持开源模型的设计决策和优化。通过在原始 FActScore 基准上评估多个开源 LLM 的 AFG 和 AFV 性能，我们报告了 AFG 的 BERTScore-F1 和 AFV 的人工标注相对错误率。实验结果显示，开源模型能够逼近闭源系统的性能表现，其中 Gemma 表现最为出色，我们的最终方案与原始 FActScore 实验实现了 0.99 的皮尔逊相关性。OpenFActScore 不仅提升了评估的透明度和可重复性，还降低了成本，现可在 GitHub 上获取：https://github.com/lflage/OpenFActScore。


> We introduce OpenFActScore, an open-source implementation of the FActScore framework for evaluating the factuality of text generated by large language models (LLMs). FActScore evaluates the factual accuracy of long-form text by using Atomic Fact Generation (AFG) to extract individual factual claims and Atomic Fact Validation (AFV) to verify each claim against a trusted knowledge source. While the original FActScore relies on closed-source and commercial models such as InstructGPT and ChatGPT, OpenFActScore enables the use of any Hugging Face-compatible model for both AFG and AFV. We provide a detailed technical overview of our implementation, highlighting design choices and modifications made to support open models. We evaluate multiple open-source LLMs on both AFG and AFV using the original FActScore benchmark, reporting BERTScore-F1 for AFG and Error Rate relative to human annotations for AFV. Our results show that open models can approximate the performance of closed-source systems, with Gemma achieving the best overall performance, and our final setup obtains a 0.99 Pearson correlation with the original FActScore experiments. OpenFActScore promotes transparency, reproducibility, and cost-effective evaluation, and is available at: https://github.com/lflage/OpenFActScore.

[Arxiv](https://arxiv.org/abs/2507.05965)