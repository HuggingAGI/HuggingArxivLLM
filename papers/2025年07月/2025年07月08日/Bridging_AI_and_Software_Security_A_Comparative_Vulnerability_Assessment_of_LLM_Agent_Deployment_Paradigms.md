# 连接AI与软件安全：LLM代理部署范式的漏洞比较评估

发布时间：2025年07月08日

`LLM理论` `AI安全` `系统安全`

> Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms

# 摘要

> 大型语言模型（LLM）代理的安全性横跨AI特有和传统软件领域，但现有研究往往割裂二者进行应对。本研究通过统一威胁分类框架，对比评估了函数调用架构与模型上下文协议（MCP）的部署范式，填补了这一研究空白。我们针对七种语言模型测试了3,250种攻击场景，评估了简单攻击、组合攻击和链式攻击对AI特有威胁（提示注入）和软件漏洞（JSON注入、服务拒绝）的攻击效果。结果显示，函数调用架构的整体攻击成功率（73.5%）高于MCP（62.59%），且系统层面的脆弱性更显著；而MCP在LLM层面的暴露程度更高。攻击复杂度的提升显著增强了攻击效果，链式攻击的成功率更是达到了91-96%。令人意外的是，尽管先进推理模型具备更强的威胁检测能力，但其可被利用性反而更高。研究结果表明，架构选择从根本上重塑了威胁格局。本研究为跨域LLM代理安全评估奠定了方法论基础，并为安全部署提供了基于证据的指导。代码与实验材料可在https://github.com/theconsciouslab-ai/llm-agent-security获取。

> Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately. This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework. We tested 3,250 attack scenarios across seven language models, evaluating simple, composed, and chained attacks targeting both AI-specific threats (prompt injection) and software vulnerabilities (JSON injection, denial-of-service). Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates. Counterintuitively, advanced reasoning models demonstrated higher exploitability despite better threat detection. Results demonstrate that architectural choices fundamentally reshape threat landscapes. This work establishes methodological foundations for cross-domain LLM agent security assessment and provides evidence-based guidance for secure deployment. Code and experimental materials are available at https: // github. com/ theconsciouslab-ai/llm-agent-security.

[Arxiv](https://arxiv.org/abs/2507.06323)