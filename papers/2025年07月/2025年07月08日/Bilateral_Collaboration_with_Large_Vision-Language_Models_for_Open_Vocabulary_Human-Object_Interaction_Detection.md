# 基于大型视觉-语言模型的开放词汇人-物交互检测的双向协作研究

发布时间：2025年07月08日

`LLM应用` `计算机视觉` `人与物互动检测`

> Bilateral Collaboration with Large Vision-Language Models for Open Vocabulary Human-Object Interaction Detection

# 摘要

> 开放词汇人与物互动检测（HOI）是一项极具挑战性的任务，旨在从图像中检测所有感兴趣的人、动词、物体三元组，包括训练集中未预先定义的。现有方法依赖大型视觉语言模型（VLMs）生成特征来增强交互表示的泛化能力，但VLMs生成的视觉特征整体性过强且粒度较粗，与检测任务的本质相悖。

为解决这一问题，我们提出了一种全新的开放词汇HOI检测双边协作框架（BC-HOI）。该框架包含两个核心组件：注意力偏置引导（ABG）和基于LLM的监督引导（LSG）。ABG组件通过HOI检测器提供的注意力偏置，引导VLM生成细粒度的实例级交互特征。LSG组件则利用VLM的LLM部分为HOI检测器提供细粒度的词级监督，进一步提升ABG生成高质量注意力偏置的能力。

我们在HICO-DET和V-COCO两个主流数据集上进行了全面实验，结果表明BC-HOI在开放词汇和封闭设置下均取得了优异性能。相关代码将在Github上开源发布。

> Open vocabulary Human-Object Interaction (HOI) detection is a challenging task that detects all <human, verb, object> triplets of interest in an image, even those that are not pre-defined in the training set. Existing approaches typically rely on output features generated by large Vision-Language Models (VLMs) to enhance the generalization ability of interaction representations. However, the visual features produced by VLMs are holistic and coarse-grained, which contradicts the nature of detection tasks. To address this issue, we propose a novel Bilateral Collaboration framework for open vocabulary HOI detection (BC-HOI). This framework includes an Attention Bias Guidance (ABG) component, which guides the VLM to produce fine-grained instance-level interaction features according to the attention bias provided by the HOI detector. It also includes a Large Language Model (LLM)-based Supervision Guidance (LSG) component, which provides fine-grained token-level supervision for the HOI detector by the LLM component of the VLM. LSG enhances the ability of ABG to generate high-quality attention bias. We conduct extensive experiments on two popular benchmarks: HICO-DET and V-COCO, consistently achieving superior performance in the open vocabulary and closed settings. The code will be released in Github.

[Arxiv](https://arxiv.org/abs/2507.06510)