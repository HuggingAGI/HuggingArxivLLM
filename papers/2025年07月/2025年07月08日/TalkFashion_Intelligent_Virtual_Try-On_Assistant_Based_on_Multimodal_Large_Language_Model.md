# TalkFashion：基于多模态大型语言模型的智能虚拟试穿助手

发布时间：2025年07月08日

`LLM应用` `人工智能`

> TalkFashion: Intelligent Virtual Try-On Assistant Based on Multimodal Large Language Model

# 摘要

> 虚拟试穿技术近年来取得了长足进步。本文探讨了如何仅通过文本指令实现多功能虚拟试穿，包括全身换装和局部编辑。以往的方法主要依赖端到端网络执行单一试穿任务，缺乏多样性和灵活性。我们提出了TalkFashion，一个智能试穿助手，它借助大型语言模型强大的理解能力来分析用户指令，确定执行的任务，并相应地激活不同的处理流程。此外，我们引入了一个基于指令的局部重绘模型，无需用户手动提供遮罩。借助多模态模型，该方法实现了全自动化局部编辑，显著提升了编辑任务的灵活性。实验结果表明，与现有方法相比，我们的方法在语义一致性和视觉质量上均有显著提升。

> Virtual try-on has made significant progress in recent years. This paper addresses how to achieve multifunctional virtual try-on guided solely by text instructions, including full outfit change and local editing. Previous methods primarily relied on end-to-end networks to perform single try-on tasks, lacking versatility and flexibility. We propose TalkFashion, an intelligent try-on assistant that leverages the powerful comprehension capabilities of large language models to analyze user instructions and determine which task to execute, thereby activating different processing pipelines accordingly. Additionally, we introduce an instruction-based local repainting model that eliminates the need for users to manually provide masks. With the help of multi-modal models, this approach achieves fully automated local editings, enhancing the flexibility of editing tasks. The experimental results demonstrate better semantic consistency and visual quality compared to the current methods.

[Arxiv](https://arxiv.org/abs/2507.05790)