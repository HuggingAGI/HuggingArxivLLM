# 基于虚拟应试者与特质-反应中介变量的心理测量项目验证

发布时间：2025年07月08日

`LLM应用` `心理测量学` `人工智能`

> Psychometric Item Validation Using Virtual Respondents with Trait-Response Mediators

# 摘要

> 随着心理测量调查在评估大型语言模型（LLMs）特质中的应用日益广泛，生成适合LLMs的可扩展调查项目的需求也随之增长。然而，一个关键挑战在于确保生成项目的构建效度，即它们是否真正测量了目标特质。传统方法需要高成本的大规模人类数据收集，而我们提出了一种基于LLMs的虚拟受访者模拟框架，以提高效率。我们的核心理念是考虑中介因素：同一特质如何通过不同中介因素导致对同一调查项目的不同回答。通过模拟具有不同中介因素的受访者，我们能够识别出能够可靠测量目标特质的调查项目。在三种心理特质理论（Big5、Schwartz、VIA）上的实验表明，我们的中介因素生成方法和模拟框架能够有效识别出高构建效度的项目。LLMs不仅能够从特质定义中生成合理中介因素，还能通过模拟受访者行为来验证调查项目。我们提出的问题设定、指标、方法和数据集为低成本的调查开发开辟了新方向，并加深了对LLMs如何模拟人类行为的理解。为了支持未来的研究工作，我们将公开发布我们的数据集和代码。

> As psychometric surveys are increasingly used to assess the traits of large language models (LLMs), the need for scalable survey item generation suited for LLMs has also grown. A critical challenge here is ensuring the construct validity of generated items, i.e., whether they truly measure the intended trait. Traditionally, this requires costly, large-scale human data collection. To make it efficient, we present a framework for virtual respondent simulation using LLMs. Our central idea is to account for mediators: factors through which the same trait can give rise to varying responses to a survey item. By simulating respondents with diverse mediators, we identify survey items that robustly measure intended traits. Experiments on three psychological trait theories (Big5, Schwartz, VIA) show that our mediator generation methods and simulation framework effectively identify high-validity items. LLMs demonstrate the ability to generate plausible mediators from trait definitions and to simulate respondent behavior for item validation. Our problem formulation, metrics, methodology, and dataset open a new direction for cost-effective survey development and a deeper understanding of how LLMs replicate human-like behavior. We will publicly release our dataset and code to support future work.

[Arxiv](https://arxiv.org/abs/2507.05890)