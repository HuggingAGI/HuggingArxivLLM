# 大型语言模型预测人类福祉——但预测能力并非全球均等

发布时间：2025年07月08日

`LLM应用` `政策决策`

> Large Language Models Predict Human Well-being -- But Not Equally Everywhere

# 摘要

> 主观幸福感是经济、医疗和政策决策中的关键指标。随着人工智能为建模人类结果提供了可扩展的工具，评估大型语言模型（LLMs）是否能够准确预测全球不同人群的幸福感变得至关重要。我们使用来自64个国家64,000名个体的数据评估了四个领先的LLMs。虽然LLMs能够捕捉收入和健康等广泛的相关因素，但其预测准确性在训练数据中代表性不足的国家中下降，凸显了根植于全球数字和经济不平等的系统性偏见。一项预注册实验表明，LLMs依赖表面语言相似性而非概念理解，导致在不熟悉或资源有限的环境中系统性低估。注入来自代表性不足背景的发现显著提升了性能，但仍存在显著差距。这些结果凸显了LLMs在预测全球幸福感方面的潜力与局限，强调了在这些领域实施前进行稳健验证的重要性。

> Subjective well-being is a key metric in economic, medical, and policy decision-making. As artificial intelligence provides scalable tools for modelling human outcomes, it is crucial to evaluate whether large language models (LLMs) can accurately predict well-being across diverse global populations. We evaluate four leading LLMs using data from 64,000 individuals in 64 countries. While LLMs capture broad correlates such as income and health, their predictive accuracy decreases in countries underrepresented in the training data, highlighting systematic biases rooted in global digital and economic inequality. A pre-registered experiment demonstrates that LLMs rely on surface-level linguistic similarity rather than conceptual understanding, leading to systematic misestimations in unfamiliar or resource-limited settings. Injecting findings from underrepresented contexts substantially enhances performance, but a significant gap remains. These results highlight both the promise and limitations of LLMs in predicting global well-being, underscoring the importance of robust validation prior to their implementation across these areas.

[Arxiv](https://arxiv.org/abs/2507.06141)