# 安全博弈（SecTOW）：强化学习驱动的多模态模型安全迭代攻防训练

发布时间：2025年07月29日

`LLM应用` `人工智能`

> Secure Tug-of-War (SecTOW): Iterative Defense-Attack Training with Reinforcement Learning for Multimodal Model Security

# 摘要

> 多模态大型语言模型（MLLMs）的快速发展推动了各类应用的突破，但其安全性仍是一个关键挑战。一个亟待解决的问题是不安全的图像-查询对——这些特制的越狱输入旨在绕过安全限制，诱导MLLMs产生非预期的响应。与一般多模态数据相比，此类不安全输入相对稀少，这限制了可用于开发稳健防御模型的训练样本的多样性和丰富性。

与此同时，现有的护栏型方法依赖于外部模块来强制执行安全约束，但未能解决MLLMs内部的固有漏洞。传统的监督微调（SFT）常常过度拒绝无害输入，从而损害整体性能。鉴于这些挑战，我们提出了安全拉锯战（SecTOW），这是一种创新的迭代防御-攻击训练方法，旨在提升MLLMs的安全性。

SecTOW包含两个模块：一个防御者和一个辅助攻击者，两者均通过强化学习（GRPO）进行迭代训练。在迭代过程中，攻击者识别防御模型中的安全漏洞并扩展越狱数据。扩展后的数据随后用于训练防御者，使其能够解决已识别的安全漏洞。我们还设计了用于GRPO的奖励机制，以简化对响应标签的使用，减少对复杂生成标签的依赖，并实现合成数据的高效利用。

此外，采用质量监控机制以缓解防御者对无害输入的过度拒绝，并确保攻击者生成的越狱数据的多样性。在安全专用和通用基准上的实验结果表明，SecTOW显著提升了安全性，同时保持了整体性能。

> The rapid advancement of multimodal large language models (MLLMs) has led to breakthroughs in various applications, yet their security remains a critical challenge. One pressing issue involves unsafe image-query pairs--jailbreak inputs specifically designed to bypass security constraints and elicit unintended responses from MLLMs. Compared to general multimodal data, such unsafe inputs are relatively sparse, which limits the diversity and richness of training samples available for developing robust defense models. Meanwhile, existing guardrail-type methods rely on external modules to enforce security constraints but fail to address intrinsic vulnerabilities within MLLMs. Traditional supervised fine-tuning (SFT), on the other hand, often over-refuses harmless inputs, compromising general performance. Given these challenges, we propose Secure Tug-of-War (SecTOW), an innovative iterative defense-attack training method to enhance the security of MLLMs. SecTOW consists of two modules: a defender and an auxiliary attacker, both trained iteratively using reinforcement learning (GRPO). During the iterative process, the attacker identifies security vulnerabilities in the defense model and expands jailbreak data. The expanded data are then used to train the defender, enabling it to address identified security vulnerabilities. We also design reward mechanisms used for GRPO to simplify the use of response labels, reducing dependence on complex generative labels and enabling the efficient use of synthetic data. Additionally, a quality monitoring mechanism is used to mitigate the defender's over-refusal of harmless inputs and ensure the diversity of the jailbreak data generated by the attacker. Experimental results on safety-specific and general benchmarks demonstrate that SecTOW significantly improves security while preserving general performance.

[Arxiv](https://arxiv.org/abs/2507.22037)