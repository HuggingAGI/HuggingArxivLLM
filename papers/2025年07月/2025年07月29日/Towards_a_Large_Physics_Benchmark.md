# #迈向大规模物理基准测试

发布时间：2025年07月29日

`LLM应用

理由：这篇论文主要讨论了大型语言模型在基础物理学领域的应用，特别是通过设计基准框架来评估和监控这些模型的表现。虽然没有直接涉及模型的理论发展，但其核心在于将LLM应用于科学领域，特别是物理学，因此归类为LLM应用。` `物理学` `科学评估`

> Towards a Large Physics Benchmark

# 摘要

> 我们推出一个专为科学界打造的基准框架，旨在评估、监控并指导大型语言模型在基础物理学领域的研发。基于科学理解和创造力的核心理念，我们设计了一套评分体系，每道题目均由专家从正确性、难度和新颖性三个维度进行评估。问题类型分为三类：(i) 概念理解的选择题，(ii) 需要数学推导的分析题，(iii) 需要综合解决能力的开放性任务。我们的数据集涵盖了丰富的案例，包括一个用于分类高能物理事件的机器学习挑战，例如四个顶夸克信号的识别。为了保持与时俱进，我们倡议建立一个动态更新的基准平台，鼓励物理学家在发表新成果时贡献问题。欢迎通过以下链接参与：http://www.physicsbenchmarks.org/。我们期待这个基准能够推动AI技术的定向发展，为基础物理研究注入新的活力。

> We introduce a benchmark framework developed by and for the scientific community to evaluate, monitor and steer large language model development in fundamental physics. Building on philosophical concepts of scientific understanding and creativity, we develop a scoring system in which each question is scored by an expert for its correctness, difficulty, and surprise. The questions are of three forms: (i) multiple-choice questions for conceptual understanding, (ii) analytical problems requiring mathematical derivation, and (iii) openended tasks requiring complex problem solving. Our current dataset contains diverse set of examples, including a machine learning challenge to classify high-energy physics events, such as the four top quark signal. To ensure continued relevance, we propose a living benchmark, where physicists contribute questions, for instance alongside new publications. We invite contributions via: http://www.physicsbenchmarks.org/. We hope that this benchmark will enable a targeted AI development that can make a meaningful contribution to fundamental physics research.

[Arxiv](https://arxiv.org/abs/2507.21695)