# HRIPBench：评估大型语言模型在减害信息提供中的能力，支持药物使用者

发布时间：2025年07月29日

`LLM应用` `公共卫生`

> HRIPBench: Benchmarking LLMs in Harm Reduction Information Provision to Support People Who Use Drugs

# 摘要

> 物质滥用带来的危害正影响着数百万人的福祉。作为一项公共卫生策略，减害措施旨在改善健康结果并降低安全风险。一些大型语言模型（LLMs）展现出了相当程度的医学知识，有望满足药物使用者（PWUD）的信息需求。然而，这些模型在相关任务中的表现仍待进一步探索。我们引入了HRIPBench，一个用于评估LLM在减害信息提供方面的准确性和安全风险的基准测试。该基准数据集HRIP-Basic包含2160个问题-答案-证据三元组，涵盖三个任务：检查安全边界、提供定量值以及推断多物质使用风险。我们构建了Instruction和RAG方案，分别基于模型的内在知识和领域知识的整合来评估模型行为。研究结果表明，目前最先进的LLMs在提供准确的减害信息方面仍面临挑战，有时甚至会对PWUD造成严重的安全风险。在减害场景下使用LLMs应谨慎受限，以避免诱发负面健康结果。注意：本文包含可能引发危害的非法内容。

> Millions of individuals' well-being are challenged by the harms of substance use. Harm reduction as a public health strategy is designed to improve their health outcomes and reduce safety risks. Some large language models (LLMs) have demonstrated a decent level of medical knowledge, promising to address the information needs of people who use drugs (PWUD). However, their performance in relevant tasks remains largely unexplored. We introduce HRIPBench, a benchmark designed to evaluate LLM's accuracy and safety risks in harm reduction information provision. The benchmark dataset HRIP-Basic has 2,160 question-answer-evidence pairs. The scope covers three tasks: checking safety boundaries, providing quantitative values, and inferring polysubstance use risks. We build the Instruction and RAG schemes to evaluate model behaviours based on their inherent knowledge and the integration of domain knowledge. Our results indicate that state-of-the-art LLMs still struggle to provide accurate harm reduction information, and sometimes, carry out severe safety risks to PWUD. The use of LLMs in harm reduction contexts should be cautiously constrained to avoid inducing negative health outcomes. WARNING: This paper contains illicit content that potentially induces harms.

[Arxiv](https://arxiv.org/abs/2507.21815)