# # 评价与基准测试
大型语言模型（LLM）代理的评估与基准测试：综述

发布时间：2025年07月29日

`LLM应用` `评估方法` `企业应用`

> Evaluation and Benchmarking of LLM Agents: A Survey

# 摘要

> LLM驱动的智能体正在重新定义AI应用的边界，但如何有效评估这些智能体仍是一个充满挑战且尚未成熟的领域。本文全面概述了新兴的LLM智能体评估领域，提出了一个二维分类法，分别从评估目标（如智能体行为、能力、可靠性和安全性）和评估过程（包括交互模式、数据集、基准、指标计算方法及工具）两个维度，对现有研究工作进行了系统性梳理。除了这一分类框架，我们还特别关注了企业环境中特有的挑战，例如基于角色的数据访问权限、对可靠性保证的需求、动态且长期的交互需求以及合规性要求，这些方面往往在现有研究中被忽视。此外，我们还指出了未来研究的几个重要方向，包括构建更全面、更贴近实际、更具可扩展性的评估体系。本文旨在为当前零散的智能体评估领域提供清晰的框架，帮助研究人员和从业者系统化地评估LLM智能体，从而推动其在实际场景中的落地应用。

> The rise of LLM-based agents has opened new frontiers in AI applications, yet evaluating these agents remains a complex and underdeveloped area. This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (2) evaluation process -- how to evaluate, including interaction modes, datasets and benchmarks, metric computation methods, and tooling. In addition to taxonomy, we highlight enterprise-specific challenges, such as role-based access to data, the need for reliability guarantees, dynamic and long-horizon interactions, and compliance, which are often overlooked in current research. We also identify future research directions, including holistic, more realistic, and scalable evaluation. This work aims to bring clarity to the fragmented landscape of agent evaluation and provide a framework for systematic assessment, enabling researchers and practitioners to evaluate LLM agents for real-world deployment.

[Arxiv](https://arxiv.org/abs/2507.21504)