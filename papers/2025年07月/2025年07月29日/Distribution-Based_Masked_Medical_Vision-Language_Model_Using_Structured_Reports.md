# 基于分布的医学视觉-语言模型，利用结构化报告进行掩码处理

发布时间：2025年07月29日

`LLM应用` `跨模态学习`

> Distribution-Based Masked Medical Vision-Language Model Using Structured Reports

# 摘要

> 医学图像-语言预训练旨在将医学图像与临床文本精准对齐，以提升模型在下游任务中的表现。然而，现有模型在应对医学数据的变异性与模糊性时仍显不足，限制了其捕捉临床细节和不确定性的能力。本研究提出了一种感知不确定性的医学图像-文本预训练模型，致力于增强医学图像分析的泛化能力。基于先前方法并聚焦于胸部X光片，我们采用大型语言模型生成的结构化文本报告，为图像数据注入临床背景。这些报告从疾病定义入手，通过`外观'部分突出关键区域，再经`观察'和`结论'部分将模型预测与临床语义紧密结合。通过建模跨模态与单模态的不确定性，我们的框架有效捕捉医学图像与文本中的固有模糊性，从而优化表示并提升下游任务表现。我们的模型在医学图像-语言预训练领域取得了显著突破，在多个下游任务中达到了当前最优水平。

> Medical image-language pre-training aims to align medical images with clinically relevant text to improve model performance on various downstream tasks. However, existing models often struggle with the variability and ambiguity inherent in medical data, limiting their ability to capture nuanced clinical information and uncertainty. This work introduces an uncertainty-aware medical image-text pre-training model that enhances generalization capabilities in medical image analysis. Building on previous methods and focusing on Chest X-Rays, our approach utilizes structured text reports generated by a large language model (LLM) to augment image data with clinically relevant context. These reports begin with a definition of the disease, followed by the `appearance' section to highlight critical regions of interest, and finally `observations' and `verdicts' that ground model predictions in clinical semantics. By modeling both inter- and intra-modal uncertainty, our framework captures the inherent ambiguity in medical images and text, yielding improved representations and performance on downstream tasks. Our model demonstrates significant advances in medical image-text pre-training, obtaining state-of-the-art performance on multiple downstream tasks.

[Arxiv](https://arxiv.org/abs/2507.21794)