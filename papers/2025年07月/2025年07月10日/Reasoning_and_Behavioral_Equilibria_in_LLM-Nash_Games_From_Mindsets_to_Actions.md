# 大语言模型纳什博弈中的推理与行为均衡分析：从思维模式到实际行动

发布时间：2025年07月10日

`Agent` `人工智能` `博弈论`

> Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions

# 摘要

> 我们提出了一个开创性的 LLM-Nash 框架，这是一个基于博弈论的模型，通过大型语言模型（LLMs）实现智能体间的推理引导决策。与传统博弈论假设智能体具备完全理性和效用最大化不同，LLM-Nash 框架通过显式建模推理过程，成功捕捉到现实中的有限理性特征。在该框架中，平衡状态定义于提示空间，而行动则表现为 LLM 推理的行为输出。这一创新方法为我们研究认知限制、思维表达能力以及知识获取提供了有力工具。通过具体案例分析，我们发现推理均衡往往偏离传统纳什均衡的结果，这为 LLM 驱动系统中的战略互动奠定了全新的理论基础。

> We introduce the LLM-Nash framework, a game-theoretic model where agents select reasoning prompts to guide decision-making via Large Language Models (LLMs). Unlike classical games that assume utility-maximizing agents with full rationality, this framework captures bounded rationality by modeling the reasoning process explicitly. Equilibrium is defined over the prompt space, with actions emerging as the behavioral output of LLM inference. This approach enables the study of cognitive constraints, mindset expressiveness, and epistemic learning. Through illustrative examples, we show how reasoning equilibria can diverge from classical Nash outcomes, offering a new foundation for strategic interaction in LLM-enabled systems.

[Arxiv](https://arxiv.org/abs/2507.08208)