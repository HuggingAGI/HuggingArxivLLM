# 提升水下任务中的共享与多智能体自主性：结合知识图谱与检索增强生成

发布时间：2025年07月27日

`LLM应用` `机器人`

> Advancing Shared and Multi-Agent Autonomy in Underwater Missions: Integrating Knowledge Graphs and Retrieval-Augmented Generation

# 摘要

> 机器人平台已成为海洋作业中不可或缺的工具，为水下基础设施检查、环境监测和资源勘探等海上资产提供了定期访问和持续监控。然而，水下环境的复杂性和动态性，如有限的能见度、不可预测的水流和通信限制，带来了巨大挑战。这些挑战要求机器人具备高级自主性，同时确保操作员的信任和监督。应对这些挑战的核心是知识表示和推理技术，特别是知识图谱和增强检索生成（RAG）系统，这些技术使机器人能够高效地结构化、检索和解释复杂的环境数据。这些能力使机器人能够推理、适应并有效应对不断变化的条件。本研究的主要目标是展示多机器人自主性和共享自主性，其中多个机器人代理在保持与人类监督员连接的同时独立运行。我们展示了如何通过知识图谱数据和领域分类学增强的RAG驱动大型语言模型，实现自主的多机器人决策制定，并促进无缝的人机交互，从而实现100%的任务验证和行为完整性。最后，消融研究表明，如果没有来自图谱和/或分类学的结构化知识，LLM容易产生幻觉，从而可能损害决策质量。

> Robotic platforms have become essential for marine operations by providing regular and continuous access to offshore assets, such as underwater infrastructure inspection, environmental monitoring, and resource exploration. However, the complex and dynamic nature of underwater environments, characterized by limited visibility, unpredictable currents, and communication constraints, presents significant challenges that demand advanced autonomy while ensuring operator trust and oversight. Central to addressing these challenges are knowledge representation and reasoning techniques, particularly knowledge graphs and retrieval-augmented generation (RAG) systems, that enable robots to efficiently structure, retrieve, and interpret complex environmental data. These capabilities empower robotic agents to reason, adapt, and respond effectively to changing conditions. The primary goal of this work is to demonstrate both multi-agent autonomy and shared autonomy, where multiple robotic agents operate independently while remaining connected to a human supervisor. We show how a RAG-powered large language model, augmented with knowledge graph data and domain taxonomy, enables autonomous multi-agent decision-making and facilitates seamless human-robot interaction, resulting in 100\% mission validation and behavior completeness. Finally, ablation studies reveal that without structured knowledge from the graph and/or taxonomy, the LLM is prone to hallucinations, which can compromise decision quality.

[Arxiv](https://arxiv.org/abs/2507.20370)