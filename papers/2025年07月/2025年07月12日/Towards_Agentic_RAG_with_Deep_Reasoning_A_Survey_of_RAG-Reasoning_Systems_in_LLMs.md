# 探索具备深度推理能力的智能体RAG：大型语言模型中的RAG推理系统综述

发布时间：2025年07月12日

`RAG` `问答系统`

> Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs

# 摘要

> 检索增强生成（RAG）通过引入外部知识显著提升了大型语言模型（LLMs）的事实准确性，但在多步推理问题上仍存在局限性；而纯粹推理导向的方法则容易出现事实幻觉或错误关联。本综述从统一的推理-检索视角整合了这两条研究脉络。首先，我们分析了先进推理机制如何优化RAG（推理增强型RAG）的各个阶段。接着，我们展示了不同类型的检索知识如何为复杂推理提供缺失的前提并扩展上下文（RAG增强推理）。最后，我们聚焦于新兴的协同化RAG-推理框架，其中（智能体型）LLMs通过迭代交织搜索与推理，在知识密集型基准测试中实现顶尖性能。我们对现有方法、数据集及开放挑战进行了分类，并概述了构建更高效、多模态适应、值得信赖且以人为中心的深度RAG-推理系统的研究方向。相关资源可从以下链接获取：https://github.com/DavidZWZ/Awesome-RAG-Reasoning.

> Retrieval-Augmented Generation (RAG) lifts the factuality of Large Language Models (LLMs) by injecting external knowledge, yet it falls short on problems that demand multi-step inference; conversely, purely reasoning-oriented approaches often hallucinate or mis-ground facts. This survey synthesizes both strands under a unified reasoning-retrieval perspective. We first map how advanced reasoning optimizes each stage of RAG (Reasoning-Enhanced RAG). Then, we show how retrieved knowledge of different type supply missing premises and expand context for complex inference (RAG-Enhanced Reasoning). Finally, we spotlight emerging Synergized RAG-Reasoning frameworks, where (agentic) LLMs iteratively interleave search and reasoning to achieve state-of-the-art performance across knowledge-intensive benchmarks. We categorize methods, datasets, and open challenges, and outline research avenues toward deeper RAG-Reasoning systems that are more effective, multimodally-adaptive, trustworthy, and human-centric. The collection is available at https://github.com/DavidZWZ/Awesome-RAG-Reasoning.

[Arxiv](https://arxiv.org/abs/2507.09477)