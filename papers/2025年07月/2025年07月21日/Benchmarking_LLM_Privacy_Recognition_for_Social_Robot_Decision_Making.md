# 社交机器人决策中的大型语言模型隐私识别基准测试。

发布时间：2025年07月21日

`Agent` `人机交互` `隐私保护`

> Benchmarking LLM Privacy Recognition for Social Robot Decision Making

# 摘要

> 社交机器人是遵循人类交流规范并与人互动的具身智能体。它们通过语言和非语言线索与人类交流，并共享物理环境。尽管社交机器人过去曾使用基于规则的系统或概率模型来进行用户交互，但大型语言模型（LLMs）的快速发展为开发增强人机交互的LLM赋能社交机器人提供了新的机遇。然而，要充分发挥这些能力，机器人需要收集音频、精细图像、视频和位置等数据。因此，LLMs经常处理敏感的个人信息，尤其是在家庭环境中。鉴于实用性和隐私风险之间的紧张关系，评估当前LLMs如何管理敏感数据至关重要。具体而言，我们旨在探索现成的LLMs在家庭社交机器人背景下对隐私的感知程度。在这项研究中，我们通过情境完整性（CI）的视角设计了一组与隐私相关的场景。首先，我们调查了用户对家庭社交机器人行为的隐私偏好，然后研究了他们的隐私取向如何影响他们对这些行为的选择（N=450）。接着，我们将相同的场景和问题提供给最先进的LLMs（N=10），发现人类与LLMs之间的一致性较低。为了进一步研究LLMs作为潜在隐私控制器的能力，我们实施了四种额外的提示策略并比较了结果。最后，我们讨论了AI隐私意识在人机交互中的影响与潜力。

> Social robots are embodied agents that interact with people while following human communication norms. These robots interact using verbal and non-verbal cues, and share the physical environments of people. While social robots have previously utilized rule-based systems or probabilistic models for user interaction, the rapid evolution of large language models (LLMs) presents new opportunities to develop LLM-empowered social robots for enhanced human-robot interaction. To fully realize these capabilities, however, robots need to collect data such as audio, fine-grained images, video, and locations. As a result, LLMs often process sensitive personal information, particularly within home environments. Given the tension between utility and privacy risks, evaluating how current LLMs manage sensitive data is critical. Specifically, we aim to explore the extent to which out-of-the-box LLMs are privacy-aware in the context of household social robots. In this study, we present a set of privacy-relevant scenarios crafted through the lens of Contextual Integrity (CI). We first survey users' privacy preferences regarding in-home social robot behaviors and then examine how their privacy orientation affects their choices of these behaviors (N = 450). We then provide the same set of scenarios and questions to state-of-the-art LLMs (N = 10) and find that the agreement between humans and LLMs is low. To further investigate the capabilities of LLMs as a potential privacy controller, we implement four additional prompting strategies and compare their results. Finally, we discuss the implications and potential of AI privacy awareness in human-robot interaction.

[Arxiv](https://arxiv.org/abs/2507.16124)