# 另一种思维：语言模型如何体现人类的时间认知

发布时间：2025年07月21日

`LLM理论` `人工智能` `认知科学`

> The Other Mind: How Language Models Exhibit Human Temporal Cognition

# 摘要

> 随着大型语言模型（LLMs）的持续发展，它们展现出一些与人类相似的认知模式，这些模式并未在训练数据中被直接规定。本研究聚焦于大型语言模型中的时间认知现象展开探讨。通过相似性判断任务，我们发现规模更大的模型会自发地建立一个主观的时间参考点，并遵循韦伯-费希纳定律，即随着时间距离参考点的增加，感知到的时间距离会呈现对数压缩现象。为了揭示这一行为背后的机制，我们在神经元、表征和信息层面进行了多维度分析。首先，我们发现了一组具有时间偏好特性的神经元，并观察到这些神经元在主观参考点处表现出最小的激活状态，并采用了一种在生物系统中也发现的对数编码方案。对年份表征的探测揭示了层次化的构建过程，其中年份从浅层的简单数值表示逐渐发展为深层的抽象时间定向。最后，通过预训练的嵌入模型，我们发现训练语料本身具有一种内在的、非线性的时间结构，为模型的内部构建提供了基础素材。在讨论部分，我们提出了一种经验主义视角来理解这些发现，即将LLMs的认知视为其内部表征系统对外部世界的主观构建。这种细致入微的视角暗示了可能存在人类无法直观预测的外来认知框架，指向了一种以引导内部构建为核心的AI对齐方向。我们的代码可在https://TheOtherMind.github.io获取。

> As Large Language Models (LLMs) continue to advance, they exhibit certain cognitive patterns similar to those of humans that are not directly specified in training data. This study investigates this phenomenon by focusing on temporal cognition in LLMs. Leveraging the similarity judgment task, we find that larger models spontaneously establish a subjective temporal reference point and adhere to the Weber-Fechner law, whereby the perceived distance logarithmically compresses as years recede from this reference point. To uncover the mechanisms behind this behavior, we conducted multiple analyses across neuronal, representational, and informational levels. We first identify a set of temporal-preferential neurons and find that this group exhibits minimal activation at the subjective reference point and implements a logarithmic coding scheme convergently found in biological systems. Probing representations of years reveals a hierarchical construction process, where years evolve from basic numerical values in shallow layers to abstract temporal orientation in deep layers. Finally, using pre-trained embedding models, we found that the training corpus itself possesses an inherent, non-linear temporal structure, which provides the raw material for the model's internal construction. In discussion, we propose an experientialist perspective for understanding these findings, where the LLMs' cognition is viewed as a subjective construction of the external world by its internal representational system. This nuanced perspective implies the potential emergence of alien cognitive frameworks that humans cannot intuitively predict, pointing toward a direction for AI alignment that focuses on guiding internal constructions. Our code is available at https://TheOtherMind.github.io.

[Arxiv](https://arxiv.org/abs/2507.15851)