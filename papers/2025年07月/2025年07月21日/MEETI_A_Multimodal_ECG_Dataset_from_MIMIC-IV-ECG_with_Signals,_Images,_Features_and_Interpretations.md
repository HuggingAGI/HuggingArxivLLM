# # MEETI：一个多模态心电数据集，来自MIMIC-IV-ECG，涵盖信号、图像、特征和解读。

发布时间：2025年07月21日

`其他` `人工智能`

> MEETI: A Multimodal ECG Dataset from MIMIC-IV-ECG with Signals, Images, Features and Interpretations

# 摘要

> 心电图 (ECG) 在现代心血管护理中发挥着基础性作用，实现了无创诊断心律失常、心肌缺血和传导障碍。尽管机器学习在 ECG 解读方面已达专家水平，但开发临床可用的多模态 AI 系统仍受限制，主要因缺乏同时包含原始信号、诊断图像和解读文本的公开数据集。现有 ECG 数据集大多仅提供单模态或双模态数据，难以在现实环境中构建整合多种 ECG 信息的模型。为解决这一问题，我们推出了 MEETI（MIMIC-IV-Ext ECG-Text-Image），这是首个大规模同步原始波形数据、高分辨率图像及大语言模型生成的详细文本解读的 ECG 数据集。此外，MEETI 包含从各导联提取的心跳级别定量 ECG 参数，提供支持精细分析和模型可解释性的结构化参数。每个 MEETI 记录在原始 ECG 波形、对应绘制图像、提取特征参数及详细解读文本间保持一致，通过唯一标识符实现统一。这一结构支持基于 transformer 的多模态学习，助力心脏健康精细推理。MEETI 弥合了传统信号分析、图像解读和语言驱动理解的鸿沟，为下一代可解释多模态心血管 AI 打下坚实基础，为研究界提供全面基准，用于开发和评估 ECG 基础 AI 系统。

> Electrocardiogram (ECG) plays a foundational role in modern cardiovascular care, enabling non-invasive diagnosis of arrhythmias, myocardial ischemia, and conduction disorders. While machine learning has achieved expert-level performance in ECG interpretation, the development of clinically deployable multimodal AI systems remains constrained, primarily due to the lack of publicly available datasets that simultaneously incorporate raw signals, diagnostic images, and interpretation text. Most existing ECG datasets provide only single-modality data or, at most, dual modalities, making it difficult to build models that can understand and integrate diverse ECG information in real-world settings. To address this gap, we introduce MEETI (MIMIC-IV-Ext ECG-Text-Image), the first large-scale ECG dataset that synchronizes raw waveform data, high-resolution plotted images, and detailed textual interpretations generated by large language models. In addition, MEETI includes beat-level quantitative ECG parameters extracted from each lead, offering structured parameters that support fine-grained analysis and model interpretability. Each MEETI record is aligned across four components: (1) the raw ECG waveform, (2) the corresponding plotted image, (3) extracted feature parameters, and (4) detailed interpretation text. This alignment is achieved using consistent, unique identifiers. This unified structure supports transformer-based multimodal learning and supports fine-grained, interpretable reasoning about cardiac health. By bridging the gap between traditional signal analysis, image-based interpretation, and language-driven understanding, MEETI established a robust foundation for the next generation of explainable, multimodal cardiovascular AI. It offers the research community a comprehensive benchmark for developing and evaluating ECG-based AI systems.

[Arxiv](https://arxiv.org/abs/2507.15255)