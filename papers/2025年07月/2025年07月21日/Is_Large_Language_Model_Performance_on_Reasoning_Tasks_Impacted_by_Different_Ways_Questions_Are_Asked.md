# 提问方式的不同是否会影响大型语言模型在推理任务中的表现？

发布时间：2025年07月21日

`LLM应用` `人工智能`

> Is Large Language Model Performance on Reasoning Tasks Impacted by Different Ways Questions Are Asked?

# 摘要

> 大型语言模型（LLMs）已通过多种问题类型进行评估，例如选择题、判断题以及简答题和详细回答题。本研究回答了一个尚未探索的问题，即不同问题类型对 LLM 在推理任务中的准确性有何影响。我们通过定量和演绎推理任务，研究了五个 LLM 在三种不同问题类型上的表现。性能指标包括推理步骤的准确性和最终答案的选择准确性。关键发现包括：（1）LLM 在不同问题类型上的表现存在显著差异。（2）推理准确性并不一定与最终选择准确性相关。（3）选项数量和措辞选择会影响 LLM 的表现。

> Large Language Models (LLMs) have been evaluated using diverse question types, e.g., multiple-choice, true/false, and short/long answers. This study answers an unexplored question about the impact of different question types on LLM accuracy on reasoning tasks. We investigate the performance of five LLMs on three different types of questions using quantitative and deductive reasoning tasks. The performance metrics include accuracy in the reasoning steps and choosing the final answer. Key Findings: (1) Significant differences exist in LLM performance across different question types. (2) Reasoning accuracy does not necessarily correlate with the final selection accuracy. (3) The number of options and the choice of words, influence LLM performance.

[Arxiv](https://arxiv.org/abs/2507.15707)