# 3LM：借助基准测试，为阿拉伯语、STEM 和代码搭建桥梁

发布时间：2025年07月21日

`LLM应用` `代码生成`

> 3LM: Bridging Arabic, STEM, and Code through Benchmarking

# 摘要

> 阿拉伯语是全球使用最广泛的语言之一，但在开发和评估阿拉伯语大型语言模型（LLMs）方面仍存在较大局限。现有基准测试多聚焦于语言、文化和宗教内容，忽视了STEM和代码生成等关键领域，而这些领域对现实世界中LLM的应用日益重要。为填补这一空白，我们推出了3LM，一套专为阿拉伯语设计的基准测试套件。第一个基准测试包含来自阿拉伯语教科书和教育练习册的STEM相关问答对。第二个基准测试由使用相同来源创建的合成生成的STEM问题组成。第三个基准测试专注于代码生成，通过仔细翻译两个广泛使用的代码基准测试构建而成，并结合人工回路机制，经过多轮审核，确保高质量和忠实的翻译。我们公开发布了这三个基准测试，以支持阿拉伯语LLM研究在这些关键但尚未充分探索领域的成长。

> Arabic is one of the most widely spoken languages in the world, yet efforts to develop and evaluate Large Language Models (LLMs) for Arabic remain relatively limited. Most existing Arabic benchmarks focus on linguistic, cultural, or religious content, leaving a significant gap in domains like STEM and code which are increasingly relevant for real-world LLM applications. To help bridge this gap, we present 3LM, a suite of three benchmarks designed specifically for Arabic. The first is a set of STEM-related question-answer pairs, naturally sourced from Arabic textbooks and educational worksheets. The second consists of synthetically generated STEM questions, created using the same sources. The third benchmark focuses on code generation, built through a careful translation of two widely used code benchmarks, incorporating a human-in-the-loop process with several rounds of review to ensure high-quality and faithful translations. We release all three benchmarks publicly to support the growth of Arabic LLM research in these essential but underrepresented areas.

[Arxiv](https://arxiv.org/abs/2507.15850)