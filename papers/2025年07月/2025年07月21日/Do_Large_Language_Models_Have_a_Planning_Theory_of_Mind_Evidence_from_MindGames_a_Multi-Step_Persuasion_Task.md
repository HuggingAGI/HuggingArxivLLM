# 大型语言模型是否具备规划的思维理论？来自MindGames的实证研究：多步骤劝说任务

发布时间：2025年07月21日

`LLM理论

摘要讨论了大型语言模型（LLMs）在“心智理论”（ToM）能力方面的表现，评估了其在动态规划和干预他人心理状态方面的应用，揭示了模型与人类之间的差距。这属于对LLM能力的理论研究，因此归类为LLM理论。` `社交推理` `人工智能`

> Do Large Language Models Have a Planning Theory of Mind? Evidence from MindGames: a Multi-Step Persuasion Task

# 摘要

> 最近研究表明，大型语言模型（LLMs）具备“心智理论”（ToM）能力。传统ToM实验多让参与者以旁观者身份预测和解释他人行为，而人类ToM能力更体现在动态规划行动和干预他人心理状态。我们推出MindGames——一个全新的“规划心智理论”（PToM）任务，要求主体通过推断对话者的信念和欲望，说服其改变行为。与以往评估不同，我们着重考察了ToM的实际应用场景。实验结果显示，在PToM任务中，人类的表现显著优于o1-preview（一个LLM）（高出11%；$p=0.006$）。我们认为，这是因为人类对其他主体有着隐含的因果理解（例如，如同任务要求，人类知道询问他人偏好）。然而，在一个基线条件下，当任务需要类似规划但较少心理状态推理时（例如，已知某人偏好时的规划任务），o1-preview的表现优于人类。这些结果揭示了人类社交推理与LLM能力之间存在显著差距。


> Recent evidence suggests Large Language Models (LLMs) display Theory of Mind (ToM) abilities. Most ToM experiments place participants in a spectatorial role, wherein they predict and interpret other agents' behavior. However, human ToM also contributes to dynamically planning action and strategically intervening on others' mental states. We present MindGames: a novel `planning theory of mind' (PToM) task which requires agents to infer an interlocutor's beliefs and desires to persuade them to alter their behavior. Unlike previous evaluations, we explicitly evaluate use cases of ToM. We find that humans significantly outperform o1-preview (an LLM) at our PToM task (11% higher; $p=0.006$). We hypothesize this is because humans have an implicit causal model of other agents (e.g., they know, as our task requires, to ask about people's preferences). In contrast, o1-preview outperforms humans in a baseline condition which requires a similar amount of planning but minimal mental state inferences (e.g., o1-preview is better than humans at planning when already given someone's preferences). These results suggest a significant gap between human-like social reasoning and LLM abilities.

[Arxiv](https://arxiv.org/abs/2507.16196)