# 大型语言模型在跨学科研究中的能力解析

发布时间：2025年07月21日

`LLM应用`

> Understanding Large Language Models' Ability on Interdisciplinary Research

# 摘要

> 大型语言模型（LLMs）近期展现出在复杂领域中进行多步逻辑推理的卓越能力，不仅成为科学研究中的得力伙伴，更打破了灵感构思仅为人类专属的固有认知。然而，现有研究缺乏专门针对跨学科研究（IDR）环境中评估LLMs创意开发能力的基准测试，这成为全面认识其优劣的关键障碍。

为此，我们推出IDRBench——首个专注于跨学科研究的评估基准。该基准包含专家标注的数据集，并设计了一系列针对性任务，旨在全面评估LLMs从不同科学领域萃取有价值研究构思的能力。IDRBench致力于为LLMs在复杂跨领域科研中的表现提供系统性评估框架。

我们的数据集从ArXiv平台精选了涵盖六个不同学科的科学文献，并由多领域专家共同标注。为确保标注质量，我们设定了清晰的维度标准，以真实反映跨学科研究的特征。IDRBench的评估任务设计贴合现实科研流程，分为三个递进阶段：1）跨学科论文识别，2）跨学科理念整合，3）跨学科理念推荐。

通过对10个主流LLMs进行基线测试，我们发现尽管这些模型在跨学科意识上有所展现，但距离生成高质量跨学科研究理念仍有较大差距。这些发现不仅为未来研究指明方向，更为开发新一代擅长跨学科研究的LLMs提供了重要参考。

> Recent advancements in Large Language Models (LLMs) have revealed their impressive ability to perform multi-step, logic-driven reasoning across complex domains, positioning them as powerful tools and collaborators in scientific discovery while challenging the long-held view that inspiration-driven ideation is uniquely human. However, the lack of a dedicated benchmark that evaluates LLMs' ability to develop ideas in Interdisciplinary Research (IDR) settings poses a critical barrier to fully understanding their strengths and limitations. To address this gap, we introduce IDRBench -- a pioneering benchmark featuring an expert annotated dataset and a suite of tasks tailored to evaluate LLMs' capabilities in proposing valuable research ideas from different scientific domains for interdisciplinary research. This benchmark aims to provide a systematic framework for assessing LLM performance in complex, cross-domain scientific research. Our dataset consists of scientific publications sourced from the ArXiv platform covering six distinct disciplines, and is annotated by domain experts with diverse academic backgrounds. To ensure high-quality annotations, we emphasize clearly defined dimensions that characterize authentic interdisciplinary research. The design of evaluation tasks in IDRBench follows a progressive, real-world perspective, reflecting the natural stages of interdisciplinary research development, including 1) IDR Paper Identification, 2) IDR Idea Integration, and 3) IDR Idea Recommendation. Using IDRBench, we construct baselines across 10 LLMs and observe that despite fostering some level of IDR awareness, LLMs still struggle to produce quality IDR ideas. These findings could not only spark new research directions, but also help to develop next-generation LLMs that excel in interdisciplinary research.

[Arxiv](https://arxiv.org/abs/2507.15736)