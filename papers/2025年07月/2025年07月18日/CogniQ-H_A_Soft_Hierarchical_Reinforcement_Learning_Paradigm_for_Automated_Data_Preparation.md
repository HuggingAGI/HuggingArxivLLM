# # 摘要  
CogniQ-H：一种自动化数据准备的软层次强化学习范式

发布时间：2025年07月18日

`LLM应用

理由：这篇论文主要探讨了如何将大型语言模型（LLM）应用于数据准备任务，提出了一种创新的数据准备框架CogniQ-H，利用LLM生成的战略先验来优化数据准备过程。虽然涉及强化学习和分层方法，但其核心贡献在于应用层面，因此归类为LLM应用。` `数据科学` `机器学习`

> CogniQ-H: A Soft Hierarchical Reinforcement Learning Paradigm for Automated Data Preparation

# 摘要

> 数据准备：机器学习基石中的挑战  
数据准备是机器学习生命周期中不可或缺但极具挑战性的环节，其核心在于处理庞大且复杂的潜在操作序列组合空间。尽管强化学习（RL）为这一领域带来了新的希望，但现有方法的效率仍有待提升，主要因为它们未能充分挖掘问题本身的结构化和分层特性。

我们提出，分层强化学习（HRL）这一在其他领域大放异彩的方法论，为数据准备任务提供了一个概念上理想却尚未被深入探索的解决方案。然而，传统的“硬分层”HRL实现方式存在明显缺陷，容易导致次优且不可逆的决策结果。

为解决这一难题，我们推出了CogniQ-H——首个基于软分层范式的稳健端到端自动化数据准备框架。CogniQ-H独辟蹊径，将动作选择过程建模为贝叶斯推理问题。其中，由大型语言模型（LLM）生成的高层战略先验以概率方式引导探索过程。这一先验与监督学习排序（LTR）模型的细粒度操作质量评分以及代理自身Q函数的长期价值估计形成协同作用。这种创新的混合架构使CogniQ-H能够实现战略指导与基于证据的自适应决策之间的完美平衡。

通过在涵盖多个领域的18个多样化数据集上的广泛实验，我们欣喜地发现：与现有最先进的RL基线方法相比，CogniQ-H在数据管道质量方面实现了高达13.9%的显著提升，同时其收敛速度更是达到了惊人的2.8倍提升。这一突破性进展标志着数据准备自动化领域的重大跨越。


> Data preparation is a foundational yet notoriously challenging component of the machine learning lifecycle, characterized by a vast combinatorial search space of potential operator sequences. While reinforcement learning (RL) offers a promising direction, existing approaches are inefficient as they fail to capture the structured, hierarchical nature of the problem. We argue that Hierarchical Reinforcement Learning (HRL), a paradigm that has been successful in other domains, provides a conceptually ideal yet previously unexplored framework for this task. However, a naive HRL implementation with a `hard hierarchy' is prone to suboptimal, irreversible decisions. To address this, we introduce CogniQ-H, the first framework to implement a soft hierarchical paradigm for robust, end-to-end automated data preparation. CogniQ-H formulates action selection as a Bayesian inference problem. A high-level strategic prior, generated by a Large Language Model (LLM), guides exploration probabilistically. This prior is synergistically combined with a fine-grained operator quality score from a supervised Learning-to-Rank (LTR) model and a long-term value estimate from the agent's own Q-function. This hybrid architecture allows CogniQ-H to balance strategic guidance with adaptive, evidence-based decision-making. Through extensive experiments on 18 diverse datasets spanning multiple domains, we demonstrate that CogniQ-H achieves up to 13.9\% improvement in pipeline quality and 2.8$\times$ faster convergence compared to state-of-the-art RL-based methods.

[Arxiv](https://arxiv.org/abs/2507.13710)