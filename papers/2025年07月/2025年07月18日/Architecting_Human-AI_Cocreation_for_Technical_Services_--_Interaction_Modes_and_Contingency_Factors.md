# 构建人机协同创作的技术服务架构——交互模式与情境因素

发布时间：2025年07月18日

`Agent` `技术服务` `协作系统`

> Architecting Human-AI Cocreation for Technical Services -- Interaction Modes and Contingency Factors

# 摘要

> 基于大型语言模型（LLMs）的智能体AI系统为技术服务中的价值共创带来了变革性的潜力。然而，幻觉和操作上的脆性等持续性挑战限制了其自主使用，亟需 robust 的框架来指导人机协作。本文基于人机协作研究和自动驾驶等领域的类比，提出了一套结构化的智能体-人类交互分类法。基于技术支撑平台的案例研究，我们提出了一种六模式的分类法，涵盖了从完全自动化到被动AI辅助的整个AI自主性范围。这一范围以“人不在环中”（HOOTL）模型为全自动化基准，以“人增强模型”（HAM）为被动AI辅助基准。在这两个极端之间，该框架进一步明确了四种不同的中间结构。其中包括“人在指挥”（HIC）模型，其中AI建议需要强制性的人类批准，以及“人在过程中”（HITP）模型，用于具有确定性人类任务的结构化工作流程。该分类法还界定了“人在环中”（HITL）模型，该模型在不确定性情况下促进智能体发起的升级，以及“人在线”（HOTL）模型，该模型使人类能够对自主AI进行酌情监督。这项工作的主要贡献是一个综合框架，它将此分类法与关键权变因素（如任务复杂性、运营风险和系统可靠性）及其相应的概念架构联系起来。通过提供选择和设计适当的人类监督级别系统方法，我们的框架为从业者提供了一个关键工具，以在自动化与控制之间权衡取舍，从而促进更安全、更有效且情境感知的技术服务系统的开发。

> Agentic AI systems, powered by Large Language Models (LLMs), offer transformative potential for value co-creation in technical services. However, persistent challenges like hallucinations and operational brittleness limit their autonomous use, creating a critical need for robust frameworks to guide human-AI collaboration. Drawing on established Human-AI teaming research and analogies from fields like autonomous driving, this paper develops a structured taxonomy of human-agent interaction. Based on case study research within technical support platforms, we propose a six-mode taxonomy that organizes collaboration across a spectrum of AI autonomy. This spectrum is anchored by the Human-Out-of-the-Loop (HOOTL) model for full automation and the Human-Augmented Model (HAM) for passive AI assistance. Between these poles, the framework specifies four distinct intermediate structures. These include the Human-in-Command (HIC) model, where AI proposals re-quire mandatory human approval, and the Human-in-the-Process (HITP) model for structured work-flows with deterministic human tasks. The taxonomy further delineates the Human-in-the-Loop (HITL) model, which facilitates agent-initiated escalation upon uncertainty, and the Human-on-the-Loop (HOTL) model, which enables discretionary human oversight of an autonomous AI. The primary contribution of this work is a comprehensive framework that connects this taxonomy to key contingency factors -- such as task complexity, operational risk, and system reliability -- and their corresponding conceptual architectures. By providing a systematic method for selecting and designing an appropriate level of human oversight, our framework offers practitioners a crucial tool to navigate the trade-offs between automation and control, thereby fostering the development of safer, more effective, and context-aware technical service systems.

[Arxiv](https://arxiv.org/abs/2507.14034)