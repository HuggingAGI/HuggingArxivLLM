# # 利用首因效应优化大型语言模型性能

发布时间：2025年07月18日

`LLM应用`

> Exploiting Primacy Effect To Improve Large Language Models

# 摘要

> 大型语言模型 (LLMs) 已经成为许多自然语言处理 (NLP) 任务中不可或缺的一部分，通过广泛的预训练和微调来实现高精度。然而，与人类一样，LLMs 也表现出偏见，特别是位置偏见，如首因效应和近因效应，这些偏见可能会影响答案的准确性。首因效应——即最先呈现的项目更容易被记住或选择——在多项选择题回答 (MCQA) 中起着关键作用，因为答案选项的顺序可能会影响预测结果。本研究专注于微调后的 LLMs 中的首因偏见：我们首先表明，微调会放大这种偏见，这可能是因为模型接触了类似人类的模式。因此，我们战略性地利用这一效应，通过重新排列与查询语义相似的响应选项来提升性能，而无需了解正确答案。我们的实验结果表明，这种方法在 MCQA 中显著提高了性能。更一般地说，我们的研究结果强调了偏见的双重性质，既是挑战也是机会，为有偏见意识的模型设计和 NLP 应用提供了见解。

> Large Language Models (LLMs) have become essential in many Natural Language Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to achieve high accuracy. However, like humans, LLMs exhibit biases, particularly positional biases such as primacy and recency effects, which can influence the accuracy of the answers. The primacy effect-where items presented first are more likely to be remembered or selected-plays a key role in Multiple Choice Question Answering (MCQA), where the order of answer options can affect prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We first show that fine-tuning amplifies this bias, probably due to exposure to human-like patterns. Hence, we strategically leverage this effect by reordering response options based on semantic similarity to the query, without requiring knowledge of the correct answer. Our experimental results show that this approach significantly improves performance in MCQA. More generally, our findings underscore the dual nature of biases as both challenges and opportunities, offering insights for bias-aware model design and NLP applications.

[Arxiv](https://arxiv.org/abs/2507.13949)