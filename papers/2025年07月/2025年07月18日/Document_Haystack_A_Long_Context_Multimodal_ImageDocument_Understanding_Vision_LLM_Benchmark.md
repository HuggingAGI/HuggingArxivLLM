# 文档海斯特：一个多模态长上下文图像与文档理解的视觉大语言模型基准测试

发布时间：2025年07月18日

`LLM应用` `文档处理` `信息检索`

> Document Haystack: A Long Context Multimodal Image/Document Understanding Vision LLM Benchmark

# 摘要

> 多模态大型语言模型的普及显著提升了对复杂多模态数据的分析和理解能力。然而，处理长文档的能力仍有待探索，主要由于缺乏合适的基准。为此，我们推出了**Document Haystack**，这是一个全面的基准测试，用于评估视觉语言模型（VLMs）在长篇、视觉复杂的文档上的表现。该基准包含从5页到200页不等的文档，并在文档中不同深度处战略性地插入纯文本或图文结合的“针线”（text+image "needles"），以考验VLMs的检索能力。Document Haystack包含400种文档变体和总计8,250个问题，并配备了客观、自动化的评估框架。我们详细介绍了该数据集的构建和特点，展示了知名VLMs的测试结果，并探讨了该领域未来的研究方向。

> The proliferation of multimodal Large Language Models has significantly advanced the ability to analyze and understand complex data inputs from different modalities. However, the processing of long documents remains under-explored, largely due to a lack of suitable benchmarks. To address this, we introduce Document Haystack, a comprehensive benchmark designed to evaluate the performance of Vision Language Models (VLMs) on long, visually complex documents. Document Haystack features documents ranging from 5 to 200 pages and strategically inserts pure text or multimodal text+image "needles" at various depths within the documents to challenge VLMs' retrieval capabilities. Comprising 400 document variants and a total of 8,250 questions, it is supported by an objective, automated evaluation framework. We detail the construction and characteristics of the Document Haystack dataset, present results from prominent VLMs and discuss potential research avenues in this area.

[Arxiv](https://arxiv.org/abs/2507.15882)