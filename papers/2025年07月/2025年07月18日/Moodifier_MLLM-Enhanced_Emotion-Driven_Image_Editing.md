# Moodifier: 基于增强情感的图像编辑器
情绪修饰器：利用多模态大语言模型实现的情感驱动图像编辑
Moodifier突破性地将多模态大语言模型与图像编辑相结合，通过增强情感理解，实现了更符合用户意图的图像编辑效果，填补了现有技术在情感表达方面的空白。

发布时间：2025年07月18日

`LLM应用` `创意产业` `视觉设计`

> Moodifier: MLLM-Enhanced Emotion-Driven Image Editing

# 摘要

> 将情感与视觉内容相结合，用于情感驱动的图像编辑，在创意产业中具有巨大潜力。然而，由于情感的抽象特性和在不同语境下的多样化表现，精确的情感驱动操作仍然面临挑战。我们提出了一种由三个互补组件组成的综合解决方案。首先，我们引入了MoodArchive，这是一个包含800多万张图像的数据集，每张图像都带有由LLaVA生成的详细分层情感标注，并经过部分人工验证。其次，我们开发了MoodifyCLIP，这是一种基于MoodArchive微调的视觉-语言模型，能够将抽象情感转化为具体的视觉属性。最后，我们提出了Moodifier，这是一种无需训练的编辑模型，它结合了MoodifyCLIP和多模态大型语言模型（MLLMs），能够在保持内容完整性的前提下实现精确的情感转换。我们的系统适用于多个领域，包括人物表情、时尚设计、珠宝和家居装饰，使创作者能够快速实现情感变化，同时保持身份和结构的一致性。通过广泛的实验评估，我们发现Moodifier在情感准确性和内容保存方面均优于现有方法，并能够提供上下文相关的编辑结果。通过将抽象情感与具体视觉变化相连接，我们的解决方案为现实世界中的情感内容创作开辟了新的可能性。我们承诺在论文被接受后，公开发布MoodArchive数据集、MoodifyCLIP模型以及Moodifier的代码和演示。

> Bridging emotions and visual content for emotion-driven image editing holds great potential in creative industries, yet precise manipulation remains challenging due to the abstract nature of emotions and their varied manifestations across different contexts. We tackle this challenge with an integrated approach consisting of three complementary components. First, we introduce MoodArchive, an 8M+ image dataset with detailed hierarchical emotional annotations generated by LLaVA and partially validated by human evaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned on MoodArchive to translate abstract emotions into specific visual attributes. Third, we propose Moodifier, a training-free editing model leveraging MoodifyCLIP and multimodal large language models (MLLMs) to enable precise emotional transformations while preserving content integrity. Our system works across diverse domains such as character expressions, fashion design, jewelry, and home décor, enabling creators to quickly visualize emotional variations while preserving identity and structure. Extensive experimental evaluations show that Moodifier outperforms existing methods in both emotional accuracy and content preservation, providing contextually appropriate edits. By linking abstract emotions to concrete visual changes, our solution unlocks new possibilities for emotional content creation in real-world applications. We will release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier code and demo publicly available upon acceptance.

[Arxiv](https://arxiv.org/abs/2507.14024)