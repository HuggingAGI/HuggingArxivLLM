# 在大型语言模型驱动的应用程序背景下，提出了一种评估自动语音识别模型性能的探讨方法。

发布时间：2025年07月22日

`LLM应用` `语音识别`

> An approach to measuring the performance of Automatic Speech Recognition (ASR) models in the context of Large Language Model (LLM) powered applications

# 摘要

> 自动语音识别（ASR）在人机交互中发挥着关键作用，是多种应用的重要接口。传统上，我们使用词错误率（WER）来评估 ASR 的性能，该指标衡量了生成转录中的插入、删除和替换数量。然而，随着大型语言模型（LLMs）在各种应用中作为核心处理组件的广泛应用，不同类型 ASR 错误在下游任务中的重要性值得进一步探索。本研究分析了 LLMs 纠正 ASR 错误的能力，并提出了一种新的评估指标，以更好地衡量 LLM 驱动应用中的 ASR 性能。

> Automatic Speech Recognition (ASR) plays a crucial role in human-machine interaction and serves as an interface for a wide range of applications. Traditionally, ASR performance has been evaluated using Word Error Rate (WER), a metric that quantifies the number of insertions, deletions, and substitutions in the generated transcriptions. However, with the increasing adoption of large and powerful Large Language Models (LLMs) as the core processing component in various applications, the significance of different types of ASR errors in downstream tasks warrants further exploration. In this work, we analyze the capabilities of LLMs to correct errors introduced by ASRs and propose a new measure to evaluate ASR performance for LLM-powered applications.

[Arxiv](https://arxiv.org/abs/2507.16456)