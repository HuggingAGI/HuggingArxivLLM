# # 探索大型语言模型中的性别偏见问题：深入探索德语

发布时间：2025年07月22日

`LLM应用` `性别偏见`

> Exploring Gender Bias in Large Language Models: An In-depth Dive into the German Language

# 摘要

> 近年来，评估大型语言模型（LLMs）性别偏见的方法层出不穷。然而，最初为英语设计的偏见测量方法在应用于其他语言时面临重大挑战。本研究通过提供五个德语数据集，为这一研究领域注入新视角。这些数据集基于成熟可靠的性别偏见概念，并采用多样化的获取方法。我们对八个多语言LLM模型的分析揭示了德语性别偏见的独特难题，包括男性职业术语的模糊解释以及看似中性的名词对性别认知的微妙影响。这项研究不仅深化了我们对跨语言LLMs性别偏见的理解，更凸显了量身定制的评估框架不可或缺。

> In recent years, various methods have been proposed to evaluate gender bias in large language models (LLMs). A key challenge lies in the transferability of bias measurement methods initially developed for the English language when applied to other languages. This work aims to contribute to this research strand by presenting five German datasets for gender bias evaluation in LLMs. The datasets are grounded in well-established concepts of gender bias and are accessible through multiple methodologies. Our findings, reported for eight multilingual LLM models, reveal unique challenges associated with gender bias in German, including the ambiguous interpretation of male occupational terms and the influence of seemingly neutral nouns on gender perception. This work contributes to the understanding of gender bias in LLMs across languages and underscores the necessity for tailored evaluation frameworks.

[Arxiv](https://arxiv.org/abs/2507.16557)