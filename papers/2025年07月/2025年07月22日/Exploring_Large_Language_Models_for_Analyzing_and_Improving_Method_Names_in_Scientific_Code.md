# 研究大型语言模型在科学代码方法名称分析与优化中的应用

发布时间：2025年07月22日

`LLM应用` `科学软件` `代码质量`

> Exploring Large Language Models for Analyzing and Improving Method Names in Scientific Code

# 摘要

> 如今，研究科学家们越来越依赖通过编写软件来支持他们的研究工作。尽管此前的研究已探讨了标识符名称对传统编程环境中程序理解的影响，但针对科学软件领域，尤其是代码中方法名称质量的研究仍十分有限。近期大型语言模型（LLMs）的进展为自动化代码分析任务带来了新机遇，例如对标识符名称的评估与建议。

我们的研究评估了四款流行的LLMs在分析语法规律并为从基于Python的Jupyter Notebook中提取的496个方法名称提出改进建议方面的能力。研究结果表明，这些LLMs在分析方法名称方面具有一定效果，并且通常遵循良好的命名规范，例如以动词开头。然而，它们在处理领域特定术语时表现不一致，且与人工标注的仅有中等程度的一致性，这表明自动化建议仍需人工评估。

这项工作为通过人工智能自动化提升科学代码质量提供了基础性的见解。


> Research scientists increasingly rely on implementing software to support their research. While previous research has examined the impact of identifier names on program comprehension in traditional programming environments, limited work has explored this area in scientific software, especially regarding the quality of method names in the code. The recent advances in Large Language Models (LLMs) present new opportunities for automating code analysis tasks, such as identifier name appraisals and recommendations. Our study evaluates four popular LLMs on their ability to analyze grammatical patterns and suggest improvements for 496 method names extracted from Python-based Jupyter Notebooks. Our findings show that the LLMs are somewhat effective in analyzing these method names and generally follow good naming practices, like starting method names with verbs. However, their inconsistent handling of domain-specific terminology and only moderate agreement with human annotations indicate that automated suggestions require human evaluation. This work provides foundational insights for improving the quality of scientific code through AI automation.

[Arxiv](https://arxiv.org/abs/2507.16439)