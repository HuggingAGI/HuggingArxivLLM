# LingBench++: 一个语言学知识驱动的基准与推理框架，助力大语言模型实现多步骤跨文化推理。

发布时间：2025年07月22日

`LLM应用` `语言学`

> LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework for Multi-Step and Cross-Cultural Inference with LLMs

# 摘要

> 我们提出 LingBench++，这是一个基于语言学的基准框架和推理框架，旨在评估大型语言模型 (LLMs) 在受国际语言学奥林匹克竞赛 (IOL) 启发的复杂语言任务上的表现。与仅关注最终答案准确性的现有基准不同，LingBench++ 提供了结构化的推理轨迹、逐步评估协议以及涵盖 90 多种低资源和跨文化语言的丰富类型学元数据。我们进一步开发了一种多代理架构，整合了语法知识检索、工具增强推理和有意识的假设检验。通过系统比较基线模型和我们提出的代理模型，我们证明了配备外部知识源和迭代推理的模型在准确性和可解释性方面均优于单次通过方法。LingBench++ 为在 LLM 中推进基于语言学、文化知识和认知合理性的推理提供了全面的基础。

> We propose LingBench++, a linguistically-informed benchmark and reasoning framework designed to evaluate large language models (LLMs) on complex linguistic tasks inspired by the International Linguistics Olympiad (IOL). Unlike prior benchmarks that focus solely on final answer accuracy, LingBench++ provides structured reasoning traces, stepwise evaluation protocols, and rich typological metadata across over 90 low-resource and cross-cultural languages. We further develop a multi-agent architecture integrating grammatical knowledge retrieval, tool-augmented reasoning, and deliberate hypothesis testing. Through systematic comparisons of baseline and our proposed agentic models, we demonstrate that models equipped with external knowledge sources and iterative reasoning outperform single-pass approaches in both accuracy and interpretability. LingBench++ offers a comprehensive foundation for advancing linguistically grounded, culturally informed, and cognitively plausible reasoning in LLMs.

[Arxiv](https://arxiv.org/abs/2507.16809)