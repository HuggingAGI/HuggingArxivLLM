# 阿拉表：评测大语言模型对阿拉伯语表格数据的推理与理解能力

发布时间：2025年07月24日

`LLM应用

摘要中的论文专注于将大型语言模型（LLMs）应用于处理阿拉伯语表格数据的推理和理解任务。通过提出AraTable基准测试和自动化评估框架，研究集中在模型在结构化数据处理中的实际应用，属于LLM应用类别。` `数据处理`

> AraTable: Benchmarking LLMs' Reasoning and Understanding of Arabic Tabular Data

# 摘要

> 大型语言模型（LLMs）的认知和推理能力推动了自然语言处理领域的显著进步。然而，它们在处理结构化数据，尤其是表格数据方面的能力仍然有限。尽管英语表格数据的基准测试广泛存在，但阿拉伯语仍代表性不足，这主要是由于公开资源的匮乏及其独特的语言特性。为了解决这一问题，我们提出了AraTable，这是一个全新的综合性基准测试，旨在评估LLMs在处理阿拉伯语表格数据时的推理和理解能力。AraTable涵盖了直接问答、事实核查和复杂推理等多种任务，涉及广泛的阿拉伯语表格数据源。我们的方法采用了一种混合流水线，初始内容由LLMs生成，随后由人类专家进行筛选和验证，以确保数据集的高质量。初步使用AraTable的分析表明，尽管LLMs在直接问答等较为简单的表格任务上表现尚可，但在需要更深入推理和事实核查的任务上，它们仍然面临显著的认知挑战。这表明在复杂表格推理任务方面，未来的工作有巨大的改进空间。我们还提出了一种完全自动化的评估框架，该框架采用自我反思机制，其性能几乎与人工评审员持平。这项研究提供了一个有价值且公开可用的资源和评估框架，有助于加速处理和分析阿拉伯语结构化数据的基础模型的发展。

> The cognitive and reasoning abilities of large language models (LLMs) have enabled remarkable progress in natural language processing. However, their performance in interpreting structured data, especially in tabular formats, remains limited. Although benchmarks for English tabular data are widely available, Arabic is still underrepresented because of the limited availability of public resources and its unique language features. To address this gap, we present AraTable, a novel and comprehensive benchmark designed to evaluate the reasoning and understanding capabilities of LLMs when applied to Arabic tabular data. AraTable consists of various evaluation tasks, such as direct question answering, fact verification, and complex reasoning, involving a wide range of Arabic tabular sources. Our methodology follows a hybrid pipeline, where initial content is generated by LLMs and subsequently filtered and verified by human experts to ensure high dataset quality. Initial analyses using AraTable show that, while LLMs perform adequately on simpler tabular tasks such as direct question answering, they continue to face significant cognitive challenges when tasks require deeper reasoning and fact verification. This indicates that there are substantial opportunities for future work to improve performance on complex tabular reasoning tasks. We also propose a fully automated evaluation framework that uses a self-deliberation mechanism and achieves performance nearly identical to that of human judges. This research provides a valuable, publicly available resource and evaluation framework that can help accelerate the development of foundational models for processing and analysing Arabic structured data.

[Arxiv](https://arxiv.org/abs/2507.18442)