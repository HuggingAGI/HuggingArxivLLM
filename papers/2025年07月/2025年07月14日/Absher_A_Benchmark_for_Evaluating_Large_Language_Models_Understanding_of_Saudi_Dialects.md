# Absher：评测大型语言模型对沙特方言理解能力的基准

发布时间：2025年07月14日

`LLM应用

摘要讨论了大型语言模型在阿拉伯语方言和文化理解中的应用，介绍了评估模型表现的基准测试，属于模型的应用评估，因此归类为LLM应用。`

> Absher: A Benchmark for Evaluating Large Language Models Understanding of Saudi Dialects

# 摘要

> 随着大型语言模型 (LLMs) 在阿拉伯语 NLP 应用中日益占据核心地位，评估其对地区方言和文化细微差别的理解变得至关重要，尤其在语言多样性显著的国家如沙特阿拉伯。本文介绍了 	exttt{Absher}，一个全面的基准测试，专门用于评估 LLMs 在主要沙特方言中的表现。 	exttt{Absher} 包含超过 18,000 个选择题，涵盖六个不同类别：意义、真/假、填空、语境用法、文化解释和位置识别。这些问题源自一个经过精心整理的数据集，包含来自沙特阿拉伯各地的方言词汇、短语和谚语。我们评估了多个最先进的 LLMs，包括多语言和专门针对阿拉伯语的模型。我们还提供了对其能力与局限性的详细分析。我们的结果显示，在需要文化推理或语境理解的任务中，模型表现存在显著差距。我们的研究结果突显了在提升 LLMs 在现实世界阿拉伯语应用中的性能方面，亟需进行方言感知训练和文化对齐的评估方法。
    

> As large language models (LLMs) become increasingly central to Arabic NLP applications, evaluating their understanding of regional dialects and cultural nuances is essential, particularly in linguistically diverse settings like Saudi Arabia. This paper introduces \texttt{Absher}, a comprehensive benchmark specifically designed to assess LLMs performance across major Saudi dialects. \texttt{Absher} comprises over 18,000 multiple-choice questions spanning six distinct categories: Meaning, True/False, Fill-in-the-Blank, Contextual Usage, Cultural Interpretation, and Location Recognition. These questions are derived from a curated dataset of dialectal words, phrases, and proverbs sourced from various regions of Saudi Arabia. We evaluate several state-of-the-art LLMs, including multilingual and Arabic-specific models. We also provide detailed insights into their capabilities and limitations. Our results reveal notable performance gaps, particularly in tasks requiring cultural inference or contextual understanding. Our findings highlight the urgent need for dialect-aware training and culturally aligned evaluation methodologies to improve LLMs performance in real-world Arabic applications.

[Arxiv](https://arxiv.org/abs/2507.10216)