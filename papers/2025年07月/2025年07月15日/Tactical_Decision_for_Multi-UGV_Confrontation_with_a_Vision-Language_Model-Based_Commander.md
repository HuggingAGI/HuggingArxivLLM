# 基于视觉语言模型的指挥官在多UGV对抗中的战术决策研究

发布时间：2025年07月15日

`LLM应用` `指挥与控制系统`

> Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander

# 摘要

> 在多无人地面车辆对抗场景中，如何从态势感知中实现多智能体战术决策的自主演化仍是一项重大挑战。传统基于手工规则的方法在复杂多变的战场环境中显得力不从心，而现有的强化学习方法由于缺乏可解释性，主要聚焦于动作操控而非战略决策。为此，我们提出了一种基于视觉语言模型的指挥官，旨在解决自主对抗中的智能感知到决策推理问题。我们的方法通过整合视觉语言模型进行场景理解，以及轻量级大型语言模型进行战略推理，在共享语义空间内实现了统一的感知与决策，展现出强大的适应性和可解释性。与基于规则的搜索和强化学习方法不同，两个模块的结合构建了一个完整的决策链路，完美模拟了人类指挥官的认知过程。通过仿真和消融实验验证，与基线模型相比，所提方法的胜率超过80%。

> In multiple unmanned ground vehicle confrontations, autonomously evolving multi-agent tactical decisions from situational awareness remain a significant challenge. Traditional handcraft rule-based methods become vulnerable in the complicated and transient battlefield environment, and current reinforcement learning methods mainly focus on action manipulation instead of strategic decisions due to lack of interpretability. Here, we propose a vision-language model-based commander to address the issue of intelligent perception-to-decision reasoning in autonomous confrontations. Our method integrates a vision language model for scene understanding and a lightweight large language model for strategic reasoning, achieving unified perception and decision within a shared semantic space, with strong adaptability and interpretability. Unlike rule-based search and reinforcement learning methods, the combination of the two modules establishes a full-chain process, reflecting the cognitive process of human commanders. Simulation and ablation experiments validate that the proposed approach achieves a win rate of over 80% compared with baseline models.

[Arxiv](https://arxiv.org/abs/2507.11079)