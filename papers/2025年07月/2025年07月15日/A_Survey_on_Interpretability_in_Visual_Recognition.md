# # 视觉识别中的可解释性综述

发布时间：2025年07月15日

`其他` `自动驾驶` `医学诊断`

> A Survey on Interpretability in Visual Recognition

# 摘要

> 近年来，视觉识别技术在各个领域取得了显著进展并得到广泛应用。尽管研究人员致力于揭示这些模型成功背后的工作机制，但将其部署到自动驾驶和医学诊断等关键领域的动力日益增长，以期更好地诊断故障，从而推动了可解释性研究的发展。本文系统性地回顾了现有视觉识别模型可解释性研究，并从以人为本的视角提出了方法分类体系。所提出的分类体系基于意图、目标、呈现和方法论对可解释性识别方法进行分类，从而为这些XAI方法建立了一套系统且连贯的分组标准。此外，我们总结了评估指标的要求，并探讨了 recent technologies（如大型多模态模型）带来的新机遇。我们旨在整理该领域的现有研究，并启发未来对视觉识别模型可解释性的研究。

> In recent years, visual recognition methods have advanced significantly, finding applications across diverse fields. While researchers seek to understand the mechanisms behind the success of these models, there is also a growing impetus to deploy them in critical areas like autonomous driving and medical diagnostics to better diagnose failures, which promotes the development of interpretability research. This paper systematically reviews existing research on the interpretability of visual recognition models and proposes a taxonomy of methods from a human-centered perspective. The proposed taxonomy categorizes interpretable recognition methods based on Intent, Object, Presentation, and Methodology, thereby establishing a systematic and coherent set of grouping criteria for these XAI methods. Additionally, we summarize the requirements for evaluation metrics and explore new opportunities enabled by recent technologies, such as large multimodal models. We aim to organize existing research in this domain and inspire future investigations into the interpretability of visual recognition models.

[Arxiv](https://arxiv.org/abs/2507.11099)