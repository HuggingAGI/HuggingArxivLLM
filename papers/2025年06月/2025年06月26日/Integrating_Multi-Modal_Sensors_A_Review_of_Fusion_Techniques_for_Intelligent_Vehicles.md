# 多模态传感器融合：智能车辆中的融合技术综述

发布时间：2025年06月26日

`其他` `自动驾驶` `传感器融合`

> Integrating Multi-Modal Sensors: A Review of Fusion Techniques for Intelligent Vehicles

# 摘要

> 多传感器融合对自动驾驶感知能力的提升至关重要，它不仅克服了单一传感器的局限性，还实现了对环境的全面理解。本文首先将多传感器融合策略系统地划分为数据层面、特征层面和决策层面三类，并对与每种策略相对应的基于深度学习的方法进行了全面回顾。我们介绍了关键的多模态数据集，重点探讨了它们在应对恶劣天气和复杂城市环境等现实挑战中的适用性。此外，我们还深入分析了视觉语言模型（VLMs）、大型语言模型（LLMs）的融合趋势，以及传感器融合在端到端自动驾驶中的关键作用，强调了其在提升系统适应性和鲁棒性方面的巨大潜力。本文的研究为多传感器融合的当前方法和未来发展方向提供了有价值的见解，为自动驾驶技术的进一步发展指明了方向。


> Multi-sensor fusion plays a critical role in enhancing perception for autonomous driving, overcoming individual sensor limitations, and enabling comprehensive environmental understanding. This paper first formalizes multi-sensor fusion strategies into data-level, feature-level, and decision-level categories and then provides a systematic review of deep learning-based methods corresponding to each strategy. We present key multi-modal datasets and discuss their applicability in addressing real-world challenges, particularly in adverse weather conditions and complex urban environments. Additionally, we explore emerging trends, including the integration of Vision-Language Models (VLMs), Large Language Models (LLMs), and the role of sensor fusion in end-to-end autonomous driving, highlighting its potential to enhance system adaptability and robustness. Our work offers valuable insights into current methods and future directions for multi-sensor fusion in autonomous driving.

[Arxiv](https://arxiv.org/abs/2506.21885)