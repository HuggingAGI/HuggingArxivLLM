# # 双重分层评估：大型语言模型中的地缘政治与文化偏见

发布时间：2025年06月26日

`LLM应用` `社会学`

> A Dual-Layered Evaluation of Geopolitical and Cultural Bias in LLMs

# 摘要

> 随着大型语言模型（LLMs）在多种语言和文化背景下广泛应用，理解其在事实性和争议性场景中的行为至关重要，尤其是在其输出可能影响公众舆论或强化主流叙事的情况下。本文通过两阶段评估，定义了LLMs中的两种偏见：模型偏见（源于模型训练的偏见）和推理偏见（由查询语言引发的偏见）。

第一阶段评估LLMs在存在单一可验证答案的事实性问题上的表现，重点关注模型在不同查询语言间是否保持一致性。第二阶段则扩展到地缘政治敏感争议领域，探索回答中可能反映出的文化嵌入或意识形态一致的观点。我们构建了一个涵盖事实性和争议性问答的多语言、多类型问题的手工整理数据集。

研究结果显示，第一阶段表现出查询语言诱导的对齐现象，而第二阶段则反映了模型训练背景与查询语言之间的相互作用。本文为在中立和敏感主题上评估LLMs行为提供了一个结构化框架，为未来在多语言环境下的LLMs部署和文化敏感性评估实践提供了重要见解。

> As large language models (LLMs) are increasingly deployed across diverse linguistic and cultural contexts, understanding their behavior in both factual and disputable scenarios is essential, especially when their outputs may shape public opinion or reinforce dominant narratives. In this paper, we define two types of bias in LLMs: model bias (bias stemming from model training) and inference bias (bias induced by the language of the query), through a two-phase evaluation. Phase 1 evaluates LLMs on factual questions where a single verifiable answer exists, assessing whether models maintain consistency across different query languages. Phase 2 expands the scope by probing geopolitically sensitive disputes, where responses may reflect culturally embedded or ideologically aligned perspectives. We construct a manually curated dataset spanning both factual and disputable QA, across four languages and question types. The results show that Phase 1 exhibits query language induced alignment, while Phase 2 reflects an interplay between the model's training context and query language. This paper offers a structured framework for evaluating LLM behavior across neutral and sensitive topics, providing insights for future LLM deployment and culturally aware evaluation practices in multilingual contexts.

[Arxiv](https://arxiv.org/abs/2506.21881)