# TaleForge：互动式多模态个性化故事创作系统

发布时间：2025年06月26日

`LLM应用` `创意产业` `数字媒体`

> TaleForge: Interactive Multimodal System for Personalized Story Creation

# 摘要

> 讲故事是一项既私密又富有创造力的活动，但现有方法往往将用户视为被动的消费者，提供缺乏个性化的通用情节。这种做法削弱了参与感和沉浸感，尤其是在个人风格或外貌至关重要的情况下。我们推出TaleForge，这是一个结合大型语言模型（LLMs）与文本到图像扩散模型的个性化故事生成系统，能够将用户的面部图像融入故事情节和插图中。

TaleForge包含三个相互关联的模块：故事生成模块，LLMs根据用户提示生成故事情节和角色描述；个性化图像生成模块，将用户的面部特征和服装选择融入角色插图；以及背景生成模块，创建包含个性化角色的场景背景。

用户研究显示，当参与者作为主角出现时，他们的参与感和拥有感显著提升。参与者对系统的实时预览和直观控制给予了高度评价，但他们也希望能有更精细的叙事编辑工具。TaleForge通过将个性化文本与图像相结合，推动了多模态叙事的发展，为用户打造了沉浸式的、以用户为中心的体验。

> Storytelling is a deeply personal and creative process, yet existing methods often treat users as passive consumers, offering generic plots with limited personalization. This undermines engagement and immersion, especially where individual style or appearance is crucial. We introduce TaleForge, a personalized story-generation system that integrates large language models (LLMs) and text-to-image diffusion to embed users' facial images within both narratives and illustrations. TaleForge features three interconnected modules: Story Generation, where LLMs create narratives and character descriptions from user prompts; Personalized Image Generation, merging users' faces and outfit choices into character illustrations; and Background Generation, creating scene backdrops that incorporate personalized characters. A user study demonstrated heightened engagement and ownership when individuals appeared as protagonists. Participants praised the system's real-time previews and intuitive controls, though they requested finer narrative editing tools. TaleForge advances multimodal storytelling by aligning personalized text and imagery to create immersive, user-centric experiences.

[Arxiv](https://arxiv.org/abs/2506.21832)