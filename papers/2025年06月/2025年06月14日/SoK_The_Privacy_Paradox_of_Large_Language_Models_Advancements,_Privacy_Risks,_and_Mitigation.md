# 大型语言模型的隐私悖论现状报告：进展、隐私风险与缓解措施

发布时间：2025年06月14日

`LLM应用` `隐私保护` `数据安全`

> SoK: The Privacy Paradox of Large Language Models: Advancements, Privacy Risks, and Mitigation

# 摘要

> 大型语言模型（LLMs）是复杂的人工智能系统，能够以惊人精度生成类人文本。尽管LLMs推动了技术进步，但其通过抓取网络数据和收集用户交互数据进行开发，带来了敏感信息泄露风险。现有研究多关注训练数据的隐私影响，却忽视了用户交互和先进LLMs能力带来的隐私风险。本文旨在通过全面分析LLMs中的隐私问题，填补这一空白，并将挑战分为四类：(i) 训练数据隐私问题，(ii) 用户提示隐私挑战，(iii) 生成输出隐私漏洞，以及(iv) LLM代理隐私挑战。我们评估了现有缓解机制的有效性和局限性，并指出了未来研究方向。

> Large language models (LLMs) are sophisticated artificial intelligence systems that enable machines to generate human-like text with remarkable precision. While LLMs offer significant technological progress, their development using vast amounts of user data scraped from the web and collected from extensive user interactions poses risks of sensitive information leakage. Most existing surveys focus on the privacy implications of the training data but tend to overlook privacy risks from user interactions and advanced LLM capabilities. This paper aims to fill that gap by providing a comprehensive analysis of privacy in LLMs, categorizing the challenges into four main areas: (i) privacy issues in LLM training data, (ii) privacy challenges associated with user prompts, (iii) privacy vulnerabilities in LLM-generated outputs, and (iv) privacy challenges involving LLM agents. We evaluate the effectiveness and limitations of existing mitigation mechanisms targeting these proposed privacy challenges and identify areas for further research.

[Arxiv](https://arxiv.org/abs/2506.12699)