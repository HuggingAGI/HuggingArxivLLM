# 探索道德判断中的文化差异：大型语言模型如何助力跨文化研究

发布时间：2025年06月14日

`LLM应用` `社会学` `文化研究`

> Exploring Cultural Variations in Moral Judgments with Large Language Models

# 摘要

> 大型语言模型（LLMs）在许多任务中表现强劲，但它们能否准确捕捉文化多样化的道德价值观仍是一个疑问。本文探讨了LLMs是否能反映世界价值观调查和皮尤研究中心全球态度调查中所报告的道德态度变化。我们对比了GPT-2、OPT、BLOOMZ和Qwen等较小的单语和多语言模型，以及GPT-4o、GPT-4o-mini、Gemma-2-9b-it和Llama-3.3-70B-Instruct等较新的指令微调模型。通过基于对数概率的道德可接受性评分，我们将模型输出与涵盖广泛伦理主题的调查数据进行了关联分析。结果显示，许多较早或较小的模型与人类判断的相关性接近零或为负。而先进的指令微调模型，如GPT-4o和GPT-4o-mini，表现出了显著更高的正相关性，表明它们更能准确反映现实世界的道德态度。尽管通过扩大模型规模和指令微调可以提升与跨文化道德标准的对齐程度，但在某些主题和区域上仍存在挑战。我们从偏差分析、训练数据多样性以及提升LLMs文化敏感性的策略等方面深入探讨了这些发现。

> Large Language Models (LLMs) have shown strong performance across many tasks, but their ability to capture culturally diverse moral values remains unclear. In this paper, we examine whether LLMs can mirror variations in moral attitudes reported by two major cross-cultural surveys: the World Values Survey and the PEW Research Center's Global Attitudes Survey. We compare smaller, monolingual, and multilingual models (GPT-2, OPT, BLOOMZ, and Qwen) with more recent instruction-tuned models (GPT-4o, GPT-4o-mini, Gemma-2-9b-it, and Llama-3.3-70B-Instruct). Using log-probability-based moral justifiability scores, we correlate each model's outputs with survey data covering a broad set of ethical topics. Our results show that many earlier or smaller models often produce near-zero or negative correlations with human judgments. In contrast, advanced instruction-tuned models (including GPT-4o and GPT-4o-mini) achieve substantially higher positive correlations, suggesting they better reflect real-world moral attitudes. While scaling up model size and using instruction tuning can improve alignment with cross-cultural moral norms, challenges remain for certain topics and regions. We discuss these findings in relation to bias analysis, training data diversity, and strategies for improving the cultural sensitivity of LLMs.

[Arxiv](https://arxiv.org/abs/2506.12433)