# # AI伴侣的兴起：人机关系如何影响身心健康

发布时间：2025年06月14日

`LLM应用` `心理学` `社会学`

> The Rise of AI Companions: How Human-Chatbot Relationships Influence Well-Being

# 摘要

> 随着大型语言模型（LLMs）增强的聊天机器人越来越富有表现力和社交反应能力，许多用户开始与它们建立类似伴侣的关系，尤其是那些模拟情感共鸣对话者的AI伙伴。这种新兴的AI伴侣关系引发了一系列重要问题：它们能否满足通常由人类关系满足的社会需求？如何影响心理健康？当用户与非人类代理建立情感联系时，又会带来哪些新的风险？本研究旨在探索人们如何与AI伴侣互动，特别是Character.AI上的模拟伙伴，以及这种使用与用户心理福祉之间的关联。我们分析了1,131名用户和4,363次聊天会话（413,509条消息）的调查数据，由244名参与者提供，重点关注了三个使用维度：互动性质、互动强度和自我披露。通过结合自我报告的主要动机、开放式的伴侣关系描述以及标注的聊天记录，我们识别了用户与AI伴侣互动的模式及其与福祉的关联。研究发现，社交网络较小的人更有可能转向聊天机器人寻求陪伴，但以陪伴为导向的聊天机器人使用与较低的心理福祉一致相关，尤其是在人们更频繁地使用聊天机器人、进行更高程度的自我披露以及缺乏强大的人类社交支持时。尽管有些人转向聊天机器人来满足社会需求，但这些聊天机器人的使用并不能完全替代人类连接。因此，心理上的益处可能有限，对于社交孤立或情感脆弱的用户来说，这种关系可能带来风险。

> As large language models (LLMs)-enhanced chatbots grow increasingly expressive and socially responsive, many users are beginning to form companionship-like bonds with them, particularly with simulated AI partners designed to mimic emotionally attuned interlocutors. These emerging AI companions raise critical questions: Can such systems fulfill social needs typically met by human relationships? How do they shape psychological well-being? And what new risks arise as users develop emotional ties to non-human agents? This study investigates how people interact with AI companions, especially simulated partners on Character.AI, and how this use is associated with users' psychological well-being. We analyzed survey data from 1,131 users and 4,363 chat sessions (413,509 messages) donated by 244 participants, focusing on three dimensions of use: nature of the interaction, interaction intensity, and self-disclosure. By triangulating self-reports primary motivation, open-ended relationship descriptions, and annotated chat transcripts, we identify patterns in how users engage with AI companions and its associations with well-being. Findings suggest that people with smaller social networks are more likely to turn to chatbots for companionship, but that companionship-oriented chatbot usage is consistently associated with lower well-being, particularly when people use the chatbots more intensively, engage in higher levels of self-disclosure, and lack strong human social support. Even though some people turn to chatbots to fulfill social needs, these uses of chatbots do not fully substitute for human connection. As a result, the psychological benefits may be limited, and the relationship could pose risks for more socially isolated or emotionally vulnerable users.

[Arxiv](https://arxiv.org/abs/2506.12605)