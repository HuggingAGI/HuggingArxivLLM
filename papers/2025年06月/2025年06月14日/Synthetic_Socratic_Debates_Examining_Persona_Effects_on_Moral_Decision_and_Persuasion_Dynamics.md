# 模拟苏格拉底对话：研究角色对道德抉择与说服机制的影响

发布时间：2025年06月14日

`LLM应用

理由：这篇论文探讨了人格特质如何影响AI在道德推理和说服中的表现，属于将大型语言模型应用于具体领域（道德推理和说服）的研究，因此归类为LLM应用。` `AI伦理` `心理学`

> Synthetic Socratic Debates: Examining Persona Effects on Moral Decision and Persuasion Dynamics

# 摘要

> # 人格特质对AI道德推理与说服的影响：基于真实世界辩论的研究

随着大型语言模型（LLMs）在道德敏感领域的广泛应用，理解人格特质如何影响其道德推理和说服行为变得尤为重要。我们开展了一项开创性的研究，首次系统性地探讨了多维度人格特质在AI-AI辩论中的影响，针对131个基于真实关系的道德困境案例展开深入分析。

通过构建一个包含年龄、性别、国家、阶级、意识形态和个性特征的六维人格空间，我们模拟了AI代理之间的结构化辩论过程。研究发现，人格特质显著影响初始道德立场和辩论结果，其中政治意识形态和个性特征的影响最为突出。具体而言，具有开放性和自由倾向的人格特质在辩论中表现尤为突出，不仅能够达成更高共识，还取得了更高的胜率。

有趣的是，尽管基于Logit的信心度在辩论过程中逐步提升，但情感和可信度相关的诉求却呈现出下降趋势，这表明随着时间推移，辩论中的论点变得更加克制和理性。这些发现与心理学和文化研究领域的既有成果高度契合，进一步凸显了在AI道德推理评估中引入人格意识框架的必要性。


> As large language models (LLMs) are increasingly used in morally sensitive domains, it is crucial to understand how persona traits affect their moral reasoning and persuasive behavior. We present the first large-scale study of multi-dimensional persona effects in AI-AI debates over real-world moral dilemmas. Using a 6-dimensional persona space (age, gender, country, class, ideology, and personality), we simulate structured debates between AI agents over 131 relationship-based cases. Our results show that personas affect initial moral stances and debate outcomes, with political ideology and personality traits exerting the strongest influence. Persuasive success varies across traits, with liberal and open personalities reaching higher consensus and win rates. While logit-based confidence grows during debates, emotional and credibility-based appeals diminish, indicating more tempered argumentation over time. These trends mirror findings from psychology and cultural studies, reinforcing the need for persona-aware evaluation frameworks for AI moral reasoning.

[Arxiv](https://arxiv.org/abs/2506.12657)