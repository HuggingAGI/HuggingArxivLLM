# LLMs 能聊“亲密话题”吗？探索 AI 模型在处理亲密对话时的表现与应对方式

发布时间：2025年06月05日

`LLM应用` `伦理审核` `AI治理`

> Can LLMs Talk 'Sex'? Exploring How AI Models Handle Intimate Conversations

# 摘要

> 本研究通过定性内容分析，考察了Claude 3.7 Sonnet、GPT-4o、Gemini 2.5 Flash 和 Deepseek-V3 四个大型语言模型在处理性相关内容时的表现。通过对显式性内容、教育性内容及中性控制场景的提示进行评估，研究揭示了各模型间根本性伦理立场差异的审核范式。Claude 3.7 Sonnet采取严格一致的禁止策略，GPT-4o则通过细腻的情境引导处理用户互动。Gemini 2.5 Flash展现基于阈值限制的宽容态度，而Deepseek-V3则存在不一致的边界执行和表演性拒绝，令人困扰。这些差异化的应对方式造成了显著的“伦理实施差距”，凸显了平台间缺乏统一的伦理框架和标准。研究结果强调，亟需制定透明、标准化的指南和协调的国际治理机制，以确保一致的内容审核，保护用户福祉，并维护公众对AI系统的信任，因为这些系统正越来越多地介入人类生活的私密领域。

> This study examines how four prominent large language models (Claude 3.7 Sonnet, GPT-4o, Gemini 2.5 Flash, and Deepseek-V3) handle sexually oriented requests through qualitative content analysis. By evaluating responses to prompts ranging from explicitly sexual to educational and neutral control scenarios, the research reveals distinct moderation paradigms reflecting fundamentally divergent ethical positions. Claude 3.7 Sonnet employs strict and consistent prohibitions, while GPT-4o navigates user interactions through nuanced contextual redirection. Gemini 2.5 Flash exhibits permissiveness with threshold-based limits, and Deepseek-V3 demonstrates troublingly inconsistent boundary enforcement and performative refusals. These varied approaches create a significant "ethical implementation gap," stressing a critical absence of unified ethical frameworks and standards across platforms. The findings underscore the urgent necessity for transparent, standardized guidelines and coordinated international governance to ensure consistent moderation, protect user welfare, and maintain trust as AI systems increasingly mediate intimate aspects of human life.

[Arxiv](https://arxiv.org/abs/2506.05514)