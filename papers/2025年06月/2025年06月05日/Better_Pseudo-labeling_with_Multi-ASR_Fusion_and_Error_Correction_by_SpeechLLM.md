# 基于多ASR融合与语音大语言模型的错误校正实现更优伪标签生成

发布时间：2025年06月05日

`LLM应用` `语音识别`

> Better Pseudo-labeling with Multi-ASR Fusion and Error Correction by SpeechLLM

# 摘要

> 自动语音识别（ASR）模型的高效训练离不开高质量的转录数据。目前，生成大型无标签音频数据集的伪标签通常依赖复杂管道，通过多阶段处理整合多个ASR输出，但这一过程往往导致错误传播、信息丢失和优化分散。我们提出了一种创新的统一多ASR提示驱动框架，通过文本或语音基础的大型语言模型（LLMs）进行后处理，取代传统的投票或其他仲裁逻辑来协调集成输出。实验表明，与传统方法相比，新框架生成的伪标签在转录准确率上实现了显著提升。此外，我们利用不同方法生成的伪标签训练半监督ASR模型，结果表明，与基线方法相比，采用文本和语音LLM转录的模型性能得到了进一步优化。

> Automatic speech recognition (ASR) models rely on high-quality transcribed data for effective training. Generating pseudo-labels for large unlabeled audio datasets often relies on complex pipelines that combine multiple ASR outputs through multi-stage processing, leading to error propagation, information loss and disjoint optimization. We propose a unified multi-ASR prompt-driven framework using postprocessing by either textual or speech-based large language models (LLMs), replacing voting or other arbitration logic for reconciling the ensemble outputs. We perform a comparative study of multiple architectures with and without LLMs, showing significant improvements in transcription accuracy compared to traditional methods. Furthermore, we use the pseudo-labels generated by the various approaches to train semi-supervised ASR models for different datasets, again showing improved performance with textual and speechLLM transcriptions compared to baselines.

[Arxiv](https://arxiv.org/abs/2506.11089)