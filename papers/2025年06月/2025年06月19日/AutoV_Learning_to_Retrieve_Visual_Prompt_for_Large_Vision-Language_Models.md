# AutoV：为大型视觉-语言模型学习视觉提示的检索方法

发布时间：2025年06月19日

`LLM应用` `计算机视觉` `机器学习`

> AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models

# 摘要

> 受到大型语言模型（LLMs）中文本提示的启发，视觉提示被用于增强大型视觉语言模型（LVLMs）的推理能力。当前方法设计了启发式视觉提示，例如将文本查询引导的注意力热图叠加在原始输入图像上。然而，手动设计有效的视觉提示既困难又耗时，而且通常无法充分利用不同视觉提示的优势，导致性能欠佳。为此，我们提出了	extbf{AutoV}，它能够根据给定的文本查询和输入图像，从多个候选中自动选择最优的视觉提示。为了训练AutoV，我们开发了一个自动数据收集和标注管道，利用预训练的LVLM评估各种视觉提示。我们将一组视觉提示输入LVLM，并根据模型生成的预测损失对它们进行排序。利用这种排序作为监督信号，我们训练AutoV自动为LVLM选择最优的视觉提示。实验结果表明，AutoV提升了多种LVLM在多个流行图像理解任务中的性能。例如，配备AutoV的LLaVA-OV在LLaVA$^{	ext{Wild}}$上实现了$	extbf{1.7}\%$的准确率提升，而AutoV使Qwen2.5-VL在MMMU上提升了$	extbf{1.9}\%$，凸显了其作为LVLM最优视觉提示方法的潜力。

> Inspired by text prompts in large language models (LLMs), visual prompts have been explored to enhance the reasoning capabilities of large vision-language models (LVLMs). Current methods design heuristic visual prompts, such as overlaying a text-query-guided attention heatmap on the original input image. However, designing effective prompts manually is challenging and time-consuming, and it often fails to explore the benefits of different visual prompts, leading to sub-optimal performance. To this end, we propose \textbf{AutoV} that learns to automatically select the optimal visual prompt from various candidates based on given textual queries and the input image. To train AutoV, we developed an automatic data collection and labeling pipeline that evaluates various visual prompts with a pre-trained LVLM. We input a set of visual prompts into the LVLM and rank them according to the prediction losses generated by the model. Using the ranking as a supervision signal, we train AutoV to automatically choose the optimal visual prompt from various visual prompts for LVLMs. Experimental results indicate that AutoV enhances the performance of various LVLMs across multiple popular image understanding tasks. For instance, LLaVA-OV with AutoV achieves $\textbf{1.7}\%$ accuracy gain on LLaVA$^{\text{Wild}}$, and AutoV boosts Qwen2.5-VL by $\textbf{1.9}\%$ on MMMU, highlighting its potential as an optimal visual prompting method for LVLMs.

[Arxiv](https://arxiv.org/abs/2506.16112)