# 代码中的LLMs：对商业软件工程格局的影响

发布时间：2025年06月19日

`LLM应用` `软件工程` `信息安全`

> LLMs in Coding and their Impact on the Commercial Software Engineering Landscape

# 摘要

> 大型语言模型编码工具如今已成为软件工程的主流。然而，随着这些工具将人类努力提升到开发堆栈的更高层次，它们也带来了新的安全威胁：10%的实际提示会泄露私人数据，42%生成的代码片段隐藏着安全漏洞，而且模型甚至会“同意”错误的想法，这一特性被称为阿谀奉承（sycophancy）。我们主张，企业必须标记并审查每一行AI生成的代码，将提示和输出限制在私有或内部部署环境中，遵守新兴的安全法规，并添加能够检测阿谀奉承回答的测试，从而在不牺牲安全性和准确性的情况下提升开发速度。

> Large-language-model coding tools are now mainstream in software engineering. But as these same tools move human effort up the development stack, they present fresh dangers: 10% of real prompts leak private data, 42% of generated snippets hide security flaws, and the models can even ``agree'' with wrong ideas, a trait called sycophancy. We argue that firms must tag and review every AI-generated line of code, keep prompts and outputs inside private or on-premises deployments, obey emerging safety regulations, and add tests that catch sycophantic answers -- so they can gain speed without losing security and accuracy.

[Arxiv](https://arxiv.org/abs/2506.16653)