# GPT-4o能否像人类专家一样评估可用性？一探究竟！启发式评估中问题识别的对比研究

发布时间：2025年06月19日

`LLM应用` `人机交互` `用户体验`

> Can GPT-4o Evaluate Usability Like Human Experts? A Comparative Study on Issue Identification in Heuristic Evaluation

# 摘要

> 启发式评估是人机交互（HCI）中常用的一种方法，通过启发式原则检查界面并发现潜在问题。近年来，大型语言模型（LLMs）如GPT-4o已被引入HCI领域，用于辅助人物角色创建、创意构思以及半结构化访谈分析。然而，由于启发式评估需要对启发式原则有深刻理解并进行高度抽象思考，LLMs在执行此类任务时可能面临挑战。然而，先前研究尚未比较GPT-4o与HCI专家在基于网络系统的启发式评估中表现。因此，本研究旨在对比GPT-4o与人类专家在启发式评估中的结果。为此，我们选取了一个网络系统的截图集，并要求GPT-4o基于文献支持的提示，根据Nielsen的启发式原则进行启发式评估。结果显示，尽管GPT-4o发现了27个新问题，但专家识别的问题中仅有21.2%也被GPT-4o发现。研究发现，GPT-4o在与美学与极简设计以及系统与现实世界匹配相关的启发式方面表现较好，但在涉及灵活性、控制力和用户效率的启发式方面则表现较弱。此外，GPT-4o因幻觉和问题预测尝试，生成了多个误报。最后，我们总结了在启发式评估中使用GPT-4o时需注意的五个关键点。

> Heuristic evaluation is a widely used method in Human-Computer Interaction (HCI) to inspect interfaces and identify issues based on heuristics. Recently, Large Language Models (LLMs), such as GPT-4o, have been applied in HCI to assist in persona creation, the ideation process, and the analysis of semi-structured interviews. However, considering the need to understand heuristics and the high degree of abstraction required to evaluate them, LLMs may have difficulty conducting heuristic evaluation. However, prior research has not investigated GPT-4o's performance in heuristic evaluation compared to HCI experts in web-based systems. In this context, this study aims to compare the results of a heuristic evaluation performed by GPT-4o and human experts. To this end, we selected a set of screenshots from a web system and asked GPT-4o to perform a heuristic evaluation based on Nielsen's Heuristics from a literature-grounded prompt. Our results indicate that only 21.2% of the issues identified by human experts were also identified by GPT-4o, despite it found 27 new issues. We also found that GPT-4o performed better for heuristics related to aesthetic and minimalist design and match between system and real world, whereas it has difficulty identifying issues in heuristics related to flexibility, control, and user efficiency. Additionally, we noticed that GPT-4o generated several false positives due to hallucinations and attempts to predict issues. Finally, we highlight five takeaways for the conscious use of GPT-4o in heuristic evaluations.

[Arxiv](https://arxiv.org/abs/2506.16345)