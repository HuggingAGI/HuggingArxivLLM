# 大型语言模型：近乎最优的决策者与独特的非人类学习行为。研究表明，这些模型在复杂决策任务中展现出近乎最优的决策能力，并且具备独特的学习行为，这种学习行为与人类截然不同。

发布时间：2025年06月19日

`LLM应用` `人工智能` `决策科学`

> Large Language Models are Near-Optimal Decision-Makers with a Non-Human Learning Behavior

# 摘要

> 人类决策构成了社会与文明的基石，但我们正站在一个转折点上，未来诸多决策将交由人工智能承担。大型语言模型（LLMs）的问世彻底改变了人工智能辅助决策的面貌，但与人类相比，它们学习决策的过程仍是个谜。本研究从现实决策的三大核心维度——不确定性、风险和情境转换——入手，评估了五款顶尖大型语言模型的决策行为。借助三个经典心理学实验任务，我们对大型语言模型与360名新招募的参与者进行了对比测试。结果显示，大型语言模型在各项任务中均超越人类，接近最优水平。然而，它们的决策过程与人类截然不同。一方面，这证明了大型语言模型在应对不确定性、权衡风险和适应变化方面的能力。另一方面，这种差异也警示我们，过度依赖AI替代人类判断存在风险，亟需深入探究。

> Human decision-making belongs to the foundation of our society and civilization, but we are on the verge of a future where much of it will be delegated to artificial intelligence. The arrival of Large Language Models (LLMs) has transformed the nature and scope of AI-supported decision-making; however, the process by which they learn to make decisions, compared to humans, remains poorly understood. In this study, we examined the decision-making behavior of five leading LLMs across three core dimensions of real-world decision-making: uncertainty, risk, and set-shifting. Using three well-established experimental psychology tasks designed to probe these dimensions, we benchmarked LLMs against 360 newly recruited human participants. Across all tasks, LLMs often outperformed humans, approaching near-optimal performance. Moreover, the processes underlying their decisions diverged fundamentally from those of humans. On the one hand, our finding demonstrates the ability of LLMs to manage uncertainty, calibrate risk, and adapt to changes. On the other hand, this disparity highlights the risks of relying on them as substitutes for human judgment, calling for further inquiry.

[Arxiv](https://arxiv.org/abs/2506.16163)