# 大型语言模型时代下的人工智能研究质量评估：优缺点及系统性影响

发布时间：2025年06月09日

`LLM应用` `文献计量学` `研究评估`

> Research quality evaluation by AI in the era of Large Language Models: Advantages, disadvantages, and systemic effects

# 摘要

> 像 ChatGPT 这样的人工智能技术正在挑战文献计量学在研究质量评估中的主导地位。这些技术已被至少一个研究质量评估系统采用，且有迹象表明许多同行评审人员也在非正式地使用它们。鉴于文献计量学在研究评估中的应用仍存争议，本文探讨了 AI 生成质量评分的利弊。技术层面，基于大型语言模型（LLMs）的生成式 AI 在准确性（与人工评分关联度更高）和覆盖范围（更多领域、更近年份）等关键维度上与文献计量学相当甚至更优，可能揭示更多研究质量特征。然而，如同文献计量学，当前 LLM 并未“测量”研究质量。消极方面，LLM 的偏见在研究评估中尚不明确，且其评分不如引用次数透明。系统层面，核心问题是引入基于 LLM 的指标将如何改变研究者行为。文献计量学鼓励研究者瞄准高影响因子期刊或追求高引用文章，而基于 LLM 的指标可能促使他们撰写误导性摘要并夸大研究，以博得 AI 青睐。此外，若 AI 生成的期刊指标取代影响因子，期刊可能默许研究者夸大其研究，威胁学术记录的严谨性。

> Artificial Intelligence (AI) technologies like ChatGPT now threaten bibliometrics as the primary generators of research quality indicators. They are already used in at least one research quality evaluation system and evidence suggests that they are used informally by many peer reviewers. Since using bibliometrics to support research evaluation continues to be controversial, this article reviews the corresponding advantages and disadvantages of AI-generated quality scores. From a technical perspective, generative AI based on Large Language Models (LLMs) equals or surpasses bibliometrics in most important dimensions, including accuracy (mostly higher correlations with human scores), and coverage (more fields, more recent years) and may reflect more research quality dimensions. Like bibliometrics, current LLMs do not "measure" research quality, however. On the clearly negative side, LLM biases are currently unknown for research evaluation, and LLM scores are less transparent than citation counts. From a systemic perspective, the key issue is how introducing LLM-based indicators into research evaluation will change the behaviour of researchers. Whilst bibliometrics encourage some authors to target journals with high impact factors or to try to write highly cited work, LLM-based indicators may push them towards writing misleading abstracts and overselling their work in the hope of impressing the AI. Moreover, if AI-generated journal indicators replace impact factors, then this would encourage journals to allow authors to oversell their work in abstracts, threatening the integrity of the academic record.

[Arxiv](https://arxiv.org/abs/2506.07748)