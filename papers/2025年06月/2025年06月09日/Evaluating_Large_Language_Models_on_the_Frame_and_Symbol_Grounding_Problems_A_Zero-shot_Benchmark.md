# 大型语言模型在框架与符号 grounding 问题上的零样本评测

发布时间：2025年06月09日

`LLM理论` `人工智能`

> Evaluating Large Language Models on the Frame and Symbol Grounding Problems: A Zero-shot Benchmark

# 摘要

> 大型语言模型（LLMs）的最新进展重新点燃了围绕人工智能的哲学辩论。历史上，两大核心难题——框架问题与符号接地问题——一直被认为是传统符号AI无法解决的。本研究探讨现代LLMs是否具备应对这些难题的能力。为此，我设计了两个基准任务，分别针对每个问题的核心，并在零-shot条件下测试了13个知名LLMs（包括开源和闭源模型），每个模型进行了五次试验，评估其输出质量。评估标准包括上下文推理、语义连贯性和信息过滤能力。结果显示，尽管开源模型因模型规模、量化及指令微调的差异在性能上存在波动，但部分闭源模型却始终表现优异。这表明，部分现代LLMs可能正在获得足够的能力，能够对这些长期存在的理论挑战给出有意义且稳定的回答。

> Recent advancements in large language models (LLMs) have revitalized philosophical debates surrounding artificial intelligence. Two of the most fundamental challenges - namely, the Frame Problem and the Symbol Grounding Problem - have historically been viewed as unsolvable within traditional symbolic AI systems. This study investigates whether modern LLMs possess the cognitive capacities required to address these problems. To do so, I designed two benchmark tasks reflecting the philosophical core of each problem, administered them under zero-shot conditions to 13 prominent LLMs (both closed and open-source), and assessed the quality of the models' outputs across five trials each. Responses were scored along multiple criteria, including contextual reasoning, semantic coherence, and information filtering. The results demonstrate that while open-source models showed variability in performance due to differences in model size, quantization, and instruction tuning, several closed models consistently achieved high scores. These findings suggest that select modern LLMs may be acquiring capacities sufficient to produce meaningful and stable responses to these long-standing theoretical challenges.

[Arxiv](https://arxiv.org/abs/2506.07896)