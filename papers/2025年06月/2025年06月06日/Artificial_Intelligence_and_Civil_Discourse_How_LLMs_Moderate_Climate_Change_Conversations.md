# 人工智能与文明对话：LLMs如何引导气候变化讨论

发布时间：2025年06月06日

`LLM应用` `社交媒体` `公共话语`

> Artificial Intelligence and Civil Discourse: How LLMs Moderate Climate Change Conversations

# 摘要

> 大型语言模型（LLMs）正在深刻影响在线平台和数字交流空间，特别是在气候变等有争议领域，其对公共话语的潜在影响亟需系统研究。本研究聚焦LLMs如何通过独特沟通行为自然调节气候变化对话。我们选取五款先进模型——三款开源LLMs（Gemma、Llama 3和Llama 3.3）及两款商用系统（OpenAI的GPT-4和Anthropic的Claude 3.5）——对社交媒体平台上LLMs与人类用户的对话展开比较分析。通过情感分析，我们发现：首先，LLMs始终维持情感中立，其情感极化程度远低于人类用户；其次，LLMs在各类情境下均保持较低情感强度，从而在对话中形成稳定效果。这些发现表明，LLMs具备内在调节能力，可显著提升有争议话题的公共讨论质量。这项研究不仅深化了我们对AI如何支持更文明、更具建设性气候对话的理解，更为设计AI辅助交流工具提供了重要参考。

> As large language models (LLMs) become increasingly integrated into online platforms and digital communication spaces, their potential to influence public discourse - particularly in contentious areas like climate change - requires systematic investigation. This study examines how LLMs naturally moderate climate change conversations through their distinct communicative behaviors. We conduct a comparative analysis of conversations between LLMs and human users on social media platforms, using five advanced models: three open-source LLMs (Gemma, Llama 3, and Llama 3.3) and two commercial systems (GPT-4o by OpenAI and Claude 3.5 by Anthropic). Through sentiment analysis, we assess the emotional characteristics of responses from both LLMs and humans. The results reveal two key mechanisms through which LLMs moderate discourse: first, LLMs consistently display emotional neutrality, showing far less polarized sentiment than human users. Second, LLMs maintain lower emotional intensity across contexts, creating a stabilizing effect in conversations. These findings suggest that LLMs possess inherent moderating capacities that could improve the quality of public discourse on controversial topics. This research enhances our understanding of how AI might support more civil and constructive climate change discussions and informs the design of AI-assisted communication tools.

[Arxiv](https://arxiv.org/abs/2506.12077)