# 借助生成式 AI 提升编程教育竞赛中的自动评估效果

发布时间：2025年06月06日

`LLM应用` `教育技术`

> Leveraging Generative AI for Enhancing Automated Assessment in Programming Education Contests

# 摘要

> 编程竞赛对培养学习者的计算思维和算法能力至关重要。然而，为有效评估编程解决方案生成全面测试用例仍是一项耗时耗力的挑战，尤其是对教育工作者而言。本文提出了一种创新的基于NLP的方法，利用生成式AI（大型语言模型）自动创建高质量的编程竞赛测试用例。我们通过多个多样化数据集对这种方法进行了全面评估，包括罗马尼亚信息学奥林匹克（OJI）五年级学生的25年数据、Kilonova.ro平台近期竞赛数据以及国际信息学奥林匹克团队赛（IIOT）的数据。结果显示，AI生成的测试用例显著提升了评估效果，在67%的OJI五年级编程问题中发现了之前未被发现的错误。这些改进突显了我们在形成性评估中技术的补充教育价值。通过公开分享我们的提示、翻译后的数据集和方法，我们为教育工作者和竞赛组织者提供了实用的基于NLP的工具，帮助他们提升评估质量、减轻工作负担并深入洞察学习者表现。

> Competitive programming contests play a crucial role in cultivating computational thinking and algorithmic skills among learners. However, generating comprehensive test cases to effectively assess programming solutions remains resource-intensive and challenging for educators. This paper introduces an innovative NLP-driven method leveraging generative AI (large language models) to automate the creation of high-quality test cases for competitive programming assessments. We extensively evaluated our approach on diverse datasets, including 25 years of Romanian Informatics Olympiad (OJI) data for 5th graders, recent competitions hosted on the Kilonova.ro platform, and the International Informatics Olympiad in Teams (IIOT). Our results demonstrate that AI-generated test cases substantially enhanced assessments, notably identifying previously undetected errors in 67% of the OJI 5th grade programming problems. These improvements underscore the complementary educational value of our technique in formative assessment contexts. By openly sharing our prompts, translated datasets, and methodologies, we offer practical NLP-based tools that educators and contest organizers can readily integrate to enhance assessment quality, reduce workload, and deepen insights into learner performance.

[Arxiv](https://arxiv.org/abs/2506.05990)