# 基于LLM的嵌入方法从社交媒体文本数据中进行可解释的抑郁症检测

发布时间：2025年06月06日

`LLM应用` `心理健康` `社交媒体`

> Interpretable Depression Detection from Social Media Text Using LLM-Derived Embeddings

# 摘要

> 准确且可解释地识别社交媒体中的抑郁语言，对早期干预心理健康问题至关重要，对临床实践和公共卫生工作都有重要影响。本文探讨了大型语言模型（LLMs）和传统机器学习分类器在三个涉及社交媒体数据的分类任务中的表现，包括二分类抑郁分类、抑郁程度分类，以及抑郁、PTSD和焦虑的鉴别诊断分类。研究比较了零样本学习的LLMs与基于传统文本嵌入和LLM生成摘要嵌入训练的监督分类器。实验结果表明，零样本学习的LLMs在二分类任务中表现优异，但在精细的有序分类任务中表现欠佳。而基于LLM生成摘要嵌入训练的分类器在分类任务中表现出色，甚至在某些情况下优于传统文本嵌入模型。研究结果凸显了LLMs在心理健康预测中的优势，并为更好利用其零样本学习能力和上下文感知的摘要技术提供了方向。

> Accurate and interpretable detection of depressive language in social media is useful for early interventions of mental health conditions, and has important implications for both clinical practice and broader public health efforts. In this paper, we investigate the performance of large language models (LLMs) and traditional machine learning classifiers across three classification tasks involving social media data: binary depression classification, depression severity classification, and differential diagnosis classification among depression, PTSD, and anxiety. Our study compares zero-shot LLMs with supervised classifiers trained on both conventional text embeddings and LLM-generated summary embeddings. Our experiments reveal that while zero-shot LLMs demonstrate strong generalization capabilities in binary classification, they struggle with fine-grained ordinal classifications. In contrast, classifiers trained on summary embeddings generated by LLMs demonstrate competitive, and in some cases superior, performance on the classification tasks, particularly when compared to models using traditional text embeddings. Our findings demonstrate the strengths of LLMs in mental health prediction, and suggest promising directions for better utilization of their zero-shot capabilities and context-aware summarization techniques.

[Arxiv](https://arxiv.org/abs/2506.06616)