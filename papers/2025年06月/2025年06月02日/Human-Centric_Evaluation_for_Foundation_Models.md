# # 以人为本的大模型评测
Human-Centric Evaluation for Foundation Models

发布时间：2025年06月02日

`LLM应用

摘要主要讨论了对大型语言模型（LLM）的评估方法，特别是提出了一种以人为本的主观评估框架（HCE），并进行了大规模的实验来评估不同模型的表现。这属于对LLM的实际应用和性能评估，因此归类为LLM应用。`

> Human-Centric Evaluation for Foundation Models

# 摘要

> 目前，几乎所有对基础模型的评估都聚焦于客观指标，通过问答表现来定义模型能力。虽然这种方法能快速评估模型性能，却无法反映真实的人类体验。为填补这一空白，我们提出了一种以人为本的主观评估（HCE）框架，重点关注问题解决能力、信息质量和交互体验三大核心维度。通过与 Deepseek R1、OpenAI o3 mini、Grok 3 和 Gemini 2.5 模型合作，我们进行了超过 540 次基于参与者的评估实验，让人类与模型共同完成开放性研究任务，从而构建了一个全面的主观数据集。该数据集涵盖了多学科领域的多样化用户反馈，揭示了不同模型的独特优势和适应性。研究结果显示，Grok 3 表现最优，其次是 Deepseek R1 和 Gemini 2.5，而 OpenAI o3 mini 则稍显逊色。本研究通过提供全新框架和丰富数据集，不仅革新了主观评估方法，更为标准化和自动化的评估体系奠定了基础，推动了 LLM 在研究与实际应用中的发展。我们的数据集链接为 https://github.com/yijinguo/Human-Centric-Evaluation。
    

> Currently, nearly all evaluations of foundation models focus on objective metrics, emphasizing quiz performance to define model capabilities. While this model-centric approach enables rapid performance assessment, it fails to reflect authentic human experiences. To address this gap, we propose a Human-Centric subjective Evaluation (HCE) framework, focusing on three core dimensions: problem-solving ability, information quality, and interaction experience. Through experiments involving Deepseek R1, OpenAI o3 mini, Grok 3, and Gemini 2.5, we conduct over 540 participant-driven evaluations, where humans and models collaborate on open-ended research tasks, yielding a comprehensive subjective dataset. This dataset captures diverse user feedback across multiple disciplines, revealing distinct model strengths and adaptability. Our findings highlight Grok 3's superior performance, followed by Deepseek R1 and Gemini 2.5, with OpenAI o3 mini lagging behind. By offering a novel framework and a rich dataset, this study not only enhances subjective evaluation methodologies but also lays the foundation for standardized, automated assessments, advancing LLM development for research and practical scenarios. Our dataset link is https://github.com/yijinguo/Human-Centric-Evaluation.

[Arxiv](https://arxiv.org/abs/2506.01793)