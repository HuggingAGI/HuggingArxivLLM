# TracLLM：长上下文大语言模型的通用归因框架

发布时间：2025年06月04日

`LLM应用` `信息检索`

> TracLLM: A Generic Framework for Attributing Long Context LLMs

# 摘要

> 长上下文大型语言模型（LLMs）在RAG、智能体和各类LLM集成应用中发挥重要作用。这些模型能够根据指令和长上下文（如文档、PDF或网页）生成基于上下文的输出，力求更准确、及时且可验证，同时减少不实和无依据的陈述。这一功能引出了一个重要研究问题：如何在上下文中精准定位对LLM输出贡献最大的关键文本（如句子或段落）？我们将其称为上下文回溯，这一技术在实践中具有广泛应用价值，包括1）调试LLM系统，2）分析针对LLM的攻击（如提示注入或知识污染攻击）的后果，3）提升用户对LLM输出的信任度。然而，现有特征归因方法（如Shapley）在长上下文LLM上的表现不尽如人意，且计算成本高昂。为此，我们开发了TracLLM——首个专为长上下文LLM设计的通用上下文回溯框架。TracLLM通过创新算法和优化技术，显著提升了上下文回溯的效率与准确性。我们的评估结果证实，TracLLM能够精准识别长上下文中影响LLM输出的关键内容。更多代码与数据，请访问：https://github.com/Wang-Yanting/TracLLM。


> Long context large language models (LLMs) are deployed in many real-world applications such as RAG, agent, and broad LLM-integrated applications. Given an instruction and a long context (e.g., documents, PDF files, webpages), a long context LLM can generate an output grounded in the provided context, aiming to provide more accurate, up-to-date, and verifiable outputs while reducing hallucinations and unsupported claims. This raises a research question: how to pinpoint the texts (e.g., sentences, passages, or paragraphs) in the context that contribute most to or are responsible for the generated output by an LLM? This process, which we call context traceback, has various real-world applications, such as 1) debugging LLM-based systems, 2) conducting post-attack forensic analysis for attacks (e.g., prompt injection attack, knowledge corruption attacks) to an LLM, and 3) highlighting knowledge sources to enhance the trust of users towards outputs generated by LLMs. When applied to context traceback for long context LLMs, existing feature attribution methods such as Shapley have sub-optimal performance and/or incur a large computational cost. In this work, we develop TracLLM, the first generic context traceback framework tailored to long context LLMs. Our framework can improve the effectiveness and efficiency of existing feature attribution methods. To improve the efficiency, we develop an informed search based algorithm in TracLLM. We also develop contribution score ensemble/denoising techniques to improve the accuracy of TracLLM. Our evaluation results show TracLLM can effectively identify texts in a long context that lead to the output of an LLM. Our code and data are at: https://github.com/Wang-Yanting/TracLLM.

[Arxiv](https://arxiv.org/abs/2506.04202)