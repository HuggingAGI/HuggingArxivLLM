# # 评估苹果智能隐私写作工具抵御大语言模型推理攻击的能力：早期数据集的见解

发布时间：2025年06月04日

`LLM应用` `隐私保护` `用户隐私`

> Evaluating Apple Intelligence's Writing Tools for Privacy Against Large Language Model-Based Inference Attacks: Insights from Early Datasets

# 摘要

> 滥用大型语言模型（LLMs）通过文本进行情感推断的恶意行为，即情感推断攻击，严重威胁用户隐私。本研究聚焦于苹果智能写作工具（集成于iPhone、iPad和MacBook）通过文本重写和语气调整等手段缓解此类风险的潜力。我们专门开发了新型早期数据集，实证分析不同文本修改对LLM基础检测的影响。这一发现凸显了苹果智能写作工具作为隐私保护机制的潜力。我们的研究为未来开发动态中和敏感情感内容的自适应重写系统奠定了基础，从而提升用户隐私保护水平。据我们所知，这是首次在隐私保护背景下对苹果智能文本修改工具进行实证研究，旨在开发基于设备、以用户为中心的隐私保护机制，抵御针对已部署系统的LLM基础高级推断攻击。

> The misuse of Large Language Models (LLMs) to infer emotions from text for malicious purposes, known as emotion inference attacks, poses a significant threat to user privacy. In this paper, we investigate the potential of Apple Intelligence's writing tools, integrated across iPhone, iPad, and MacBook, to mitigate these risks through text modifications such as rewriting and tone adjustment. By developing early novel datasets specifically for this purpose, we empirically assess how different text modifications influence LLM-based detection. This capability suggests strong potential for Apple Intelligence's writing tools as privacy-preserving mechanisms. Our findings lay the groundwork for future adaptive rewriting systems capable of dynamically neutralizing sensitive emotional content to enhance user privacy. To the best of our knowledge, this research provides the first empirical analysis of Apple Intelligence's text-modification tools within a privacy-preservation context with the broader goal of developing on-device, user-centric privacy-preserving mechanisms to protect against LLMs-based advanced inference attacks on deployed systems.

[Arxiv](https://arxiv.org/abs/2506.03870)