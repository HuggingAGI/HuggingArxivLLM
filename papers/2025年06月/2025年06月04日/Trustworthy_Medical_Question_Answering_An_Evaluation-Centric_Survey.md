# 可信医学问答系统：评估视角的综述

发布时间：2025年06月04日

`LLM应用` `可信AI`

> Trustworthy Medical Question Answering: An Evaluation-Centric Survey

# 摘要

> 医疗问答系统的可信度对保障患者安全、临床效果和用户信心至关重要。随着大型语言模型（LLMs）在医疗领域应用的日益普及，其响应的可靠性直接关系到临床决策和患者预后。然而，医疗问答系统要实现全面可信度面临诸多挑战，这源于医疗数据的复杂性、临床场景的紧迫性以及可信AI的多维度特性。本研究系统探讨了医疗问答系统中的六个关键可信度维度，即事实性、稳健性、公平性、安全性、可解释性和校准性。我们回顾了现有基于LLM的医疗问答系统在各个维度上的评估方法，并对专门用于评估这些维度的主要基准进行了整理和比较。此外，我们分析了以评估为导向的技术如何推动模型改进，如增强型检索 grounding、对抗性微调和安全对齐等方法。最后，我们指出了当前仍存在的开放性挑战，包括可扩展的专家评估、多维度综合指标以及真实世界部署研究等，并提出了未来的研究方向，以推动基于LLM的医疗问答系统实现更安全、可靠和透明的应用。

> Trustworthiness in healthcare question-answering (QA) systems is important for ensuring patient safety, clinical effectiveness, and user confidence. As large language models (LLMs) become increasingly integrated into medical settings, the reliability of their responses directly influences clinical decision-making and patient outcomes. However, achieving comprehensive trustworthiness in medical QA poses significant challenges due to the inherent complexity of healthcare data, the critical nature of clinical scenarios, and the multifaceted dimensions of trustworthy AI. In this survey, we systematically examine six key dimensions of trustworthiness in medical QA, i.e., Factuality, Robustness, Fairness, Safety, Explainability, and Calibration. We review how each dimension is evaluated in existing LLM-based medical QA systems. We compile and compare major benchmarks designed to assess these dimensions and analyze evaluation-guided techniques that drive model improvements, such as retrieval-augmented grounding, adversarial fine-tuning, and safety alignment. Finally, we identify open challenges-such as scalable expert evaluation, integrated multi-dimensional metrics, and real-world deployment studies-and propose future research directions to advance the safe, reliable, and transparent deployment of LLM-powered medical QA.

[Arxiv](https://arxiv.org/abs/2506.03659)