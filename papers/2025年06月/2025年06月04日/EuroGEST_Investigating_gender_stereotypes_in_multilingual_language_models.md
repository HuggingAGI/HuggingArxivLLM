# EuroGEST: 探究多语言模型中的性别刻板印象

发布时间：2025年06月04日

`LLM应用` `社会学` `人工智能`

> EuroGEST: Investigating gender stereotypes in multilingual language models

# 摘要

> 尽管大型语言模型越来越多地支持多种语言，但目前用于衡量性别偏见的基准测试大多仍以英语为中心。为此，我们推出了 EuroGEST 数据集，专门用于衡量大型语言模型在英语和 29 种欧洲语言中的性别刻板印象推理能力。该数据集基于涵盖 16 种性别刻板印象的现有专家知识基准，并通过翻译工具、质量评估指标和形态学启发式方法进行了扩展。人工评估证实，我们的数据生成方法在翻译和性别标签的跨语言准确性方面表现优异。我们使用 EuroGEST 评估了来自六个模型家族的 24 种多语言模型，结果显示所有模型在所有语言中最强的刻板印象是：女性被描述为 	extit{美丽的}、	extit{富有同理心的} 和 	extit{整洁的}，而男性则被描述为 	extit{领导者}、	extit{强壮的}、	extit{坚韧的} 和 	extit{专业的}。此外，我们发现模型规模越大，性别刻板印象越强烈，而指令微调并不能始终如一地减少性别偏见。这项研究不仅凸显了对大型语言模型公平性进行多语言研究的必要性，还提供了可扩展的方法和资源来审核跨语言的性别偏见。

> Large language models increasingly support multiple languages, yet most benchmarks for gender bias remain English-centric. We introduce EuroGEST, a dataset designed to measure gender-stereotypical reasoning in LLMs across English and 29 European languages. EuroGEST builds on an existing expert-informed benchmark covering 16 gender stereotypes, expanded in this work using translation tools, quality estimation metrics, and morphological heuristics. Human evaluations confirm that our data generation method results in high accuracy of both translations and gender labels across languages. We use EuroGEST to evaluate 24 multilingual language models from six model families, demonstrating that the strongest stereotypes in all models across all languages are that women are \textit{beautiful,} \textit{empathetic} and \textit{neat} and men are \textit{leaders}, \textit{strong, tough} and \textit{professional}. We also show that larger models encode gendered stereotypes more strongly and that instruction finetuning does not consistently reduce gendered stereotypes. Our work highlights the need for more multilingual studies of fairness in LLMs and offers scalable methods and resources to audit gender bias across languages.

[Arxiv](https://arxiv.org/abs/2506.03867)