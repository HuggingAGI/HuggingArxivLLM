# # 探索多模态图大型语言模型之路

发布时间：2025年06月11日

`LLM理论` `多模态图`

> Towards Multi-modal Graph Large Language Model

# 摘要

> 多模态图在现实应用中无处不在，它们整合了多样化的多模态特征与关系。然而，现有的多模态图学习方法通常针对特定任务和数据从头训练，难以实现跨任务和跨数据的泛化。为填补这一空白，我们探索了多模态图大语言模型（MG-LLM）的潜力，提出了一种统一的多模态图数据、任务和模型框架，揭示了多模态图的多粒度和多尺度特性。

具体而言，我们提出了MG-LLM的五大关键特性：1）统一的多模态结构与属性空间，2）处理多样化多模态图任务的能力，3）多模态图的上下文学习，4）与自然语言的多模态交互，5）多模态图推理。我们详细分析了实现这些特性的关键挑战，回顾了相关研究进展，并指出了未来研究的突破方向。最后，我们总结了适用于模型训练的多种多模态图数据集。我们相信，本文将为推动多模态图数据和任务的泛化研究提供重要参考。

> Multi-modal graphs, which integrate diverse multi-modal features and relations, are ubiquitous in real-world applications. However, existing multi-modal graph learning methods are typically trained from scratch for specific graph data and tasks, failing to generalize across various multi-modal graph data and tasks. To bridge this gap, we explore the potential of Multi-modal Graph Large Language Models (MG-LLM) to unify and generalize across diverse multi-modal graph data and tasks. We propose a unified framework of multi-modal graph data, task, and model, discovering the inherent multi-granularity and multi-scale characteristics in multi-modal graphs. Specifically, we present five key desired characteristics for MG-LLM: 1) unified space for multi-modal structures and attributes, 2) capability of handling diverse multi-modal graph tasks, 3) multi-modal graph in-context learning, 4) multi-modal graph interaction with natural language, and 5) multi-modal graph reasoning. We then elaborate on the key challenges, review related works, and highlight promising future research directions towards realizing these ambitious characteristics. Finally, we summarize existing multi-modal graph datasets pertinent for model training. We believe this paper can contribute to the ongoing advancement of the research towards MG-LLM for generalization across multi-modal graph data and tasks.

[Arxiv](https://arxiv.org/abs/2506.09738)