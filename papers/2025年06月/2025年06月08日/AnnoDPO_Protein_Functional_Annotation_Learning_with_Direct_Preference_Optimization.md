# AnnoDPO：通过直接优化偏好实现蛋白质功能注释学习

发布时间：2025年06月08日

`其他` `蛋白质功能预测` `生物信息学`

> AnnoDPO: Protein Functional Annotation Learning with Direct Preference Optimization

# 摘要

> 蛋白质功能的解析仍是蛋白质表示学习中的根本挑战。蛋白质语言模型（PLMs）在功能注释任务中面临两大难题：数量庞大的注释类别和生物本体中注释实例的高度不平衡分布。受强化学习从人类反馈（RLHF）在大型语言模型（LLM）对齐方面取得的显著成功启发，我们提出了AnnoDPO，这是一个基于直接偏好优化（DPO）的新型多模态蛋白质功能预测框架。通过偏好对齐的训练目标，AnnoDPO有效应对了注释稀缺和类别不平衡的双重挑战，为蛋白质表示学习中生物知识的整合开辟了新的研究范式。

> Deciphering protein function remains a fundamental challenge in protein representation learning. The task presents significant difficulties for protein language models (PLMs) due to the sheer volume of functional annotation categories and the highly imbalanced distribution of annotated instances across biological ontologies. Inspired by the remarkable success of reinforcement learning from human feedback (RLHF) in large language model (LLM) alignment, we propose AnnoDPO, a novel multi-modal framework for protein function prediction that leverages Direct Preference Optimization (DPO) to enhance annotation learning. Our methodology addresses the dual challenges of annotation scarcity and category imbalance through preference-aligned training objectives, establishing a new paradigm for biological knowledge integration in protein representation learning.

[Arxiv](https://arxiv.org/abs/2506.07035)