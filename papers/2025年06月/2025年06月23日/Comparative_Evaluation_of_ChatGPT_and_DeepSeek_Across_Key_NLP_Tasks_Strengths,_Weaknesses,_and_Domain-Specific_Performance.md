# # ChatGPT 和 DeepSeek 在关键 NLP 任务中的对比评估：优势、劣势及领域特定性能表现

发布时间：2025年06月23日

`LLM应用` `模型评估`

> Comparative Evaluation of ChatGPT and DeepSeek Across Key NLP Tasks: Strengths, Weaknesses, and Domain-Specific Performance

# 摘要

> 大型语言模型在自然语言处理领域的广泛应用引发了对其在不同应用场景中有效性评估的广泛关注。尽管像ChatGPT和DeepSeek这样的模型在许多NLP领域表现优异，但进行全面评估至关重要，以深入了解它们的优势、劣势和领域特定能力。这一点尤为重要，因为这些模型被应用于从情感分析到更复杂的任务（如文本蕴含和翻译）等多种任务。本研究旨在对ChatGPT和DeepSeek在五个关键NLP任务上进行评估：情感分析、主题分类、文本摘要、机器翻译和文本蕴含。为确保公平性并减少变异性，采用了结构化的实验协议。两种模型均在相同的中性提示下进行测试，并在每个任务上使用两个基准数据集进行评估，涵盖新闻、评论以及正式/非正式文本等领域。结果显示，DeepSeek在分类稳定性和逻辑推理方面表现突出，而ChatGPT在需要细微理解与灵活性的任务中表现更佳。这些发现为根据任务需求选择合适的大型语言模型提供了宝贵的见解。

> The increasing use of large language models (LLMs) in natural language processing (NLP) tasks has sparked significant interest in evaluating their effectiveness across diverse applications. While models like ChatGPT and DeepSeek have shown strong results in many NLP domains, a comprehensive evaluation is needed to understand their strengths, weaknesses, and domain-specific abilities. This is critical as these models are applied to various tasks, from sentiment analysis to more nuanced tasks like textual entailment and translation. This study aims to evaluate ChatGPT and DeepSeek across five key NLP tasks: sentiment analysis, topic classification, text summarization, machine translation, and textual entailment. A structured experimental protocol is used to ensure fairness and minimize variability. Both models are tested with identical, neutral prompts and evaluated on two benchmark datasets per task, covering domains like news, reviews, and formal/informal texts. The results show that DeepSeek excels in classification stability and logical reasoning, while ChatGPT performs better in tasks requiring nuanced understanding and flexibility. These findings provide valuable insights for selecting the appropriate LLM based on task requirements.

[Arxiv](https://arxiv.org/abs/2506.18501)