# # 从人类视角看AI：探究机器心理学中的认知理论

发布时间：2025年06月22日

`LLM应用` `心理学` `AI伦理`

> AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology

# 摘要

> 我们探究了大型语言模型 (LLMs) 在心理学领域四个 established 框架下是否展现出类似人类的认知模式：主题领悟测验 (TAT)、框架偏见、道德基础理论 (MFT) 以及认知失调。通过结构化提示和自动化评分，我们评估了多个专有和开源模型。研究发现，这些模型经常生成连贯的故事叙述，易受正面框架影响，表现出与自由/压迫相关的道德判断，并展示出经过大量合理化调和的自我矛盾。这些行为虽然反映了人类认知倾向，但同时也受到其训练数据和对齐方法的影响。我们讨论了这些发现对 AI 透明度、伦理部署以及结合认知心理学与 AI 安全的未来工作的意义。

> We investigate whether Large Language Models (LLMs) exhibit human-like cognitive patterns under four established frameworks from psychology: Thematic Apperception Test (TAT), Framing Bias, Moral Foundations Theory (MFT), and Cognitive Dissonance. We evaluated several proprietary and open-source models using structured prompts and automated scoring. Our findings reveal that these models often produce coherent narratives, show susceptibility to positive framing, exhibit moral judgments aligned with Liberty/Oppression concerns, and demonstrate self-contradictions tempered by extensive rationalization. Such behaviors mirror human cognitive tendencies yet are shaped by their training data and alignment methods. We discuss the implications for AI transparency, ethical deployment, and future work that bridges cognitive psychology and AI safety

[Arxiv](https://arxiv.org/abs/2506.18156)