# LLMs的学习能力还能提升多少？以人类对比衡量模型测试时的学习效果

发布时间：2025年06月17日

`LLM理论

摘要讨论了大型语言模型的评估设计，特别是测试时学习的能力，属于理论层面的研究，探讨模型的动态学习和推理能力，而非具体应用或检索增强生成。` `人工智能`

> How Far Can LLMs Improve from Experience? Measuring Test-Time Learning Ability in LLMs with Human Comparison

# 摘要

> 大型语言模型的评估设计对通往人工通用智能至关重要，因此需要全面且具有前瞻性的评估。现有基准主要评估静态知识，但智能还应包括从经验中快速学习的能力。为此，我们提出测试时学习（Test-time Learning）的评估，即模型在测试时通过经验提升在推理密集型任务中的性能。我们引入语义游戏作为评估测试时学习的有效测试床，因其具备抗饱和性和对战略推理的内在需求。评估框架包含四种经验表示形式，并比较了模型在有限和累积经验下的表现。为提供基准，我们招募了八名人类参与者完成相同任务。结果显示，大型语言模型具备可测量的测试时学习能力，但其在累积经验下的改进不如人类稳定且速度较慢。这表明大型语言模型具有作为通用学习机器的潜力，但与人类相比仍存在显著智力差距，即便其在静态基准上表现优异。

> As evaluation designs of large language models may shape our trajectory toward artificial general intelligence, comprehensive and forward-looking assessment is essential. Existing benchmarks primarily assess static knowledge, while intelligence also entails the ability to rapidly learn from experience. To this end, we advocate for the evaluation of Test-time Learning, the capacity to improve performance in experience-based, reasoning-intensive tasks during test time. In this work, we propose semantic games as effective testbeds for evaluating test-time learning, due to their resistance to saturation and inherent demand for strategic reasoning. We introduce an objective evaluation framework that compares model performance under both limited and cumulative experience settings, and contains four forms of experience representation. To provide a comparative baseline, we recruit eight human participants to complete the same task. Results show that LLMs exhibit measurable test-time learning capabilities; however, their improvements are less stable under cumulative experience and progress more slowly than those observed in humans. These findings underscore the potential of LLMs as general-purpose learning machines, while also revealing a substantial intellectual gap between models and humans, irrespective of how well LLMs perform on static benchmarks.

[Arxiv](https://arxiv.org/abs/2506.14448)