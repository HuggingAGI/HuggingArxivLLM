# # 研究亮点
神经图谱中的因果关系，以及大型语言模型中因果推理能力的测试——哲学未来的 glimpse?

发布时间：2025年06月17日

`LLM理论` `人工智能`

> Causes in neuron diagrams, and testing causal reasoning in Large Language Models. A glimpse of the future of philosophy?

# 摘要

> 基于因果关系哲学研究，特别是D. Lewis推广的神经图，我们提出了一种用于AI的抽象因果推理测试。我们在ChatGPT、DeepSeek和Gemini等先进大型语言模型上展示了该测试。令人惊讶的是，这些聊天机器人已经能够正确识别文献中激烈讨论的案例中的原因。为了评估这些LLM和未来专用AI的表现，我们提出了一种比迄今已发布的定义具有更广泛适用性的神经图因果定义，这挑战了因果定义难以捉摸的普遍观点。我们认为这些结果展示了未来哲学研究可能如何发展：作为人类与人工智能之间的一种互动。

> We propose a test for abstract causal reasoning in AI, based on scholarship in the philosophy of causation, in particular on the neuron diagrams popularized by D. Lewis. We illustrate the test on advanced Large Language Models (ChatGPT, DeepSeek and Gemini). Remarkably, these chatbots are already capable of correctly identifying causes in cases that are hotly debated in the literature. In order to assess the results of these LLMs and future dedicated AI, we propose a definition of cause in neuron diagrams with a wider validity than published hitherto, which challenges the widespread view that such a definition is elusive. We submit that these results are an illustration of how future philosophical research might evolve: as an interplay between human and artificial expertise.

[Arxiv](https://arxiv.org/abs/2506.14239)