# Thunder-NUBench：评估大语言模型句子层面否定理解能力的基准测试

发布时间：2025年06月17日

`LLM应用` `语义理解`

> Thunder-NUBench: A Benchmark for LLMs' Sentence-Level Negation Understanding

# 摘要

> 否定是语言中的基本现象，但大型语言模型（LLMs）在处理否定时仍面临挑战，尤其在需要深度语义理解的任务中表现突出。现有基准测试往往将否定作为更广泛任务（如自然语言推理）的次要情况处理，导致缺乏专注于否定理解的基准测试。为此，我们推出了	extbf{Thunder-NUBench}，这是一个专为评估LLMs在句子级别否定理解能力而设计的新基准。Thunder-NUBench超越了简单的表面线索检测，通过对比标准否定与结构多样的替代形式（如局部否定、矛盾和同义改写）来深入评估模型能力。该基准由精心整理的句子-否定对和一个多项选择数据集组成，能够全面评估模型的否定理解能力。

> Negation is a fundamental linguistic phenomenon that poses persistent challenges for Large Language Models (LLMs), particularly in tasks requiring deep semantic understanding. Existing benchmarks often treat negation as a side case within broader tasks like natural language inference, resulting in a lack of benchmarks that exclusively target negation understanding. In this work, we introduce \textbf{Thunder-NUBench}, a novel benchmark explicitly designed to assess sentence-level negation understanding in LLMs. Thunder-NUBench goes beyond surface-level cue detection by contrasting standard negation with structurally diverse alternatives such as local negation, contradiction, and paraphrase. The benchmark consists of manually curated sentence-negation pairs and a multiple-choice dataset that enables in-depth evaluation of models' negation understanding.

[Arxiv](https://arxiv.org/abs/2506.14397)