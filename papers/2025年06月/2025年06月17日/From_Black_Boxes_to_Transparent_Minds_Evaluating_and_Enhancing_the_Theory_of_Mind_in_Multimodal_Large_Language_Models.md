# 从黑箱到透明心智：评估与提升多模态大型语言模型的“心智理论”

发布时间：2025年06月17日

`LLM理论` `人工智能`

> From Black Boxes to Transparent Minds: Evaluating and Enhancing the Theory of Mind in Multimodal Large Language Models

# 摘要

> 大型语言模型的演进让人们对其模拟类人的“心智理论”（ToM）以辅助日常任务充满期待。然而，现有的机器ToM评估方法主要集中在单模态模型上，并且大多将这些模型视为黑箱，缺乏对内部机制的解释性探索。为应对这一挑战，本研究采用基于内部机制的方法，对多模态大型语言模型（MLLMs）中的ToM进行解释性评估。具体而言，我们构建了一个多模态ToM测试数据集GridToM，其中包含了多样化的信念测试任务和多角度的感知信息。我们的分析表明，多模态大型模型的注意力头能够跨视角区分认知信息，这为ToM能力提供了证据。此外，我们提出了一种轻量级、无需训练的方法，通过调整注意力头的方向，显著提升了模型展现出的ToM能力。

> As large language models evolve, there is growing anticipation that they will emulate human-like Theory of Mind (ToM) to assist with routine tasks. However, existing methods for evaluating machine ToM focus primarily on unimodal models and largely treat these models as black boxes, lacking an interpretative exploration of their internal mechanisms. In response, this study adopts an approach based on internal mechanisms to provide an interpretability-driven assessment of ToM in multimodal large language models (MLLMs). Specifically, we first construct a multimodal ToM test dataset, GridToM, which incorporates diverse belief testing tasks and perceptual information from multiple perspectives. Next, our analysis shows that attention heads in multimodal large models can distinguish cognitive information across perspectives, providing evidence of ToM capabilities. Furthermore, we present a lightweight, training-free approach that significantly enhances the model's exhibited ToM by adjusting in the direction of the attention head.

[Arxiv](https://arxiv.org/abs/2506.14224)