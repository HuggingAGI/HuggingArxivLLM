# # 假设检验，用于量化多选设置中LLM与人类不一致的假设检验

发布时间：2025年06月17日

`LLM应用` `社会科学` `模型评估`

> Hypothesis Testing for Quantifying LLM-Human Misalignment in Multiple Choice Settings

# 摘要

> 随着大型语言模型（LLMs）在社会科学（如经济学和市场营销）研究中的广泛应用，评估这些模型模拟人类行为的能力变得至关重要。本研究采用假设检验方法，提出了一种定量框架，用于评估 LLM 模拟与实际人类行为在多项选择调查中的偏差。该框架能够系统化地判断特定语言模型是否能够有效模拟人类观点、决策和行为。我们将此框架应用于一个流行的用于模拟公众调查中人们观点的语言模型，发现该模型在模拟不同种族、年龄和收入群体在有争议问题上的行为时表现不佳。这表明该语言模型与测试人群之间存在显著偏差，凸显了在社会科学研究中使用 LLMs 时，需超越简单的人类行为模拟，探索更先进的实践方法。

> As Large Language Models (LLMs) increasingly appear in social science research (e.g., economics and marketing), it becomes crucial to assess how well these models replicate human behavior. In this work, using hypothesis testing, we present a quantitative framework to assess the misalignment between LLM-simulated and actual human behaviors in multiple-choice survey settings. This framework allows us to determine in a principled way whether a specific language model can effectively simulate human opinions, decision-making, and general behaviors represented through multiple-choice options. We applied this framework to a popular language model for simulating people's opinions in various public surveys and found that this model is ill-suited for simulating the tested sub-populations (e.g., across different races, ages, and incomes) for contentious questions. This raises questions about the alignment of this language model with the tested populations, highlighting the need for new practices in using LLMs for social science studies beyond naive simulations of human subjects.

[Arxiv](https://arxiv.org/abs/2506.14997)