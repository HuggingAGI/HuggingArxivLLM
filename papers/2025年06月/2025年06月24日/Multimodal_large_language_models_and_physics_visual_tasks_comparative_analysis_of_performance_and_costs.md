# # 多模态大模型与物理视觉任务：性能与成本对比分析

发布时间：2025年06月24日

`LLM应用` `教育技术`

> Multimodal large language models and physics visual tasks: comparative analysis of performance and costs

# 摘要

> 多模态大型语言模型（MLLMs）正逐步应用于物理教育领域，如辅导、形成性评估和评分。本研究评估了来自三大提供商（Anthropic、Google和OpenAI）的15个MLLMs在102个基于图像的物理概念评估中的表现，重点关注两个问题：模型在视觉物理任务中的表现及其使用成本。结果显示，模型性能从76%到21%不等，昂贵模型并不总能胜出，便宜模型在某些场景下同样适用。这一发现对资源有限或大规模教育实施MLLMs尤为重要。我们的分析旨在为教育决策者提供参考，助其基于证据选择适合的模型，推动AI支持的物理教育发展。

> Multimodal large language models (MLLMs) capable of processing both text and visual inputs are increasingly being explored for uses in physics education, such as tutoring, formative assessment, and grading. This study evaluates a range of publicly available MLLMs on a set of standardized, image-based physics research-based conceptual assessments (concept inventories). We benchmark 15 models from three major providers (Anthropic, Google, and OpenAI) across 102 physics items, focusing on two main questions: (1) How well do these models perform on conceptual physics tasks involving visual representations? and (2) What are the financial costs associated with their use? The results show high variability in both performance and cost. The performance of the tested models ranges from around 76\% to as low as 21\%. We also found that expensive models do not always outperform cheaper ones and that, depending on the demands of the context, cheaper models may be sufficiently capable for some tasks. This is especially relevant in contexts where financial resources are limited or for large-scale educational implementation of MLLMs. By providing these analyses, our aim is to inform teachers, institutions, and other educational stakeholders so that they can make evidence-based decisions about the selection of models for use in AI-supported physics education.

[Arxiv](https://arxiv.org/abs/2506.19662)