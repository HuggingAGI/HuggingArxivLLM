# 通过结合视觉与语言模型，捕捉到了人类大脑中视觉语义表征的时间进程。

发布时间：2025年06月24日

`LLM应用` `神经科学` `认知科学`

> The time course of visuo-semantic representations in the human brain is captured by combining vision and language models

# 摘要

> 人类视觉系统赋予我们对世界的丰富且有意义的感知，将视网膜信号转化为视觉语义表征。为了构建这些表征的模型，我们整合了视觉深度神经网络（DNN）和大型语言模型（LLM）这两种当前主导的方法。基于大规模人类脑电图（EEG）数据，我们在观看物体图像时构建了编码模型，利用视觉DNN、LLM及其融合的表征来预测EEG反应。结果显示，融合编码模型在预测视觉刺激引发的神经反应方面表现最佳，优于仅基于视觉DNN或LLM的编码模型，以及之前的建模方法。视觉DNN和LLM在解释EEG反应中的刺激相关信号方面相辅相成：视觉DNN独特地捕捉到了早期的宽带EEG信号，而LLM则独特地捕捉到了后期的低频信号，以及详细的视觉语义刺激信息。这些发现共同为人类大脑中视觉语义处理的时间进程提供了更精确的模型。


> The human visual system provides us with a rich and meaningful percept of the world, transforming retinal signals into visuo-semantic representations. For a model of these representations, here we leveraged a combination of two currently dominating approaches: vision deep neural networks (DNNs) and large language models (LLMs). Using large-scale human electroencephalography (EEG) data recorded during object image viewing, we built encoding models to predict EEG responses using representations from a vision DNN, an LLM, and their fusion. We show that the fusion encoding model outperforms encoding models based on either the vision DNN or the LLM alone, as well as previous modelling approaches, in predicting neural responses to visual stimulation. The vision DNN and the LLM complemented each other in explaining stimulus-related signal in the EEG responses. The vision DNN uniquely captured earlier and broadband EEG signals, whereas the LLM uniquely captured later and low frequency signals, as well as detailed visuo-semantic stimulus information. Together, this provides a more accurate model of the time course of visuo-semantic processing in the human brain.

[Arxiv](https://arxiv.org/abs/2506.19497)