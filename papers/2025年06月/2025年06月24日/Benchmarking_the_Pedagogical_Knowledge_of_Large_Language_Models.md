# 评测大型语言模型的教学知识

发布时间：2025年06月24日

`LLM应用` `教育技术`

> Benchmarking the Pedagogical Knowledge of Large Language Models

# 摘要

> 大规模多任务语言理解（MMLU）等基准测试在评估AI跨领域知识和能力方面发挥了关键作用。然而，现有基准主要关注内容知识，忽视了评估模型对教学法（教学方法和实践）理解这一关键领域。本文介绍了《教学法基准》，这是一个旨在评估大型语言模型跨领域教学知识（CDPK）和特殊教育需求与残疾（SEND）教学知识的新数据集。这些基准建立在一套精选自教师专业发展考试的问题集上，涵盖教学策略和评估方法等教学法子领域。本文概述了这些基准的方法论和开发过程。我们报告了97个模型的结果，准确率在28%到89%之间。我们探讨了成本与准确性的关系，并绘制了帕累托价值前沿的时间演变图。我们提供了在线排行榜（https://rebrand.ly/pedagogy），定期更新新模型，并支持基于模型属性（如每token成本和权重开放/封闭状态）的交互式探索和筛选，同时查看不同学科的表现。大型语言模型和生成式AI在影响教育和应对全球学习危机方面具有巨大潜力。以教育为重点的基准对于衡量模型理解教学概念、恰当回应学习者需求以及支持多样背景下有效教学实践的能力至关重要。它们对于在教育环境中负责任和基于证据地部署大型语言模型和LLM工具至关重要，并为开发和政策决策提供指导。

> Benchmarks like Massive Multitask Language Understanding (MMLU) have played a pivotal role in evaluating AI's knowledge and abilities across diverse domains. However, existing benchmarks predominantly focus on content knowledge, leaving a critical gap in assessing models' understanding of pedagogy - the method and practice of teaching. This paper introduces The Pedagogy Benchmark, a novel dataset designed to evaluate large language models on their Cross-Domain Pedagogical Knowledge (CDPK) and Special Education Needs and Disability (SEND) pedagogical knowledge. These benchmarks are built on a carefully curated set of questions sourced from professional development exams for teachers, which cover a range of pedagogical subdomains such as teaching strategies and assessment methods. Here we outline the methodology and development of these benchmarks. We report results for 97 models, with accuracies spanning a range from 28% to 89% on the pedagogical knowledge questions. We consider the relationship between cost and accuracy and chart the progression of the Pareto value frontier over time. We provide online leaderboards at https://rebrand.ly/pedagogy which are updated with new models and allow interactive exploration and filtering based on various model properties, such as cost per token and open-vs-closed weights, as well as looking at performance in different subjects. LLMs and generative AI have tremendous potential to influence education and help to address the global learning crisis. Education-focused benchmarks are crucial to measure models' capacities to understand pedagogical concepts, respond appropriately to learners' needs, and support effective teaching practices across diverse contexts. They are needed for informing the responsible and evidence-based deployment of LLMs and LLM-based tools in educational settings, and for guiding both development and policy decisions.

[Arxiv](https://arxiv.org/abs/2506.18710)