# # 开源LLM为何在数据分析中表现挣扎？系统性实证研究

发布时间：2025年06月24日

`LLM应用

理由：这篇论文探讨了如何提升开源大型语言模型在数据分析任务中的能力，属于对LLM应用的研究，特别是通过数据策略和合成方法优化其性能。` `数据分析` `自动化`

> Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study

# 摘要

> 大型语言模型 (LLMs) 在数据分析任务的自动化方面展现出巨大潜力，但开源模型在需要复杂推理的场景中仍存在明显局限。本研究旨在探索提升开源 LLM 数据分析能力的有效策略。通过构建一个涵盖多样且现实场景的种子数据集，我们从数据理解、代码生成和战略规划三个维度对模型进行全面评估。研究发现：(1) 战略规划质量是决定模型性能的核心因素；(2) 交互设计和任务复杂度显著影响模型的推理能力；(3) 数据质量相较于多样性对性能优化的影响更为关键。基于这些发现，我们开发了一种数据合成方法，成功提升了开源 LLM 在分析推理任务中的表现。

> Large Language Models (LLMs) hold promise in automating data analysis tasks, yet open-source models face significant limitations in these kinds of reasoning-intensive scenarios. In this work, we investigate strategies to enhance the data analysis capabilities of open-source LLMs. By curating a seed dataset of diverse, realistic scenarios, we evaluate models across three dimensions: data understanding, code generation, and strategic planning. Our analysis reveals three key findings: (1) Strategic planning quality serves as the primary determinant of model performance; (2) Interaction design and task complexity significantly influence reasoning capabilities; (3) Data quality demonstrates a greater impact than diversity in achieving optimal performance. We leverage these insights to develop a data synthesis methodology, demonstrating significant improvements in open-source LLMs' analytical reasoning capabilities.

[Arxiv](https://arxiv.org/abs/2506.19794)