# # 摘要  
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年06月15日

`其他` `社交网络` `隐私保护`

> Governments Should Mandate Tiered Anonymity on Social-Media Platforms to Counter Deepfakes and LLM-Driven Mass Misinformation

# 摘要

> 本文主张，鉴于深度伪造技术的易产性以及大型语言模型驱动的错误信息，政府应要求社交平台实施三重匿名框架作为应对措施。该框架的层级由用户的影响力评分决定：第一级允许小号完全使用假名，以保护日常隐私；第二级要求有一定影响力账号绑定私人法律身份，以在中等影响力范围内恢复现实世界的责任制；第三级则要求传统意义上的大众信息来源账号在每条帖子发布前进行独立的、机器学习辅助的事实核查和审核。

对Reddit的分析表明，随着受众规模的扩大，志愿者 moderation 趋于实施类似的准入机制—— karma 阈值、审核队列和身份证明——这证明了该框架的操作可行性和社会正当性。我们承认现有的互动激励机制可能阻碍自愿采纳，因此提出了一个监管路径，该路径通过调整现有的美国司法判例和近期的欧盟-英国安全法规，将影响力比例的身份核查嵌入现有平台工具中，从而在保护日常隐私的同时遏制大规模错误信息的传播。

> This position paper argues that governments should mandate a three-tier anonymity framework on social-media platforms as a reactionary measure prompted by the ease-of-production of deepfakes and large-language-model-driven misinformation. The tiers are determined by a given user's $\textit{reach score}$: Tier 1 permits full pseudonymity for smaller accounts, preserving everyday privacy; Tier 2 requires private legal-identity linkage for accounts with some influence, reinstating real-world accountability at moderate reach; Tier 3 would require per-post, independent, ML-assisted fact-checking, review for accounts that would traditionally be classed as sources-of-mass-information.
  An analysis of Reddit shows volunteer moderators converge on comparable gates as audience size increases -- karma thresholds, approval queues, and identity proofs -- demonstrating operational feasibility and social legitimacy. Acknowledging that existing engagement incentives deter voluntary adoption, we outline a regulatory pathway that adapts existing US jurisprudence and recent EU-UK safety statutes to embed reach-proportional identity checks into existing platform tooling, thereby curbing large-scale misinformation while preserving everyday privacy.

[Arxiv](https://arxiv.org/abs/2506.12814)