# 基于序列到序列模型的聊天机器人文本转换

发布时间：2025年06月15日

`LLM应用

理由：这篇论文探讨了如何利用Seq2Seq模型对抗GPT生成的文本，使其更接近人类撰写风格，从而欺骗检测模型。同时，它也研究了这种转换技术在改进分类器中的应用。这些内容涉及大型语言模型的应用和对抗攻击，因此归类为LLM应用。` `文本检测`

> Transforming Chatbot Text: A Sequence-to-Sequence Approach

# 摘要

> 随着像ChatGPT这样的大型语言模型（LLMs）的进步，人类撰写文本与AI生成文本之间的界限日益模糊。然而，近期研究表明，可靠地检测GPT生成文本是可行的。本文提出了一种新颖的策略，利用序列到序列（Seq2Seq）模型对GPT生成的文本进行对抗性转换，使其更贴近人类撰写风格。我们实验了T5-small和BART这两种Seq2Seq模型，用于修改GPT生成的句子，使其包含更多符合人类撰写文本特征的语言、结构和语义成分。实验结果表明，经过这些Seq2Seq模型修改后的文本，分类模型（用于区分GPT生成文本）的准确率显著下降。然而，当在我们的Seq2Seq技术生成的数据上重新训练分类模型后，模型能够以高准确率区分经过转换的GPT生成文本与人类生成文本。这项研究进一步丰富了文本转换作为攻击工具（击败分类模型）和防御工具（改进分类器）的知识积累，从而加深了我们对AI生成文本的理解。

> Due to advances in Large Language Models (LLMs) such as ChatGPT, the boundary between human-written text and AI-generated text has become blurred. Nevertheless, recent work has demonstrated that it is possible to reliably detect GPT-generated text. In this paper, we adopt a novel strategy to adversarially transform GPT-generated text using sequence-to-sequence (Seq2Seq) models, with the goal of making the text more human-like. We experiment with the Seq2Seq models T5-small and BART which serve to modify GPT-generated sentences to include linguistic, structural, and semantic components that may be more typical of human-authored text. Experiments show that classification models trained to distinguish GPT-generated text are significantly less accurate when tested on text that has been modified by these Seq2Seq models. However, after retraining classification models on data generated by our Seq2Seq technique, the models are able to distinguish the transformed GPT-generated text from human-generated text with high accuracy. This work adds to the accumulating knowledge of text transformation as a tool for both attack -- in the sense of defeating classification models -- and defense -- in the sense of improved classifiers -- thereby advancing our understanding of AI-generated text.

[Arxiv](https://arxiv.org/abs/2506.12843)