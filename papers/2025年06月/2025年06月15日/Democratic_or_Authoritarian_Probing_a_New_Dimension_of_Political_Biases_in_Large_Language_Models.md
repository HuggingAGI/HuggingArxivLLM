# 民主 vs 威权：深入探索大型语言模型中的政治偏见新维度。

发布时间：2025年06月15日

`LLM应用` `地缘政治`

> Democratic or Authoritarian? Probing a New Dimension of Political Biases in Large Language Models

# 摘要

> 随着大型语言模型（LLMs）逐渐融入日常生活和信息生态系统，关于其隐性偏见的担忧依然存在。尽管先前的研究主要关注社会人口统计和左右翼政治维度，但对LLMs如何与更广泛地缘政治价值体系，尤其是民主与威权主义谱系相契合的关注却微乎其微。本文提出了一种全新的方法来评估这种契合度，结合了以下三个要素：(1) F量表，一种用于衡量威权倾向的心理测量工具，(2) FavScore，一个新引入的用于评估模型对世界领导人的偏好程度的指标，以及(3) 角色模型探查，用于评估LLMs一般会将哪些人物作为榜样提及。我们发现，LLMs通常更倾向于民主价值观和领导人，但在以普通话提示时，其对威权人物的偏好程度有所增加。此外，我们发现模型经常将威权人物作为榜样提及，即使在非明确政治语境下也是如此。这些结果揭示了LLMs可能反映并强化全球政治意识形态的方式，强调了在超越传统社会政治轴线的背景下评估偏见的重要性。我们的代码可在以下链接获取：https://github.com/irenestrauss/Democratic-Authoritarian-Bias-LLMs

> As Large Language Models (LLMs) become increasingly integrated into everyday life and information ecosystems, concerns about their implicit biases continue to persist. While prior work has primarily examined socio-demographic and left--right political dimensions, little attention has been paid to how LLMs align with broader geopolitical value systems, particularly the democracy--authoritarianism spectrum. In this paper, we propose a novel methodology to assess such alignment, combining (1) the F-scale, a psychometric tool for measuring authoritarian tendencies, (2) FavScore, a newly introduced metric for evaluating model favorability toward world leaders, and (3) role-model probing to assess which figures are cited as general role-models by LLMs. We find that LLMs generally favor democratic values and leaders, but exhibit increases favorability toward authoritarian figures when prompted in Mandarin. Further, models are found to often cite authoritarian figures as role models, even outside explicit political contexts. These results shed light on ways LLMs may reflect and potentially reinforce global political ideologies, highlighting the importance of evaluating bias beyond conventional socio-political axes. Our code is available at: https://github.com/irenestrauss/Democratic-Authoritarian-Bias-LLMs

[Arxiv](https://arxiv.org/abs/2506.12758)