# # 跨越链接：评估大型语言模型在全球媒体中分类政治内容的能力

发布时间：2025年06月20日

`LLM应用` `政治科学` `数字媒体`

> Beyond the Link: Assessing LLMs' ability to Classify Political Content across Global Media

# 摘要

> 大型语言模型（LLMs）在政治科学领域中的应用日益普遍，尤其是在分析个人使用数字媒体的研究中。然而，尽管先前的研究已经展示了LLMs在标注任务中的能力，但使用LLMs仅从URL来分类政治内容（PC）的有效性尚未得到充分探索。本文的研究成果填补了这一空白，通过评估LLMs是否能够准确区分政治内容与非政治内容，分别从五个国家（法国、德国、西班牙、英国和美国）以及不同语言的文章文本和URL中进行分析。我们利用GPT、Llama、Mistral、Deepseek、Qwen和Gemma等前沿的LLMs，衡量模型性能，以评估URL级别的分析是否可以作为全文分析PC的优良近似，即使是在不同的语言和国家背景下。将模型输出与人工标注的文章以及传统监督机器学习技术进行比较，以建立性能基准。总体而言，我们的研究结果表明，URL能够嵌入大部分新闻内容，为准确性和成本之间的平衡提供了重要视角。我们还考虑了情境限制，并提出了在政治科学研究中使用LLMs的方法建议。

> The use of large language models (LLMs) is becoming common in the context of political science, particularly in studies that analyse individuals use of digital media. However, while previous research has demonstrated LLMs ability at labelling tasks, the effectiveness of using LLMs to classify political content (PC) from just URLs is not yet well explored. The work presented in this article bridges this gap by evaluating whether LLMs can accurately identify PC vs. non-PC from both the article text and the URLs from five countries (France, Germany, Spain, the UK, and the US) and different languages. Using cutting-edge LLMs like GPT, Llama, Mistral, Deepseek, Qwen and Gemma, we measure model performance to assess whether URL-level analysis can be a good approximation for full-text analysis of PC, even across different linguistic and national contexts. Model outputs are compared with human-labelled articles, as well as traditional supervised machine learning techniques, to set a baseline of performance. Overall, our findings suggest the capacity of URLs to embed most of the news content, providing a vital perspective on accuracy-cost balancing. We also account for contextual limitations and suggest methodological recommendations to use LLMs within political science studies.

[Arxiv](https://arxiv.org/abs/2506.17435)