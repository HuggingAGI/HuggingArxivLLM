# # 超越链接：评估LLMs在跨全球媒体环境下对政治内容的分类能力

发布时间：2025年06月20日

`LLM应用` `政治科学` `媒体分析`

> Beyond the Link: Assessing LLMs' ability to Classify Political Content across Global Media

# 摘要

> 大型语言模型（LLMs）在政治科学领域，特别是在分析个人使用数字媒体的研究中，正变得越来越普遍。然而，尽管之前的研究已经展示了LLMs在标签任务上的能力，但利用LLMs仅通过URL分类政治内容（PC）的有效性尚未得到充分探索。本文的研究填补了这一空白，通过评估LLMs是否能够准确识别来自五个国家（法国、德国、西班牙、英国和美国）的文章文本和URL中的政治内容（PC）与非政治内容（non-PC）来实现。我们使用像GPT、Llama、Mistral、Deepseek、Qwen和Gemma这样的前沿LLMs，衡量模型性能，以评估URL级别的分析是否可以作为全文分析PC的优良近似，即使在不同的语言和国家背景下也是如此。我们将模型输出与人工标注的文章以及传统监督机器学习技术进行比较，以设定性能基准。总体而言，我们的研究结果表明，URL能够嵌入大部分新闻内容，为准确性和成本之间的平衡提供了重要的视角。我们还考虑了情境限制，并提出了在政治科学研究中使用LLMs的方法建议。

> The use of large language models (LLMs) is becoming common in the context of political science, particularly in studies that analyse individuals use of digital media. However, while previous research has demonstrated LLMs ability at labelling tasks, the effectiveness of using LLMs to classify political content (PC) from just URLs is not yet well explored. The work presented in this article bridges this gap by evaluating whether LLMs can accurately identify PC vs. non-PC from both the article text and the URLs from five countries (France, Germany, Spain, the UK, and the US) and different languages. Using cutting-edge LLMs like GPT, Llama, Mistral, Deepseek, Qwen and Gemma, we measure model performance to assess whether URL-level analysis can be a good approximation for full-text analysis of PC, even across different linguistic and national contexts. Model outputs are compared with human-labelled articles, as well as traditional supervised machine learning techniques, to set a baseline of performance. Overall, our findings suggest the capacity of URLs to embed most of the news content, providing a vital perspective on accuracy-cost balancing. We also account for contextual limitations and suggest methodological recommendations to use LLMs within political science studies.

[Arxiv](https://arxiv.org/abs/2506.17435)