# # 偏见评估方法是否也存在偏见？
偏见评估方法是否也存在偏见？

发布时间：2025年06月20日

`LLM理论

这篇论文探讨了大型语言模型的安全性评估，特别是通过基准测试来分析模型在偏见、毒性等方面的性能。研究重点在于评估方法的稳健性和一致性，属于对LLM的理论和安全性研究，因此归类为LLM理论。` `可信AI` `基准测试`

> Are Bias Evaluation Methods Biased ?

# 摘要

> 评估大型语言模型的安全性是可信 AI 领域的核心工作之一。通过创建基准测试，可以在毒性、偏见、有害行为等多个安全维度对模型进行横向对比。独立的基准测试采用了不同的方法、数据集和评估方式。我们通过不同方法对一组具有代表性的模型在偏见方面进行排名，研究这些基准测试的稳健性，并比较整体排名的相似性。我们发现，不同但广泛使用的偏见评估方法会导致模型排名的差异。最后，我们为社区在使用这些基准测试时提出了一些建议。

> The creation of benchmarks to evaluate the safety of Large Language Models is one of the key activities within the trusted AI community. These benchmarks allow models to be compared for different aspects of safety such as toxicity, bias, harmful behavior etc. Independent benchmarks adopt different approaches with distinct data sets and evaluation methods. We investigate how robust such benchmarks are by using different approaches to rank a set of representative models for bias and compare how similar are the overall rankings. We show that different but widely used bias evaluations methods result in disparate model rankings. We conclude with recommendations for the community in the usage of such benchmarks.

[Arxiv](https://arxiv.org/abs/2506.17111)