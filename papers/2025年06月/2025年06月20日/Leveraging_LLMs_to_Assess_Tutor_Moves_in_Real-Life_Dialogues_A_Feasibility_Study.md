# # 标题
借助 LLMs 评估真实对话中的导师行为：可行性研究

发布时间：2025年06月20日

`LLM应用` `教育技术`

> Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study

# 摘要

> 辅导显著提升学生学习成果，但如何基于音频转录识别与大规模学习最相关的辅导行为仍是开放难题。本研究探讨生成式 AI 在真实数学辅导中识别和评估辅导动作的可行性和可扩展性。我们分析了50份大学学生远程辅导初中生数学的对话记录。利用 GPT-4 系列、Gemini-1.5-pro 以及 LearnLM 等模型，评估辅导者在“给予有效表扬”和“回应数学错误”两个技能上的表现。所有模型均能准确识别相关情境，如辅导者给予表扬（94-98%准确率）和学生出现错误（82-88%准确率），并有效评估辅导者遵循最佳实践的程度，与人工判断高度一致（83-89%和73-77%）。我们提出了一种成本效益高的提示策略，并探讨了在真实场景中使用大型语言模型支持大规模评估的实际意义。这项研究进一步贡献了支持可重复性和人工智能辅助学习研究的大型语言模型提示方案。


> Tutoring improves student achievement, but identifying and studying what tutoring actions are most associated with student learning at scale based on audio transcriptions is an open research problem. This present study investigates the feasibility and scalability of using generative AI to identify and evaluate specific tutor moves in real-life math tutoring. We analyze 50 randomly selected transcripts of college-student remote tutors assisting middle school students in mathematics. Using GPT-4, GPT-4o, GPT-4-turbo, Gemini-1.5-pro, and LearnLM, we assess tutors' application of two tutor skills: delivering effective praise and responding to student math errors. All models reliably detected relevant situations, for example, tutors providing praise to students (94-98% accuracy) and a student making a math error (82-88% accuracy) and effectively evaluated the tutors' adherence to tutoring best practices, aligning closely with human judgments (83-89% and 73-77%, respectively). We propose a cost-effective prompting strategy and discuss practical implications for using large language models to support scalable assessment in authentic settings. This work further contributes LLM prompts to support reproducibility and research in AI-supported learning.

[Arxiv](https://arxiv.org/abs/2506.17410)