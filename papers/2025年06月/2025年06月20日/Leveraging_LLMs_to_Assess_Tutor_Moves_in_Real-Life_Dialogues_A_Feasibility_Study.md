# 利用大型语言模型分析真实对话中的导师行为：一项可行性研究

发布时间：2025年06月20日

`LLM应用` `生成式AI`

> Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study

# 摘要

> 辅导有助于提高学生成绩，但如何基于音频转录识别并研究哪些辅导行为最能促进大规模学习仍是一个开放的研究问题。本研究旨在探讨利用生成式AI识别和评估真实数学辅导中具体辅导行为的可行性和可扩展性。我们分析了50份随机选取的大学学生远程辅导教师帮助中学生学习数学的转录记录。通过使用GPT-4、GPT-4o、GPT-4-turbo、Gemini-1.5-pro和LearnLM，我们评估了辅导教师在两项辅导技能上的应用：给予有效表扬和回应学生数学错误。所有模型均能可靠地检测相关情境，例如教师给予学生表扬（94-98%准确率）和学生出现数学错误（82-88%准确率），并能有效评估辅导教师对最佳辅导实践的遵循情况，与人工判断高度一致（分别为83-89%和73-77%）。我们提出了一种成本效益高的提示策略，并探讨了在真实场景中使用大型语言模型支持可扩展评估的实际意义。这项工作进一步贡献了支持LLM提示的可重复性和AI支持学习的研究。
    

> Tutoring improves student achievement, but identifying and studying what tutoring actions are most associated with student learning at scale based on audio transcriptions is an open research problem. This present study investigates the feasibility and scalability of using generative AI to identify and evaluate specific tutor moves in real-life math tutoring. We analyze 50 randomly selected transcripts of college-student remote tutors assisting middle school students in mathematics. Using GPT-4, GPT-4o, GPT-4-turbo, Gemini-1.5-pro, and LearnLM, we assess tutors' application of two tutor skills: delivering effective praise and responding to student math errors. All models reliably detected relevant situations, for example, tutors providing praise to students (94-98% accuracy) and a student making a math error (82-88% accuracy) and effectively evaluated the tutors' adherence to tutoring best practices, aligning closely with human judgments (83-89% and 73-77%, respectively). We propose a cost-effective prompting strategy and discuss practical implications for using large language models to support scalable assessment in authentic settings. This work further contributes LLM prompts to support reproducibility and research in AI-supported learning.

[Arxiv](https://arxiv.org/abs/2506.17410)