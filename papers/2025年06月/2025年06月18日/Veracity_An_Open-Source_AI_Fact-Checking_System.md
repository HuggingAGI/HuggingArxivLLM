# Veracity：开源AI事实核查系统

发布时间：2025年06月18日

`LLM应用

理由：这篇论文主要讨论了如何利用大型语言模型（LLMs）来解决虚假信息的问题，通过结合网络检索代理和LLMs构建了一个开源的事实核查系统。这属于LLM的应用层面，而非理论研究或Agent、RAG等其他分类。`

> Veracity: An Open-Source AI Fact-Checking System

# 摘要

> 虚假信息的泛滥正对社会构成严峻挑战，而生成式AI的泛滥更使这一威胁雪上加霜。本文演示论文介绍的Veracity开源AI系统，旨在通过透明且易用的事实核查功能，赋能个人有效识别和抵制虚假信息。该系统巧妙结合大型语言模型（LLMs）与网络检索代理，通过对用户提交声明的深入分析，提供有依据的真实度评估和直观的解释说明。Veracity的亮点包括多语言支持、声明真实性的量化评分，以及一个受常见即时通讯应用启发的友好交互界面。本文将重点展示Veracity不仅能够精准识别虚假信息，更能清晰解释其推理过程，从而助力提升公众媒介素养，推动社会走向更加明智和理性的未来。

> The proliferation of misinformation poses a significant threat to society, exacerbated by the capabilities of generative AI. This demo paper introduces Veracity, an open-source AI system designed to empower individuals to combat misinformation through transparent and accessible fact-checking. Veracity leverages the synergy between Large Language Models (LLMs) and web retrieval agents to analyze user-submitted claims and provide grounded veracity assessments with intuitive explanations. Key features include multilingual support, numerical scoring of claim veracity, and an interactive interface inspired by familiar messaging applications. This paper will showcase Veracity's ability to not only detect misinformation but also explain its reasoning, fostering media literacy and promoting a more informed society.

[Arxiv](https://arxiv.org/abs/2506.15794)