# 经济学家都更内向吗？探讨角色赋予大语言模型中的一致性。

发布时间：2025年06月03日

`LLM应用` `生成模型`

> Are Economists Always More Introverted? Analyzing Consistency in Persona-Assigned LLMs

# 摘要

> 个性化大型语言模型（LLMs）在各种应用场景中越来越受欢迎，这些模型被赋予特定的人设（例如快乐的高中老师），以指导它们的回应方式。尽管先前的研究探讨了LLMs在写作风格上如何遵循预定义的人设，但对于不同人设和任务类型之间的一致性进行全面分析仍然不足。本文中，我们提出了一种新的标准化框架，用于分析被赋予人设的LLMs的一致性。我们将一致性定义为模型在被赋予相同人设的情况下，在不同任务和运行中保持连贯回应的程度。我们的框架评估了四个不同类别的人设（快乐、职业、个性和政治立场），涵盖了多个任务维度（调查写作、文章生成、社交媒体帖子生成、单轮对话和多轮对话）。研究发现，一致性受到多个因素的影响，包括赋予的人设、刻板印象和模型设计选择。一致性在不同任务中也有所差异，随着任务结构的增强和上下文的增加而提高。所有代码均可在GitHub上获取。

> Personalized Large Language Models (LLMs) are increasingly used in diverse applications, where they are assigned a specific persona - such as a happy high school teacher - to guide their responses. While prior research has examined how well LLMs adhere to predefined personas in writing style, a comprehensive analysis of consistency across different personas and task types is lacking. In this paper, we introduce a new standardized framework to analyze consistency in persona-assigned LLMs. We define consistency as the extent to which a model maintains coherent responses when assigned the same persona across different tasks and runs. Our framework evaluates personas across four different categories (happiness, occupation, personality, and political stance) spanning multiple task dimensions (survey writing, essay generation, social media post generation, single turn, and multi-turn conversations). Our findings reveal that consistency is influenced by multiple factors, including the assigned persona, stereotypes, and model design choices. Consistency also varies across tasks, increasing with more structured tasks and additional context. All code is available on GitHub.

[Arxiv](https://arxiv.org/abs/2506.02659)