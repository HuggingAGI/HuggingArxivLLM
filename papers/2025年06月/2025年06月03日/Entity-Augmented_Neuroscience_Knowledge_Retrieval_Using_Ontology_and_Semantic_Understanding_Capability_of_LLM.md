# 利用实体增强的神经科学知识检索，基于本体论和大型语言模型的语义理解能力

发布时间：2025年06月03日

`LLM应用

摘要中提到，论文提出了一种基于大型语言模型（LLM）的新方法，用于从无标注的神经科学研究语料库中构建知识图谱。这表明LLM被应用于特定的文本处理任务，属于LLM的应用层面。` `神经科学` `知识图谱`

> Entity-Augmented Neuroscience Knowledge Retrieval Using Ontology and Semantic Understanding Capability of LLM

# 摘要

> 神经科学文献蕴含着海量知识，精准提取这些信息并发现新见解对推动研究至关重要。然而，面对分散在多个来源中的知识，现有方法往往难以提取所需信息。知识图谱（KG）能够整合多源知识，但现有构建神经科学KG的方法通常依赖标注数据且需要专业知识。对于神经科学这样专业的领域，获取大规模标注数据极具挑战性。

本研究提出了一种基于大型语言模型（LLM）、神经科学本体和文本嵌入，从无标注神经科学研究语料库构建知识图谱的新方法。我们分析了LLM识别的神经科学文本片段在KG构建中的语义相关性，并引入了一种基于实体增强的信息检索算法来提取知识。实验结果表明，我们的方法显著提升了从无标注神经科学文献中发现知识的能力，在实体提取方面实现了0.84的F1分数，使超过54%的问题得到了更好的解答。
    

> Neuroscience research publications encompass a vast wealth of knowledge. Accurately retrieving existing information and discovering new insights from this extensive literature is essential for advancing the field. However, when knowledge is dispersed across multiple sources, current state-of-the-art retrieval methods often struggle to extract the necessary information. A knowledge graph (KG) can integrate and link knowledge from multiple sources, but existing methods for constructing KGs in neuroscience often rely on labeled data and require domain expertise. Acquiring large-scale, labeled data for a specialized area like neuroscience presents significant challenges. This work proposes novel methods for constructing KG from unlabeled large-scale neuroscience research corpus utilizing large language models (LLM), neuroscience ontology, and text embeddings. We analyze the semantic relevance of neuroscience text segments identified by LLM for building the knowledge graph. We also introduce an entity-augmented information retrieval algorithm to extract knowledge from the KG. Several experiments were conducted to evaluate the proposed approaches, and the results demonstrate that our methods significantly enhance knowledge discovery from the unlabeled neuroscience research corpus. It achieves an F1 score of 0.84 for entity extraction, and the knowledge obtained from the KG improves answers to over 54% of the questions.

[Arxiv](https://arxiv.org/abs/2506.03145)