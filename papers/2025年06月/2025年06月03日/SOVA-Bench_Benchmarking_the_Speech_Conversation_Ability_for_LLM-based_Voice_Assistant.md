# # SOVA-Bench：针对LLM语音助手的语音对话能力基准测试

发布时间：2025年06月03日

`LLM应用` `语音技术` `语音交互`

> SOVA-Bench: Benchmarking the Speech Conversation Ability for LLM-based Voice Assistant

# 摘要

> 得益于大型语言模型（LLMs）、语音编码算法以及声码器结构的稳步进步，我们现在已经能够直接从用户指令生成语音回复。然而，随着从追求语义准确性转向生动自然的语音流畅度，对生成语音质量的评估却是一个被忽视但至关重要的问题。之前的评估主要关注语音理解能力，缺乏对音质的量化。在本文中，我们提出了Speech cOnversational Voice Assistant Benchmark（SOVA-Bench），它提供了一种全面的对比评估，涵盖现有语音LLMs在常识理解、语音识别与理解，以及语义和音质生成能力方面的表现。据我们所知，SOVA-Bench是目前针对语音LLMs最系统化的评估框架之一，为语音交互系统的发展方向提供了重要启示。

> Thanks to the steady progress of large language models (LLMs), speech encoding algorithms and vocoder structure, recent advancements have enabled generating speech response directly from a user instruction. However, benchmarking the generated speech quality has been a neglected but critical issue, considering the shift from the pursuit of semantic accuracy to vivid and spontaneous speech flow. Previous evaluation focused on the speech-understanding ability, lacking a quantification of acoustic quality. In this paper, we propose Speech cOnversational Voice Assistant Benchmark (SOVA-Bench), providing a comprehension comparison of the general knowledge, speech recognition and understanding, along with both semantic and acoustic generative ability between available speech LLMs. To the best of our knowledge, SOVA-Bench is one of the most systematic evaluation frameworks for speech LLMs, inspiring the direction of voice interaction systems.

[Arxiv](https://arxiv.org/abs/2506.02457)