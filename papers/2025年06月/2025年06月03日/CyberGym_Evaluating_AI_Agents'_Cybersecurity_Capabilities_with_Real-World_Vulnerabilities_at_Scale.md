# CyberGym：大规模评估AI代理的网络安全能力，利用真实世界漏洞进行测试

发布时间：2025年06月03日

`LLM应用

论文摘要讨论了大型语言模型（LLM）代理在网络安全任务中的应用，特别是漏洞检测和修复。它引入了一个评估框架CyberGym，用于测试这些代理的能力。虽然提到了代理，但主要关注的是LLM的应用，因此归类为LLM应用。` `网络安全` `漏洞管理`

> CyberGym: Evaluating AI Agents' Cybersecurity Capabilities with Real-World Vulnerabilities at Scale

# 摘要

> 大型语言模型（LLM）代理在自主处理网络安全任务方面日益娴熟。鉴于该领域的高风险性，全面评估其网络安全能力既关键又紧迫。然而，现有的基准测试存在不足，往往未能涵盖现实场景或在范围上有所限制。为填补这一空白，我们推出CyberGym——一个大规模、高质量的网络安全评估框架，涵盖从188个大型软件项目中发现并修复的1,507个真实世界漏洞。虽然CyberGym包含多种设置的任务，但它主要聚焦于基于文本描述和对应源代码仓库生成概念验证（PoC）测试，用于漏洞复现。完成此任务颇具挑战性，因为它要求对整个代码库进行全方位推理，以定位相关代码片段并生成有效的PoC，从程序入口点出发精准触发目标漏洞。我们对4个最先进的代理框架和9个LLM的评估显示，即使是最优组合（OpenHands与Claude-3.7-Sonnet）也只能实现11.9%的复现成功率，且主要集中在较为简单的案例上。除了复现历史漏洞外，我们发现LLM代理生成的PoC还能揭示新漏洞，识别出影响软件项目最新版本的15个零日漏洞。

> Large language model (LLM) agents are becoming increasingly skilled at handling cybersecurity tasks autonomously. Thoroughly assessing their cybersecurity capabilities is critical and urgent, given the high stakes in this domain. However, existing benchmarks fall short, often failing to capture real-world scenarios or being limited in scope. To address this gap, we introduce CyberGym, a large-scale and high-quality cybersecurity evaluation framework featuring 1,507 real-world vulnerabilities found and patched across 188 large software projects. While it includes tasks of various settings, CyberGym primarily focuses on the generation of proof-of-concept (PoC) tests for vulnerability reproduction, based on text descriptions and corresponding source repositories. Solving this task is particularly challenging, as it requires comprehensive reasoning across entire codebases to locate relevant code fragments and produce effective PoCs that accurately trigger the target vulnerability starting from the program's entry point. Our evaluation across 4 state-of-the-art agent frameworks and 9 LLMs reveals that even the best combination (OpenHands and Claude-3.7-Sonnet) achieves only a 11.9% reproduction success rate, mainly on simpler cases. Beyond reproducing historical vulnerabilities, we find that PoCs generated by LLM agents can reveal new vulnerabilities, identifying 15 zero-days affecting the latest versions of the software projects.

[Arxiv](https://arxiv.org/abs/2506.02548)