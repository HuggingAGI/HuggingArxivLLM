# # 解析AI生成产品描述中的性别偏差

发布时间：2025年06月03日

`LLM应用` `电子商务`

> Understanding Gender Bias in AI-Generated Product Descriptions

# 摘要

> 尽管大型语言模型（LLMs）中的性别偏见已在多个领域得到了广泛研究，但其在电子商务中的应用却鲜少被深入探讨，这可能揭示出新型算法偏见与潜在危害。我们的研究聚焦于这一领域，针对产品描述生成场景，开发了基于数据驱动的性别偏见分类体系，并将其与现有通用危害分类体系进行了对比分析。我们展示了AI生成的产品描述如何以独特的方式呈现性别偏见，这些偏见往往需要专门的检测与缓解方法。此外，我们对用于此任务的两个模型——GPT-3.5和一个专为电子商务设计的LLM——进行了定量分析，结果表明这些偏见形式在实际应用中普遍存在。我们的研究揭示了性别偏见中一些独特且未被充分探索的维度，例如对服装尺码的假设、广告中产品特性的刻板偏见，以及劝说性语言使用的差异。这些发现加深了我们对现有框架所识别的三种AI危害的理解：排他性规范、刻板印象以及性能差异，特别是在电子商务的背景下。


> While gender bias in large language models (LLMs) has been extensively studied in many domains, uses of LLMs in e-commerce remain largely unexamined and may reveal novel forms of algorithmic bias and harm. Our work investigates this space, developing data-driven taxonomic categories of gender bias in the context of product description generation, which we situate with respect to existing general purpose harms taxonomies. We illustrate how AI-generated product descriptions can uniquely surface gender biases in ways that require specialized detection and mitigation approaches. Further, we quantitatively analyze issues corresponding to our taxonomic categories in two models used for this task -- GPT-3.5 and an e-commerce-specific LLM -- demonstrating that these forms of bias commonly occur in practice. Our results illuminate unique, under-explored dimensions of gender bias, such as assumptions about clothing size, stereotypical bias in which features of a product are advertised, and differences in the use of persuasive language. These insights contribute to our understanding of three types of AI harms identified by current frameworks: exclusionary norms, stereotyping, and performance disparities, particularly for the context of e-commerce.

[Arxiv](https://arxiv.org/abs/2506.05390)