# ACCESS DENIED INC：首个敏感度意识基准环境

发布时间：2025年06月01日

`LLM应用

理由：这篇论文探讨了大型语言模型（LLMs）在企业数据管理中的应用，特别是在处理敏感信息和访问控制方面。它提出了敏感性意识（SA）的概念，并开发了一个基准测试环境来评估这一概念。研究结果为企业隐私AI系统的优化提供了方向，属于LLM的实际应用研究。` `企业数据管理` `隐私AI系统`

> ACCESS DENIED INC: The First Benchmark Environment for Sensitivity Awareness

# 摘要

> 大型语言模型（LLMs）在企业数据管理中的价值日益凸显，因其能够处理多种文档格式并支持自然语言查询。然而，与员工交互时，LLMs必须谨慎处理信息敏感性，特别是在访问受限的情况下。简单的基于用户 clearance 级别的过滤方式难以兼顾性能与隐私。为此，我们提出了敏感性意识（SA）的概念，使LLMs能够遵循预设的访问规则。我们还开发了名为ACCESS DENIED INC的基准测试环境来评估SA。实验表明，不同模型在处理数据请求时行为差异显著，尤其在有效响应合法查询的同时管理未经授权请求方面。这项研究为评估敏感性语言模型奠定了基础，并为企业隐私AI系统提供了优化方向。

> Large language models (LLMs) are increasingly becoming valuable to corporate data management due to their ability to process text from various document formats and facilitate user interactions through natural language queries. However, LLMs must consider the sensitivity of information when communicating with employees, especially given access restrictions. Simple filtering based on user clearance levels can pose both performance and privacy challenges. To address this, we propose the concept of sensitivity awareness (SA), which enables LLMs to adhere to predefined access rights rules. In addition, we developed a benchmarking environment called ACCESS DENIED INC to evaluate SA. Our experimental findings reveal significant variations in model behavior, particularly in managing unauthorized data requests while effectively addressing legitimate queries. This work establishes a foundation for benchmarking sensitivity-aware language models and provides insights to enhance privacy-centric AI systems in corporate environments.

[Arxiv](https://arxiv.org/abs/2506.00964)