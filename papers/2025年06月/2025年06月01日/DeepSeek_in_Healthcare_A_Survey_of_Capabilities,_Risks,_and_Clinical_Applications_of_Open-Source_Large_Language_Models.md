# DeepSeek在医疗领域：开源大型语言模型的能力、风险及临床应用综述

发布时间：2025年06月01日

`LLM应用` `人工智能`

> DeepSeek in Healthcare: A Survey of Capabilities, Risks, and Clinical Applications of Open-Source Large Language Models

# 摘要

> # 摘要  
DeepSeek-R1 是深度求索（DeepSeek）开发的前沿开源大型语言模型（LLM），通过混合架构融合了专家模型（MoE）、链式思维（CoT）推理和强化学习，展现了卓越的推理能力。在 MIT 许可证下开放，DeepSeek-R1 为 GPT-4 和 Claude-3 Opus 等专有模型提供了透明且经济的替代方案。在数学、医疗诊断、代码生成和药物研发等结构化领域，它表现尤为出色。在 United States Medical Licensing Examination (USMLE) 和 American Invitational Mathematics Examination (AIME) 等基准测试中，DeepSeek-R1 展现了强大的竞争力，并在儿科和眼科临床决策支持任务中取得了优异成绩。其架构实现了高效推理的同时保持了推理深度，适用于资源受限环境下的部署。然而，DeepSeek-R1 在多语言和伦理敏感情境下对偏见、虚假信息、对抗性操控和安全漏洞表现出更高的易感性。本研究综述了该模型的优势，包括可解释性、可扩展性和适应性，同时也指出了其在通用语言流畅度和安全对齐方面的局限性。未来研究重点将放在改进偏见缓解、自然语言理解、领域特定验证和监管合规性方面。总体而言，DeepSeek-R1 代表了开放、可扩展人工智能领域的重大进展，强调了协作治理的重要性，以确保负责任和公平的部署。

> DeepSeek-R1 is a cutting-edge open-source large language model (LLM) developed by DeepSeek, showcasing advanced reasoning capabilities through a hybrid architecture that integrates mixture of experts (MoE), chain of thought (CoT) reasoning, and reinforcement learning. Released under the permissive MIT license, DeepSeek-R1 offers a transparent and cost-effective alternative to proprietary models like GPT-4o and Claude-3 Opus; it excels in structured problem-solving domains such as mathematics, healthcare diagnostics, code generation, and pharmaceutical research. The model demonstrates competitive performance on benchmarks like the United States Medical Licensing Examination (USMLE) and American Invitational Mathematics Examination (AIME), with strong results in pediatric and ophthalmologic clinical decision support tasks. Its architecture enables efficient inference while preserving reasoning depth, making it suitable for deployment in resource-constrained settings. However, DeepSeek-R1 also exhibits increased vulnerability to bias, misinformation, adversarial manipulation, and safety failures - especially in multilingual and ethically sensitive contexts. This survey highlights the model's strengths, including interpretability, scalability, and adaptability, alongside its limitations in general language fluency and safety alignment. Future research priorities include improving bias mitigation, natural language comprehension, domain-specific validation, and regulatory compliance. Overall, DeepSeek-R1 represents a major advance in open, scalable AI, underscoring the need for collaborative governance to ensure responsible and equitable deployment.

[Arxiv](https://arxiv.org/abs/2506.01257)