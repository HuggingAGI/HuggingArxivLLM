# SocialEval：测评大语言模型的社交能力

发布时间：2025年06月01日

`LLM应用` `社交智能`

> SocialEval: Evaluating Social Intelligence of Large Language Models

# 摘要

> 大型语言模型在模拟人类行为方面展现出令人鼓舞的社交智能（SI）能力，这促使我们对其社交智能及其与人类的差异进行深入评估。社交智能赋予人类在社交互动中实现目标的能力，而现有研究尚未解决这一关键问题。为此，我们提出了SocialEval，一个基于叙事脚本的双语社交智能评估基准。通过手动编纂世界树结构的叙事脚本，我们整合了目标导向和过程导向的评估维度，全面考察LLMs在社交互动中的表现。实验结果显示，LLMs在社交智能评估中仍落后于人类，展现出亲社会倾向，并更倾向于选择积极的社交行为，即使这可能导致目标未达成。进一步分析发现，LLMs在表示空间和神经元激活模式上已发展出类似人类大脑的功能分区，展现出特定能力的模块化特征。

> LLMs exhibit promising Social Intelligence (SI) in modeling human behavior, raising the need to evaluate LLMs' SI and their discrepancy with humans. SI equips humans with interpersonal abilities to behave wisely in navigating social interactions to achieve social goals. This presents an operational evaluation paradigm: outcome-oriented goal achievement evaluation and process-oriented interpersonal ability evaluation, which existing work fails to address. To this end, we propose SocialEval, a script-based bilingual SI benchmark, integrating outcome- and process-oriented evaluation by manually crafting narrative scripts. Each script is structured as a world tree that contains plot lines driven by interpersonal ability, providing a comprehensive view of how LLMs navigate social interactions. Experiments show that LLMs fall behind humans on both SI evaluations, exhibit prosociality, and prefer more positive social behaviors, even if they lead to goal failure. Analysis of LLMs' formed representation space and neuronal activations reveals that LLMs have developed ability-specific functional partitions akin to the human brain.

[Arxiv](https://arxiv.org/abs/2506.00900)