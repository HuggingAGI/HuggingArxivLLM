# 评估大型语言模型模拟人类个性驱动的虚假信息易感性

发布时间：2025年06月30日

`LLM应用` `心理学` `人工智能`

> Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs

# 摘要

> 大型语言模型（LLMs）为生成大规模合成行为数据提供了可能，为人类实验提供了既合乎伦理又经济的选择。然而，这类数据能否准确捕捉到人格特质驱动的心理差异，仍是一个未解之谜。我们研究了基于五大人格模型的LLM代理在模拟人格特质影响下的错误信息易感性方面的能力，特别是新闻辨别能力，即准确区分真假新闻标题的能力。通过已发布的人类数据集，参与者根据自身人格特质对新闻标题的准确性进行了评分，我们创建了匹配的LLM代理，并将其表现与人类数据进行了对比。研究发现，某些人格特质与错误信息之间的关联，特别是宜人性和尽责性，得到了可靠复制，而其他关联则出现了偏差，揭示了LLMs在理解和表达人格特质时的系统性偏差。这些结果不仅展现了人格特质对齐的LLM在行为模拟中的潜力，也指出了其局限性，并为人工代理中认知多样性的建模提供了新的视角。

> Large language models (LLMs) make it possible to generate synthetic behavioural data at scale, offering an ethical and low-cost alternative to human experiments. Whether such data can faithfully capture psychological differences driven by personality traits, however, remains an open question. We evaluate the capacity of LLM agents, conditioned on Big-Five profiles, to reproduce personality-based variation in susceptibility to misinformation, focusing on news discernment, the ability to judge true headlines as true and false headlines as false. Leveraging published datasets in which human participants with known personality profiles rated headline accuracy, we create matching LLM agents and compare their responses to the original human patterns. Certain trait-misinformation associations, notably those involving Agreeableness and Conscientiousness, are reliably replicated, whereas others diverge, revealing systematic biases in how LLMs internalize and express personality. The results underscore both the promise and the limits of personality-aligned LLMs for behavioral simulation, and offer new insight into modeling cognitive diversity in artificial agents.

[Arxiv](https://arxiv.org/abs/2506.23610)