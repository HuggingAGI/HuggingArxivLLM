# 大型语言模型难以理解和解答数学文字题。一项从数学教育视角出发的综述研究

发布时间：2025年06月30日

`LLM应用` `数学教育`

> Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective

# 摘要

> 大型语言模型（LLMs）如ChatGPT的进步引发了它们如何融入教育领域的讨论。其中一个希望是它们能够支持数学学习，包括解决数学应用题。虽然LLMs能够轻松处理文本输入，似乎非常适合解决数学应用题，但它们的真实能力、是否能理解现实世界背景，以及对课堂的影响仍然不明朗。我们从数学教育的角度进行了一项范围广泛的审查，包括三个部分：技术概述、系统性审查用于研究的数学应用题，以及对LLMs在数学应用题上的最新实证评估。

首先，在技术概述中，我们对比了LLMs和学生在数学应用题的概念化及其解题过程。在计算机科学研究中，这通常被标记为数学推理，这一术语与数学教育中的使用并不一致。其次，我们对213项研究的文献综述显示，最受欢迎的数学应用题语料库主要由s-problems构成，这类问题不需要考虑其现实世界的实际背景。最后，我们对GPT-3.5-turbo、GPT-4o-mini、GPT-4.1和o3在287个数学应用题上的评估表明，最新的LLMs能够以接近完美的准确度解决这些s-problems，其中包括在PISA的20个问题上获得满分。然而，LLMs在处理涉及复杂或不合逻辑现实背景的问题时仍显不足。

综上所述，我们从上述三个方面得出结论：LLMs已经掌握了一种表面的解题过程，但并未真正理解数学应用题，这可能限制了它们作为数学课堂教学工具的价值。

> The progress of Large Language Models (LLMs) like ChatGPT raises the question of how they can be integrated into education. One hope is that they can support mathematics learning, including word-problem solving. Since LLMs can handle textual input with ease, they appear well-suited for solving mathematical word problems. Yet their real competence, whether they can make sense of the real-world context, and the implications for classrooms remain unclear. We conducted a scoping review from a mathematics-education perspective, including three parts: a technical overview, a systematic review of word problems used in research, and a state-of-the-art empirical evaluation of LLMs on mathematical word problems. First, in the technical overview, we contrast the conceptualization of word problems and their solution processes between LLMs and students. In computer-science research this is typically labeled mathematical reasoning, a term that does not align with usage in mathematics education. Second, our literature review of 213 studies shows that the most popular word-problem corpora are dominated by s-problems, which do not require a consideration of realities of their real-world context. Finally, our evaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, and o3 on 287 word problems shows that most recent LLMs solve these s-problems with near-perfect accuracy, including a perfect score on 20 problems from PISA. LLMs still showed weaknesses in tackling problems where the real-world context is problematic or non-sensical. In sum, we argue based on all three aspects that LLMs have mastered a superficial solution process but do not make sense of word problems, which potentially limits their value as instructional tools in mathematics classrooms.

[Arxiv](https://arxiv.org/abs/2506.24006)