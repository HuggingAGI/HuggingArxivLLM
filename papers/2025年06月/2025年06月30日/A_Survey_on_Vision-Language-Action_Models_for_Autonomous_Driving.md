# # 自动驾驶中的视觉-语言-动作模型研究综述
A Survey on Vision-Language-Action Models for Autonomous Driving

发布时间：2025年06月30日

`LLM应用

摘要讨论了多模态大型语言模型在自动驾驶中的应用，属于LLM的实际应用案例。` `自动驾驶` `人工智能`

> A Survey on Vision-Language-Action Models for Autonomous Driving

# 摘要

> 多模态大型语言模型 (MLLM) 的快速发展为视觉-语言-行动 (VLA) 范式铺平了道路，这些范式在单一策略中集成了视觉感知、自然语言理解和控制功能。自动驾驶领域的研究人员正在积极将这些方法适应到车辆领域。此类模型有望实现能够解释高级指令、推理复杂交通场景并自主决策的自动驾驶汽车。然而，相关文献仍然分散且迅速扩张。本综述为自动驾驶领域的 VLA (VLA4AD) 提供了首个全面概述。

我们 (i) 格式化了近期工作中共享的架构构建模块，(ii) 追踪了从早期解释器到以推理为中心的 VLA 模型的演变，(iii) 根据 VLA 在自动驾驶领域取得的进展，比较了 20 多种代表性模型。我们还整合了现有的数据集和基准测试，强调了同时衡量驾驶安全、准确性和解释质量的协议。最后，我们详细阐述了开放性挑战——鲁棒性、实时效率和形式验证——并概述了 VLA4AD 的未来方向。本综述为推动可解释且与社会对齐的自动驾驶汽车提供了简洁而完整的参考。GitHub 仓库可在此访问：\href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}。

> The rapid progress of multimodal large language models (MLLM) has paved the way for Vision-Language-Action (VLA) paradigms, which integrate visual perception, natural language understanding, and control within a single policy. Researchers in autonomous driving are actively adapting these methods to the vehicle domain. Such models promise autonomous vehicles that can interpret high-level instructions, reason about complex traffic scenes, and make their own decisions. However, the literature remains fragmented and is rapidly expanding. This survey offers the first comprehensive overview of VLA for Autonomous Driving (VLA4AD). We (i) formalize the architectural building blocks shared across recent work, (ii) trace the evolution from early explainer to reasoning-centric VLA models, and (iii) compare over 20 representative models according to VLA's progress in the autonomous driving domain. We also consolidate existing datasets and benchmarks, highlighting protocols that jointly measure driving safety, accuracy, and explanation quality. Finally, we detail open challenges - robustness, real-time efficiency, and formal verification - and outline future directions of VLA4AD. This survey provides a concise yet complete reference for advancing interpretable socially aligned autonomous vehicles. Github repo is available at \href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.

[Arxiv](https://arxiv.org/abs/2506.24044)