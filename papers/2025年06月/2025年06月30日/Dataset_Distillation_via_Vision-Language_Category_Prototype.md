# 基于视觉语言类别原型的数据集蒸馏

发布时间：2025年06月30日

`LLM应用

理由：这篇论文主要探讨了如何将大型语言模型（LLM）生成的描述性文本信息整合到数据集蒸馏过程中，以提升视觉模型的性能。虽然论文的重点是数据集蒸馏和视觉语言模型的优化，但其中关键的创新点在于使用了大型语言模型生成文本原型，属于将LLM应用于具体任务的范畴，因此归类为LLM应用。` `数据集蒸馏` `视觉语言`

> Dataset Distillation via Vision-Language Category Prototype

# 摘要

> 数据集蒸馏（DD）将大型数据集浓缩为既紧凑又信息丰富的替代品，保留与原数据相当的性能，同时降低存储、传输成本和计算消耗。然而，传统方法主要关注图像信息的提取，往往忽视数据中的语义信息。上下文信息的缺失限制了模型的泛化能力，尤其在处理复杂数据集时，可能导致输出不合理或遗漏关键对象。本研究通过引入文本原型来蒸馏语言信息，并与图像原型协同合成数据，将视觉语言方法整合到 DD 中，从而提升蒸馏效果。值得注意的是，本研究中的文本原型源自开源大型语言模型生成的描述性文本信息。该框架在无预先文本描述的数据集上也展现出广泛应用潜力，将数据集蒸馏的应用范围扩展至传统图像方法之外。与其它方法相比，本方法生成的图像逻辑连贯且包含目标对象，实现了最先进的验证性能并展现了强大的泛化能力。源代码和生成数据可在 https://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/ 获取。

> Dataset distillation (DD) condenses large datasets into compact yet informative substitutes, preserving performance comparable to the original dataset while reducing storage, transmission costs, and computational consumption. However, previous DD methods mainly focus on distilling information from images, often overlooking the semantic information inherent in the data. The disregard for context hinders the model's generalization ability, particularly in tasks involving complex datasets, which may result in illogical outputs or the omission of critical objects. In this study, we integrate vision-language methods into DD by introducing text prototypes to distill language information and collaboratively synthesize data with image prototypes, thereby enhancing dataset distillation performance. Notably, the text prototypes utilized in this study are derived from descriptive text information generated by an open-source large language model. This framework demonstrates broad applicability across datasets without pre-existing text descriptions, expanding the potential of dataset distillation beyond traditional image-based approaches. Compared to other methods, the proposed approach generates logically coherent images containing target objects, achieving state-of-the-art validation performance and demonstrating robust generalization. Source code and generated data are available in https://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/

[Arxiv](https://arxiv.org/abs/2506.23580)