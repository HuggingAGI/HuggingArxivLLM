# # 多智能体LLM系统规范及评估——原型系统与网络安全应用实例

发布时间：2025年06月12日

`Agent` `网络安全` `问答系统`

> Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications

# 摘要

> 近期大型语言模型（LLMs）的进展显示了其在新型应用中的潜力，例如通过 OpenAI 和 DeepSeek 最新模型的推理能力。在文本生成之外的特定领域应用这些模型时，可以利用基于 LLM 的多智能体方法，结合推理技术、代码生成和软件执行来解决复杂任务。这些应用可利用这些能力以及专门 LLM 智能体的知识。然而，尽管对 LLMs、推理技术和应用进行了许多单独评估，但它们的联合规范和综合应用尚未得到充分探索。需要为多智能体 LLM 系统定义规范，以探索其潜力及其在特定应用中的适用性，从而系统地评估 LLMs、推理技术和相关方面。本文通过多智能体系统报告了探索性研究结果，涉及系统架构、原型扩展以及多智能体系统的规范。测试案例显示，涉及网络安全任务的架构和评估方法具有可行性。特别是，结果展示了问答、服务器安全和网络安全任务的评估，这些任务由 OpenAI 和 DeepSeek 的 LLM 驱动的智能体正确完成。

> Recent advancements in LLMs indicate potential for novel applications, e.g., through reasoning capabilities in the latest OpenAI and DeepSeek models. For applying these models in specific domains beyond text generation, LLM-based multi-agent approaches can be utilized that solve complex tasks by combining reasoning techniques, code generation, and software execution. Applications might utilize these capabilities and the knowledge of specialized LLM agents. However, while many evaluations are performed on LLMs, reasoning techniques, and applications individually, their joint specification and combined application is not explored well. Defined specifications for multi-agent LLM systems are required to explore their potential and their suitability for specific applications, allowing for systematic evaluations of LLMs, reasoning techniques, and related aspects. This paper reports the results of exploratory research to specify and evaluate these aspects through a multi-agent system. The system architecture and prototype are extended from previous research and a specification is introduced for multi-agent systems. Test cases involving cybersecurity tasks indicate feasibility of the architecture and evaluation approach. In particular, the results show the evaluation of question answering, server security, and network security tasks that were completed correctly by agents with LLMs from OpenAI and DeepSeek.

[Arxiv](https://arxiv.org/abs/2506.10467)