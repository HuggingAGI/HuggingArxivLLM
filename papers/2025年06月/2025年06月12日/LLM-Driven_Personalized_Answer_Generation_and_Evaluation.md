# LLM驱动的个性化回答生成与评估

发布时间：2025年06月12日

`LLM应用` `个性化学习`

> LLM-Driven Personalized Answer Generation and Evaluation

# 摘要

> 在线学习因其灵活性和便捷性蓬勃发展，个性化学习在其中扮演了重要角色。个性化学习的关键在于为学习者提供量身定制的回答，以提升学习体验。本文探讨了大型语言模型（LLMs）生成个性化答案的潜力，旨在提高学习者参与度并为教育者减负。我们基于StackExchange平台，在语言学习和编程领域进行了系统性研究，开发了验证自动生成个性化答案的框架和数据集。通过0-shot、1-shot和few-shot等策略生成个性化答案，并采用BERTScore、LLM评估和人工评估三种方法进行评估。研究发现，为LLMs提供示例答案可显著提升其个性化能力。

> Online learning has experienced rapid growth due to its flexibility and accessibility. Personalization, adapted to the needs of individual learners, is crucial for enhancing the learning experience, particularly in online settings. A key aspect of personalization is providing learners with answers customized to their specific questions. This paper therefore explores the potential of Large Language Models (LLMs) to generate personalized answers to learners' questions, thereby enhancing engagement and reducing the workload on educators. To evaluate the effectiveness of LLMs in this context, we conducted a comprehensive study using the StackExchange platform in two distinct areas: language learning and programming. We developed a framework and a dataset for validating automatically generated personalized answers. Subsequently, we generated personalized answers using different strategies, including 0-shot, 1-shot, and few-shot scenarios. The generated answers were evaluated using three methods: 1. BERTScore, 2. LLM evaluation, and 3. human evaluation. Our findings indicated that providing LLMs with examples of desired answers (from the learner or similar learners) can significantly enhance the LLMs' ability to tailor responses to individual learners' needs.

[Arxiv](https://arxiv.org/abs/2506.10829)