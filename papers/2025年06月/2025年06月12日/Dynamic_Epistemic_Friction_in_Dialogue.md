# 对话中的动态知识摩擦力

发布时间：2025年06月12日

`Agent` `人机协作` `对话系统`

> Dynamic Epistemic Friction in Dialogue

# 摘要

> 近期，大型语言模型（LLMs）与人类偏好对齐方面的研究取得了显著进展，极大提升了其在人机协作场景中的实用性。然而，现有方法往往忽视了“认识论摩擦”这一关键因素，即在面对新信息、冲突信息或模糊信息时更新信念所遇到的内在阻力。本文将动态认识论摩擦定义为对知识整合的阻力，其特征在于智能体当前的信念状态与外部证据支持的新命题之间存在错位。我们将其纳入动态认识论逻辑框架（Van Benthem 和 Pacuit, 2011），其中摩擦表现为智能体在交互过程中进行的非平凡信念修正。通过一个情境化协作任务的分析，我们展示了这一认识论摩擦模型如何能有效预测对话中的信念更新，并进一步探讨了如何将信念对齐模型作为衡量认识论阻力或摩擦的手段，使其自然地更加复杂化以适应现实世界对话场景的复杂性。

> Recent developments in aligning Large Language Models (LLMs) with human preferences have significantly enhanced their utility in human-AI collaborative scenarios. However, such approaches often neglect the critical role of "epistemic friction," or the inherent resistance encountered when updating beliefs in response to new, conflicting, or ambiguous information. In this paper, we define dynamic epistemic friction as the resistance to epistemic integration, characterized by the misalignment between an agent's current belief state and new propositions supported by external evidence. We position this within the framework of Dynamic Epistemic Logic (Van Benthem and Pacuit, 2011), where friction emerges as nontrivial belief-revision during the interaction. We then present analyses from a situated collaborative task that demonstrate how this model of epistemic friction can effectively predict belief updates in dialogues, and we subsequently discuss how the model of belief alignment as a measure of epistemic resistance or friction can naturally be made more sophisticated to accommodate the complexities of real-world dialogue scenarios.

[Arxiv](https://arxiv.org/abs/2506.10934)