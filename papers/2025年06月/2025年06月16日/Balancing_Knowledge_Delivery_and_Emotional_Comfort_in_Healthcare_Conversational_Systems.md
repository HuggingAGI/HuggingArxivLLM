# 医疗对话系统中知识传递与情感安慰的平衡之道

发布时间：2025年06月16日

`LLM应用

论文摘要：大型语言模型的发展使得许多对话系统能够为患者的医疗状况提供合理且有用的信息。然而，当患者咨询医生时，由于病情的严重性和紧迫性，他们可能会产生负面情绪。如果模型能够在回答医疗问题的同时，根据患者的负面情绪提供适当的安慰和同理心，那么在医疗咨询过程中将能够提供更加令人安心的体验。为了解决这一问题，我们的论文探讨了医疗对话过程中知识共享与情感支持之间的平衡。我们利用大型语言模型重写了一个真实世界的互动医疗对话数据集，生成带有负面情绪的患者查询以及旨在安抚患者情绪并解答其疑虑的医疗回复。经过修改的数据用于通过各种微调方法优化最新的大型语言模型，使它们能够准确地提供既包含情感安慰又具有建设性建议的句子，以回应患者的问题。与原始的LLM模型相比，我们的实验结果表明，我们的方法显著提高了模型生成情感回应的能力，同时保持了其原有的提供准确知识型答案的能力。

LLM应用` `医疗咨询` `情感支持`

> Balancing Knowledge Delivery and Emotional Comfort in Healthcare Conversational Systems

# 摘要

> 大型语言模型的发展使得许多对话系统能够为患者的医疗状况提供合理且有用的信息。然而，当患者咨询医生时，由于病情的严重性和紧迫性，他们可能会产生负面情绪。如果模型能够在回答医疗问题的同时，根据患者的负面情绪提供适当的安慰和同理心，那么在医疗咨询过程中将能够提供更加令人安心的体验。为了解决这一问题，我们的论文探讨了医疗对话过程中知识共享与情感支持之间的平衡。我们利用大型语言模型重写了一个真实世界的互动医疗对话数据集，生成带有负面情绪的患者查询以及旨在安抚患者情绪并解答其疑虑的医疗回复。经过修改的数据用于通过各种微调方法优化最新的大型语言模型，使它们能够准确地提供既包含情感安慰又具有建设性建议的句子，以回应患者的问题。与原始的LLM模型相比，我们的实验结果表明，我们的方法显著提高了模型生成情感回应的能力，同时保持了其原有的提供准确知识型答案的能力。

> With the advancement of large language models, many dialogue systems are now capable of providing reasonable and informative responses to patients' medical conditions. However, when patients consult their doctor, they may experience negative emotions due to the severity and urgency of their situation. If the model can provide appropriate comfort and empathy based on the patient's negative emotions while answering medical questions, it will likely offer a more reassuring experience during the medical consultation process. To address this issue, our paper explores the balance between knowledge sharing and emotional support in the healthcare dialogue process. We utilize a large language model to rewrite a real-world interactive medical dialogue dataset, generating patient queries with negative emotions and corresponding medical responses aimed at soothing the patient's emotions while addressing their concerns. The modified data serves to refine the latest large language models with various fine-tuning methods, enabling them to accurately provide sentences with both emotional reassurance and constructive suggestions in response to patients' questions. Compared to the original LLM model, our experimental results demonstrate that our methodology significantly enhances the model's ability to generate emotional responses while maintaining its original capability to provide accurate knowledge-based answers.

[Arxiv](https://arxiv.org/abs/2506.13692)