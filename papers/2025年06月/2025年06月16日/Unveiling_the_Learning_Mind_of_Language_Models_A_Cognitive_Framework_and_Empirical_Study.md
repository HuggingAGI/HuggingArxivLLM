# 解码语言模型的学习机制：认知框架与实证研究

发布时间：2025年06月16日

`LLM理论` `人工智能`

> Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study

# 摘要

> 大型语言模型（LLMs）在数学、编码和推理等任务中表现卓越，但其学习能力——对适应动态环境和获取新知识至关重要——仍待深入探索。本研究通过引入一个受认知心理学和教育学启发的框架，填补了这一空白。我们从三个相互独立、互补的学习维度重新定义了一般学习能力：从教师学习（通过明确指导获取知识）、从概念学习（内化抽象结构并推广到新情境）和从经验学习（通过积累的探索和反馈进行适应）。通过全面实证研究，我们发现了几个关键点：（i）交互显著提升学习效果；（ii）概念理解能力随模型规模增长而涌现，且更有利于大型模型；（iii）LLMs擅长少样本学习，但在多样本学习中表现有限。基于此框架和发现，我们提出了一套基准测试，提供了一个统一且现实的评估体系，用于衡量LLMs在三个学习维度上的一般学习能力。这不仅有助于诊断模型的不足，还为开发更适应性和类人化的模型提供了重要参考。

> Large language models (LLMs) have shown impressive capabilities across tasks such as mathematics, coding, and reasoning, yet their learning ability, which is crucial for adapting to dynamic environments and acquiring new knowledge, remains underexplored. In this work, we address this gap by introducing a framework inspired by cognitive psychology and education. Specifically, we decompose general learning ability into three distinct, complementary dimensions: Learning from Instructor (acquiring knowledge via explicit guidance), Learning from Concept (internalizing abstract structures and generalizing to new contexts), and Learning from Experience (adapting through accumulated exploration and feedback). We conduct a comprehensive empirical study across the three learning dimensions and identify several insightful findings, such as (i) interaction improves learning; (ii) conceptual understanding is scale-emergent and benefits larger models; and (iii) LLMs are effective few-shot learners but not many-shot learners. Based on our framework and empirical findings, we introduce a benchmark that provides a unified and realistic evaluation of LLMs' general learning abilities across three learning cognition dimensions. It enables diagnostic insights and supports evaluation and development of more adaptive and human-like models.

[Arxiv](https://arxiv.org/abs/2506.13464)