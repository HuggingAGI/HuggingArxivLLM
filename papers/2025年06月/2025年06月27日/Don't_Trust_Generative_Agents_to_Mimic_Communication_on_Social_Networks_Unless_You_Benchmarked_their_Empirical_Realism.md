# 若未验证生成式智能体在社交网络沟通中的实证现实性，切勿轻信其模拟能力。

发布时间：2025年06月27日

`LLM应用

理由：论文探讨了大型语言模型在模拟社交网络用户行为中的应用，构建了框架并进行了实证测试，属于LLM的应用层面研究。` `社会科学` `社交网络分析`

> Don't Trust Generative Agents to Mimic Communication on Social Networks Unless You Benchmarked their Empirical Realism

# 摘要

> 大型语言模型 (LLMs) 在模拟人类行为方面的能力激发了计算社会科学领域的大量研究，这些研究假设可以通过AI代理代替人类进行实证研究。然而，关于这一假设是否成立以及何时成立的研究结果存在矛盾，因此有必要深入理解不同实验设计之间的差异。我们专注于利用LLMs复制社交网络用户行为，以分析社交网络上的沟通。首先，我们为社交网络模拟构建了一个正式的框架，随后聚焦于模仿用户沟通这一子任务。我们通过实证测试了在英语和德语环境下模仿X平台上用户行为的不同方法。我们的研究发现表明，社交模拟应通过其在模拟组件拟合环境中测得的经验现实性来验证。本文主张在将生成式智能体建模应用于社会模拟时应更加严谨。

> The ability of Large Language Models (LLMs) to mimic human behavior triggered a plethora of computational social science research, assuming that empirical studies of humans can be conducted with AI agents instead. Since there have been conflicting research findings on whether and when this hypothesis holds, there is a need to better understand the differences in their experimental designs. We focus on replicating the behavior of social network users with the use of LLMs for the analysis of communication on social networks. First, we provide a formal framework for the simulation of social networks, before focusing on the sub-task of imitating user communication. We empirically test different approaches to imitate user behavior on X in English and German. Our findings suggest that social simulations should be validated by their empirical realism measured in the setting in which the simulation components were fitted. With this paper, we argue for more rigor when applying generative-agent-based modeling for social simulation.

[Arxiv](https://arxiv.org/abs/2506.21974)