# 越狱策略的演进：融合多种技术的创新方法，针对大型语言模型漏洞展开攻击并突破现代防护体系

发布时间：2025年06月27日

`LLM应用` `人工智能`

> Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses

# 摘要

> 预训练语言模型（PTLMs）和大型语言模型（LLMs）的进展推动了它们在各领域的广泛应用。然而，这些模型仍存在安全漏洞，容易受到两类主要攻击：token级和prompt级jailbreak攻击。Token级攻击通过嵌入对抗序列实现攻击，但存在可检测模式和依赖梯度优化的局限；而prompt级攻击虽能通过语义输入诱发出有害响应，但可靠性不足。为解决这些局限，我们提出两种混合方法：GCG + PAIR和GCG + WordGame，将token和prompt级技术相结合。实验结果表明，GCG + PAIR在Llama-3上的攻击成功率高达91.6%，显著优于PAIR的58.4%；GCG + WordGame则在严格评估下仍保持80%以上的成功率。更重要的是，这两种方法均能突破Gradient Cuff和JBShield等高级防御，揭示了现有安全机制的漏洞，强调了在防御稳健性与攻击成功率之间权衡的重要性，并呼吁建立更全面的安全防护体系以应对自适应攻击。

> The advancement of Pre-Trained Language Models (PTLMs) and Large Language Models (LLMs) has led to their widespread adoption across diverse applications. Despite their success, these models remain vulnerable to attacks that exploit their inherent weaknesses to bypass safety measures. Two primary inference-phase threats are token-level and prompt-level jailbreaks. Token-level attacks embed adversarial sequences that transfer well to black-box models like GPT but leave detectable patterns and rely on gradient-based token optimization, whereas prompt-level attacks use semantically structured inputs to elicit harmful responses yet depend on iterative feedback that can be unreliable. To address the complementary limitations of these methods, we propose two hybrid approaches that integrate token- and prompt-level techniques to enhance jailbreak effectiveness across diverse PTLMs. GCG + PAIR and the newly explored GCG + WordGame hybrids were evaluated across multiple Vicuna and Llama models. GCG + PAIR consistently raised attack-success rates over its constituent techniques on undefended models; for instance, on Llama-3, its Attack Success Rate (ASR) reached 91.6%, a substantial increase from PAIR's 58.4% baseline. Meanwhile, GCG + WordGame matched the raw performance of WordGame maintaining a high ASR of over 80% even under stricter evaluators like Mistral-Sorry-Bench. Crucially, both hybrids retained transferability and reliably pierced advanced defenses such as Gradient Cuff and JBShield, which fully blocked single-mode attacks. These findings expose previously unreported vulnerabilities in current safety stacks, highlight trade-offs between raw success and defensive robustness, and underscore the need for holistic safeguards against adaptive adversaries.

[Arxiv](https://arxiv.org/abs/2506.21972)