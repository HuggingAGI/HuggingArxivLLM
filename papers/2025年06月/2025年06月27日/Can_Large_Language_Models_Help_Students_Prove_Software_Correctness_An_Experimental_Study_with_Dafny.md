# 大型语言模型能否助力学生证明软件正确性？基于 Dafny 的实验研究

发布时间：2025年06月27日

`LLM应用`

> Can Large Language Models Help Students Prove Software Correctness? An Experimental Study with Dafny

# 摘要

> 如今，计算教育中的学生们越来越多地使用如ChatGPT这样的大型语言模型（LLMs）。然而，这些模型在支持像演绎程序验证这样需要高度认知能力的任务中的作用仍不明确。本文聚焦于学生在使用LLM解决Dafny语言中的形式化验证练习时的互动模式。Dafny是一种支持函数正确性的编程语言，允许程序员编写正式规范并自动验证实现是否满足规范。我们以参与形式化方法课程的硕士生为研究对象，采用混合方法研究。每位参与者需完成两个验证问题，其中一个可使用定制的ChatGPT界面（记录所有互动），另一个则不可使用。我们发现，成功学生采用了特定策略，并且学生对LLMs的信任程度也值得关注。研究结果表明，使用ChatGPT的学生表现显著提升，但这种提升与提示质量密切相关。最后，我们提出了将LLMs更有效地融入形式化方法课程的建议，包括设计促进学习而非替代的LLM感知挑战。

> Students in computing education increasingly use large language models (LLMs) such as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding tasks, like deductive program verification, remains poorly understood. This paper investigates how students interact with an LLM when solving formal verification exercises in Dafny, a language that supports functional correctness, by allowing programmers to write formal specifications and automatically verifying that the implementation satisfies the specification. We conducted a mixed-methods study with master's students enrolled in a formal methods course. Each participant completed two verification problems, one with access to a custom ChatGPT interface, that logged all interactions, and the other without. We identified strategies used by successful students and assessed the level of trust students place in LLMs. %\todo{Our findings show that something here} Our findings show that students perform significantly better when using ChatGPT; however, performance gains are tied to prompt quality. We conclude with practical recommendations for integrating LLMs into formal methods courses more effectively, including designing LLM-aware challenges that promote learning rather than substitution.

[Arxiv](https://arxiv.org/abs/2506.22370)