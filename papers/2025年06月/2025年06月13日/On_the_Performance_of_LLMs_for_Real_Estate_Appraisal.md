# 大型语言模型在房地产评估中的表现

发布时间：2025年06月13日

`LLM应用` `房地产`

> On the Performance of LLMs for Real Estate Appraisal

# 摘要

> 房地产市场对全球经济举足轻重，却长期受困于信息不对称。本研究探索了大型语言模型（LLMs）如何通过优化的In-Context Learning（ICL）策略，生成既具竞争力又易于理解的房价评估，从而让房地产洞察更加普及。我们对领先LLMs进行了系统性评估，涵盖多种国际住房数据集，对比了零-shot、少-shot、市场报告增强和混合提示技术。研究发现，LLMs能有效利用房产规模、配套设施等效用变量生成有意义的估价。虽然传统机器学习模型在预测准确性上仍占优势，但LLMs以其更易用、互动性和可解释性更强的特点脱颖而出。尽管自解释结果需谨慎对待，LLMs的预测解释与前沿模型高度一致，印证了其可靠性。通过基于特征相似性和地理邻近性精心挑选上下文示例，LLMs性能得到显著提升，但其在价格区间过自信和空间推理能力有限方面仍有待突破。我们通过提示优化为结构化预测任务提供了实用指导。本研究不仅揭示了LLMs在提升房地产评估透明度方面的潜力，更为相关利益方提供了切实可行的见解。

> The real estate market is vital to global economies but suffers from significant information asymmetry. This study examines how Large Language Models (LLMs) can democratize access to real estate insights by generating competitive and interpretable house price estimates through optimized In-Context Learning (ICL) strategies. We systematically evaluate leading LLMs on diverse international housing datasets, comparing zero-shot, few-shot, market report-enhanced, and hybrid prompting techniques. Our results show that LLMs effectively leverage hedonic variables, such as property size and amenities, to produce meaningful estimates. While traditional machine learning models remain strong for pure predictive accuracy, LLMs offer a more accessible, interactive and interpretable alternative. Although self-explanations require cautious interpretation, we find that LLMs explain their predictions in agreement with state-of-the-art models, confirming their trustworthiness. Carefully selected in-context examples based on feature similarity and geographic proximity, significantly enhance LLM performance, yet LLMs struggle with overconfidence in price intervals and limited spatial reasoning. We offer practical guidance for structured prediction tasks through prompt optimization. Our findings highlight LLMs' potential to improve transparency in real estate appraisal and provide actionable insights for stakeholders.

[Arxiv](https://arxiv.org/abs/2506.11812)