# Revealing Political Bias in LLMs through Structured Multi-Agent Debate
通过多智能体结构化辩论揭示大型语言模型中的政治偏见

发布时间：2025年06月13日

`LLM应用` `政治学` `社会行为模拟`

> Revealing Political Bias in LLMs through Structured Multi-Agent Debate

# 摘要

> 大型语言模型（LLMs）在模拟社会行为方面应用日益广泛，然而它们在辩论中的政治偏见和互动动态尚未得到充分研究。我们通过构建结构化的多代理辩论框架，探讨LLM类型及代理性别属性对政治偏见的影响，邀请立场中立、共和党及民主党倾向的美国LLM代理参与政治敏感话题的辩论。我们系统性地调整底层LLMs、代理性别及辩论形式，以考察模型来源及代理角色对辩论全程中政治偏见和态度的影响。研究发现，中立型代理在辩论中始终与民主党保持一致，而共和党则向中立靠拢；性别对代理态度具有显著影响，代理在了解其他代理性别后会相应调整观点；与先前研究相反，具有相同政治立场的代理可能形成回音室，随着辩论深入，其态度呈现预期强化趋势。

> Large language models (LLMs) are increasingly used to simulate social behaviour, yet their political biases and interaction dynamics in debates remain underexplored. We investigate how LLM type and agent gender attributes influence political bias using a structured multi-agent debate framework, by engaging Neutral, Republican, and Democrat American LLM agents in debates on politically sensitive topics. We systematically vary the underlying LLMs, agent genders, and debate formats to examine how model provenance and agent personas influence political bias and attitudes throughout debates. We find that Neutral agents consistently align with Democrats, while Republicans shift closer to the Neutral; gender influences agent attitudes, with agents adapting their opinions when aware of other agents' genders; and contrary to prior research, agents with shared political affiliations can form echo chambers, exhibiting the expected intensification of attitudes as debates progress.

[Arxiv](https://arxiv.org/abs/2506.11825)