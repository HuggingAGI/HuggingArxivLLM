# # 基于 GPT-4 的漏洞见证单元测试生成方法

发布时间：2025年06月13日

`LLM应用

摘要讨论了使用GPT-4生成单元测试用例来检测软件漏洞，这属于将大型语言模型应用于特定领域（软件测试），因此归类为LLM应用。` `软件工程`

> Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation

# 摘要

> 软件开发过程中，测试是质量保障的关键环节。有效的测试不仅提升代码覆盖率，预防回归问题，更能及时发现并修复软件漏洞。然而，创建高质量的测试用例往往是一项复杂且耗时的工作。为助力开发者和安全专家，本研究探索了广受欢迎的大型语言模型GPT-4在漏洞检测领域的自动单元测试生成能力。我们选取了VUL4J数据集中的真实漏洞及其修复方案，验证GPT-4能否基于修复前后的代码生成语法和/或语义上正确的单元测试。研究重点包括代码上下文的影响、GPT-4的自我修正能力，以及生成测试用例的实用性。结果显示，在无特定领域预训练的情况下，GPT-4有66.5%的概率生成语法正确的测试用例。尽管仅有7.5%的案例能自动验证修复的语义正确性，但我们的评估表明，GPT-4生成的测试模板通常只需少量手动调整，即可发展为功能完整的漏洞见证测试。因此，尽管数据有限，我们的初步发现表明，GPT-4在生成漏洞见证测试方面具有显著潜力。它或许无法完全自主运行，但在部分自动化流程中发挥着重要作用。

> In the life-cycle of software development, testing plays a crucial role in quality assurance. Proper testing not only increases code coverage and prevents regressions but it can also ensure that any potential vulnerabilities in the software are identified and effectively fixed. However, creating such tests is a complex, resource-consuming manual process. To help developers and security experts, this paper explores the automatic unit test generation capability of one of the most widely used large language models, GPT-4, from the perspective of vulnerabilities. We examine a subset of the VUL4J dataset containing real vulnerabilities and their corresponding fixes to determine whether GPT-4 can generate syntactically and/or semantically correct unit tests based on the code before and after the fixes as evidence of vulnerability mitigation. We focus on the impact of code contexts, the effectiveness of GPT-4's self-correction ability, and the subjective usability of the generated test cases. Our results indicate that GPT-4 can generate syntactically correct test cases 66.5\% of the time without domain-specific pre-training. Although the semantic correctness of the fixes could be automatically validated in only 7. 5\% of the cases, our subjective evaluation shows that GPT-4 generally produces test templates that can be further developed into fully functional vulnerability-witnessing tests with relatively minimal manual effort.
  Therefore, despite the limited data, our initial findings suggest that GPT-4 can be effectively used in the generation of vulnerability-witnessing tests. It may not operate entirely autonomously, but it certainly plays a significant role in a partially automated process.

[Arxiv](https://arxiv.org/abs/2506.11559)