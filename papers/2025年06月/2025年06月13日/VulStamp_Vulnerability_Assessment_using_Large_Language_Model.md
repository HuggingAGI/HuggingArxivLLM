# VulStamp：基于大型语言模型的漏洞评估

发布时间：2025年06月13日

`LLM应用` `软件开发` `信息安全`

> VulStamp: Vulnerability Assessment using Large Language Model

# 摘要

> 现代漏洞检测工具让开发者能够高效识别众多安全缺陷，但盲目修复这些漏洞往往会导致不必要的开发成本。这是因为大部分检测到的漏洞要么难以被利用，要么在实际环境中影响微乎其微。因此，漏洞严重性评估成为了优化软件开发效率的关键环节。现有的漏洞评估方法大多依赖人工编写的源代码描述，但由于描述质量参差不齐和意图解读的主观性，这些方法的性能受到很大限制。为了解决这一问题，本文提出了一种名为 VulStamp 的全新意图引导框架，旨在实现无需描述的漏洞评估。具体来说，VulStamp 结合了静态分析和大型语言模型（LLM），能够提取漏洞代码的意图信息。基于这些意图信息，VulStamp 使用经过微调的模型来进行漏洞评估。此外，为了解决漏洞类型数据不平衡的问题，VulStamp 还引入了一种基于强化学习（RL）的提示微调方法来训练评估模型。

> Although modern vulnerability detection tools enable developers to efficiently identify numerous security flaws, indiscriminate remediation efforts often lead to superfluous development expenses. This is particularly true given that a substantial portion of detected vulnerabilities either possess low exploitability or would incur negligible impact in practical operational environments. Consequently, vulnerability severity assessment has emerged as a critical component in optimizing software development efficiency. Existing vulnerability assessment methods typically rely on manually crafted descriptions associated with source code artifacts. However, due to variability in description quality and subjectivity in intention interpretation, the performance of these methods is seriously limited. To address this issue, this paper introduces VulStamp, a novel intention-guided framework, to facilitate description-free vulnerability assessment. Specifically, VulStamp adopts static analysis together with Large Language Model (LLM) to extract the intention information of vulnerable code. Based on the intention information, VulStamp uses a prompt-tuned model for vulnerability assessment. Furthermore, to mitigate the problem of imbalanced data associated with vulnerability types, VulStamp integrates a Reinforcement Learning (RL)-based prompt-tuning method to train the assessment model.

[Arxiv](https://arxiv.org/abs/2506.11484)