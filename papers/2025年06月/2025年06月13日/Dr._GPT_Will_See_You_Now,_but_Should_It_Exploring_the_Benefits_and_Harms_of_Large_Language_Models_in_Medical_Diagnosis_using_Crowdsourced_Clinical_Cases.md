# GPT医生来了，但这真的合适吗？——通过众包临床案例，探讨大型语言模型在医疗诊断中的利弊

发布时间：2025年06月13日

`LLM应用` `健康问答`

> Dr. GPT Will See You Now, but Should It? Exploring the Benefits and Harms of Large Language Models in Medical Diagnosis using Crowdsourced Clinical Cases

# 摘要

> 大型语言模型（LLMs）在医疗（自我）诊断和初步分诊等高风险场景中的广泛应用，引发了对其有效性、适当性和潜在危害性的重大伦理和实际担忧。尽管先前研究探讨了LLMs在回答专家编写的健康查询、医学考试题库问题或基于临床案例的查询方面的有效性，但这些研究完全忽略了对LLMs在回答普通用户日常健康问题方面有效性的真实世界评估，而这正是LLMs更为常见的应用场景。为填补这一研究空白，本文介绍了来自一项大学级别竞赛的发现，该竞赛利用了一种新颖的众包方法来评估LLMs在回答日常健康问题方面的有效性。在为期一周的时间里，34名参与者向4个公开可用的LLMs提出了212个真实（或想象的）健康问题，随后由一支9名认证医师组成的团队对LLMs生成的回答进行了评估。总体而言，平均而言，212个LLMs回答中有76%被医师认为是准确的。此外，我们还调查了这些LLMs的RAG版本（配备全面的医学知识库）是否能提高LLMs生成的回答质量。最后，通过采访7名医疗专业人士（他们在比赛中观看了所有提示），我们得出了定性见解，以解释我们的定量发现。本文旨在提供一个更扎实的理解，说明LLMs在现实世界日常健康交流中的表现。

> The proliferation of Large Language Models (LLMs) in high-stakes applications such as medical (self-)diagnosis and preliminary triage raises significant ethical and practical concerns about the effectiveness, appropriateness, and possible harmfulness of the use of these technologies for health-related concerns and queries. Some prior work has considered the effectiveness of LLMs in answering expert-written health queries/prompts, questions from medical examination banks, or queries based on pre-existing clinical cases. Unfortunately, these existing studies completely ignore an in-the-wild evaluation of the effectiveness of LLMs in answering everyday health concerns and queries typically asked by general users, which corresponds to the more prevalent use case for LLMs. To address this research gap, this paper presents the findings from a university-level competition that leveraged a novel, crowdsourced approach for evaluating the effectiveness of LLMs in answering everyday health queries. Over the course of a week, a total of 34 participants prompted four publicly accessible LLMs with 212 real (or imagined) health concerns, and the LLM generated responses were evaluated by a team of nine board-certified physicians. At a high level, our findings indicate that on average, 76% of the 212 LLM responses were deemed to be accurate by physicians. Further, with the help of medical professionals, we investigated whether RAG versions of these LLMs (powered with a comprehensive medical knowledge base) can improve the quality of responses generated by LLMs. Finally, we also derive qualitative insights to explain our quantitative findings by conducting interviews with seven medical professionals who were shown all the prompts in our competition. This paper aims to provide a more grounded understanding of how LLMs perform in real-world everyday health communication.

[Arxiv](https://arxiv.org/abs/2506.13805)