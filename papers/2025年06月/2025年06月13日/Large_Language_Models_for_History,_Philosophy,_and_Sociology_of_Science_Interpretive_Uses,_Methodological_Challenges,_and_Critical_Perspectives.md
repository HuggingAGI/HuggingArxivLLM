# 大型语言模型在科学史、哲学与社会学中的解释性应用、方法论挑战及批判性视角

发布时间：2025年06月13日

`LLM应用

摘要讨论了大型语言模型（LLMs）在科学史、科学哲学与科学社会学（HPSS）领域的应用，探讨了其在处理非结构化文本和上下文推断方面的优势，以及如何将其整合到HPSS中的策略。这属于LLM的应用层面，因此归类为LLM应用。` `科学史` `科学哲学与科学社会学`

> Large Language Models for History, Philosophy, and Sociology of Science: Interpretive Uses, Methodological Challenges, and Critical Perspectives

# 摘要

> 本文探讨了将大型语言模型（LLMs）作为科学史、科学哲学与科学社会学（HPSS）领域的研究工具的应用。LLMs在处理非结构化文本和从上下文中推断意义方面表现出色，为HPSS提供了新的可能性，挑战了计算方法与解释性方法之间长期存在的分界。这为HPSS带来了机遇与挑战，因为HPSS强调解释性方法，认为意义是上下文依赖的、模糊的，并且具有历史背景。我们主张HPSS不仅能够从LLMs的能力中获益，还能对其知识假设和基础设施影响进行批判性考察。为此，我们首先为非技术读者提供了一个简明扼要的LLM架构和训练范式的入门指南。我们将LLMs不仅视为中立的工具，而是作为编码了关于意义、上下文和相似性的假设的知识基础设施，这些假设由其训练数据、架构和使用模式所决定。然后，我们探讨了增强的计算技术（如结构化数据、检测模式和建模动态过程）如何被LLMs赋能，并应用于支持HPSS中的解释性研究。我们的分析比较了全上下文和生成模型，概述了领域和任务适应策略（例如持续预训练、微调和检索增强生成），并评估了它们在HPSS解释性研究中的优缺点。最后，我们提出了将LLMs整合到HPSS中的四点经验：（1）模型选择涉及解释性权衡；（2）LLM素养是基础；（3）HPSS必须定义自己的基准和语料库；（4）LLMs应增强而非取代解释性方法。

> This paper explores the use of large language models (LLMs) as research tools in the history, philosophy, and sociology of science (HPSS). LLMs are remarkably effective at processing unstructured text and inferring meaning from context, offering new affordances that challenge long-standing divides between computational and interpretive methods. This raises both opportunities and challenges for HPSS, which emphasizes interpretive methodologies and understands meaning as context-dependent, ambiguous, and historically situated. We argue that HPSS is uniquely positioned not only to benefit from LLMs' capabilities but also to interrogate their epistemic assumptions and infrastructural implications. To this end, we first offer a concise primer on LLM architectures and training paradigms tailored to non-technical readers. We frame LLMs not as neutral tools but as epistemic infrastructures that encode assumptions about meaning, context, and similarity, conditioned by their training data, architecture, and patterns of use. We then examine how computational techniques enhanced by LLMs, such as structuring data, detecting patterns, and modeling dynamic processes, can be applied to support interpretive research in HPSS. Our analysis compares full-context and generative models, outlines strategies for domain and task adaptation (e.g., continued pretraining, fine-tuning, and retrieval-augmented generation), and evaluates their respective strengths and limitations for interpretive inquiry in HPSS. We conclude with four lessons for integrating LLMs into HPSS: (1) model selection involves interpretive trade-offs; (2) LLM literacy is foundational; (3) HPSS must define its own benchmarks and corpora; and (4) LLMs should enhance, not replace, interpretive methods.

[Arxiv](https://arxiv.org/abs/2506.12242)