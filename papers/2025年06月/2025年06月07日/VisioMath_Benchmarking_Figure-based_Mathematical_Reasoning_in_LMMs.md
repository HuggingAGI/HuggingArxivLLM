# VisioMath：评估大型数学模型中的基于图像数学推理能力

发布时间：2025年06月07日

`LLM应用` `数学教育` `计算机视觉`

> VisioMath: Benchmarking Figure-based Mathematical Reasoning in LMMs

# 摘要

> 大型多模态模型 (LMMs) 在多领域问题解决中表现出色，但在涉及图像答案选项的数学推理能力上仍有许多待探索之处。为此，我们推出了 VisioMath，这一基准测试专注于评估基于图像选项的多模态数学推理能力。VisioMath 包含 8,070 张图像和 1,800 个多项选择题，每个答案都是图像形式，这对现有模型提出了独特挑战。作为首个专为基于图像选项场景设计的数据集，VisioMath 强调了答案选项间细微差别对准确解题的重要性。我们对当前最先进的 LMMs 进行了系统性评估，发现即使是表现最佳的 GPT-4o 也只能达到 45.9% 的准确率，凸显了现有模型在处理视觉相似答案时的局限。VisioMath 通过填补现有基准的空白，为未来研究提供了严格的测试平台，助力多模态推理技术的进一步发展。

> Large Multimodal Models (LMMs) have demonstrated remarkable problem-solving capabilities across various domains. However, their ability to perform mathematical reasoning when answer options are represented as images--an essential aspect of multi-image comprehension--remains underexplored. To bridge this gap, we introduce VisioMath, a benchmark designed to evaluate mathematical reasoning in multimodal contexts involving image-based answer choices. VisioMath comprises 8,070 images and 1,800 multiple-choice questions, where each answer option is an image, presenting unique challenges to existing LMMs. To the best of our knowledge, VisioMath is the first dataset specifically tailored for mathematical reasoning in image-based-option scenarios, where fine-grained distinctions between answer choices are critical for accurate problem-solving. We systematically evaluate state-of-the-art LMMs on VisioMath and find that even the most advanced models struggle with this task. Notably, GPT-4o achieves only 45.9% accuracy, underscoring the limitations of current models in reasoning over visually similar answer choices. By addressing a crucial gap in existing benchmarks, VisioMath establishes a rigorous testbed for future research, driving advancements in multimodal reasoning.

[Arxiv](https://arxiv.org/abs/2506.06727)