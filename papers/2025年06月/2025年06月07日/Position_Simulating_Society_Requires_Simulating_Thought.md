# # 观点：模拟社会，必须模拟思维

发布时间：2025年06月07日

`Agent

摘要讨论了使用大型语言模型（LLMs）构建智能体来模拟社会行为和推理，提出了一个新的概念建模范式和评估框架，重点在于智能体的设计和能力，因此属于Agent类别。` `人工智能` `认知科学`

> Position: Simulating Society Requires Simulating Thought

# 摘要

> 我们认为，用大型语言模型（LLMs）模拟社会，不仅要生成合理的行为，更需要具备认知基础的推理能力，这种推理需要结构化、可修订且可追溯。目前，基于LLM的智能体越来越多地被用于模拟个体和群体行为，主要通过提示和监督微调来实现。然而，这些智能体常常缺乏内在一致性、因果推理能力和信念可追溯性，这使得它们在分析人类推理、商议或对干预措施的反应时不可靠。为解决这一问题，我们提出了一种概念建模范式——生成心智（GenMinds），它借鉴了认知科学，以支持生成智能体中的结构化信念表示。为了评估此类智能体，我们引入了RECAP（重建因果路径）框架，这是一个基准测试，旨在通过因果可追溯性、人口统计基础和干预一致性来评估推理的保真度。这些贡献推动了一个更广泛的变化：从表面模仿转向能够模拟思想（而不仅仅是语言）的生成智能体，从而实现更深入的社会模拟。

> Simulating society with large language models (LLMs), we argue, requires more than generating plausible behavior -- it demands cognitively grounded reasoning that is structured, revisable, and traceable. LLM-based agents are increasingly used to emulate individual and group behavior -- primarily through prompting and supervised fine-tuning. Yet they often lack internal coherence, causal reasoning, and belief traceability -- making them unreliable for analyzing how people reason, deliberate, or respond to interventions.
  To address this, we present a conceptual modeling paradigm, Generative Minds (GenMinds), which draws from cognitive science to support structured belief representations in generative agents. To evaluate such agents, we introduce the RECAP (REconstructing CAusal Paths) framework, a benchmark designed to assess reasoning fidelity via causal traceability, demographic grounding, and intervention consistency. These contributions advance a broader shift: from surface-level mimicry to generative agents that simulate thought -- not just language -- for social simulations.

[Arxiv](https://arxiv.org/abs/2506.06958)