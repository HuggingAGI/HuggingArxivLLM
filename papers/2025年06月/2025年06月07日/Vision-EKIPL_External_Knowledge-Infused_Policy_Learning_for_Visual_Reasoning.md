# Vision-EKIPL：基于外部知识增强的策略学习，助力视觉推理

发布时间：2025年06月07日

`LLM应用` `视觉推理` `人工智能`

> Vision-EKIPL: External Knowledge-Infused Policy Learning for Visual Reasoning

# 摘要

> 视觉推理是理解复杂多模态数据和推动人工通用智能发展的关键。现有方法通过强化学习（RL）微调（如GRPO）来提升多模态大语言模型（MLLMs）的推理能力。然而，当前RL方法仅从策略模型本身中采样动作组，这限制了模型推理能力的上限，并导致训练效率低下。为了解决这些问题，本文提出了一种名为	extbf{Vision-EKIPL}的新型RL框架。该框架的核心是在RL训练过程中引入外部辅助模型生成的高质量动作，以指导策略模型的优化。通过从外部模型注入知识进行策略学习，显著扩展了模型的探索空间，有效提升了推理边界，大幅加快了训练收敛速度和效率。实验结果表明，与现有最优方法（SOTA）相比，我们提出的Vision-EKIPL在Reason-RFT-CoT基准上实现了高达5%的性能提升。这表明Vision-EKIPL能够克服传统RL方法的局限性，显著增强MLLMs的视觉推理性能，并为该领域的研究提供了一个新的有效范式。

> Visual reasoning is crucial for understanding complex multimodal data and advancing Artificial General Intelligence. Existing methods enhance the reasoning capability of Multimodal Large Language Models (MLLMs) through Reinforcement Learning (RL) fine-tuning (e.g., GRPO). However, current RL approaches sample action groups solely from the policy model itself, which limits the upper boundary of the model's reasoning capability and leads to inefficient training. To address these limitations, this paper proposes a novel RL framework called \textbf{Vision-EKIPL}. The core of this framework lies in introducing high-quality actions generated by external auxiliary models during the RL training process to guide the optimization of the policy model. The policy learning with knowledge infusion from external models significantly expands the model's exploration space, effectively improves the reasoning boundary, and substantially accelerates training convergence speed and efficiency. Experimental results demonstrate that our proposed Vision-EKIPL achieved up to a 5\% performance improvement on the Reason-RFT-CoT Benchmark compared to the state-of-the-art (SOTA). It reveals that Vision-EKIPL can overcome the limitations of traditional RL methods, significantly enhance the visual reasoning performance of MLLMs, and provide a new effective paradigm for research in this field.

[Arxiv](https://arxiv.org/abs/2506.06856)