# # 当前LLMs解读政治话语隐含内容的局限性：他们假装不理解

发布时间：2025年06月07日

`LLM应用`

> They want to pretend not to understand: The Limits of Current LLMs in Interpreting Implicit Content of Political Discourse

# 摘要

> 隐性内容在政治话语中扮演着关键角色，说话者系统性地运用会话含意和预设等语用策略来影响受众。大型语言模型（LLMs）在需要复杂语义和语用理解的任务中表现出色，凸显了其在检测和解释隐性内容含义方面的潜力。然而，它们在政治话语中实现这一点的能力仍然鲜为人知。我们首次利用大型IMPAQTS语料库，该语料库包含标注了操纵性隐性内容的意大利政治演讲，提出方法来测试LLMs在此具有挑战性的问题中的有效性。通过选择题任务和开放生成任务，我们证明所有测试的模型在解释预设和会话含意方面都存在困难。我们得出结论，当前的LLMs缺乏准确解读高度隐性语言（如政治话语中常见语言）所需的关键语用能力。同时，我们指出了提高模型性能的有前景的趋势和未来方向。我们在https://github.com/WalterPaci/IMPAQTS-PID上发布了我们的数据和代码。


> Implicit content plays a crucial role in political discourse, where speakers systematically employ pragmatic strategies such as implicatures and presuppositions to influence their audiences. Large Language Models (LLMs) have demonstrated strong performance in tasks requiring complex semantic and pragmatic understanding, highlighting their potential for detecting and explaining the meaning of implicit content. However, their ability to do this within political discourse remains largely underexplored. Leveraging, for the first time, the large IMPAQTS corpus, which comprises Italian political speeches with the annotation of manipulative implicit content, we propose methods to test the effectiveness of LLMs in this challenging problem. Through a multiple-choice task and an open-ended generation task, we demonstrate that all tested models struggle to interpret presuppositions and implicatures. We conclude that current LLMs lack the key pragmatic capabilities necessary for accurately interpreting highly implicit language, such as that found in political discourse. At the same time, we highlight promising trends and future directions for enhancing model performance. We release our data and code at https://github.com/WalterPaci/IMPAQTS-PID

[Arxiv](https://arxiv.org/abs/2506.06775)