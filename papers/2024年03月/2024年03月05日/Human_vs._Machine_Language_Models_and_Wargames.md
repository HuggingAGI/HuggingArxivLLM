# 人类与机器的较量：探究语言模型在战争模拟游戏中的表现与应用

发布时间：2024年03月05日

`Agent`

> Human vs. Machine: Language Models and Wargames

# 摘要

> 战争游戏历来在塑造军事战略及应对国与国之间的冲突中扮演关键角色，而AI技术尤其是大型语言模型（LLMs）的应用，则有望提升决策精准度和整体军事效果。然而，AI系统与人类在实际行为表现上的异同仍有待探讨。鉴于此，我们在一场针对虚构中美冲突危机升级的战争游戏中，组织了107位国家安全专家作为真人玩家，并将其行动与LLM模拟的反馈进行比较。研究揭示，虽然LLM模拟与人类玩家的决策在一定程度上有相似之处，但在战争游戏过程中，模拟玩家与真人玩家在量化和质化层面的显著差异不容忽视。这些发现警示政策制定者，在赋予AI自主决策权或采纳基于AI的战略建议前，应审慎对待并深入理解这些差异。

> Wargames have a long history in the development of military strategy and the response of nations to threats or attacks. The advent of artificial intelligence (AI) promises better decision-making and increased military effectiveness. However, there is still debate about how AI systems, especially large language models (LLMs), behave as compared to humans. To this end, we use a wargame experiment with 107 national security expert human players designed to look at crisis escalation in a fictional US-China scenario and compare human players to LLM-simulated responses. We find considerable agreement in the LLM and human responses but also significant quantitative and qualitative differences between simulated and human players in the wargame, motivating caution to policymakers before handing over autonomy or following AI-based strategy recommendations.

[Arxiv](https://arxiv.org/abs/2403.03407)