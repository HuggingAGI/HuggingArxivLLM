# 针对大型语言模型（LLM）对话中的说服力，本研究采用随机对照试验方法进行深入探究。

发布时间：2024年03月21日

`LLM应用` `社交媒体` `人工智能伦理`

> On the Conversational Persuasiveness of Large Language Models: A Randomized Controlled Trial

# 摘要

> 随着LLMs的开发与广泛应用，人们担心它们会被用来制造针对个体的、极具说服力的虚假或误导性言论。前期研究表明，语言模型生成的内容往往可媲美甚至超越人类编写的文本，但在与真人对话中LLMs的说服力以及个性化如何提升其表现的研究尚不够深入。本预注册实验在安全可控的环境下探讨了由AI驱动的说服力效应。我们搭建了一个在线辩论平台，参与者与实时对手展开多轮简短辩论。按照两因素交叉设计，参与者被随机分为四组实验条件：一是对抗方为两位人类或一位人类与一个LLM；二是是否开启个性化设置，允许一方获取对手的基础社会人口学信息。研究发现，那些在与GPT-4辩论时能看到对手个人信息的参与者，相比于与真人辩论者，他们对对手观点的认同度提高了81.7%（p < 0.01，共有820名独立参与者）。而在非个性化条件下，尽管GPT-4依然表现出优于人类的能力，但效果较弱且统计上不具显著性（p=0.31）。总之，我们的研究成果揭示了个性化问题的重要性，这为社交媒体管理和新型在线环境设计带来了重要的实践指导意义。

> The development and popularization of large language models (LLMs) have raised concerns that they will be used to create tailor-made, convincing arguments to push false or misleading narratives online. Early work has found that language models can generate content perceived as at least on par and often more persuasive than human-written messages. However, there is still limited knowledge about LLMs' persuasive capabilities in direct conversations with human counterparts and how personalization can improve their performance. In this pre-registered study, we analyze the effect of AI-driven persuasion in a controlled, harmless setting. We create a web-based platform where participants engage in short, multiple-round debates with a live opponent. Each participant is randomly assigned to one of four treatment conditions, corresponding to a two-by-two factorial design: (1) Games are either played between two humans or between a human and an LLM; (2) Personalization might or might not be enabled, granting one of the two players access to basic sociodemographic information about their opponent. We found that participants who debated GPT-4 with access to their personal information had 81.7% (p < 0.01; N=820 unique participants) higher odds of increased agreement with their opponents compared to participants who debated humans. Without personalization, GPT-4 still outperforms humans, but the effect is lower and statistically non-significant (p=0.31). Overall, our results suggest that concerns around personalization are meaningful and have important implications for the governance of social media and the design of new online environments.

[Arxiv](https://arxiv.org/abs/2403.14380)