# ChatGPT 抗衡媒体偏见：探究 GPT-3.5 与精细调校语言模型的差异

发布时间：2024年03月29日

`LLM应用` `偏见识别`

> ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned Language Models

# 摘要

> 在这个瞬息万变的数字世界里，识别媒体偏见的能力显得尤为重要，它能左右公众情绪，甚至影响重大决策的走向。以ChatGPT为代表的大型语言模型，因其在自然语言处理（NLP）任务上的广泛适用性而备受关注，这也激发了我们对其在媒体偏见识别方面的探索。ChatGPT能否揭示媒体偏见的面纱？本研究利用媒体偏见识别基准（MBIB）对ChatGPT的这一能力进行了测试，将其与经过精细调整的模型如BART、ConvBERT和GPT-2进行了对比。结果显示出一种复杂的局面：ChatGPT在识别仇恨言论和文本层面偏见方面与精细调整的模型不相上下，但在捕捉更为微妙的偏见元素，如假新闻、种族、性别和认知偏见时，却显得有些力不从心。

> In our rapidly evolving digital sphere, the ability to discern media bias becomes crucial as it can shape public sentiment and influence pivotal decisions. The advent of large language models (LLMs), such as ChatGPT, noted for their broad utility in various natural language processing (NLP) tasks, invites exploration of their efficacy in media bias detection. Can ChatGPT detect media bias? This study seeks to answer this question by leveraging the Media Bias Identification Benchmark (MBIB) to assess ChatGPT's competency in distinguishing six categories of media bias, juxtaposed against fine-tuned models such as BART, ConvBERT, and GPT-2. The findings present a dichotomy: ChatGPT performs at par with fine-tuned models in detecting hate speech and text-level context bias, yet faces difficulties with subtler elements of other bias detections, namely, fake news, racial, gender, and cognitive biases.

[Arxiv](https://arxiv.org/abs/2403.20158)