# 本研究专注于探究上下文相关健康问题中潜在的偏见，并对其进行深入评估。

发布时间：2024年03月07日

`LLM应用`

> Evaluating Biases in Context-Dependent Health Questions

# 摘要

> 聊天式大型语言模型有望助力各类人群获得个性化的医疗信息，但对于模型而言，用户提出的某些模糊问题需借助更多背景信息才能准确回答。本研究聚焦于大型语言模型在处理医疗领域情境化问题时所体现的偏见现象。为此，我们构建了一组关注性与生殖健康领域的数据集，其中问题涉及年龄、性别和地点等属性。通过对模型在提供和未提供人口统计学背景情况下输出的回答进行对比分析，探究情境问题中不同群体的一致性表现。实验揭示了在各个属性维度上的偏见，特别是对年轻成年女性用户的倾向性更为明显。

> Chat-based large language models have the opportunity to empower individuals lacking high-quality healthcare access to receive personalized information across a variety of topics. However, users may ask underspecified questions that require additional context for a model to correctly answer. We study how large language model biases are exhibited through these contextual questions in the healthcare domain. To accomplish this, we curate a dataset of sexual and reproductive healthcare questions that are dependent on age, sex, and location attributes. We compare models' outputs with and without demographic context to determine group alignment among our contextual questions. Our experiments reveal biases in each of these attributes, where young adult female users are favored.

![本研究专注于探究上下文相关健康问题中潜在的偏见，并对其进行深入评估。](../../../paper_images/2403.04858/x1.png)

![本研究专注于探究上下文相关健康问题中潜在的偏见，并对其进行深入评估。](../../../paper_images/2403.04858/sex_instructions.png)

![本研究专注于探究上下文相关健康问题中潜在的偏见，并对其进行深入评估。](../../../paper_images/2403.04858/sex_example.png)

![本研究专注于探究上下文相关健康问题中潜在的偏见，并对其进行深入评估。](../../../paper_images/2403.04858/age_instructions.png)

![本研究专注于探究上下文相关健康问题中潜在的偏见，并对其进行深入评估。](../../../paper_images/2403.04858/age_example.png)

![本研究专注于探究上下文相关健康问题中潜在的偏见，并对其进行深入评估。](../../../paper_images/2403.04858/location_instructions.png)

![本研究专注于探究上下文相关健康问题中潜在的偏见，并对其进行深入评估。](../../../paper_images/2403.04858/location_example.png)

[Arxiv](https://arxiv.org/abs/2403.04858)