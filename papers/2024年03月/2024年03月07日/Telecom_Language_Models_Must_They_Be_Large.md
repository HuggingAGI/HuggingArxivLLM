# 电信领域的语言模型是否必须具备大模型特性？

发布时间：2024年03月07日

`LLM应用`

> Telecom Language Models: Must They Be Large?

# 摘要

> 随着LLMs在电信行业的热度上升，揭示了其革新运营效能的巨大潜力。不过，由于大型模型的庞大体积和高计算要求，实际应用时常面临困境，尤其是在资源有限的情况下。面对这一难题，最近的研究进展推出了若干小巧的语言模型，如Phi-2，虽身形精悍却能在编码、常识推理等许多任务上展现出与大型模型相当的性能。本文对代表新型高效小规模语言模型的Phi-2在电信领域的内建理解能力进行了深度评测。鉴于尺寸上的局限，我们运用检索增强生成策略，精心结合了一个专门针对电信标准规范编纂的大规模知识库来强化Phi-2的功能。升级后的Phi-2在回答涉及电信标准的问题时，精度大幅提升，甚至可与资源消耗较大的GPT-3.5一较高下。此外，本文还深入探究了优化后的Phi-2在应对电信行业内的各类问题解决场景时所展现的优势及其局限。

> The increasing interest in Large Language Models (LLMs) within the telecommunications sector underscores their potential to revolutionize operational efficiency. However, the deployment of these sophisticated models is often hampered by their substantial size and computational demands, raising concerns about their viability in resource-constrained environments. Addressing this challenge, recent advancements have seen the emergence of small language models that surprisingly exhibit performance comparable to their larger counterparts in many tasks, such as coding and common-sense reasoning. Phi-2, a compact yet powerful model, exemplifies this new wave of efficient small language models. This paper conducts a comprehensive evaluation of Phi-2's intrinsic understanding of the telecommunications domain. Recognizing the scale-related limitations, we enhance Phi-2's capabilities through a Retrieval-Augmented Generation approach, meticulously integrating an extensive knowledge base specifically curated with telecom standard specifications. The enhanced Phi-2 model demonstrates a profound improvement in accuracy, answering questions about telecom standards with a precision that closely rivals the more resource-intensive GPT-3.5. The paper further explores the refined capabilities of Phi-2 in addressing problem-solving scenarios within the telecom sector, highlighting its potential and limitations.

[Arxiv](https://arxiv.org/abs/2403.04666)