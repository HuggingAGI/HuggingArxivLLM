# DiaHalu：一款针对大型语言模型设计的对话级 hallucination 评估基准工具，旨在精准衡量其在对话生成中的幻觉现象表现。

发布时间：2024年03月01日

`LLM应用`

> DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models

# 摘要

> 鉴于LLMs近年来的成功，幻觉问题依旧是一大难题，人们纷纷推出各类基准来检测此类问题。然而，部分基准因非自然生成于LLMs，而是刻意诱发产生，且多数仅专注事实性幻觉，忽略了忠实性幻觉。尽管在LLM时代对话模式应用广泛，现有基准却主要聚焦于单句与段落层面的幻觉。为此，我们创新性地提出了首个对话级别的幻觉评估基准——DiaHalu。研究过程中，我们将收集的主题融入系统提示，引导两个ChatGPT3.5模型展开对话，并针对不符合人类语言习惯的部分进行人工调整及LLMs再生成，力求模拟真实人机对话情境。最终，所有数据集样本均由专业学者精心标注。DiaHalu覆盖了四大常见多轮对话领域及源于事实性和忠实性幻觉的五种细分幻觉类型。经过若干知名LLMs和检测方法在该数据集上的验证，结果显示DiaHalu是一个颇具挑战性的基准，对于未来研究具有不可小觑的价值。

> Since large language models (LLMs) achieve significant success in recent years, the hallucination issue remains a challenge, numerous benchmarks are proposed to detect the hallucination. Nevertheless, some of these benchmarks are not naturally generated by LLMs but are intentionally induced. Also, many merely focus on the factuality hallucination while ignoring the faithfulness hallucination. Additionally, although dialogue pattern is more widely utilized in the era of LLMs, current benchmarks only concentrate on sentence-level and passage-level hallucination. In this study, we propose DiaHalu, the first dialogue-level hallucination evaluation benchmark to our knowledge. Initially, we integrate the collected topics into system prompts and facilitate a dialogue between two ChatGPT3.5. Subsequently, we manually modify the contents that do not adhere to human language conventions and then have LLMs re-generate, simulating authentic human-machine interaction scenarios. Finally, professional scholars annotate all the samples in the dataset. DiaHalu covers four common multi-turn dialogue domains and five hallucination subtypes, extended from factuality and faithfulness hallucination. Experiments through some well-known LLMs and detection methods on the dataset show that DiaHalu is a challenging benchmark, holding significant value for further research.

[Arxiv](https://arxiv.org/abs/2403.00896)