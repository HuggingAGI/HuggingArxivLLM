# ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？

发布时间：2024年03月26日

`LLM应用` `人工智能`

> ChatGPT Rates Natural Language Explanation Quality Like Humans: But on Which Scales?

# 摘要

> 随着AI日益融入日常生活，对透明度和责任感的追求也日益增强。自然语言解释对于揭示AI决策逻辑极为关键，但要通过人类评价来衡量其质量却是一项充满挑战的任务，因为这涉及到主观判断和精细评分的需求。本项研究旨在探究ChatGPT与人类评价在不同尺度（二元、三元和7分量表）上的契合度。我们从三个不同的NLE数据集中提取了300个样本，并收集了900条人类评价，以此来衡量文本的信息量和清晰度。此外，我们还进行了一系列的配对比较实验，这些实验基于8346条人类评价数据进行。研究结果显示，ChatGPT在较为宏观的评价尺度上与人类评价更为吻合。同时，通过配对比较和动态提示（例如，在提示中引入语义相近的案例）可以进一步提升这一契合度。此项研究深化了我们对大型语言模型评估文本解释质量能力的认识，为负责任的AI发展提供了支持。

> As AI becomes more integral in our lives, the need for transparency and responsibility grows. While natural language explanations (NLEs) are vital for clarifying the reasoning behind AI decisions, evaluating them through human judgments is complex and resource-intensive due to subjectivity and the need for fine-grained ratings. This study explores the alignment between ChatGPT and human assessments across multiple scales (i.e., binary, ternary, and 7-Likert scale). We sample 300 data instances from three NLE datasets and collect 900 human annotations for both informativeness and clarity scores as the text quality measurement. We further conduct paired comparison experiments under different ranges of subjectivity scores, where the baseline comes from 8,346 human annotations. Our results show that ChatGPT aligns better with humans in more coarse-grained scales. Also, paired comparisons and dynamic prompting (i.e., providing semantically similar examples in the prompt) improve the alignment. This research advances our understanding of large language models' capabilities to assess the text explanation quality in different configurations for responsible AI development.

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x1.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x2.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x3.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x4.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x5.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x6.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x7.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x8.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x9.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x10.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x11.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x12.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x13.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x14.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x15.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x16.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x17.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/x18.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/MTurk-1.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/MTurk-3.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/MTurk-2.png)

![ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](../../../paper_images/2403.17368/MTurk-4.png)

[Arxiv](https://arxiv.org/abs/2403.17368)