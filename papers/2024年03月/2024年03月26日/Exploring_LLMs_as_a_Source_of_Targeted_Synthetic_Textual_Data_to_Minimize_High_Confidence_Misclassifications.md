# 本研究致力于研究大型语言模型，将其作为生成针对性合成文本数据的新途径，目的是减少那些过于自信的错误分类情况。

发布时间：2024年03月26日

`LLM应用` `数据增强`

> Exploring LLMs as a Source of Targeted Synthetic Textual Data to Minimize High Confidence Misclassifications

# 摘要

> 为提高自然语言处理模型的预测准确性，我们尝试利用大型语言模型进行数据增强，以应对模型在分类任务中过于自信的错误判断。通过对比LLMs创造的合成数据与人类数据，我们评估了这一策略的有效性。在这一过程中，无论是人类还是LLMs，都通过描述高信心误判的情况来生成新的数据，进而扩充训练集。经过对三个不同分类任务的深入测试，我们发现这种方法能有效降低模型自信错误的发生，同时保持准确度不受影响。更令人振奋的是，与人类相比，LLMs在成本上大幅降低，展现出与人类相媲美的性能，且更具扩展潜力。

> Natural Language Processing (NLP) models optimized for predictive performance often make high confidence errors and suffer from vulnerability to adversarial and out-of-distribution data. Existing work has mainly focused on mitigation of such errors using either humans or an automated approach. In this study, we explore the usage of large language models (LLMs) for data augmentation as a potential solution to the issue of NLP models making wrong predictions with high confidence during classification tasks. We compare the effectiveness of synthetic data generated by LLMs with that of human data obtained via the same procedure. For mitigation, humans or LLMs provide natural language characterizations of high confidence misclassifications to generate synthetic data, which are then used to extend the training set. We conduct an extensive evaluation of our approach on three classification tasks and demonstrate its effectiveness in reducing the number of high confidence misclassifications present in the model, all while maintaining the same level of accuracy. Moreover, we find that the cost gap between humans and LLMs surpasses an order of magnitude, as LLMs attain human-like performance while being more scalable.

[Arxiv](https://arxiv.org/abs/2403.17860)