# 探索内在子图生成，助力可解读的图形视觉问答系统

发布时间：2024年03月26日

`RAG` `视觉问答` `可解释人工智能`

> Intrinsic Subgraph Generation for Interpretable Graph based Visual Question Answering

# 摘要

> 深度学习在视觉问答 (VQA) 领域的突破性进展，也带来了对可解释性方法的迫切需求。目前，大多数可解释人工智能 (XAI) 技术都是事后诸葛亮，而非从模型的内在可解释性出发。本研究提出了一种全新的图基础 VQA 可解释方法，在 GQA 数据集上展现出了不俗的表现，成功地连接了可解释性与高效性能之间的桥梁。该模型能够在回答问题的过程中，自然生成一个子图作为解释，让我们得以一窥其决策过程。为了衡量这些子图的质量，我们不仅将其与现有的图神经网络事后解释方法进行了比较，还进行了人类评估的测试。此外，我们还开发了与人类评价标准相一致的量化指标，为这些生成的解释性子图提供了自动化的评价标准。相关实现代码已在 https://github.com/DigitalPhonetics/Intrinsic-Subgraph-Generation-for-VQA 上公开。

> The large success of deep learning based methods in Visual Question Answering (VQA) has concurrently increased the demand for explainable methods. Most methods in Explainable Artificial Intelligence (XAI) focus on generating post-hoc explanations rather than taking an intrinsic approach, the latter characterizing an interpretable model. In this work, we introduce an interpretable approach for graph-based VQA and demonstrate competitive performance on the GQA dataset. This approach bridges the gap between interpretability and performance. Our model is designed to intrinsically produce a subgraph during the question-answering process as its explanation, providing insight into the decision making. To evaluate the quality of these generated subgraphs, we compare them against established post-hoc explainability methods for graph neural networks, and perform a human evaluation. Moreover, we present quantitative metrics that correlate with the evaluations of human assessors, acting as automatic metrics for the generated explanatory subgraphs. Our implementation is available at https://github.com/DigitalPhonetics/Intrinsic-Subgraph-Generation-for-VQA.

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x1.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x2.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x3.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x4.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x5.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x6.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x7.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x8.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x9.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x10.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x11.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x12.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x13.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x14.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x15.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x16.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x17.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x18.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x19.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x20.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x21.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x22.png)

![探索内在子图生成，助力可解读的图形视觉问答系统](../../../paper_images/2403.17647/x23.png)

[Arxiv](https://arxiv.org/abs/2403.17647)