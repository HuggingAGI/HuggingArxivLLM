# 本文旨在深入探讨中国大型语言模型在隐私保护方面的能力及其潜力。

发布时间：2024年03月26日

`LLM理论` `隐私保护` `人工智能安全`

> Exploring the Privacy Protection Capabilities of Chinese Large Language Models

# 摘要

> 大型语言模型（LLMs）以其在众多任务上的卓越表现而备受赞誉，极大地推动了人工智能的前进步伐。然而，这些技术进步也带来了对隐私和安全性的担忧。为了应对这些挑战并揭示这些模型所固有的风险，我们构建了一个分层次的三级递进框架，旨在评估语言系统中的隐私保护。该框架在每一级都设置了由浅入深、日益复杂的隐私测试任务。我们的核心目标是全方位评估大型语言模型对个人隐私信息的敏感度，探究它们在不同情境下识别、处理和保护敏感数据的能力。通过这种有序的评估，我们得以洞察这些模型对隐私保护准则的遵循程度，以及它们内在隐私防护机制的有效性。我们的研究发现，现有的中文大型语言模型普遍展现出对隐私保护的不足。这似乎是一个当前不可避免的普遍问题，可能会在基于这些模型的应用中引发相应的隐私风险。

> Large language models (LLMs), renowned for their impressive capabilities in various tasks, have significantly advanced artificial intelligence. Yet, these advancements have raised growing concerns about privacy and security implications. To address these issues and explain the risks inherent in these models, we have devised a three-tiered progressive framework tailored for evaluating privacy in language systems. This framework consists of progressively complex and in-depth privacy test tasks at each tier. Our primary objective is to comprehensively evaluate the sensitivity of large language models to private information, examining how effectively they discern, manage, and safeguard sensitive data in diverse scenarios. This systematic evaluation helps us understand the degree to which these models comply with privacy protection guidelines and the effectiveness of their inherent safeguards against privacy breaches. Our observations indicate that existing Chinese large language models universally show privacy protection shortcomings. It seems that at the moment this widespread issue is unavoidable and may pose corresponding privacy risks in applications based on these models.

[Arxiv](https://arxiv.org/abs/2403.18205)