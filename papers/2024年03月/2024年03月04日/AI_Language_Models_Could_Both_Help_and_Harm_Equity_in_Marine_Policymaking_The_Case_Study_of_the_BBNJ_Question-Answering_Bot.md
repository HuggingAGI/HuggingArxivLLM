# AI语言模型在海洋政策制定领域的应用，如BBNJ问答机器人案例所示，既能促进公平性也可能带来潜在的不平等问题。本研究通过该案例探讨了这一双刃剑效应。

发布时间：2024年03月04日

`LLM应用`

> AI Language Models Could Both Help and Harm Equity in Marine Policymaking: The Case Study of the BBNJ Question-Answering Bot

# 摘要

> 人工智能LLMs如ChatGPT正在革新政策制定过程的部分环节。政策从业者已开始利用ChatGPT处理各类任务，从撰写文档到研究背景无所不包。我们谨慎乐观地期待，LLMs可以通过协助处理繁琐事务，特别是在资源有限、谈判中处于劣势的发展中国家，助力决策者间形成更为均衡的对话基础。然而，面对气候变化等紧迫危机、高度不确定性和跨界影响，环境和海洋政策领域的LLM应用所蕴含的风险不容小觑。为深入了解LLMs在海洋政策制定中的实际潜力、局限性及其公平性风险，我们以新近采纳的“国家管辖范围外生物多样性协议”（BBNJ）为例，构建了一个AI聊天机器人，并对其在关键政策问题上的回答进行了深度评估。该案例表明，LLMs在海洋政策制定中可能因偏好生成反映西方经济中心观点的文本，而忽视发展中国家的声音，从而潜藏危害。我们揭示了这种偏见如何通过三个方面渗入系统：基础语言模型固有的偏见、与联合国谈判文件连接导致的偏见，以及应用设计引入的偏见。因此，我们呼吁在海洋政策制定中谨慎运用生成式AI，并倡议加强对其公平公正性影响的研究。同时，我们也强调发展中国家的政策制定者亟需提升自身与AI技术有效互动的技术实力。

> AI Large Language Models (LLMs) like ChatGPT are set to reshape some aspects of policymaking processes. Policy practitioners are already using ChatGPT for help with a variety of tasks: from drafting statements, submissions, and presentations, to conducting background research. We are cautiously hopeful that LLMs could be used to promote a marginally more balanced footing among decision makers in policy negotiations by assisting with certain tedious work, particularly benefiting developing countries who face capacity constraints that put them at a disadvantage in negotiations. However, the risks are particularly concerning for environmental and marine policy uses, due to the urgency of crises like climate change, high uncertainty, and trans-boundary impact.
  To explore the realistic potentials, limitations, and equity risks for LLMs in marine policymaking, we present a case study of an AI chatbot for the recently adopted Biodiversity Beyond National Jurisdiction Agreement (BBNJ), and critique its answers to key policy questions. Our case study demonstrates the dangers of LLMs in marine policymaking via their potential bias towards generating text that favors the perspectives of mainly Western economic centers of power, while neglecting developing countries' viewpoints. We describe several ways these biases can enter the system, including: (1) biases in the underlying foundational language models; (2) biases arising from the chatbot's connection to UN negotiation documents, and (3) biases arising from the application design. We urge caution in the use of generative AI in ocean policy processes and call for more research on its equity and fairness implications. Our work also underscores the need for developing countries' policymakers to develop the technical capacity to engage with AI on their own terms.

[Arxiv](https://arxiv.org/abs/2403.01755)