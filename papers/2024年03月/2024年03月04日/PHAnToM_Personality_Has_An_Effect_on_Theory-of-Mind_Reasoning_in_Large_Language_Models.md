# PHAnToM研究表明，大型语言模型的心智理论推理会受到模型所具备的个性特征的影响。

发布时间：2024年03月04日

`LLM应用`

> PHAnToM: Personality Has An Effect on Theory-of-Mind Reasoning in Large Language Models

# 摘要

> 近年来，LLMs在自然语言处理多项任务上的表现已能媲美甚至超越人类，然而，对于人类天生擅长的社会认知推理，LLMs的表现仍显不足。受心理学中人格特质与心智理论（ToM）推理关联性研究启发，以及提示工程技术中关于提示高度影响LLMs性能的探索成果，本研究尝试利用提示为LLMs注入不同人格特征，进而观察其对ToM推理能力的影响。实验结果显示，在三项不同的ToM任务中，特定注入的人格特质可显著改变LLMs（如GPT-3.5、Llama 2和Mistral）的推理效能，其中，黑暗三角人格特质在各任务中对上述模型的影响尤为显著且变化多样。有趣的是，我们还发现在ToM任务中对不同人格提示反应差异大的LLMs模型，在人格测试中更能精准调控其内在人格特质——只需通过精心设计的人格提示即可调节GPT-3.5、Llama 2和Mistral等模型的人格属性。鉴于当前LLMs常被用于角色扮演场景，我们的研究警示，在赋予模型特定人格特征时应保持审慎，因为这可能以意料之外的方式改变模型的推理能力。

> Recent advances in large language models (LLMs) demonstrate that their capabilities are comparable, or even superior, to humans in many tasks in natural language processing. Despite this progress, LLMs are still inadequate at social-cognitive reasoning, which humans are naturally good at. Drawing inspiration from psychological research on the links between certain personality traits and Theory-of-Mind (ToM) reasoning, and from prompt engineering research on the hyper-sensitivity of prompts in affecting LLMs capabilities, this study investigates how inducing personalities in LLMs using prompts affects their ToM reasoning capabilities. Our findings show that certain induced personalities can significantly affect the LLMs' reasoning capabilities in three different ToM tasks. In particular, traits from the Dark Triad have a larger variable effect on LLMs like GPT-3.5, Llama 2, and Mistral across the different ToM tasks. We find that LLMs that exhibit a higher variance across personality prompts in ToM also tends to be more controllable in personality tests: personality traits in LLMs like GPT-3.5, Llama 2 and Mistral can be controllably adjusted through our personality prompts. In today's landscape where role-play is a common strategy when using LLMs, our research highlights the need for caution, as models that adopt specific personas with personalities potentially also alter their reasoning abilities in an unexpected manner.

[Arxiv](https://arxiv.org/abs/2403.02246)