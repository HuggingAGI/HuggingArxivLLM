# 这款基于大型语言模型的进化优化器，通过精英主义原理进行智能推理。它巧妙地运用了大型语言模型的优势，在不断优化过程中甄选并借鉴最优解决方案进行迭代升级。

发布时间：2024年03月04日

`LLM应用`

> Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism

# 摘要

> LLMs 凭借其出色的推理能力，在黑盒优化领域崭露头角。本研究断言，LLMs 在不同情境下均具有零样本优化的潜力，覆盖多元目标和高维难题。为此，我们创新性地提出了基于LLMs的数值优化群体方法——语言模型演化优化器（LEO）。这一观点在一系列丰富实例中得到验证，涉及超音速喷嘴外形优化、传热及风电场布局等多个基准与工业工程问题。对比了多种梯度依赖和非依赖的优化策略后，发现LLMs能取得与现有最优方法比肩的成果。然而，鉴于LLMs天马行空的想象特质及其易产生“幻觉”的特点，运用时需格外审慎。我们提供了一份实用指导以确保从LLMs获取可靠答案，并探讨了LEO方法的局限性以及未来可能的研究路径。

> Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, prompting interest in their application as black-box optimizers. This paper asserts that LLMs possess the capability for zero-shot optimization across diverse scenarios, including multi-objective and high-dimensional problems. We introduce a novel population-based method for numerical optimization using LLMs called Language-Model-Based Evolutionary Optimizer (LEO). Our hypothesis is supported through numerical examples, spanning benchmark and industrial engineering problems such as supersonic nozzle shape optimization, heat transfer, and windfarm layout optimization. We compare our method to several gradient-based and gradient-free optimization approaches. While LLMs yield comparable results to state-of-the-art methods, their imaginative nature and propensity to hallucinate demand careful handling. We provide practical guidelines for obtaining reliable answers from LLMs and discuss method limitations and potential research directions.

[Arxiv](https://arxiv.org/abs/2403.02054)