# 在大型语言模型中探讨公平性问题：一项系统性综述

发布时间：2024年03月31日

`LLM理论` `公平性` `大型语言模型`

> Fairness in Large Language Models: A Taxonomic Survey

# 摘要

> 大型语言模型（LLMs）在众多领域取得了令人瞩目的成就。尽管它们在现实世界的多种应用中展现出强大的潜力，但大多数模型在公平性方面尚显不足，有时甚至可能导致对特定群体，尤其是那些处于社会边缘的群体产生歧视性的结果。这一问题引发了对构建公平LLMs的深入研究。与传统机器学习不同，LLMs的公平性问题需要我们考虑其特有的背景、分类体系和实现方法。本文综述了近期关于公平LLMs的研究进展，首先简要介绍了LLMs的基本概念，然后分析了造成LLMs偏见的各种原因。文章还系统地探讨了LLMs公平性的定义，总结了评估LLMs偏见的指标和目前用于提升公平性的算法。同时，文中汇总了用于评估LLMs偏见的工具和数据集资源，并在最后讨论了当前研究面临的挑战和未来的研究方向。

> Large Language Models (LLMs) have demonstrated remarkable success across various domains. However, despite their promising performance in numerous real-world applications, most of these algorithms lack fairness considerations. Consequently, they may lead to discriminatory outcomes against certain communities, particularly marginalized populations, prompting extensive study in fair LLMs. On the other hand, fairness in LLMs, in contrast to fairness in traditional machine learning, entails exclusive backgrounds, taxonomies, and fulfillment techniques. To this end, this survey presents a comprehensive overview of recent advances in the existing literature concerning fair LLMs. Specifically, a brief introduction to LLMs is provided, followed by an analysis of factors contributing to bias in LLMs. Additionally, the concept of fairness in LLMs is discussed categorically, summarizing metrics for evaluating bias in LLMs and existing algorithms for promoting fairness. Furthermore, resources for evaluating bias in LLMs, including toolkits and datasets, are summarized. Finally, existing research challenges and open questions are discussed.

[Arxiv](https://arxiv.org/abs/2404.01349)