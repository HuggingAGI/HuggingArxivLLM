# 本实证研究探讨了利用大型语言模型进行自动化漏洞定位的方法。

发布时间：2024年03月30日

`LLM应用` `漏洞定位` `自动化安全`

> An Empirical Study of Automated Vulnerability Localization with Large Language Models

# 摘要

> 近期，自动化漏洞定位（AVL）成为研究热点，其目的是通过准确识别引发安全漏洞的代码行，以简化问题诊断。尽管大型语言模型（LLMs）在众多领域展现出巨大潜力，但其在漏洞定位上的效果尚待深入挖掘。本研究首次对LLMs在AVL领域的应用进行了深入探讨。我们评估了10余款适用于代码分析的顶尖LLMs，如ChatGPT及众多开源模型，覆盖从仅编码器、编码器-解码器到仅解码器的三种架构，参数规模从6000万至160亿不等。通过零次学习、一次学习、判别性微调和生成性微调四种方法，我们对这些模型的有效性进行了测试，并针对C/C++的BigVul数据集及智能合约漏洞数据集进行了评估。研究发现，通过判别性微调的LLMs在AVL任务上的表现显著超越了传统基于学习的 方法，而其他方法的效果则不尽人意或出人意料地不佳。同时，我们还发现了在编码器和解码器微调过程中输入长度和单向上下文的限制性问题。为此，我们提出了滑动窗口和右向嵌入两种改进策略，有效提升了模型性能。此外，我们的研究还揭示了LLMs在处理不同项目和常见弱点枚举（CWEs）时的泛化潜力，为它们在漏洞定位实际应用中的前景增添了希望。

> Recently, Automated Vulnerability Localization (AVL) has attracted much attention, aiming to facilitate diagnosis by pinpointing the lines of code responsible for discovered vulnerabilities. Large Language Models (LLMs) have shown potential in various domains, yet their effectiveness in vulnerability localization remains underexplored. In this work, we perform the first comprehensive study of LLMs for AVL. Our investigation encompasses 10+ leading LLMs suitable for code analysis, including ChatGPT and various open-source models, across three architectural types: encoder-only, encoder-decoder, and decoder-only, with model sizes ranging from 60M to 16B parameters. We explore the efficacy of these LLMs using 4 distinct paradigms: zero-shot learning, one-shot learning, discriminative fine-tuning, and generative fine-tuning. Our evaluation framework is applied to the BigVul-based dataset for C/C++, and an additional dataset comprising smart contract vulnerabilities. The results demonstrate that discriminative fine-tuning of LLMs can significantly outperform existing learning-based methods for AVL, while other paradigms prove less effective or unexpectedly ineffective for the task. We also identify challenges related to input length and unidirectional context in fine-tuning processes for encoders and decoders. We then introduce two remedial strategies: the sliding window and the right-forward embedding, both of which substantially enhance performance. Furthermore, our findings highlight certain generalization capabilities of LLMs across Common Weakness Enumerations (CWEs) and different projects, indicating a promising pathway toward their practical application in vulnerability localization.

[Arxiv](https://arxiv.org/abs/2404.00287)