# 大型语言模型在防止网络诱导行为方面是利大于弊还是弊大于利？本研究深入探讨其实际效用。步骤分解：

发布时间：2024年03月14日

`LLM应用` `儿童安全` `网络防护`

> Helpful or Harmful? Exploring the Efficacy of Large Language Models for Online Grooming Prevention

# 摘要

> 如今，功能强大的生成型LLMs已成为大众常用的问答工具，甚至被儿童等弱势群体接触和利用。鉴于此，针对儿童频繁使用的现状，研究者急需深入探究LLMs的安全性，尤其在应对可能带来严重后果的应用场景，如处理线上儿童安全问题时。本篇论文通过研究超过6000次LLM交互实验，探讨了LLMs在预防网络引诱中的应用效果，包括通过生成针对性建议以识别并规避网络引诱风险，以及通过调整输入上下文和提示的特定性来研究提示设计对模型表现的影响。然而，结果显示目前尚无一款模型完全适合用于预防网络引诱，它们表现出的行为不一致，且开源模型尤有可能生成有害答案。文章揭示了模型存在的短板，并提出了改进建议，同时发现了若干能显著影响模型性能的提示设计方案，这些发现将有助于构建基于最佳实践的LLM使用指南。

> Powerful generative Large Language Models (LLMs) are becoming popular tools amongst the general public as question-answering systems, and are being utilised by vulnerable groups such as children. With children increasingly interacting with these tools, it is imperative for researchers to scrutinise the safety of LLMs, especially for applications that could lead to serious outcomes, such as online child safety queries. In this paper, the efficacy of LLMs for online grooming prevention is explored both for identifying and avoiding grooming through advice generation, and the impact of prompt design on model performance is investigated by varying the provided context and prompt specificity. In results reflecting over 6,000 LLM interactions, we find that no models were clearly appropriate for online grooming prevention, with an observed lack of consistency in behaviours, and potential for harmful answer generation, especially from open-source models. We outline where and how models fall short, providing suggestions for improvement, and identify prompt designs that heavily altered model performance in troubling ways, with findings that can be used to inform best practice usage guides.

[Arxiv](https://arxiv.org/abs/2403.09795)