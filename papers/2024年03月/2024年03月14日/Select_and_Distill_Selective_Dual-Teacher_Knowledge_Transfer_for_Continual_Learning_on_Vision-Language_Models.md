# 为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。

发布时间：2024年03月14日

`LLM应用` `持续学习`

> Select and Distill: Selective Dual-Teacher Knowledge Transfer for Continual Learning on Vision-Language Models

# 摘要

> 大规模VLMs在处理未知领域数据时表现出卓越的零样本泛化能力，但在连续适应下游任务时，易遗忘已学知识并削弱其零样本分类性能。为此，我们创新性地提出了“选择性双教师知识迁移”框架，它借助最近微调的VLM和原始预训练VLM作为双重教师，分别维护旧知识与零样本能力。只利用无标签参考数据集，此框架通过衡量来自双教师VLM的特征差异实施选择性知识提炼。这样一来，这种选择性双教师知识提炼机制能够在保护预训练VLM零样本能力的同时，缓解对已学知识的灾难性遗忘问题。我们在多个基准数据集上进行了广泛实验，结果显示，相较于现有最先进的持续学习方法，本框架在防止灾难性遗忘及零样本性能衰退方面表现更为优秀。

> Large-scale vision-language models (VLMs) have shown a strong zero-shot generalization capability on unseen-domain data. However, when adapting pre-trained VLMs to a sequence of downstream tasks, they are prone to forgetting previously learned knowledge and degrade their zero-shot classification capability. To tackle this problem, we propose a unique Selective Dual-Teacher Knowledge Transfer framework that leverages the most recent fine-tuned and the original pre-trained VLMs as dual teachers to preserve the previously learned knowledge and zero-shot capabilities, respectively. With only access to an unlabeled reference dataset, our proposed framework performs a selective knowledge distillation mechanism by measuring the feature discrepancy from the dual teacher VLMs. Consequently, our selective dual-teacher knowledge distillation would mitigate catastrophic forgetting of previously learned knowledge while preserving the zero-shot capabilities from pre-trained VLMs. Through extensive experiments on benchmark datasets, we show that our proposed framework is favorable against state-of-the-art continual learning approaches for preventing catastrophic forgetting and zero-shot degradation.

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x1.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x2.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x3.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x4.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x5.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x6.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x7.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/fgvc-aircraft.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/stanford-cars.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/flowers-102.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/food-101.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x8.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x9.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x10.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x11.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x12.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x13.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x14.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x15.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x16.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x17.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x18.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x19.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x20.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x21.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x22.png)

![为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](../../../paper_images/2403.09296/x23.png)

[Arxiv](https://arxiv.org/abs/2403.09296)