# 在医疗保健领域，大型语言模型（LLMs）与用户信任的关系备受关注。本研究将重点探讨LLMs如何赢得并维持用户信任，特别是在关乎健康信息处理的关键场景中。

发布时间：2024年03月15日

`LLM理论` `人工智能`

> Large Language Models and User Trust: Focus on Healthcare

# 摘要

> 这篇论文研究了临床医生对 LLM 信任度随时间推移的变化、数据源由人为主转为 AI 生成内容的过程，及其对 LLM 准确性和医生专业能力的连锁反应。一个核心忧虑是，随着 LLM 对自身输出愈发依赖以进行学习，可能出现恶性循环，导致输出质量下滑，临床医生因减少与基础诊断过程的互动而削弱技能。尽管当前仍在理论阶段，但这种循环在 LLM 在医疗领域深度融合的过程中将构成重大挑战，强调了开展前瞻性对话与制定策略措施确保 LLM 技术安全有效使用的必要性。进一步地，我们探究了 LLM 自我引用学习机制以及医疗专业人士技能退化所带来的潜在风险。当 LLM 在“回音室”中运作，即 AI 内容不断反馈至学习算法时，可能损害数据池的多元性和质量，从而加剧偏见并削弱 LLM 效果。同时，过度依赖 LLM 完成日常或关键任务可能导致医疗提供者的诊断能力和思维技巧衰退，对培养未来专业人才尤为不利。

> This paper explores the evolving relationship between clinician trust in LLMs, the transformation of data sources from predominantly human-generated to AI-generated content, and the subsequent impact on the precision of LLMs and clinician competence. One of the primary concerns identified is the potential feedback loop that arises as LLMs become more reliant on their outputs for learning, which may lead to a degradation in output quality and a reduction in clinician skills due to decreased engagement with fundamental diagnostic processes. While theoretical at this stage, this feedback loop poses a significant challenge as the integration of LLMs in healthcare deepens, emphasizing the need for proactive dialogue and strategic measures to ensure the safe and effective use of LLM technology. Moreover, we delve into the potential risks associated with LLMs' self-referential learning loops and the deskilling of healthcare professionals. The risk of LLMs operating within an echo chamber, where AI-generated content feeds into the learning algorithms, threatens the diversity and quality of the data pool, potentially entrenching biases and reducing the efficacy of LLMs. Concurrently, reliance on LLMs for routine or critical tasks could result in a decline in healthcare providers' diagnostic and thinking skills, particularly affecting the training and development of future professionals.

[Arxiv](https://arxiv.org/abs/2403.14691)