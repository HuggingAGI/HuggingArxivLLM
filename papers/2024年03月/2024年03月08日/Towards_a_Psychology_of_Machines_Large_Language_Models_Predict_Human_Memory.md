# 致力于探索机器的心理学层面，大型语言模型已展现出预测人类记忆的能力。

发布时间：2024年03月08日

`LLM理论`

> Towards a Psychology of Machines: Large Language Models Predict Human Memory

# 摘要

> LLMs虽然缺少人类认知基础，却在多种任务上展现出非凡实力，不禁令人思考：它们是否能在模仿人类语言之外，揭示人类认知背后的运行机制呢？本研究聚焦于ChatGPT预测人类在语言记忆任务表现的能力。根据文本理解理论，我们推测，在模棱两可的句子（如“由于比尔喝酒，家里从不存酒”）前添加恰当的上下文信息有助于理解。实验中，无论是人类还是ChatGPT，都被呈现一对句子，其中第二句是刻意设计的具有内在歧义的“迷宫句”，而第一句则可能提供贴切（如“比尔有慢性酗酒症”）或不贴切（如“比尔喜欢打高尔夫球”）的语境。我们对比了人类与ChatGPT对句子相关度的评分，记录了ChatGPT对“迷宫句”的记忆性评分，以及人类对“迷宫句”的自然记忆效果。结果令人惊讶，ChatGPT的评估与人类实际表现高度吻合——它认为相关度更高、更具记忆性的句子，人类确实记得更牢，尽管ChatGPT的内部运作机制与人类认知大相径庭。通过使用同义词进行验证，这一发现进一步凸显了生成型AI模型精准预测人类行为的可能性。我们进一步探讨了这些发现对于借助LLMs推动心理学理论发展及深化对人类认知理解的重要启示。

> Large language models (LLMs) are demonstrating remarkable capabilities across various tasks despite lacking a foundation in human cognition. This raises the question: can these models, beyond simply mimicking human language patterns, offer insights into the mechanisms underlying human cognition? This study explores the ability of ChatGPT to predict human performance in a language-based memory task. Building upon theories of text comprehension, we hypothesize that recognizing ambiguous sentences (e.g., "Because Bill drinks wine is never kept in the house") is facilitated by preceding them with contextually relevant information. Participants, both human and ChatGPT, were presented with pairs of sentences. The second sentence was always a garden-path sentence designed to be inherently ambiguous, while the first sentence either provided a fitting (e.g., "Bill has chronic alcoholism") or an unfitting context (e.g., "Bill likes to play golf"). We measured both human's and ChatGPT's ratings of sentence relatedness, ChatGPT's memorability ratings for the garden-path sentences, and humans' spontaneous memory for the garden-path sentences. The results revealed a striking alignment between ChatGPT's assessments and human performance. Sentences deemed more related and assessed as being more memorable by ChatGPT were indeed better remembered by humans, even though ChatGPT's internal mechanisms likely differ significantly from human cognition. This finding, which was confirmed with a robustness check employing synonyms, underscores the potential of generative AI models to predict human performance accurately. We discuss the broader implications of these findings for leveraging LLMs in the development of psychological theories and for gaining a deeper understanding of human cognition.

[Arxiv](https://arxiv.org/abs/2403.05152)