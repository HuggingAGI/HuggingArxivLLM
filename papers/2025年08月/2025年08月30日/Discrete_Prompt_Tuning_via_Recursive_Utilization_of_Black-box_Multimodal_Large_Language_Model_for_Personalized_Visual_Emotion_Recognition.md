# 基于黑盒多模态大型语言模型递归利用的离散提示调优：个性化视觉情感识别

发布时间：2025年08月30日

`LLM应用` `媒体与娱乐`

> Discrete Prompt Tuning via Recursive Utilization of Black-box Multimodal Large Language Model for Personalized Visual Emotion Recognition

# 摘要

> 视觉情感识别（VER）凭借其在意见挖掘、广告设计等领域的广泛应用，成为一项重要研究课题。若将这一能力延伸至个体层面的情感识别，其应用潜力将进一步拓展。近年来，多模态大型语言模型（MLLMs）备受关注，其性能已可与传统VER方法媲美。但MLLMs的训练数据来自包含普遍观点的大型多样化数据集，这使得它们更倾向于多数观点和熟悉模式。这种倾向制约了其在个性化VER中的表现——而个性化VER对实际应用至关重要，这也揭示了一个亟待改进的关键方向。为解决这一局限，本文提出的方法借鉴人类提示工程的思路，采用离散提示调优，使VER任务能够适应每个个体。该方法从生成的提示中筛选出最佳自然语言表示，并用其更新提示，从而实现精准的个性化VER。

> Visual Emotion Recognition (VER) is an important research topic due to its wide range of applications, including opinion mining and advertisement design. Extending this capability to recognize emotions at the individual level further broadens its potential applications. Recently, Multimodal Large Language Models (MLLMs) have attracted increasing attention and demonstrated performance comparable to that of conventional VER methods. However, MLLMs are trained on large and diverse datasets containing general opinions, which causes them to favor majority viewpoints and familiar patterns. This tendency limits their performance in a personalized VER, which is crucial for practical and real-world applications, and indicates a key area for improvement. To address this limitation, the proposed method employs discrete prompt tuning inspired by the process of humans' prompt engineering to adapt the VER task to each individual. Our method selects the best natural language representation from the generated prompts and uses it to update the prompt for the realization of accurate personalized VER.

[Arxiv](https://arxiv.org/abs/2509.04480)