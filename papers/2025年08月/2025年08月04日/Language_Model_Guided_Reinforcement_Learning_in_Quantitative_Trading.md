# 语言模型驱动的强化学习在量化交易中的实践

发布时间：2025年08月04日

`LLM应用` `金融建模`

> Language Model Guided Reinforcement Learning in Quantitative Trading

# 摘要

> 算法交易需要短期决策与长期财务目标相契合。尽管强化学习（RL）在战术决策方面有所探索，但其应用仍受限于短视行为和不透明的策略推理。相比之下，大语言模型（LLMs）在合理设计的提示下，近期展示了战略推理和多模态财务信号解读的能力。我们提出了一种混合系统，其中LLMs生成高级交易策略来指导RL代理的行为。我们评估了（i）通过专家评审的LLM生成策略的推理依据，以及（ii）LLM引导代理与无引导基线的夏普比率（SR）和最大回撤（MDD）。实验结果显示，与标准RL相比，LLM引导的代理在回报和风险指标上均有显著提升。

> Algorithmic trading requires short-term decisions aligned with long-term financial goals. While reinforcement learning (RL) has been explored for such tactical decisions, its adoption remains limited by myopic behavior and opaque policy rationale. In contrast, large language models (LLMs) have recently demonstrated strategic reasoning and multi-modal financial signal interpretation when guided by well-designed prompts.
  We propose a hybrid system where LLMs generate high-level trading strategies to guide RL agents in their actions. We evaluate (i) the rationale of LLM-generated strategies via expert review, and (ii) the Sharpe Ratio (SR) and Maximum Drawdown (MDD) of LLM-guided agents versus unguided baselines. Results show improved return and risk metrics over standard RL.

[Arxiv](https://arxiv.org/abs/2508.02366)