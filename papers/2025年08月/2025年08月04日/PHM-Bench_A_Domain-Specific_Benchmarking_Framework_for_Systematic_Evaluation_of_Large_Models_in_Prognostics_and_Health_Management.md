# PHM-Bench：面向特定领域，系统评估大型模型在预测与健康管理领域的基准测试框架。

发布时间：2025年08月04日

`LLM应用

摘要中讨论了大型语言模型（LLMs）在预测与健康管理（PHM）中的应用，并提出了一个评估框架PHM-Bench。该框架专注于LLMs在PHM任务中的评估和优化，属于将LLMs应用于特定领域的范畴，因此归类为LLM应用。` `预测与健康管理`

> PHM-Bench: A Domain-Specific Benchmarking Framework for Systematic Evaluation of Large Models in Prognostics and Health Management

# 摘要

> 生成式人工智能的快速发展推动了大型语言模型（LLMs）在工业领域的广泛应用，为预测与健康管理（PHM）开辟了新的可能性。这些模型有效应对了PHM领域面临的高成本、长周期和低通用性等挑战。然而，尽管PHM与LLMs的结合日益紧密，现有评估方法在完整性、全面性和细致性上仍显不足，限制了LLMs在PHM领域的深入应用。为此，本研究提出了PHM-Bench——一种专为PHM设计的三维评估框架。基于基本能力、核心任务和完整生命周期的三元结构，PHM-Bench精准满足PHM系统工程的独特需求。它涵盖了知识理解、算法生成和任务优化等多层级评估指标，与状态监测、故障诊断、剩余使用寿命（RUL）预测和维护决策等典型PHM任务高度契合。通过整合精选案例集和公开工业数据集，PHM-Bench实现了跨多种PHM任务的通用型与领域特定模型的多维度评估。这一框架不仅为LLMs在PHM领域的规模化评估奠定了方法论基础，更为从通用型向PHM专用型模型的转变提供了关键基准。

> With the rapid advancement of generative artificial intelligence, large language models (LLMs) are increasingly adopted in industrial domains, offering new opportunities for Prognostics and Health Management (PHM). These models help address challenges such as high development costs, long deployment cycles, and limited generalizability. However, despite the growing synergy between PHM and LLMs, existing evaluation methodologies often fall short in structural completeness, dimensional comprehensiveness, and evaluation granularity. This hampers the in-depth integration of LLMs into the PHM domain. To address these limitations, this study proposes PHM-Bench, a novel three-dimensional evaluation framework for PHM-oriented large models. Grounded in the triadic structure of fundamental capability, core task, and entire lifecycle, PHM-Bench is tailored to the unique demands of PHM system engineering. It defines multi-level evaluation metrics spanning knowledge comprehension, algorithmic generation, and task optimization. These metrics align with typical PHM tasks, including condition monitoring, fault diagnosis, RUL prediction, and maintenance decision-making. Utilizing both curated case sets and publicly available industrial datasets, our study enables multi-dimensional evaluation of general-purpose and domain-specific models across diverse PHM tasks. PHM-Bench establishes a methodological foundation for large-scale assessment of LLMs in PHM and offers a critical benchmark to guide the transition from general-purpose to PHM-specialized models.

[Arxiv](https://arxiv.org/abs/2508.02490)