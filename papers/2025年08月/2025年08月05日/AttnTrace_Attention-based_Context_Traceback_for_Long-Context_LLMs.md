# # AttnTrace: 基于注意力机制的长上下文LLM上下文回溯

发布时间：2025年08月05日

`LLM应用`

> AttnTrace: Attention-based Context Traceback for Long-Context LLMs

# 摘要

> 长上下文大型语言模型（LLMs），如 Gemini-2.5-Pro 和 Claude-Sonnet-4，正在被广泛应用于增强高级 AI 系统，包括检索增强生成（RAG）管道和自主代理。在这些系统中，LLM 接收一个指令以及一个上下文（通常由从知识库或记忆中检索的文本组成），并根据指令生成一个有上下文依据的响应。近期研究设计了解决方案，可以追溯到上下文中对 LLM 生成的响应贡献最大的一部分文本。这些解决方案在现实世界中有许多应用，包括执行攻击后的取证分析，以及提高 LLM 输出的可解释性和可信度。

尽管付出了巨大努力，但现有的解决方案如 TracLLM 通常会导致较高的计算成本。例如，TracLLM 需要数百秒才能完成一个响应-上下文对的回溯。在这项工作中，我们提出了 AttnTrace，这是一种新的上下文回溯方法，基于 LLM 为提示生成的注意力权重。为了有效利用注意力权重，我们引入了两种设计来增强 AttnTrace 的有效性，并提供了我们设计选择的理论见解。我们还对 AttnTrace 进行了系统的评估。结果表明，AttnTrace 比现有的最先进的上下文回溯方法更准确和高效。

此外，我们展示了 AttnTrace 可以通过归因-检测范式改进最先进的长上下文提示注入检测方法。作为现实世界的应用，我们展示了 AttnTrace 可以有效识别出用于操纵 LLM 生成评论的论文中注入的指令。代码位于 https://github.com/Wang-Yanting/AttnTrace。


> Long-context large language models (LLMs), such as Gemini-2.5-Pro and Claude-Sonnet-4, are increasingly used to empower advanced AI systems, including retrieval-augmented generation (RAG) pipelines and autonomous agents. In these systems, an LLM receives an instruction along with a context--often consisting of texts retrieved from a knowledge database or memory--and generates a response that is contextually grounded by following the instruction. Recent studies have designed solutions to trace back to a subset of texts in the context that contributes most to the response generated by the LLM. These solutions have numerous real-world applications, including performing post-attack forensic analysis and improving the interpretability and trustworthiness of LLM outputs. While significant efforts have been made, state-of-the-art solutions such as TracLLM often lead to a high computation cost, e.g., it takes TracLLM hundreds of seconds to perform traceback for a single response-context pair. In this work, we propose AttnTrace, a new context traceback method based on the attention weights produced by an LLM for a prompt. To effectively utilize attention weights, we introduce two techniques designed to enhance the effectiveness of AttnTrace, and we provide theoretical insights for our design choice. We also perform a systematic evaluation for AttnTrace. The results demonstrate that AttnTrace is more accurate and efficient than existing state-of-the-art context traceback methods. We also show that AttnTrace can improve state-of-the-art methods in detecting prompt injection under long contexts through the attribution-before-detection paradigm. As a real-world application, we demonstrate that AttnTrace can effectively pinpoint injected instructions in a paper designed to manipulate LLM-generated reviews. The code is at https://github.com/Wang-Yanting/AttnTrace.

[Arxiv](https://arxiv.org/abs/2508.03793)