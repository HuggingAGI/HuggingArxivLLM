# 为高能物理实验中的中微子事件分析微调视觉-语言模型

发布时间：2025年08月26日

`LLM应用` `基础理论`

> Fine-Tuning Vision-Language Models for Neutrino Event Analysis in High-Energy Physics Experiments

# 摘要

> 大型语言模型（LLMs）的最新进展展现出超越自然语言的强大多模态推理潜力。本研究探索了基于LLaMA 3.2微调的视觉语言模型（VLM）在高能物理（HEP）实验中的应用——通过像素化探测器图像对中微子相互作用进行分类。我们将其性能与NOvA和DUNE等实验中采用的成熟CNN基线模型对比，评估了分类准确率、精确率、召回率及AUC-ROC等指标。结果显示，VLM不仅达到甚至超越了CNN的性能，还能实现更丰富的推理，并更好地整合辅助文本或语义上下文。这些发现表明，VLMs有望成为HEP事件分类的通用骨干，为实验中微子物理的多模态研究方法奠定了基础。

> Recent progress in large language models (LLMs) has shown strong potential for multimodal reasoning beyond natural language. In this work, we explore the use of a fine-tuned Vision-Language Model (VLM), based on LLaMA 3.2, for classifying neutrino interactions from pixelated detector images in high-energy physics (HEP) experiments. We benchmark its performance against an established CNN baseline used in experiments like NOvA and DUNE, evaluating metrics such as classification accuracy, precision, recall, and AUC-ROC. Our results show that the VLM not only matches or exceeds CNN performance but also enables richer reasoning and better integration of auxiliary textual or semantic context. These findings suggest that VLMs offer a promising general-purpose backbone for event classification in HEP, paving the way for multimodal approaches in experimental neutrino physics.

[Arxiv](https://arxiv.org/abs/2508.19376)