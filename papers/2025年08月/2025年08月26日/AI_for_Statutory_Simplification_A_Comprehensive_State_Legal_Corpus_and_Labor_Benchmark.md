# 人工智能赋能法规简化：全面的州级法律语料库与劳动基准

发布时间：2025年08月26日

`RAG` `法律科技`

> AI for Statutory Simplification: A Comprehensive State Legal Corpus and Labor Benchmark

# 摘要

> AI在法律领域的新兴应用之一是法规简化：精简、提炼并简化复杂的成文法或监管语言。美国某州声称借助AI删除了该州三分之一的法规。但我们尚未对此类方法的准确性、可靠性及风险进行系统性评估。为此，我们推出了LaborBench——一个旨在评估AI在该领域能力的问答基准数据集。我们利用独特数据源构建了LaborBench：美国劳工部律师团队每年更新的数据集——他们历时六个月汇总了50个州失业保险法在101多个维度上的差异，最终形成200页的表格出版物。我们曾与美国某州合作，探索利用大型语言模型（LLMs）简化该领域（其复杂性尤为突出）的法规，受此启发，我们将劳工部的出版物转化为LaborBench。这为评估AI处理、提炼和提取真实法规信息的能力提供了独特基准。为评估检索增强生成（RAG）方法的性能，我们还汇编了StateCodes——一个8.7 GB的全新综合州法规与监管语料库，为州法规的系统性研究奠定了基础。我们基于这些数据对信息检索和最先进的大型语言模型进行了性能基准测试，结果显示：尽管这些模型在法规简化的初步研究中有所助益，但整体准确性远未达到将LLMs吹捧为监管简化端到端解决方案的宣传水平。

> One of the emerging use cases of AI in law is for code simplification: streamlining, distilling, and simplifying complex statutory or regulatory language. One U.S. state has claimed to eliminate one third of its state code using AI. Yet we lack systematic evaluations of the accuracy, reliability, and risks of such approaches. We introduce LaborBench, a question-and-answer benchmark dataset designed to evaluate AI capabilities in this domain. We leverage a unique data source to create LaborBench: a dataset updated annually by teams of lawyers at the U.S. Department of Labor, who compile differences in unemployment insurance laws across 50 states for over 101 dimensions in a six-month process, culminating in a 200-page publication of tables. Inspired by our collaboration with one U.S. state to explore using large language models (LLMs) to simplify codes in this domain, where complexity is particularly acute, we transform the DOL publication into LaborBench. This provides a unique benchmark for AI capacity to conduct, distill, and extract realistic statutory and regulatory information. To assess the performance of retrieval augmented generation (RAG) approaches, we also compile StateCodes, a novel and comprehensive state statute and regulatory corpus of 8.7 GB, enabling much more systematic research into state codes. We then benchmark the performance of information retrieval and state-of-the-art large LLMs on this data and show that while these models are helpful as preliminary research for code simplification, the overall accuracy is far below the touted promises for LLMs as end-to-end pipelines for regulatory simplification.

[Arxiv](https://arxiv.org/abs/2508.19365)