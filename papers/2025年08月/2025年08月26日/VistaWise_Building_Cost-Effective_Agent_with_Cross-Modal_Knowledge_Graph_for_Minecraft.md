# VistaWise：基于跨模态知识图谱构建面向《我的世界》的经济高效智能体

发布时间：2025年08月26日

`Agent` `媒体与娱乐`

> VistaWise: Building Cost-Effective Agent with Cross-Modal Knowledge Graph for Minecraft

# 摘要

> 大型语言模型（LLMs）在虚拟开放世界环境的具身决策任务中已展现出巨大潜力。然而，由于缺乏领域特定知识，其性能受到了限制。而在大规模领域数据上进行微调的方法开发成本极高，令人望而却步。本文提出VistaWise——一个经济高效的智能体框架，它整合跨模态领域知识，并针对视觉分析微调专用目标检测模型。该框架将领域特定训练数据的需求量从数百万样本降至仅几百个。VistaWise将视觉信息与文本依赖关系融入跨模态知识图谱（KG），从而能够全面准确地理解多模态环境。我们还为智能体配备了基于检索的池化策略（用于从知识图谱提取任务相关信息）和桌面级技能库（支持通过鼠标键盘直接操作Minecraft桌面客户端）。实验结果显示，VistaWise在各类开放世界任务中均达到了最先进性能，充分证明了其在降低开发成本的同时提升智能体性能的显著效果。

> Large language models (LLMs) have shown significant promise in embodied decision-making tasks within virtual open-world environments. Nonetheless, their performance is hindered by the absence of domain-specific knowledge. Methods that finetune on large-scale domain-specific data entail prohibitive development costs. This paper introduces VistaWise, a cost-effective agent framework that integrates cross-modal domain knowledge and finetunes a dedicated object detection model for visual analysis. It reduces the requirement for domain-specific training data from millions of samples to a few hundred. VistaWise integrates visual information and textual dependencies into a cross-modal knowledge graph (KG), enabling a comprehensive and accurate understanding of multimodal environments. We also equip the agent with a retrieval-based pooling strategy to extract task-related information from the KG, and a desktop-level skill library to support direct operation of the Minecraft desktop client via mouse and keyboard inputs. Experimental results demonstrate that VistaWise achieves state-of-the-art performance across various open-world tasks, highlighting its effectiveness in reducing development costs while enhancing agent performance.

[Arxiv](https://arxiv.org/abs/2508.18722)