# 在线行为研究的LLM污染识别、预测与缓解

发布时间：2025年08月02日

`LLM应用` `在线行为研究` `社会学`

> Recognising, Anticipating, and Mitigating LLM Pollution of Online Behavioural Research

# 摘要

> 在线行为研究正面临一个新兴威胁：LLM污染。随着参与者越来越多地使用大型语言模型（LLMs）寻求建议、翻译或任务委托，我们识别出三种相互作用的变体，它们威胁着在线行为研究的有效性和完整性。

首先，部分LLM中介发生在参与者选择性地使用LLMs完成任务的特定部分（如翻译或措辞支持）时，导致研究者将LLM塑造的输出误认为是人类的产物。其次，完全LLM委托出现在能动的LLMs在几乎没有或完全没有人工监督的情况下完成研究时，这在更基础的层面上动摇了以人为研究对象的核心前提。第三，LLM溢出指的是人类参与者在开始预期在线研究中存在LLM时改变其行为，即使没有LLM参与。

虽然部分中介和完全委托构成了自动化程度递增的连续体，但LLM溢出反映了二阶反应性效应。这些变体相互作用，产生级联失真，损害样本真实性，引入难以事后检测的偏差，并最终削弱在线研究在人类认知和行为方面的知识基础。

至关重要的是，LLM污染的威胁正在与生成式AI的进步共同进化，形成了一场不断升级的方法论军备竞赛。为应对这一挑战，我们提出了一种多层面的应对策略，涵盖研究者实践、平台问责和社区努力。随着这一挑战的演变，协调适应将对于维护方法学严谨性和保护在线行为研究的有效性至关重要。


> Online behavioural research faces an emerging threat as participants increasingly turn to large language models (LLMs) for advice, translation, or task delegation: LLM Pollution. We identify three interacting variants through which LLM Pollution threatens the validity and integrity of online behavioural research. First, Partial LLM Mediation occurs when participants make selective use of LLMs for specific aspects of a task, such as translation or wording support, leading researchers to (mis)interpret LLM-shaped outputs as human ones. Second, Full LLM Delegation arises when agentic LLMs complete studies with little to no human oversight, undermining the central premise of human-subject research at a more foundational level. Third, LLM Spillover signifies human participants altering their behaviour as they begin to anticipate LLM presence in online studies, even when none are involved. While Partial Mediation and Full Delegation form a continuum of increasing automation, LLM Spillover reflects second-order reactivity effects. Together, these variants interact and generate cascading distortions that compromise sample authenticity, introduce biases that are difficult to detect post hoc, and ultimately undermine the epistemic grounding of online research on human cognition and behaviour. Crucially, the threat of LLM Pollution is already co-evolving with advances in generative AI, creating an escalating methodological arms race. To address this, we propose a multi-layered response spanning researcher practices, platform accountability, and community efforts. As the challenge evolves, coordinated adaptation will be essential to safeguard methodological integrity and preserve the validity of online behavioural research.

[Arxiv](https://arxiv.org/abs/2508.01390)