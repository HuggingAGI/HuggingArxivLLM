# CORE：基于强化学习的检索增强LLMs无损压缩

发布时间：2025年08月24日

`RAG` `基础理论`

> CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning

# 摘要

> 检索增强生成（RAG）作为一种颇具前景的方法，有效提升了大型语言模型（LLMs）知识的时效性与响应的事实准确性。但纳入过多检索文档会显著增加输入长度，进而提高计算成本。以往研究尝试在上下文整合前将检索文档压缩为更短文本，然而这类方法常导致最终任务性能下降。由于缺乏明确的压缩目标，许多方法不得不依赖固定启发式规则，难以确保压缩内容对最终任务的有效支持。针对这些局限，我们提出了CORE——一种为RAG实现无损上下文压缩的全新方法。CORE借助强化学习优化压缩过程，且无需依赖预定义的压缩标签。具体而言，该方法将最终任务性能作为奖励信号，并采用广义强化学习策略优化（GRPO）训练压缩器。这种端到端训练框架让压缩器能够生成最大化LLM答案准确性的摘要。在四个数据集上的大量实验验证了我们方法的优越性：凭借3%的高压缩率，我们的方法在所有数据集上不仅避免了与前置完整文档相比的性能损失，还将平均精确匹配（EM）分数提升了3.3分。代码即将发布。

> Retrieval-Augmented Generation (RAG) has emerged as a promising approach to enhance the timeliness of knowledge and the factual accuracy of responses in Large Language Models (LLMs). However, the inclusion of excessive retrieved documents substantially increases the input length, leading to higher computational costs. Previous studies have attempted to compress retrieved documents into shorter texts before in-context integration, but such methods often compromise end-task performance. The lack of well-defined compression targets forces many approaches to rely on fixed heuristics, which cannot guarantee that the compressed content will effectively support the end task. To address these limitations, we propose CORE, a novel method designed to achieve lossless context compression for RAG. CORE employs reinforcement learning to optimize the compression process without relying on predefined compression labels. Specifically, it utilizes end-task performance as a reward signal and applies Generalized Reinforcement Learning Policy Optimization (GRPO) to train the compressor. This end-to-end training framework enables the compressor to generate summaries that maximize the accuracy of answers generated by the LLM. Extensive experiments on four datasets demonstrate the superiority of our approach. With a high compression ratio of 3\%, our method not only avoids performance degradation compared to prepending full documents across all datasets but also improves the average Exact Match (EM) score by 3.3 points. The code will be released soon.

[Arxiv](https://arxiv.org/abs/2508.19282)