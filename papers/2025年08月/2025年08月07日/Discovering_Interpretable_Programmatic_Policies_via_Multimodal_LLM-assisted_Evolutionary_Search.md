# # 探索多模态 LLM 辅助的进化搜索在可解释策略发现中的应用

发布时间：2025年08月07日

`LLM应用` `自动化控制` `机器人技术`

> Discovering Interpretable Programmatic Policies via Multimodal LLM-assisted Evolutionary Search

# 摘要

> 在设计控制策略时，可解释性和高性能是两大核心目标，特别是在安全关键任务中。深度强化学习虽然显著提升了性能，但其与生俱来的不可解释性常常削弱了信任并阻碍了实际部署。本研究通过引入一种名为多模态大语言模型辅助进化搜索（MLES）的新颖程序化策略发现方法，同时解决了这两个挑战。MLES将多模态大语言模型用作策略生成器，并结合进化机制实现自动策略优化。它在策略生成过程中融入视觉反馈驱动的行为分析，以识别失败模式并促进针对性改进，从而提升策略发现的效率，并生成适应性强且符合人类意图的策略。实验结果表明，在两个控制任务中，MLES的策略发现能力与效率可与近端策略优化（PPO）相媲美，同时提供了透明的控制逻辑和可追溯的设计过程。这一范式克服了预定义领域特定语言的局限性，促进了知识的迁移与复用，并可扩展至多种控制任务。MLES有望成为下一代可解释控制策略发现的领先方法。


> Interpretability and high performance are essential goals in designing control policies, particularly for safety-critical tasks. Deep reinforcement learning has greatly enhanced performance, yet its inherent lack of interpretability often undermines trust and hinders real-world deployment. This work addresses these dual challenges by introducing a novel approach for programmatic policy discovery, called Multimodal Large Language Model-assisted Evolutionary Search (MLES). MLES utilizes multimodal large language models as policy generators, combining them with evolutionary mechanisms for automatic policy optimization. It integrates visual feedback-driven behavior analysis within the policy generation process to identify failure patterns and facilitate targeted improvements, enhancing the efficiency of policy discovery and producing adaptable, human-aligned policies. Experimental results show that MLES achieves policy discovery capabilities and efficiency comparable to Proximal Policy Optimization (PPO) across two control tasks, while offering transparent control logic and traceable design processes. This paradigm overcomes the limitations of predefined domain-specific languages, facilitates knowledge transfer and reuse, and is scalable across various control tasks. MLES shows promise as a leading approach for the next generation of interpretable control policy discovery.

[Arxiv](https://arxiv.org/abs/2508.05433)