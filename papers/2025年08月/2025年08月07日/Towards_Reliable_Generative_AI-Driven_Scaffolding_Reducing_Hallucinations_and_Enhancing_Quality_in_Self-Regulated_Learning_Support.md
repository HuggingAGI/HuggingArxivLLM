# # 摘要  
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年08月07日

`LLM应用` `教育技术`

> Towards Reliable Generative AI-Driven Scaffolding: Reducing Hallucinations and Enhancing Quality in Self-Regulated Learning Support

# 摘要

> 生成式人工智能（GenAI）有望通过自动创建个性化学习支架，推动现有教育技术的发展，从而支持学生的自主学习（SRL）。尽管大型语言模型（LLMs）的进步为SRL教育技术的适应性和质量带来了提升，但LLMs生成内容中的幻觉问题仍令人担忧，可能影响学习体验和伦理标准。为应对这些挑战，我们提出了一种基于GenAI的方法，用于在向学生展示之前评估个性化的SRL支架，旨在减少幻觉并提升LLMs生成的个性化支架的整体质量。具体而言，我们研究了两种方法。第一种方法涉及开发一种多智能体系统方法来进行可靠性评估，以评估LLMs生成的支架在多大程度上准确针对相关的SRL过程。第二种方法利用了“LLM作为裁判”的技术来进行质量评估，评估LLMs生成的支架在支持学生方面的有效性。我们构建了评估数据集，并将我们的结果与单智能体LLM系统和机器学习方法基线进行了比较。我们的研究结果表明，可靠性评估方法非常有效，并且优于基线方法，几乎与人类专家的评估完全一致。此外，两种提出的评估方法都可以有效减少幻觉。另外，我们还识别并讨论了“LLM作为裁判”技术在评估LLMs生成支架时的偏见和局限性。我们建议将这些方法整合到基于GenAI的个性化SRL支架系统中，以缓解幻觉问题并提升整体支架质量。

> Generative Artificial Intelligence (GenAI) holds a potential to advance existing educational technologies with capabilities to automatically generate personalised scaffolds that support students' self-regulated learning (SRL). While advancements in large language models (LLMs) promise improvements in the adaptability and quality of educational technologies for SRL, there remain concerns about the hallucinations in content generated by LLMs, which can compromise both the learning experience and ethical standards. To address these challenges, we proposed GenAI-enabled approaches for evaluating personalised SRL scaffolds before they are presented to students, aiming for reducing hallucinations and improving the overall quality of LLM-generated personalised scaffolds. Specifically, two approaches are investigated. The first approach involved developing a multi-agent system approach for reliability evaluation to assess the extent to which LLM-generated scaffolds accurately target relevant SRL processes. The second approach utilised the "LLM-as-a-Judge" technique for quality evaluation that evaluates LLM-generated scaffolds for their helpfulness in supporting students. We constructed evaluation datasets, and compared our results with single-agent LLM systems and machine learning approach baselines. Our findings indicate that the reliability evaluation approach is highly effective and outperforms the baselines, showing almost perfect alignment with human experts' evaluations. Moreover, both proposed evaluation approaches can be harnessed to effectively reduce hallucinations. Additionally, we identified and discussed bias limitations of the "LLM-as-a-Judge" technique in evaluating LLM-generated scaffolds. We suggest incorporating these approaches into GenAI-powered personalised SRL scaffolding systems to mitigate hallucination issues and improve the overall scaffolding quality.

[Arxiv](https://arxiv.org/abs/2508.05929)