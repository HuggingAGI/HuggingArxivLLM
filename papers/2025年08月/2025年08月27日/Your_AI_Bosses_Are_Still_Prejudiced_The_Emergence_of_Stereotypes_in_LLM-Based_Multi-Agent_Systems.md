# 你的AI老板们仍存偏见：基于LLM的多智能体系统中刻板印象的显现

发布时间：2025年08月27日

`Agent` `基础理论`

> Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems

# 摘要

> 尽管刻板印象在人类社会互动中早有大量研究证实，但AI系统通常被认为更能免于此类偏见。以往研究多聚焦于训练数据继承的偏见，而AI智能体互动中是否会自发产生刻板印象，这一问题亟待深入探索。我们通过全新实验框架模拟工作场所互动（初始条件保持中性），深入研究了基于LLM的多智能体系统中刻板印象的形成与演变。研究发现：（1）即便初始无预定义偏见，基于LLM的AI智能体在互动中仍会逐渐形成由刻板印象驱动的偏见；（2）随着互动轮次增多和决策权提升，尤其是引入层级结构后，刻板印象效应愈发显著；（3）这些系统展现出与人类社会行为相似的群体效应，包括光环效应、确认偏误及角色一致性；（4）不同LLM架构中，这些刻板印象模式均稳定存在。综合定量分析表明，AI系统中的刻板印象可能是多智能体互动产生的涌现属性，而非单纯源于训练数据偏见。本研究凸显了未来探索这一现象内在机制及制定伦理影响缓解策略的必要性。

> While stereotypes are well-documented in human social interactions, AI systems are often presumed to be less susceptible to such biases. Previous studies have focused on biases inherited from training data, but whether stereotypes can emerge spontaneously in AI agent interactions merits further exploration. Through a novel experimental framework simulating workplace interactions with neutral initial conditions, we investigate the emergence and evolution of stereotypes in LLM-based multi-agent systems. Our findings reveal that (1) LLM-Based AI agents develop stereotype-driven biases in their interactions despite beginning without predefined biases; (2) stereotype effects intensify with increased interaction rounds and decision-making power, particularly after introducing hierarchical structures; (3) these systems exhibit group effects analogous to human social behavior, including halo effects, confirmation bias, and role congruity; and (4) these stereotype patterns manifest consistently across different LLM architectures. Through comprehensive quantitative analysis, these findings suggest that stereotype formation in AI systems may arise as an emergent property of multi-agent interactions, rather than merely from training data biases. Our work underscores the need for future research to explore the underlying mechanisms of this phenomenon and develop strategies to mitigate its ethical impacts.

[Arxiv](https://arxiv.org/abs/2508.19919)