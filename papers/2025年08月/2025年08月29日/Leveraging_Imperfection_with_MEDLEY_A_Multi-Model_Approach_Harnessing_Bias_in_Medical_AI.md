# 善用不完美：MEDLEY——一种利用医疗AI偏差的多模型方法

发布时间：2025年08月29日

`LLM应用` `医疗健康`

> Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI

# 摘要

> 医疗人工智能中的偏见通常被视作必须消除的缺陷。但人类推理本身就蕴含着由教育、文化和经验塑造的偏见——这意味着偏见的存在或许不可避免，甚至可能具有价值。为此，我们提出MEDLEY（利用多样性的医疗集成诊断系统）——一个协调多个AI模型的概念框架，它保留各模型的多样化输出，而非将其合并为单一共识。与传统方法抑制分歧不同，MEDLEY将特定模型的偏见记录为潜在优势，并把幻觉当作供临床医生验证的临时假说。我们利用30多个大型语言模型开发了概念验证演示器，构建出一个最小可行产品，能在合成病例中同时保留共识与少数派观点，让诊断不确定性和潜在偏见在临床监督中一目了然。尽管这一演示器尚未成为经过验证的临床工具，但它展示了结构化多样性如何在临床医生的监督下提升医疗推理能力。通过将AI的不完美重新定位为一种资源，MEDLEY带来了范式转变，为开发可信赖的医疗AI系统开辟了全新的监管、伦理与创新路径。

> Bias in medical artificial intelligence is conventionally viewed as a defect requiring elimination. However, human reasoning inherently incorporates biases shaped by education, culture, and experience, suggesting their presence may be inevitable and potentially valuable. We propose MEDLEY (Medical Ensemble Diagnostic system with Leveraged diversitY), a conceptual framework that orchestrates multiple AI models while preserving their diverse outputs rather than collapsing them into a consensus. Unlike traditional approaches that suppress disagreement, MEDLEY documents model-specific biases as potential strengths and treats hallucinations as provisional hypotheses for clinician verification. A proof-of-concept demonstrator was developed using over 30 large language models, creating a minimum viable product that preserved both consensus and minority views in synthetic cases, making diagnostic uncertainty and latent biases transparent for clinical oversight. While not yet a validated clinical tool, the demonstration illustrates how structured diversity can enhance medical reasoning under clinician supervision. By reframing AI imperfection as a resource, MEDLEY offers a paradigm shift that opens new regulatory, ethical, and innovation pathways for developing trustworthy medical AI systems.

[Arxiv](https://arxiv.org/abs/2508.21648)