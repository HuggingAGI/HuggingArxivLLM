# 大型语言模型与中文动漫爱好者对决：情感支持型角色扮演的对比研究

发布时间：2025年08月08日

`LLM应用` `人机交互`

> LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing

# 摘要

> 大型语言模型（LLMs）在角色扮演对话和情感支持方面展现了出色的能力，但如何将两者结合以实现与虚拟角色的情感支持型互动仍是一个研究空白。为此，我们选择动漫角色作为研究对象，因其鲜明的个性和庞大的粉丝群体。我们推出了首个情感支持型角色扮演（ESRP）数据集——ChatAnime。首先，我们从热门动漫社区精选了20个顶级角色，并设计了60个以情感为核心的真实场景问题。随后，我们通过全国选拔，招募了40位对中国动漫有深厚了解且擅长角色扮演的爱好者。接着，我们系统性地从10个LLMs和这40位爱好者中收集了两轮对话数据。为了全面评估LLMs的ESRP能力，我们设计了一个包含基本对话、角色扮演和情感支持三大维度的用户体验导向评估系统，共9个精细指标，并新增了响应多样性评估。最终，数据集包含2,400个人工编写和24,000个LLM生成的回答，得到了超过132,000个人工标注的支持。实验结果显示，顶尖LLMs在角色扮演和情感支持方面超越了人类，但人类在响应多样性上仍具优势。我们希望这项研究能为未来优化LLMs在情感支持型角色扮演领域的应用提供宝贵资源和新思路。数据集已开源，详情请访问https://github.com/LanlanQiu/ChatAnime。

> Large Language Models (LLMs) have demonstrated impressive capabilities in role-playing conversations and providing emotional support as separate research directions. However, there remains a significant research gap in combining these capabilities to enable emotionally supportive interactions with virtual characters. To address this research gap, we focus on anime characters as a case study because of their well-defined personalities and large fan bases. This choice enables us to effectively evaluate how well LLMs can provide emotional support while maintaining specific character traits. We introduce ChatAnime, the first Emotionally Supportive Role-Playing (ESRP) dataset. We first thoughtfully select 20 top-tier characters from popular anime communities and design 60 emotion-centric real-world scenario questions. Then, we execute a nationwide selection process to identify 40 Chinese anime enthusiasts with profound knowledge of specific characters and extensive experience in role-playing. Next, we systematically collect two rounds of dialogue data from 10 LLMs and these 40 Chinese anime enthusiasts. To evaluate the ESRP performance of LLMs, we design a user experience-oriented evaluation system featuring 9 fine-grained metrics across three dimensions: basic dialogue, role-playing and emotional support, along with an overall metric for response diversity. In total, the dataset comprises 2,400 human-written and 24,000 LLM-generated answers, supported by over 132,000 human annotations. Experimental results show that top-performing LLMs surpass human fans in role-playing and emotional support, while humans still lead in response diversity. We hope this work can provide valuable resources and insights for future research on optimizing LLMs in ESRP. Our datasets are available at https://github.com/LanlanQiu/ChatAnime.

[Arxiv](https://arxiv.org/abs/2508.06388)