# # GLM-4.5: 智能体、推理与编程 (ARC) 基础模型

发布时间：2025年08月08日

`LLM应用` `智能体AI系统` `推理系统`

> GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models

# 摘要

> 我们很高兴推出开源混合专家模型GLM-4.5，该模型拥有3550亿总参数和3200亿激活参数，支持思考和直接响应两种推理模式。通过在23万亿标记上进行多阶段训练，并结合专家模型迭代和强化学习的全面后训练，GLM-4.5在智能体、推理和编码（ARC）任务中表现优异，在TAU-Bench、AIME 24和SWE-bench Verified上分别取得70.1%、91.0%和64.2%的成绩。尽管参数数量远少于多个竞争对手，GLM-4.5在所有评估模型中总体排名第三，并在智能体基准测试中排名第二。为了推动推理和智能体AI系统的研究，我们发布了GLM-4.5（3550亿参数）和一个紧凑版本GLM-4.5-Air（1060亿参数）。更多信息请访问我们的GitHub仓库：https://github.com/zai-org/GLM-4.5。

> We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language model with 355B total parameters and 32B activated parameters, featuring a hybrid reasoning method that supports both thinking and direct response modes. Through multi-stage training on 23T tokens and comprehensive post-training with expert model iteration and reinforcement learning, GLM-4.5 achieves strong performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer parameters than several competitors, GLM-4.5 ranks 3rd overall among all evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance research in reasoning and agentic AI systems. Code, models, and more information are available at https://github.com/zai-org/GLM-4.5.

[Arxiv](https://arxiv.org/abs/2508.06471)