# 提升德语语音意图识别的大型语言模型数据生成

发布时间：2025年08月08日

`LLM应用` `AI助手` `老龄服务`

> Large Language Model Data Generation for Enhanced Intent Recognition in German Speech

# 摘要

> 语音命令的意图识别（IR）对AI助手系统至关重要，但现有方法多局限于简短的英语指令。本文聚焦于老年德语用户的语音意图识别，提出了一种创新方法：结合针对老年德语语音（SVC-de）微调的Whisper语音识别模型，以及基于Transformer的语言模型。这些模型使用由LeoLM、Llama3和ChatGPT等大型语言模型生成的合成文本数据集进行训练。为验证方法的鲁棒性，我们通过语音合成模型生成测试数据，并进行了跨数据集的广泛测试。结果显示，LLM生成的合成数据显著提升了分类性能和对不同说话风格及未见词汇的适应能力。值得注意的是，专门针对特定领域优化的130亿参数LLM（LeoLM）在德语意图识别数据集质量上，优于规模大得多的1750亿参数ChatGPT。我们的研究证明，生成式AI能有效填补低资源领域数据缺口。此外，我们提供了完整的数据生成和训练文档，确保研究透明且可重复。

> Intent recognition (IR) for speech commands is essential for artificial intelligence (AI) assistant systems; however, most existing approaches are limited to short commands and are predominantly developed for English. This paper addresses these limitations by focusing on IR from speech by elderly German speakers. We propose a novel approach that combines an adapted Whisper ASR model, fine-tuned on elderly German speech (SVC-de), with Transformer-based language models trained on synthetic text datasets generated by three well-known large language models (LLMs): LeoLM, Llama3, and ChatGPT. To evaluate the robustness of our approach, we generate synthetic speech with a text-to-speech model and conduct extensive cross-dataset testing. Our results show that synthetic LLM-generated data significantly boosts classification performance and robustness to different speaking styles and unseen vocabulary. Notably, we find that LeoLM, a smaller, domain-specific 13B LLM, surpasses the much larger ChatGPT (175B) in dataset quality for German intent recognition. Our approach demonstrates that generative AI can effectively bridge data gaps in low-resource domains. We provide detailed documentation of our data generation and training process to ensure transparency and reproducibility.

[Arxiv](https://arxiv.org/abs/2508.06277)