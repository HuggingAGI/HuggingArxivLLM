# # 题目
大型语言模型驱动的精神病学中的非典型性问题

发布时间：2025年08月08日

`LLM应用` `精神病学` `心理健康`

> The Problem of Atypicality in LLM-Powered Psychiatry

# 摘要

> 大型语言模型（LLMs）正越来越多地被视为解决全球心理健康危机的可扩展方案。然而，它们在精神病学领域的应用引发了一个独特的伦理挑战：非典型性问题。由于LLMs的输出基于群体统计规律，虽然这些回应通常适合普通用户，但对常表现出非典型认知或解释模式的精神病患者而言，可能产生危险的误解。我们主张，传统的缓解策略如提示工程或微调无法解决这一结构性风险。为此，我们提出了一种动态上下文认证（DCC）框架：一种分阶段、可逆且上下文敏感的LLMs在精神病学中部署的框架，灵感源自人工智能治理中的临床转化和动态安全模型。DCC将聊天机器人的部署重新定义为一个持续的、注重知识与伦理的过程，优先考虑解释性安全而非静态性能指标。我们主张，非典型性无法完全消除，但必须且可以被积极管理。

> Large language models (LLMs) are increasingly proposed as scalable solutions to the global mental health crisis. But their deployment in psychiatric contexts raises a distinctive ethical concern: the problem of atypicality. Because LLMs generate outputs based on population-level statistical regularities, their responses -- while typically appropriate for general users -- may be dangerously inappropriate when interpreted by psychiatric patients, who often exhibit atypical cognitive or interpretive patterns. We argue that standard mitigation strategies, such as prompt engineering or fine-tuning, are insufficient to resolve this structural risk. Instead, we propose dynamic contextual certification (DCC): a staged, reversible and context-sensitive framework for deploying LLMs in psychiatry, inspired by clinical translation and dynamic safety models from artificial intelligence governance. DCC reframes chatbot deployment as an ongoing epistemic and ethical process that prioritises interpretive safety over static performance benchmarks. Atypicality, we argue, cannot be eliminated -- but it can, and must, be proactively managed.

[Arxiv](https://arxiv.org/abs/2508.06479)