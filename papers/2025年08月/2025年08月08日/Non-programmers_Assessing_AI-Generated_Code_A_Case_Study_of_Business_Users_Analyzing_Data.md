# 非程序员评估AI生成代码：企业用户数据分析的案例研究

发布时间：2025年08月08日

`LLM应用` `市场营销` `人工智能`

> Non-programmers Assessing AI-Generated Code: A Case Study of Business Users Analyzing Data

# 摘要

> 越来越多的非技术终端用户依赖AI代码生成来完成数据分析等技术任务。然而，大型语言模型（LLMs）的可靠性仍然不足，尤其是在现实和领域特定的场景中，终端用户是否能有效识别模型错误尚不清楚。我们对市场营销和销售专业人士进行了调查，以评估他们对LLM生成的营销数据分析的批判性评估能力。参与者被展示了AI代码的自然语言解释，反复被告知AI经常犯错误，并被明确提示去识别这些错误。然而，参与者经常未能检测到可能损害决策的关键缺陷，其中许多缺陷无需技术知识即可识别。为了调查原因，我们将AI响应重新格式化为清晰界定的步骤，并为每个决策提供了替代方法，以支持批判性评估。虽然这些变化产生了积极影响，但参与者往往难以通过AI的步骤和替代方案进行推理。我们的研究结果表明，业务专业人士无法可靠地自行验证AI生成的数据分析，并探讨原因以指导未来的设计。随着非程序员采用代码生成AI来执行技术任务，不可靠的AI和不足的人为监督可能导致不安全或低质量的决策。

> Non-technical end-users increasingly rely on AI code generation to perform technical tasks like data analysis. However, large language models (LLMs) remain unreliable, and it is unclear whether end-users can effectively identify model errors $unicode{x2014}$ especially in realistic and domain-specific scenarios. We surveyed marketing and sales professionals to assess their ability to critically evaluate LLM-generated analyses of marketing data. Participants were shown natural language explanations of the AI's code, repeatedly informed the AI often makes mistakes, and explicitly prompted to identify them. Yet, participants frequently failed to detect critical flaws that could compromise decision-making, many of which required no technical knowledge to recognize. To investigate why, we reformatted AI responses into clearly delineated steps and provided alternative approaches for each decision to support critical evaluation. While these changes had a positive effect, participants often struggled to reason through the AI's steps and alternatives. Our findings suggest that business professionals cannot reliably verify AI-generated data analyses on their own and explore reasons why to inform future designs. As non-programmers adopt code-generating AI for technical tasks, unreliable AI and insufficient human oversight poses risks of unsafe or low-quality decisions.

[Arxiv](https://arxiv.org/abs/2508.06484)