# 探索大型语言模型在家庭环境中生成细粒度视觉隐私政策的有效性

发布时间：2025年08月01日

`LLM应用` `智能家居` `隐私保护`

> Evaluating the Efficacy of Large Language Models for Generating Fine-Grained Visual Privacy Policies in Homes

# 摘要

> 智能眼镜等可穿戴设备的普及，使得视觉传感器在智能家居环境中无处不在，这给隐私保护带来了巨大挑战。现有隐私控制手段往往静态且粒度粗放，难以适应家庭环境中动态变化和社会语境的复杂性。本文提出了一种创新方案，将大型语言模型（LLMs）作为动态自适应隐私策略引擎的核心。我们设计了一个概念框架，通过多维分类框架对视觉数据进行分类，综合考虑数据敏感性、空间背景和社会存在性等因素。随后，大型语言模型基于这些上下文信息，实时推理并执行精细化隐私规则，例如选择性物体模糊化。在模拟家居环境中对当前先进的视觉语言模型（包括GPT-4o和Qwen-VL系列）进行对比评估后，我们的研究结果表明了该方法的可行性。基于LLM的引擎在机器评估中获得了高达3.99/5的适宜性评分，而模型生成的隐私策略在人工评估中获得了4.00/5的最高评分。

> The proliferation of visual sensors in smart home environments, particularly through wearable devices like smart glasses, introduces profound privacy challenges. Existing privacy controls are often static and coarse-grained, failing to accommodate the dynamic and socially nuanced nature of home environments. This paper investigates the viability of using Large Language Models (LLMs) as the core of a dynamic and adaptive privacy policy engine. We propose a conceptual framework where visual data is classified using a multi-dimensional schema that considers data sensitivity, spatial context, and social presence. An LLM then reasons over this contextual information to enforce fine-grained privacy rules, such as selective object obfuscation, in real-time. Through a comparative evaluation of state-of-the-art Vision Language Models (including GPT-4o and the Qwen-VL series) in simulated home settings , our findings show the feasibility of this approach. The LLM-based engine achieved a top machine-evaluated appropriateness score of 3.99 out of 5, and the policies generated by the models received a top human-evaluated score of 4.00 out of 5.

[Arxiv](https://arxiv.org/abs/2508.00321)