# 思考机器：LLM时代的数学推理

发布时间：2025年08月01日

`LLM应用`

> Thinking Machines: Mathematical Reasoning in the Age of LLMs

# 摘要

> 大型语言模型（LLMs）在结构化推理和符号任务中表现卓越，尤其在编码领域展现出了显著优势。这一成功激发了将LLMs应用于数学领域的浓厚兴趣，包括非正式问题解决和正式定理证明。尽管编程和证明构造在表面上有相似之处，但正式数学领域的进展却要困难得多。这种差异引发了关于LLMs如何推理、如何被监督以及是否在内部跟踪计算或演绎状态的重要问题。本文聚焦于该领域的最新进展，探讨机器学习与数学认知交叉领域的三大核心问题：(i)正式与非正式数学作为训练领域之间的权衡；(ii)证明生成为何比代码合成更为脆弱的深层原因；(iii)LLMs是否代表或仅模仿了一种演进逻辑状态。我们的目标不是划定严格的界限，而是识别当前的限制所在，并探索如何扩展这些界限。

> Large Language Models (LLMs) have shown remarkable abilities in structured reasoning and symbolic tasks, with coding emerging as a particular area of strength. This success has sparked growing interest in applying LLMs to mathematics, both in informal problem-solving and formal theorem proving. However, progress in formal mathematics has proven to be significantly more difficult, despite surface-level similarities between programming and proof construction. This discrepancy raises important questions about how LLMs ``reason'', how they are supervised, and whether they internally track a notion of computational or deductive state. In this article, we address the state-of-the-art of the discipline, focusing on recent models and benchmarks, and explore three central issues at the intersection of machine learning and mathematical cognition: (i) the trade-offs between formal and informal mathematics as training domains; (ii) the deeper reasons why proof generation remains more brittle than code synthesis; (iii) and the question of whether LLMs represent, or merely mimic, a notion of evolving logical state. Our goal is not to draw hard boundaries, but to identify where the current limits lie, and how they might be extended.

[Arxiv](https://arxiv.org/abs/2508.00459)