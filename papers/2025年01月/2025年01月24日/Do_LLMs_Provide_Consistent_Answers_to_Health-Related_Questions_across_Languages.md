# LLMs 在不同语言中对健康相关问题的回答是否一致？

发布时间：2025年01月24日

`LLM应用

理由：这篇论文主要研究了大型语言模型（LLMs）在多语言环境下对健康相关问题的回答一致性，并提出了一个多语言健康查询数据集和评估工作流程。研究重点在于LLMs在实际应用中的表现和潜在问题，特别是医疗信息传播的准确性和公平性。因此，这篇论文属于LLM应用类别。` `公共卫生`

> Do LLMs Provide Consistent Answers to Health-Related Questions across Languages?

# 摘要

> # 摘要
公平获取可靠的健康信息对公共卫生至关重要，然而在线健康资源的质量因语言差异而参差不齐，这引发了人们对LLMs在医疗保健领域一致性的担忧。本研究考察了LLMs在英语、德语、土耳其语和中文中对健康相关问题的回答一致性。我们通过按疾病类型分类健康问题，并扩展了土耳其语和中文翻译，大幅丰富了HealthFC数据集。研究发现，LLMs的回答存在显著不一致性，可能导致医疗错误信息的传播。我们的主要贡献包括：1）一个带有疾病类别元信息的多语言健康查询数据集；2）一种基于提示的评估工作流程，通过解析实现两种语言之间的子维度比较。研究结果揭示了在多语言环境中部署LLM工具的关键挑战，并强调了改进跨语言对齐以确保医疗信息准确性和公平性的重要性。

> Equitable access to reliable health information is vital for public health, but the quality of online health resources varies by language, raising concerns about inconsistencies in Large Language Models (LLMs) for healthcare. In this study, we examine the consistency of responses provided by LLMs to health-related questions across English, German, Turkish, and Chinese. We largely expand the HealthFC dataset by categorizing health-related questions by disease type and broadening its multilingual scope with Turkish and Chinese translations. We reveal significant inconsistencies in responses that could spread healthcare misinformation. Our main contributions are 1) a multilingual health-related inquiry dataset with meta-information on disease categories, and 2) a novel prompt-based evaluation workflow that enables sub-dimensional comparisons between two languages through parsing. Our findings highlight key challenges in deploying LLM-based tools in multilingual contexts and emphasize the need for improved cross-lingual alignment to ensure accurate and equitable healthcare information.

[Arxiv](https://arxiv.org/abs/2501.14719)