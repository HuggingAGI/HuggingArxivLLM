# 借助ChatGPT的多模态视觉能力，按贫困水平对卫星图像进行排序，推动社会科学研究工具的进步

发布时间：2025年01月24日

`LLM应用

**理由**：该论文探讨了具备视觉能力的大型语言模型（LLMs）在卫星图像分析中的应用，特别是用于村级贫困预测。这属于LLM在实际问题中的应用，因此归类为LLM应用。` `社会经济` `卫星图像分析`

> Leveraging ChatGPT's Multimodal Vision Capabilities to Rank Satellite Images by Poverty Level: Advancing Tools for Social Science Research

# 摘要

> 本文探讨了具备视觉能力的大型语言模型（LLMs）在卫星图像分析中的应用，用于村级贫困预测。尽管LLMs最初是为自然语言理解设计的，但其在多模态任务（如地理空间分析）中的适应性为数据驱动研究开辟了新领域。通过视觉增强型LLMs的进展，我们评估了其从卫星图像中提供可解释、可扩展且可靠的贫困洞察的能力。采用成对比较方法，我们展示了ChatGPT能够根据贫困水平对卫星图像进行排名，其准确性与领域专家相当。这些发现揭示了LLMs在社会经济研究中的潜力与局限，为将其整合到贫困评估工作流程奠定了基础。本研究为福利分析中非常规数据源的探索提供了新思路，并为低成本、大规模的贫困监测开辟了道路。

> This paper investigates the novel application of Large Language Models (LLMs) with vision capabilities to analyze satellite imagery for village-level poverty prediction. Although LLMs were originally designed for natural language understanding, their adaptability to multimodal tasks, including geospatial analysis, has opened new frontiers in data-driven research. By leveraging advancements in vision-enabled LLMs, we assess their ability to provide interpretable, scalable, and reliable insights into human poverty from satellite images. Using a pairwise comparison approach, we demonstrate that ChatGPT can rank satellite images based on poverty levels with accuracy comparable to domain experts. These findings highlight both the promise and the limitations of LLMs in socioeconomic research, providing a foundation for their integration into poverty assessment workflows. This study contributes to the ongoing exploration of unconventional data sources for welfare analysis and opens pathways for cost-effective, large-scale poverty monitoring.

[Arxiv](https://arxiv.org/abs/2501.14546)