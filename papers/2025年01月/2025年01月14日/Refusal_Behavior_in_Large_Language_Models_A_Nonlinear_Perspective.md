# 大型语言模型的拒绝行为：非线性视角

发布时间：2025年01月14日

`LLM理论

理由：这篇论文主要研究了大型语言模型（LLMs）的拒绝行为，探讨了其非线性、多维特征，并强调了非线性可解释性在改进对齐研究和指导更安全的AI部署策略中的重要性。这些内容属于对LLM内部机制和理论的研究，因此分类为LLM理论。` `人工智能`

> Refusal Behavior in Large Language Models: A Nonlinear Perspective

# 摘要

> # 摘要
大型语言模型（LLMs）的拒绝行为使其能够拒绝回应有害、不道德或不适当的提示，确保符合道德标准。本文研究了来自三个架构家族的六个LLMs的拒绝行为，并通过降维技术（如PCA、t-SNE和UMAP）挑战了拒绝行为是线性现象的假设。结果表明，拒绝机制具有非线性、多维特征，且因模型架构和层次而异。这些发现凸显了非线性可解释性在改进对齐研究和指导更安全的AI部署策略中的重要性。

> Refusal behavior in large language models (LLMs) enables them to decline responding to harmful, unethical, or inappropriate prompts, ensuring alignment with ethical standards. This paper investigates refusal behavior across six LLMs from three architectural families. We challenge the assumption of refusal as a linear phenomenon by employing dimensionality reduction techniques, including PCA, t-SNE, and UMAP. Our results reveal that refusal mechanisms exhibit nonlinear, multidimensional characteristics that vary by model architecture and layer. These findings highlight the need for nonlinear interpretability to improve alignment research and inform safer AI deployment strategies.

[Arxiv](https://arxiv.org/abs/2501.08145)