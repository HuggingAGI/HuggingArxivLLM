# 破解可持续AI三难困境：LLM代理与RAG的案例研究

发布时间：2025年01月14日

`LLM应用

理由：这篇论文主要讨论了大型语言模型（LLMs）在应用中的可持续性挑战，特别是推理能耗问题。论文提出了“可持续AI三难困境”概念，并通过对LLM代理和检索增强生成（RAG）的系统研究，分析了内存模块设计中的能源消耗。虽然提到了RAG，但论文的核心关注点是LLM在实际应用中的能源效率和可持续性，因此更适合归类为LLM应用。` `人工智能` `可持续发展`

> Addressing the sustainable AI trilemma: a case study on LLM agents and RAG

# 摘要

> 大型语言模型（LLMs）展现了强大的能力，但其广泛应用和高级功能带来了可持续性挑战，尤其是在推理能耗方面。我们提出了“可持续AI三难困境”概念，揭示了AI能力、数字公平和环境可持续性之间的矛盾。通过对LLM代理和检索增强生成（RAG）的系统研究，我们剖析了内存模块设计中的能源消耗，并引入新指标量化能耗与性能的权衡。实验结果表明，当前内存增强框架存在显著的能源低效问题，资源受限环境更是效率损失严重。这一发现挑战了以LLM为中心的代理设计范式，为开发更可持续的AI系统提供了新思路。

> Large language models (LLMs) have demonstrated significant capabilities, but their widespread deployment and more advanced applications raise critical sustainability challenges, particularly in inference energy consumption. We propose the concept of the Sustainable AI Trilemma, highlighting the tensions between AI capability, digital equity, and environmental sustainability. Through a systematic case study of LLM agents and retrieval-augmented generation (RAG), we analyze the energy costs embedded in memory module designs and introduce novel metrics to quantify the trade-offs between energy consumption and system performance. Our experimental results reveal significant energy inefficiencies in current memory-augmented frameworks and demonstrate that resource-constrained environments face disproportionate efficiency penalties. Our findings challenge the prevailing LLM-centric paradigm in agent design and provide practical insights for developing more sustainable AI systems.

[Arxiv](https://arxiv.org/abs/2501.08262)