# 在FLIP基准测试中探索大型蛋白质语言模型的受限评估场景

发布时间：2025年01月30日

`LLM应用

解释：该论文探讨了大型蛋白质语言模型（如ESM-2和SaProt）在数据稀缺环境下的表现，特别是它们在蛋白质适应性预测任务中的应用。虽然这些模型是专门针对蛋白质领域的，但它们仍然属于大型语言模型（LLM）的应用范畴，因为它们使用了类似的技术和方法来处理和预测蛋白质序列。因此，这篇论文应被分类为“LLM应用”。` `生物信息学` `蛋白质预测`

> Exploring Large Protein Language Models in Constrained Evaluation Scenarios within the FLIP Benchmark

# 摘要

> 本研究扩展了FLIP基准，该基准用于评估蛋白质适应性预测模型在小型、专门任务中的表现。我们通过在FLIP数据集上测试ESM-2和SaProt等先进的大型蛋白质语言模型，探讨了它们在数据稀缺环境下的表现。与ProteinGym等广泛覆盖多种任务的基准不同，FLIP专注于数据有限的场景，成为评估模型在任务特定数据稀缺情况下性能的理想工具。我们研究了蛋白质语言模型的最新进展是否在此类环境中带来了显著提升，研究结果为大规模模型在专门蛋白质预测任务中的表现提供了重要见解。

> In this study, we expand upon the FLIP benchmark-designed for evaluating protein fitness prediction models in small, specialized prediction tasks-by assessing the performance of state-of-the-art large protein language models, including ESM-2 and SaProt on the FLIP dataset. Unlike larger, more diverse benchmarks such as ProteinGym, which cover a broad spectrum of tasks, FLIP focuses on constrained settings where data availability is limited. This makes it an ideal framework to evaluate model performance in scenarios with scarce task-specific data. We investigate whether recent advances in protein language models lead to significant improvements in such settings. Our findings provide valuable insights into the performance of large-scale models in specialized protein prediction tasks.

[Arxiv](https://arxiv.org/abs/2501.18223)