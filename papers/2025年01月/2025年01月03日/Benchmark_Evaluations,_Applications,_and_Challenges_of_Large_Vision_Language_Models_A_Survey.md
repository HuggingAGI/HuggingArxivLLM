# # 大型视觉语言模型的基准评估、应用与挑战：综述

发布时间：2025年01月03日

`LLM应用

理由：这篇论文主要讨论了多模态视觉语言模型（VLMs）在计算机视觉与自然语言处理交叉领域的应用，包括模型的核心架构、训练方法、评估指标以及在具身代理、机器人及视频生成等领域的应用。虽然涉及了模型的理论和架构，但重点在于这些模型的实际应用和在不同领域中的表现，因此归类为“LLM应用”更为合适。` `计算机视觉`

> Benchmark Evaluations, Applications, and Challenges of Large Vision Language Models: A Survey

# 摘要

> 多模态视觉语言模型（VLMs）作为计算机视觉与自然语言处理交叉领域的革命性技术，赋予了机器通过视觉和文本模态感知与推理世界的能力。例如，CLIP、Claude 和 GPT-4V 等模型在视觉与文本数据上展现了强大的推理与理解能力，并在零样本分类任务中超越了传统单模态视觉模型。尽管 VLMs 在研究中进展迅速，应用日益广泛，但针对现有 VLMs 研究的全面综述仍显不足，尤其是对希望在特定领域应用 VLMs 的研究人员而言。为此，我们从以下几个方面系统梳理了 VLMs：过去五年（2019-2024）主要 VLMs 的模型信息；这些模型的核心架构与训练方法；VLMs 常用基准与评估指标的总结与分类；VLMs 在具身代理、机器人及视频生成等领域的应用；以及当前 VLMs 面临的挑战，如幻觉、公平性与安全性等。详细资源，包括论文与模型仓库链接，请访问 https://github.com/zli12321/Awesome-VLM-Papers-And-Models.git。

> Multimodal Vision Language Models (VLMs) have emerged as a transformative technology at the intersection of computer vision and natural language processing, enabling machines to perceive and reason about the world through both visual and textual modalities. For example, models such as CLIP, Claude, and GPT-4V demonstrate strong reasoning and understanding abilities on visual and textual data and beat classical single modality vision models on zero-shot classification. Despite their rapid advancements in research and growing popularity in applications, a comprehensive survey of existing studies on VLMs is notably lacking, particularly for researchers aiming to leverage VLMs in their specific domains. To this end, we provide a systematic overview of VLMs in the following aspects: model information of the major VLMs developed over the past five years (2019-2024); the main architectures and training methods of these VLMs; summary and categorization of the popular benchmarks and evaluation metrics of VLMs; the applications of VLMs including embodied agents, robotics, and video generation; the challenges and issues faced by current VLMs such as hallucination, fairness, and safety. Detailed collections including papers and model repository links are listed in https://github.com/zli12321/Awesome-VLM-Papers-And-Models.git.

[Arxiv](https://arxiv.org/abs/2501.02189)