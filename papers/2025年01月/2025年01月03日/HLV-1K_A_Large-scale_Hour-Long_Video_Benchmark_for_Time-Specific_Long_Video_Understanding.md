# HLV-1K: 大规模小时级视频基准，专为时间特定长视频理解而设计

发布时间：2025年01月03日

`LLM应用

**理由**：该论文主要讨论的是多模态大型语言模型在长时间视频理解中的应用，特别是通过构建一个大规模的长视频基准HLV-1K来评估长视频理解模型。这属于大型语言模型在实际应用中的具体应用场景，因此分类为LLM应用。` `视频理解` `人工智能`

> HLV-1K: A Large-scale Hour-Long Video Benchmark for Time-Specific Long Video Understanding

# 摘要

> 多模态大型语言模型因其广泛的实际应用前景，已成为深度视觉理解领域的热门话题。然而，时长超过一小时、包含数万帧画面的长时间视频理解仍未被充分探索，主要原因有三：1）长期视频分析的挑战性，2）大型模型方法的低效性，以及3）缺乏大规模基准数据集。本文聚焦于构建一个大规模的长视频基准HLV-1K，旨在评估长视频理解模型。HLV-1K包含1009个时长一小时以上的视频，配有14,847个高质量的问题回答（QA）和多选问题回答（MCQA）对，具备时间感知查询和多样化注释，涵盖帧级、事件内级、跨事件级和长期推理任务。我们使用现有最先进方法评估该基准，展示了其在测试不同层次和任务下的深度长视频理解能力方面的价值，并为未来的长视频理解任务（如长直播视频、会议记录和电影的深度理解）提供了细粒度的推动力。

> Multimodal large language models have become a popular topic in deep visual understanding due to many promising real-world applications. However, hour-long video understanding, spanning over one hour and containing tens of thousands of visual frames, remains under-explored because of 1) challenging long-term video analyses, 2) inefficient large-model approaches, and 3) lack of large-scale benchmark datasets. Among them, in this paper, we focus on building a large-scale hour-long long video benchmark, HLV-1K, designed to evaluate long video understanding models. HLV-1K comprises 1009 hour-long videos with 14,847 high-quality question answering (QA) and multi-choice question asnwering (MCQA) pairs with time-aware query and diverse annotations, covering frame-level, within-event-level, cross-event-level, and long-term reasoning tasks. We evaluate our benchmark using existing state-of-the-art methods and demonstrate its value for testing deep long video understanding capabilities at different levels and for various tasks. This includes promoting future long video understanding tasks at a granular level, such as deep understanding of long live videos, meeting recordings, and movies.

[Arxiv](https://arxiv.org/abs/2501.01645)