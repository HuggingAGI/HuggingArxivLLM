# KPL: 免训练的医学知识挖掘视觉-语言模型

发布时间：2025年01月19日

`LLM应用

理由：这篇论文主要讨论了如何利用视觉语言模型（如CLIP）和大型语言模型（LLM）来提升医学图像分类的效果。虽然论文中提到了代理学习（KPL），但其核心是通过LLM来增强文本描述，从而优化CLIP的多模态理解能力。因此，这篇论文更符合“LLM应用”这一分类，因为它主要关注如何将LLM应用于医学图像分类任务中。` `图像识别`

> KPL: Training-Free Medical Knowledge Mining of Vision-Language Models

# 摘要

> # 摘要
视觉语言模型（如CLIP）凭借广泛的图像-文本预训练在图像识别领域表现出色。然而，在医学图像诊断的零样本分类中，CLIP推理面临两大挑战：1）仅用单一类别名称难以充分表示图像类别；2）CLIP编码器生成的视觉与文本空间存在模态差距。尽管尝试用大型语言模型丰富疾病描述，但缺乏特定类别的知识往往导致效果不佳。此外，现有代理学习方法在自然图像数据集上的零样本分类表现不稳定，难以直接应用于医学数据集。为此，我们提出了知识代理学习（KPL），旨在通过文本代理优化和多模态代理学习，挖掘CLIP的多模态理解能力，提升医学图像分类效果。具体而言，KPL从知识增强库中检索与图像相关的知识描述，丰富语义文本代理，并结合输入图像和CLIP编码的描述，稳定生成多模态代理，显著提升零样本分类性能。在医学和自然图像数据集上的大量实验表明，KPL在零样本图像分类中表现优异，超越所有基线方法。这一研究揭示了从CLIP中挖掘知识用于医学图像分类及更广泛领域的巨大潜力。

> Visual Language Models such as CLIP excel in image recognition due to extensive image-text pre-training. However, applying the CLIP inference in zero-shot classification, particularly for medical image diagnosis, faces challenges due to: 1) the inadequacy of representing image classes solely with single category names; 2) the modal gap between the visual and text spaces generated by CLIP encoders. Despite attempts to enrich disease descriptions with large language models, the lack of class-specific knowledge often leads to poor performance. In addition, empirical evidence suggests that existing proxy learning methods for zero-shot image classification on natural image datasets exhibit instability when applied to medical datasets. To tackle these challenges, we introduce the Knowledge Proxy Learning (KPL) to mine knowledge from CLIP. KPL is designed to leverage CLIP's multimodal understandings for medical image classification through Text Proxy Optimization and Multimodal Proxy Learning. Specifically, KPL retrieves image-relevant knowledge descriptions from the constructed knowledge-enhanced base to enrich semantic text proxies. It then harnesses input images and these descriptions, encoded via CLIP, to stably generate multimodal proxies that boost the zero-shot classification performance. Extensive experiments conducted on both medical and natural image datasets demonstrate that KPL enables effective zero-shot image classification, outperforming all baselines. These findings highlight the great potential in this paradigm of mining knowledge from CLIP for medical image classification and broader areas.

[Arxiv](https://arxiv.org/abs/2501.11231)