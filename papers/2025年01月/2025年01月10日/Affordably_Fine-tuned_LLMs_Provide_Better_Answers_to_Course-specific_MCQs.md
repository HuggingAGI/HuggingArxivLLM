# 经济实惠的微调LLMs为课程特定MCQs提供了更优解答

发布时间：2025年01月10日

`LLM应用

理由：这篇论文探讨了大型语言模型（LLMs）在教育领域的应用，特别是如何通过微调和量化技术来优化LLMs在回答多项选择题（MCQs）时的表现。研究聚焦于如何使LLMs在教育环境中更具可负担性，这属于LLM在实际场景中的应用研究。因此，将其分类为“LLM应用”是合适的。`

> Affordably Fine-tuned LLMs Provide Better Answers to Course-specific MCQs

# 摘要

> 在教育领域，大型语言模型（LLMs）生成类人文本的能力激发了关于如何提升学习和教学效率的研究。我们通过研究LLMs在硬件限制和优化技术下如何回答多项选择题（MCQs），探讨了这些模型对教育工作者和学生的可负担性。我们使用通用的预训练LLMs（LLaMA-2的7B、13B和70B变体）来回答来自编程语言（PL）课程的162个本科水平MCQs——MCQ数据集是本工作的贡献，我们将其公开。具体来说，我们剖析了不同因素，如使用现成材料（课程教科书的部分内容）进行微调和量化（以减少资源使用）如何改变回答的准确性。主要结论是，基于教科书微调的较小模型优于通用的较大模型（其预训练需要大量资源），使得使用LLMs回答MCQs在资源和材料方面更具可负担性。

> In education, the capability of generating human-like text of Large Language Models (LLMs) inspired work on how they can increase the efficiency of learning and teaching. We study the affordability of these models for educators and students by investigating how LLMs answer multiple-choice questions (MCQs) with respect to hardware constraints and refinement techniques. We explore this space by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of LLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming Languages (PL) -- the MCQ dataset is a contribution of this work, which we make publicly available. Specifically, we dissect how different factors, such as using readily-available material -- (parts of) the course's textbook -- for fine-tuning and quantisation (to decrease resource usage) can change the accuracy of the responses. The main takeaway is that smaller textbook-based fine-tuned models outperform generic larger ones (whose pre-training requires conspicuous resources), making the usage of LLMs for answering MCQs resource- and material-wise affordable.

[Arxiv](https://arxiv.org/abs/2501.05891)