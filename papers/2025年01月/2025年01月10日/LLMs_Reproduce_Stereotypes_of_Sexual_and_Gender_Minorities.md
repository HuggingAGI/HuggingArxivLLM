# 大型语言模型（LLMs）重现了性少数和性别少数群体的刻板印象。

发布时间：2025年01月10日

`LLM理论

理由：这篇论文探讨了大型语言模型（LLMs）在处理性别和性少数群体时的偏见问题，特别是超越了传统的二元性别观。研究基于心理学中的刻板印象内容模型，分析了LLMs在回答社会认知问题和文本生成场景中的表现。这种对LLMs内在机制和行为的深入分析，以及对模型偏见的理论探讨，属于LLM理论的研究范畴。` `社会心理学`

> LLMs Reproduce Stereotypes of Sexual and Gender Minorities

# 摘要

> 大量研究表明，NLP系统中存在显著的性别偏见。大多数研究采用二元性别观，将性别局限于_男性_和_女性_，混淆了性别与生理性别，忽视了多样化的性别认同。然而，性别和性取向是多元的，因此本文探讨了大型语言模型（LLMs）对超越二元类别的性别和性少数群体的偏见。基于心理学中的刻板印象内容模型，我们发现，LLMs在回答关于社会认知的英语调查问题时，会像人类一样对性别和性少数群体产生更多负面刻板印象。进一步，我们将这一框架应用于文本生成场景，发现LLMs生成的文本中对性别和性少数群体的刻板印象依然存在，这引发了对其在创意写作等广泛使用场景中可能放大代表性伤害的担忧。

> A large body of research has found substantial gender bias in NLP systems. Most of this research takes a binary, essentialist view of gender: limiting its variation to the categories _men_ and _women_, conflating gender with sex, and ignoring different sexual identities. But gender and sexuality exist on a spectrum, so in this paper we study the biases of large language models (LLMs) towards sexual and gender minorities beyond binary categories. Grounding our study in a widely used psychological framework -- the Stereotype Content Model -- we demonstrate that English-language survey questions about social perceptions elicit more negative stereotypes of sexual and gender minorities from LLMs, just as they do from humans. We then extend this framework to a more realistic use case: text generation. Our analysis shows that LLMs generate stereotyped representations of sexual and gender minorities in this setting, raising concerns about their capacity to amplify representational harms in creative writing, a widely promoted use case.

[Arxiv](https://arxiv.org/abs/2501.05926)