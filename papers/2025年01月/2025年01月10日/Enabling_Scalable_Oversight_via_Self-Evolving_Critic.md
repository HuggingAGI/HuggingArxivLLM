# 通过自我进化批评者实现可扩展监督

发布时间：2025年01月10日

`LLM应用

理由：这篇论文主要讨论的是如何通过自我进化的批评者（SCRIT）框架来增强LLMs的批评能力，特别是在没有外部监督的情况下。这涉及到LLMs在实际应用中的改进和优化，因此属于LLM应用的范畴。` `人工智能`

> Enabling Scalable Oversight via Self-Evolving Critic

# 摘要

> 尽管LLMs表现卓越，但其发展在可扩展监督方面面临一个关键挑战：如何为人类难以评估或LLMs超越人类的任务提供有效反馈。尽管使用LLMs进行批评的兴趣日益增长，但现有方法仍依赖人类注释或更强大的模型，导致在没有外部监督的情况下增强批评能力的问题悬而未决。我们提出了SCRIT（自我进化的批评者），这是一个能够实现批评能力真正自我进化的框架。SCRIT通过训练合成数据进行自我改进，这些数据由基于对比的自我批评者生成，该批评者使用参考解决方案进行逐步批评，并通过自我验证机制确保批评质量。SCRIT使用Qwen2.5-72B-Instruct（最强大的LLMs之一）实现，在批评-纠正和错误识别基准上实现了高达10.3%的提升。分析表明，SCRIT的性能随数据和模型规模的增加而提升，优于其他方法，且其自我验证组件对其性能至关重要。

> Despite their remarkable performance, the development of Large Language Models (LLMs) faces a critical challenge in scalable oversight: providing effective feedback for tasks where human evaluation is difficult or where LLMs outperform humans. While there is growing interest in using LLMs for critique, current approaches still rely on human annotations or more powerful models, leaving the issue of enhancing critique capabilities without external supervision unresolved. We introduce SCRIT (Self-evolving CRITic), a framework that enables genuine self-evolution of critique abilities. Technically, SCRIT self-improves by training on synthetic data, generated by a contrastive-based self-critic that uses reference solutions for step-by-step critique, and a self-validation mechanism that ensures critique quality through correction outcomes. Implemented with Qwen2.5-72B-Instruct, one of the most powerful LLMs, SCRIT achieves up to a 10.3\% improvement on critique-correction and error identification benchmarks. Our analysis reveals that SCRIT's performance scales positively with data and model size, outperforms alternative approaches, and benefits critically from its self-validation component.

[Arxiv](https://arxiv.org/abs/2501.05727)