# UAV-VLA: 大规模空中任务生成的视觉-语言-动作系统

发布时间：2025年01月09日

`Agent

理由：该论文描述了一个结合了视觉语言模型（VLM）和GPT的系统，用于生成飞行路径和行动计划。这种系统可以被视为一个智能体（Agent），因为它能够根据输入（如文本请求和卫星图像）自主生成决策和行动计划。因此，该论文属于Agent分类。` `无人机` `卫星图像`

> UAV-VLA: Vision-Language-Action System for Large Scale Aerial Mission Generation

# 摘要

> UAV-VLA（视觉-语言-动作）系统是一个促进与空中机器人通信的工具。它结合了卫星图像处理、视觉语言模型（VLM）和GPT的强大功能，用户只需通过简单的文本请求即可生成通用的飞行路径和行动计划。该系统利用卫星图像提供的丰富上下文信息，提升了决策和任务规划能力。VLM的视觉分析与GPT的自然语言处理相结合，为用户提供路径和动作集，使空中操作更加高效便捷。新方法在K-最近邻（KNN）算法中显示，创建轨迹的长度差异为22%，且在地图上找到感兴趣对象的平均误差为34.22米（欧几里得距离）。

> The UAV-VLA (Visual-Language-Action) system is a tool designed to facilitate communication with aerial robots. By integrating satellite imagery processing with the Visual Language Model (VLM) and the powerful capabilities of GPT, UAV-VLA enables users to generate general flight paths-and-action plans through simple text requests. This system leverages the rich contextual information provided by satellite images, allowing for enhanced decision-making and mission planning. The combination of visual analysis by VLM and natural language processing by GPT can provide the user with the path-and-action set, making aerial operations more efficient and accessible. The newly developed method showed the difference in the length of the created trajectory in 22% and the mean error in finding the objects of interest on a map in 34.22 m by Euclidean distance in the K-Nearest Neighbors (KNN) approach.

[Arxiv](https://arxiv.org/abs/2501.05014)