# “发生了什么”——一个以人为本的多模态解释器，解读自动驾驶汽车的行为

发布时间：2025年01月09日

`LLM应用

理由：这篇论文主要讨论了如何利用微调的大型语言模型（LLM）进行语音交互，以提升自动驾驶汽车的乘客信任度。虽然论文也涉及了多模态解释器的设计，但其核心应用场景和解决方案依赖于LLM的技术，因此应归类为LLM应用。` `自动驾驶` `人机交互`

> "What's Happening"- A Human-centered Multimodal Interpreter Explaining the Actions of Autonomous Vehicles

# 摘要

> 公众对自动驾驶汽车的信任危机日益加剧。研究表明，向乘客解释车辆行为是提升自动驾驶系统信任的关键。解释器通过增强透明度和降低感知风险来建立信任。然而，现有解决方案往往忽视了以人为本的多模态解释集成。本文提出了一种创新的以人为本多模态解释器（HMI）系统，该系统根据人类偏好提供视觉、文本和听觉反馈。HMI系统集成了鸟瞰图（BEV）、地图和文本显示的视觉界面，并采用微调的大型语言模型（LLM）进行语音交互。我们的用户研究覆盖了多样化参与者，结果显示，HMI系统显著提升了乘客对自动驾驶汽车的信任，平均信任度提升超过8%，在普通环境中的信任度甚至提升了30%。这些发现凸显了HMI系统通过提供清晰、实时且情境化的车辆行为解释，有望大幅提升自动驾驶汽车的接受度和可靠性。

> Public distrust of self-driving cars is growing. Studies emphasize the need for interpreting the behavior of these vehicles to passengers to promote trust in autonomous systems. Interpreters can enhance trust by improving transparency and reducing perceived risk. However, current solutions often lack a human-centric approach to integrating multimodal interpretations. This paper introduces a novel Human-centered Multimodal Interpreter (HMI) system that leverages human preferences to provide visual, textual, and auditory feedback. The system combines a visual interface with Bird's Eye View (BEV), map, and text display, along with voice interaction using a fine-tuned large language model (LLM). Our user study, involving diverse participants, demonstrated that the HMI system significantly boosts passenger trust in AVs, increasing average trust levels by over 8%, with trust in ordinary environments rising by up to 30%. These results underscore the potential of the HMI system to improve the acceptance and reliability of autonomous vehicles by providing clear, real-time, and context-sensitive explanations of vehicle actions.

[Arxiv](https://arxiv.org/abs/2501.05322)