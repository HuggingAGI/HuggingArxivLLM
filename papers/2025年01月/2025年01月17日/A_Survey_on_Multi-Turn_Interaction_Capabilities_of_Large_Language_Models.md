# # 大型语言模型多轮交互能力综述

发布时间：2025年01月17日

`Agent

理由：这篇论文主要讨论了大型语言模型（LLMs）在多轮交互中的应用，特别是在对话系统、智能体交互等场景中的能力。论文关注的是LLMs如何在与用户或环境的动态交互中保持上下文并生成连贯的响应，这与智能体（Agent）的研究和应用密切相关。因此，这篇论文更适合归类为Agent。` `对话系统` `智能交互`

> A Survey on Multi-Turn Interaction Capabilities of Large Language Models

# 摘要

> # 摘要
多轮交互在对话系统研究中指的是系统在多个对话轮次中保持上下文的能力，从而生成连贯且与上下文相关的响应。近年来，大型语言模型（LLMs）的突破性进展极大地拓展了多轮交互的应用范围，使其不再局限于聊天机器人，而是能够与用户或环境进行更动态的智能体交互。本文聚焦于LLMs的多轮交互能力，这一能力在对话搜索与推荐、咨询服务以及互动辅导等众多下游应用中至关重要。我们深入探讨了四个关键方面：（1）支撑有效多轮交互的核心模型能力，（2）当前多轮交互的评估方法，（3）提升多轮交互的通用算法，以及（4）该领域未来的研究方向。

> Multi-turn interaction in the dialogue system research refers to a system's ability to maintain context across multiple dialogue turns, enabling it to generate coherent and contextually relevant responses. Recent advancements in large language models (LLMs) have significantly expanded the scope of multi-turn interaction, moving beyond chatbots to enable more dynamic agentic interactions with users or environments. In this paper, we provide a focused review of the multi-turn capabilities of LLMs, which are critical for a wide range of downstream applications, including conversational search and recommendation, consultation services, and interactive tutoring. This survey explores four key aspects: (1) the core model capabilities that contribute to effective multi-turn interaction, (2) how multi-turn interaction is evaluated in current practice, (3) the general algorithms used to enhance multi-turn interaction, and (4) potential future directions for research in this field.

[Arxiv](https://arxiv.org/abs/2501.09959)