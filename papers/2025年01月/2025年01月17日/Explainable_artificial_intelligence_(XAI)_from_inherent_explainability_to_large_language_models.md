# 可解释的人工智能（XAI）：从内在可解释性到大型语言模型

发布时间：2025年01月17日

`LLM应用

理由：这篇论文主要讨论了可解释的人工智能（XAI）技术，特别是如何利用大型语言模型（LLM）和视觉语言模型（VLM）来增强其他机器学习模型的可解释性。虽然论文涉及了LLM的理论和应用，但其核心关注点是如何将LLM应用于提升模型的可解释性，因此更适合归类为“LLM应用”。` `人工智能` `可解释性`

> Explainable artificial intelligence (XAI): from inherent explainability to large language models

# 摘要

> # 摘要
近年来，人工智能（AI）取得了显著成就。然而，这些系统的决策逻辑往往缺乏透明度，导致利益相关者难以理解、解释或解释其行为。这种局限性削弱了对机器学习系统的信任，特别是在医疗保健和自动驾驶等关键领域，阻碍了其实际应用。可解释的人工智能（XAI）技术通过增强机器学习模型的可解释性，使用户能够理解决策依据，从而避免不良行为。本文全面回顾了XAI方法的进展，从本质上可解释的模型到实现各种黑箱模型（包括大型语言模型（LLM））可解释性的现代技术。我们还探讨了利用LLM和视觉语言模型（VLM）框架来自动化或提升其他机器学习模型可解释性的方法。LLM和VLM作为可解释性工具，能够提供高级、语义丰富的模型决策和行为解释。本文详细分析了当前最先进方法的科学原理、优势与不足，并指出了改进方向。在适当情况下，我们还展示了不同方法的定性和定量比较结果。最后，我们讨论了XAI面临的主要挑战及未来研究的方向。

> Artificial Intelligence (AI) has continued to achieve tremendous success in recent times. However, the decision logic of these frameworks is often not transparent, making it difficult for stakeholders to understand, interpret or explain their behavior. This limitation hinders trust in machine learning systems and causes a general reluctance towards their adoption in practical applications, particularly in mission-critical domains like healthcare and autonomous driving. Explainable AI (XAI) techniques facilitate the explainability or interpretability of machine learning models, enabling users to discern the basis of the decision and possibly avert undesirable behavior. This comprehensive survey details the advancements of explainable AI methods, from inherently interpretable models to modern approaches for achieving interpretability of various black box models, including large language models (LLMs). Additionally, we review explainable AI techniques that leverage LLM and vision-language model (VLM) frameworks to automate or improve the explainability of other machine learning models. The use of LLM and VLM as interpretability methods particularly enables high-level, semantically meaningful explanations of model decisions and behavior. Throughout the paper, we highlight the scientific principles, strengths and weaknesses of state-of-the-art methods and outline different areas of improvement. Where appropriate, we also present qualitative and quantitative comparison results of various methods to show how they compare. Finally, we discuss the key challenges of XAI and directions for future research.

[Arxiv](https://arxiv.org/abs/2501.09967)