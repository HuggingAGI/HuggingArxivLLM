# 基于内部表示的大型语言模型生成代码正确性评估

发布时间：2025年01月22日

`LLM应用

**理由**：这篇论文主要讨论了如何利用大型语言模型（LLMs）的内部状态信息来评估生成代码的正确性，提出了一种名为OPENIA的白箱框架。该研究聚焦于LLMs在代码生成过程中的应用，并通过实验验证了其方法的有效性。因此，这篇论文属于LLM应用类别。` `软件开发` `人工智能`

> Correctness Assessment of Code Generated by Large Language Models Using Internal Representations

# 摘要

> 确保大型语言模型（LLMs）生成代码的正确性是AI驱动软件开发中的一大挑战。现有方法多依赖黑箱评估，生成后才判断正确性，未能充分利用LLMs在代码生成过程中的内部状态信息。本文提出OPENIA，一种创新的白箱框架，利用这些内部表示来评估LLM生成代码的正确性。OPENIA系统分析了DeepSeek-Coder、CodeLlama和MagicCoder等代表性开源LLMs的中间状态，覆盖多种代码生成基准。实证分析显示，这些内部表示蕴含潜在信息，与代码正确性高度相关。基于此，OPENIA采用白箱方法预测代码正确性，在适应性和鲁棒性上显著优于传统分类方法和零-shot方法。实验表明，OPENIA在独立代码生成中准确率、精确率、召回率和F1分数均优于基线模型，最高提升2倍，在特定仓库场景中提升46%。通过挖掘过程中信号，OPENIA为LLM辅助代码生成提供了更主动高效的质量保证机制。

> Ensuring the correctness of code generated by Large Language Models (LLMs) presents a significant challenge in AI-driven software development. Existing approaches predominantly rely on black-box (closed-box) approaches that evaluate correctness post-generation, failing to utilize the rich insights embedded in the LLMs' internal states during code generation. In this paper, we introduce OPENIA, a novel white-box (open-box) framework that leverages these internal representations to assess the correctness of LLM-generated code. OPENIA systematically analyzes the intermediate states of representative open-source LLMs specialized for code, including DeepSeek-Coder, CodeLlama, and MagicCoder, across diverse code generation benchmarks. Our empirical analysis reveals that these internal representations encode latent information, which strongly correlates with the correctness of the generated code. Building on these insights, OPENIA uses a white-box/open-box approach to make informed predictions about code correctness, offering significant advantages in adaptability and robustness over traditional classification-based methods and zero-shot approaches. Experimental results demonstrate that OPENIA consistently outperforms baseline models, achieving higher accuracy, precision, recall, and F1-Scores with up to a 2X improvement in standalone code generation and a 46% enhancement in repository-specific scenarios. By unlocking the potential of in-process signals, OPENIA paves the way for more proactive and efficient quality assurance mechanisms in LLM-assisted code generation.

[Arxiv](https://arxiv.org/abs/2501.12934)