# 生成式AI在网络安全教育中的潜在滥用：英国学位课程案例研究

发布时间：2025年01月22日

`LLM应用

**理由**：这篇论文主要探讨了生成式AI（如ChatGPT、Google Gemini等LLMs）在高等教育中的滥用风险，并提出了相应的应对策略。虽然涉及到了LLM的应用场景（如学术评估），但核心关注点是如何应对LLM带来的挑战，而不是LLM本身的理论研究或技术实现。因此，将其归类为“LLM应用”更为合适。` `网络安全`

> Generative AI Misuse Potential in Cyber Security Education: A Case Study of a UK Degree Program

# 摘要

> # 摘要
生成式AI（如ChatGPT、Google Gemini等LLMs）的迅猛发展，给高等教育的学术诚信带来了巨大挑战。本文以英国罗素集团大学的一门硕士网络安全课程为例，探讨了LLM滥用的风险。通过定量评估框架，我们发现该课程在独立项目和报告评估中尤为脆弱。模块化教学和国际学生比例高等因素加剧了这一风险。为此，我们建议采用抗LLM的评估方式、引入检测工具，并强调培养伦理学习环境的重要性，以维护学术标准并帮助学生应对现实网络安全的复杂性。

> Recent advances in generative artificial intelligence (AI), such as ChatGPT, Google Gemini, and other large language models (LLMs), pose significant challenges to upholding academic integrity in higher education. This paper investigates the susceptibility of a Master's-level cyber security degree program at a UK Russell Group university, accredited by a leading national body, to LLM misuse. Through the application and extension of a quantitative assessment framework, we identify a high exposure to misuse, particularly in independent project- and report-based assessments. Contributing factors, including block teaching and a predominantly international cohort, are highlighted as potential amplifiers of these vulnerabilities. To address these challenges, we discuss the adoption of LLM-resistant assessments, detection tools, and the importance of fostering an ethical learning environment. These approaches aim to uphold academic standards while preparing students for the complexities of real-world cyber security.

[Arxiv](https://arxiv.org/abs/2501.12883)