# SteLLA: 基于RAG和LLMs的结构化评分系统

发布时间：2025年01月15日

`LLM应用

理由：这篇论文主要讨论了如何利用大型语言模型（LLMs）和检索增强生成（RAG）方法来改进自动短答案评分（ASAG）系统。论文提出了一个名为SteLLA的系统，该系统结合了LLMs和RAG技术，专门为ASAG任务赋能。论文还通过实验验证了该系统的有效性，并分析了GPT4在评分任务中的表现。因此，这篇论文属于LLM应用类别，因为它探讨了如何将LLMs应用于具体的教育评估任务中。` `自动评分`

> SteLLA: A Structured Grading System Using LLMs with RAG

# 摘要

> 大型语言模型（LLMs）在众多应用中展现了强大的通用能力，但在自动短答案评分（ASAG）等特定任务中，如何使其成为可靠工具仍具挑战。我们提出了SteLLA（基于LLMs和RAG的结构化评分系统），该系统通过a）检索增强生成（RAG）方法，从教师提供的参考答案和评分标准中提取高度相关的外部知识，专门为ASAG任务赋能LLMs；b）LLM对学生答案进行结构化和问答式评估，提供分析性评分和反馈。我们从大学生物学课程中收集了一个真实的学生考试答案数据集。实验表明，该系统与人类评分者达成显著一致，并能提供问题中所有知识点的细分评分和反馈。对GPT4生成的反馈进行定性和错误分析发现，GPT4擅长捕捉事实，但在评分任务中可能过度推断文本含义，这为LLMs在ASAG系统中的使用提供了重要见解。

> Large Language Models (LLMs) have shown strong general capabilities in many applications. However, how to make them reliable tools for some specific tasks such as automated short answer grading (ASAG) remains a challenge. We present SteLLA (Structured Grading System Using LLMs with RAG) in which a) Retrieval Augmented Generation (RAG) approach is used to empower LLMs specifically on the ASAG task by extracting structured information from the highly relevant and reliable external knowledge based on the instructor-provided reference answer and rubric, b) an LLM performs a structured and question-answering-based evaluation of student answers to provide analytical grades and feedback. A real-world dataset that contains students' answers in an exam was collected from a college-level Biology course. Experiments show that our proposed system can achieve substantial agreement with the human grader while providing break-down grades and feedback on all the knowledge points examined in the problem. A qualitative and error analysis of the feedback generated by GPT4 shows that GPT4 is good at capturing facts while may be prone to inferring too much implication from the given text in the grading task which provides insights into the usage of LLMs in the ASAG system.

[Arxiv](https://arxiv.org/abs/2501.09092)