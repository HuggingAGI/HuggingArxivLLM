# 最优利用解耦大型语言模型的探索

发布时间：2025年01月15日

`LLM理论` `人工智能` `机器学习`

> Disentangling Exploration of Large Language Models by Optimal Exploitation

# 摘要

> 探索是自我提升和开放式问题解决的核心能力。然而，大型语言模型能否有效探索状态空间仍是一个未知数。现有研究多聚焦于探索与利用的权衡，通常通过多臂赌博机问题来评估。与此不同，本研究将探索作为唯一目标，要求模型提供能提升未来回报的信息。我们提出通过测量已探索状态的最优回报，将缺失回报分解为探索和利用两部分。实验表明，大多数模型难以充分探索状态空间，且弱探索效果不佳。模型规模与探索性能呈正相关，大模型表现更优。此外，我们的分解方法揭示了提示工程中指令驱动的行为差异，为提升模型在探索任务中的表现提供了有力工具。

> Exploration is a crucial skill for self-improvement and open-ended problem-solving. However, it remains uncertain whether large language models can effectively explore the state-space. Existing evaluations predominantly focus on the trade-off between exploration and exploitation, often assessed in multi-armed bandit problems. In contrast, this work isolates exploration as the sole objective, tasking the agent with delivering information that enhances future returns. For the evaluation, we propose to decompose missing rewards into exploration and exploitation components by measuring the optimal achievable return for the states already explored. Our experiments with various LLMs reveal that most models struggle to sufficiently explore the state-space and that weak exploration is insufficient. We observe a positive correlation between model size and exploration performance, with larger models demonstrating superior capabilities. Furthermore, we show that our decomposition provides insights into differences in behaviors driven by agent instructions during prompt engineering, offering a valuable tool for refining LLM performance in exploratory tasks.

[Arxiv](https://arxiv.org/abs/2501.08925)