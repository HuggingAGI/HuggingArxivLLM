# 基于LLM的推荐系统：不确定性量化和分解

发布时间：2025年01月29日

`LLM应用

理由：这篇论文主要讨论了在推荐系统中使用大型语言模型（LLMs）时，如何评估和提升其推荐结果的可靠性。论文提出了一个框架来估计预测不确定性，并进一步分解为推荐不确定性和提示不确定性，以分析不确定性的来源。此外，论文还提出了不确定性感知提示来降低预测不确定性并提升推荐效果。这些内容都属于LLM在实际应用中的改进和优化，因此分类为“LLM应用”。` `推荐系统` `人工智能`

> Uncertainty Quantification and Decomposition for LLM-based Recommendation

# 摘要

> 尽管LLMs在推荐系统中广泛应用，但其推荐结果常伴随不确定性。为确保LLMs推荐的可信度，我们强调评估其推荐可靠性的重要性。为此，我们提出了一个新颖的框架，用于估计预测不确定性，从而定量衡量LLMs推荐的可靠性。我们进一步将预测不确定性分解为推荐不确定性和提示不确定性，以深入分析不确定性的主要来源。通过大量实验，我们（1）验证了预测不确定性能有效指示LLMs推荐的可靠性，（2）通过分解的不确定性度量探究了不确定性的来源，并（3）提出了不确定性感知提示，以降低预测不确定性并提升推荐效果。源代码和模型权重已开源：https://github.com/WonbinKweon/UNC_LLM_REC_WWW2025。

> Despite the widespread adoption of large language models (LLMs) for recommendation, we demonstrate that LLMs often exhibit uncertainty in their recommendations. To ensure the trustworthy use of LLMs in generating recommendations, we emphasize the importance of assessing the reliability of recommendations generated by LLMs. We start by introducing a novel framework for estimating the predictive uncertainty to quantitatively measure the reliability of LLM-based recommendations. We further propose to decompose the predictive uncertainty into recommendation uncertainty and prompt uncertainty, enabling in-depth analyses of the primary source of uncertainty. Through extensive experiments, we (1) demonstrate predictive uncertainty effectively indicates the reliability of LLM-based recommendations, (2) investigate the origins of uncertainty with decomposed uncertainty measures, and (3) propose uncertainty-aware prompting for a lower predictive uncertainty and enhanced recommendation. Our source code and model weights are available at https://github.com/WonbinKweon/UNC_LLM_REC_WWW2025

[Arxiv](https://arxiv.org/abs/2501.17630)