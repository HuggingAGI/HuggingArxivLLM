# # 连接可视化与优化：多模态大语言模型在图结构组合优化中的应用

发布时间：2025年01月21日

`LLM应用

理由：该论文主要探讨了如何利用多模态大型语言模型（MLLMs）来解决图结构组合问题。虽然涉及到了图结构数据的处理，但其核心在于应用MLLMs来提升机器理解和分析图结构数据的能力，并结合简单搜索技术开发高效框架。因此，该论文应归类为LLM应用。` `图结构分析` `组合优化`

> Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization

# 摘要

> # 摘要
图结构组合问题因其非线性和复杂性，传统方法往往难以应对或成本高昂。然而，人类通过视觉表示能更自然地解决这些问题，利用我们天生的空间推理能力。本研究提出将图转换为图像，以准确保留其高阶结构特征，从而革新图结构组合任务的表示方法。这种方法使机器能够模仿人类处理复杂组合挑战的方式。通过将多模态大型语言模型（MLLMs）的创新范式与简单搜索技术结合，我们旨在开发一种新颖且高效的框架来解决此类问题。我们对MLLMs的研究涵盖了从影响最大化等组合问题到网络拆解中的顺序决策，以及六个基本的图相关问题。研究结果表明，MLLMs展现出卓越的空间智能和独特的处理能力，显著提升了机器理解和分析图结构数据的潜力，其深度和直觉类似于人类认知。这些结果还表明，将MLLMs与简单优化策略结合，可以形成一种新颖且高效的方法，用于应对图结构组合挑战，而无需复杂的推导、计算密集型的训练和微调。

> Graph-structured combinatorial challenges are inherently difficult due to their nonlinear and intricate nature, often rendering traditional computational methods ineffective or expensive. However, these challenges can be more naturally tackled by humans through visual representations that harness our innate ability for spatial reasoning. In this study, we propose transforming graphs into images to preserve their higher-order structural features accurately, revolutionizing the representation used in solving graph-structured combinatorial tasks. This approach allows machines to emulate human-like processing in addressing complex combinatorial challenges. By combining the innovative paradigm powered by multimodal large language models (MLLMs) with simple search techniques, we aim to develop a novel and effective framework for tackling such problems. Our investigation into MLLMs spanned a variety of graph-based tasks, from combinatorial problems like influence maximization to sequential decision-making in network dismantling, as well as addressing six fundamental graph-related issues. Our findings demonstrate that MLLMs exhibit exceptional spatial intelligence and a distinctive capability for handling these problems, significantly advancing the potential for machines to comprehend and analyze graph-structured data with a depth and intuition akin to human cognition. These results also imply that integrating MLLMs with simple optimization strategies could form a novel and efficient approach for navigating graph-structured combinatorial challenges without complex derivations, computationally demanding training and fine-tuning.

[Arxiv](https://arxiv.org/abs/2501.11968)