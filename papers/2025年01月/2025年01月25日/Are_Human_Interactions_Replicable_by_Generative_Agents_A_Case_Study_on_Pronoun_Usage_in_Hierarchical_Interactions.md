# 生成式智能体能否复制人类互动？——以层级互动中的代词使用为例

发布时间：2025年01月25日

`Agent

理由：这篇论文主要探讨了大型语言模型（LLMs）在代理（Agent）之间的互动中的应用，特别是研究了LLM代理在模拟人类互动时的表现。论文关注的是LLM代理在模拟社会互动中的行为模式，尤其是代词使用的差异，这属于Agent研究的范畴。因此，将其分类为Agent是合适的。` `社会模拟` `语言模型`

> Are Human Interactions Replicable by Generative Agents? A Case Study on Pronoun Usage in Hierarchical Interactions

# 摘要

> 随着大型语言模型（LLMs）能力的不断提升，研究人员越来越多地将其应用于社会模拟。本文探讨了LLM代理之间的互动是否与人类相似，特别是领导者和非领导者在代词使用上的差异。我们研究了模拟是否能让LLMs在互动中展现出类似人类的代词使用模式。评估结果显示，基于LLM的模拟与人类代词使用存在显著差异，基于提示或专门设计的代理未能展现出类似人类的代词使用模式。此外，即使LLMs理解人类的代词使用模式，它们在实际互动中也难以展现这些模式。本研究揭示了基于LLM代理的社会模拟的局限性，提醒从业者在决策过程中谨慎使用此类模拟。

> As Large Language Models (LLMs) advance in their capabilities, researchers have increasingly employed them for social simulation. In this paper, we investigate whether interactions among LLM agents resemble those of humans. Specifically, we focus on the pronoun usage difference between leaders and non-leaders, examining whether the simulation would lead to human-like pronoun usage patterns during the LLMs' interactions. Our evaluation reveals the significant discrepancies between LLM-based simulations and human pronoun usage, with prompt-based or specialized agents failing to demonstrate human-like pronoun usage patterns. In addition, we reveal that even if LLMs understand the human pronoun usage patterns, they fail to demonstrate them in the actual interaction process. Our study highlights the limitations of social simulations based on LLM agents, urging caution in using such social simulation in practitioners' decision-making process.

[Arxiv](https://arxiv.org/abs/2501.15283)