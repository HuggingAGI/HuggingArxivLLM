# 大型语言模型的表示

发布时间：2025年01月01日

`LLM理论

理由：这篇论文主要探讨了大型语言模型（LLMs）的行为是否由基于表征的信息处理驱动，并提出了相关的理论框架。这涉及到LLMs的认知能力和工作原理，属于对LLMs的理论性探讨，因此应归类为LLM理论。` `人工智能` `认知科学`

> Representation in large language models

# 摘要

> 最近大型语言模型（LLMs）在各种任务上的卓越表现引发了大量科学和哲学理论的探讨，试图解释其工作原理。然而，由于在基本理论问题上的分歧，LLM的乐观派和悲观派陷入了僵局，双方对这些系统的运作方式持有截然不同的观点。要打破僵局，必须在基本问题上达成共识。本文旨在探讨其中一个关键问题：LLM的行为是否部分由基于表征的信息处理驱动（类似于生物认知），还是完全依赖于记忆和随机查表过程？这一问题关乎LLMs所采用的算法类型，其答案将直接影响我们如何看待这些系统是否具备信念、意图、概念、知识和理解等高级认知能力。本文主张LLM的行为部分由基于表征的信息处理驱动，并提出并辩护了一系列实用技术，用于研究这些表征并构建相关解释。这一理论框架为未来关于语言模型及其继任者的研究奠定了基础。

> The extraordinary success of recent Large Language Models (LLMs) on a diverse array of tasks has led to an explosion of scientific and philosophical theorizing aimed at explaining how they do what they do. Unfortunately, disagreement over fundamental theoretical issues has led to stalemate, with entrenched camps of LLM optimists and pessimists often committed to very different views of how these systems work. Overcoming stalemate requires agreement on fundamental questions, and the goal of this paper is to address one such question, namely: is LLM behavior driven partly by representation-based information processing of the sort implicated in biological cognition, or is it driven entirely by processes of memorization and stochastic table look-up? This is a question about what kind of algorithm LLMs implement, and the answer carries serious implications for higher level questions about whether these systems have beliefs, intentions, concepts, knowledge, and understanding. I argue that LLM behavior is partially driven by representation-based information processing, and then I describe and defend a series of practical techniques for investigating these representations and developing explanations on their basis. The resulting account provides a groundwork for future theorizing about language models and their successors.

[Arxiv](https://arxiv.org/abs/2501.00885)