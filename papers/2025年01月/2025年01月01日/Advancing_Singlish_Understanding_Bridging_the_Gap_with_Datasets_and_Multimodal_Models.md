# 提升新加坡式英语理解：利用数据集和多模态模型填补鸿沟

发布时间：2025年01月01日

`LLM应用

理由：该论文主要介绍了SingAudioLLM，一个多任务多模态模型，利用多模态大型语言模型（LLM）处理多种任务，如自动语音识别、口语问答、口语对话摘要等。这表明该研究是将大型语言模型应用于特定领域（Singlish语境）的实际问题解决，因此属于LLM应用。` `语言学` `语音识别`

> Advancing Singlish Understanding: Bridging the Gap with Datasets and Multimodal Models

# 摘要

> # 摘要
Singlish，一种源于英语的克里奥尔语，是多语言和多文化背景下语言研究的重点。然而，其口语形式的研究仍显不足，限制了对其语言结构和应用的深入理解。为此，我们标准化并注释了最大的口语Singlish语料库，推出了多任务国家语音语料库（MNSC）。该数据集支持自动语音识别（ASR）、口语问答（SQA）、口语对话摘要（SDS）和副语言问答（PQA）等多种任务。我们发布了标准化分割和人工验证的测试集，以推动进一步研究。此外，我们提出了SingAudioLLM，一个多任务多模态模型，利用多模态大型语言模型同时处理这些任务。实验表明，该模型在Singlish语境下表现出色，性能领先于其他AudioLLMs和级联解决方案10-30%。

> Singlish, a Creole language rooted in English, is a key focus in linguistic research within multilingual and multicultural contexts. However, its spoken form remains underexplored, limiting insights into its linguistic structure and applications. To address this gap, we standardize and annotate the largest spoken Singlish corpus, introducing the Multitask National Speech Corpus (MNSC). These datasets support diverse tasks, including Automatic Speech Recognition (ASR), Spoken Question Answering (SQA), Spoken Dialogue Summarization (SDS), and Paralinguistic Question Answering (PQA). We release standardized splits and a human-verified test set to facilitate further research. Additionally, we propose SingAudioLLM, a multi-task multimodal model leveraging multimodal large language models to handle these tasks concurrently. Experiments reveal our models adaptability to Singlish context, achieving state-of-the-art performance and outperforming prior models by 10-30% in comparison with other AudioLLMs and cascaded solutions.

[Arxiv](https://arxiv.org/abs/2501.01034)