# AI 助力多样性与包容性

发布时间：2025年01月16日

`LLM应用

**解释**：这篇论文主要讨论了大型语言模型（LLMs）在多样性与包容性方面的应用，包括如何使LLMs更加透明、包容，以及如何识别和减少社会偏见。虽然论文涉及了LLMs的理论背景，但其核心关注点在于LLMs在实际应用中的表现和改进，特别是在社会公平和包容性方面的应用。因此，将其分类为“LLM应用”更为合适。` `人工智能` `社会公平`

> AI in Support of Diversity and Inclusion

# 摘要

> 在本文中，我们探讨了人工智能如何助力多样性与包容性，并展示了相关研究项目。首先，我们分析了使大型语言模型（LLMs）更加透明、包容且能识别社会偏见的挑战与进展。尽管ChatGPT等LLMs表现出色，但在理解多元文化背景和进行深度对话方面仍有不足。语言处理中的偏见，尤其是机器翻译中的偏见，可能加剧不平等。解决这些问题需要多学科协作，确保AI推动多样性、公平与包容。我们还强调了AI在识别媒体偏见内容中的作用，这对提升代表性至关重要。通过检测社会群体的不平等描绘，AI有助于打破刻板印象，推动更具包容性的技术发展。透明的AI算法，能够清晰解释决策过程，是建立信任、减少偏见的关键。此外，AI系统需要多样化的训练数据。例如，儿童成长监测器项目通过广泛数据应用，有效应对营养不良和贫困等现实问题。我们还展示了一个项目，利用AI监控搜索引擎在传播LGBTQ+社区虚假信息中的作用。此外，SignON项目展示了技术如何弥合听障与非听障人群的沟通鸿沟，强调了合作与信任在开发包容性AI中的重要性。总之，本文倡导构建不仅高效且具社会责任感的人工智能系统，促进人机之间的公平与包容互动。

> In this paper, we elaborate on how AI can support diversity and inclusion and exemplify research projects conducted in that direction. We start by looking at the challenges and progress in making large language models (LLMs) more transparent, inclusive, and aware of social biases. Even though LLMs like ChatGPT have impressive abilities, they struggle to understand different cultural contexts and engage in meaningful, human like conversations. A key issue is that biases in language processing, especially in machine translation, can reinforce inequality. Tackling these biases requires a multidisciplinary approach to ensure AI promotes diversity, fairness, and inclusion. We also highlight AI's role in identifying biased content in media, which is important for improving representation. By detecting unequal portrayals of social groups, AI can help challenge stereotypes and create more inclusive technologies. Transparent AI algorithms, which clearly explain their decisions, are essential for building trust and reducing bias in AI systems. We also stress AI systems need diverse and inclusive training data. Projects like the Child Growth Monitor show how using a wide range of data can help address real world problems like malnutrition and poverty. We present a project that demonstrates how AI can be applied to monitor the role of search engines in spreading disinformation about the LGBTQ+ community. Moreover, we discuss the SignON project as an example of how technology can bridge communication gaps between hearing and deaf people, emphasizing the importance of collaboration and mutual trust in developing inclusive AI. Overall, with this paper, we advocate for AI systems that are not only effective but also socially responsible, promoting fair and inclusive interactions between humans and machines.

[Arxiv](https://arxiv.org/abs/2501.09534)