# TinyLLaVA-Video: 小规模大型多模态模型的视频理解框架

发布时间：2025年01月26日

`LLM应用` `视频理解` `多模态学习`

> TinyLLaVA-Video: A Simple Framework of Small-scale Large Multimodal Models for Video Understanding

# 摘要

> 我们推出了TinyLLaVA-Video，一个参数不超过4B的视频理解模型，它以简洁的方式处理视频序列，无需复杂架构，支持fps采样和均匀帧采样。该模型具备模块化和可扩展性，能在有限计算资源下进行训练和推理，并允许用户按需替换组件。通过实验验证，最佳模型在多个视频理解基准测试中表现优异，与某些7B模型相当。代码和训练配方完全开源，所有组件和训练数据均公开。我们希望这项工作能为探索小规模多模态视频理解模型的从业者提供基准。详情请访问url{https://github.com/ZhangXJ199/TinyLLaVA-Video}。

> We present the TinyLLaVA-Video, a video understanding model with parameters not exceeding 4B that processes video sequences in a simple manner, without the need for complex architectures, supporting both fps sampling and uniform frame sampling. Our model is characterized by modularity and scalability, allowing training and inference with limited computational resources and enabling users to replace components based on their needs. We validate the effectiveness of this framework through experiments, the best model achieving performance comparable to certain existing 7B models on multiple video understanding benchmarks. The code and training recipes are fully open source, with all components and training data publicly available. We hope this work can serve as a baseline for practitioners exploring small-scale multimodal models for video understanding. It is available at \url{https://github.com/ZhangXJ199/TinyLLaVA-Video}.

[Arxiv](https://arxiv.org/abs/2501.15513)