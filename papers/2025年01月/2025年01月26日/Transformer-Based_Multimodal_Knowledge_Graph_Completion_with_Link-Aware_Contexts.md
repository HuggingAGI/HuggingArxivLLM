# 基于Transformer的多模态知识图谱补全：链接感知上下文

发布时间：2025年01月26日

`LLM应用

**理由**：这篇论文主要讨论了如何将大型视觉语言模型（VLMs）与基于Transformer的知识图谱嵌入模型结合，用于多模态知识图谱补全（MMKGC）。虽然涉及了多模态信息和知识图谱，但其核心是利用预训练的VLMs生成跨模态上下文，并将其应用于知识图谱补全任务。这属于大型语言模型（LLM）在实际任务中的应用，因此分类为LLM应用。` `知识图谱` `多模态学习`

> Transformer-Based Multimodal Knowledge Graph Completion with Link-Aware Contexts

# 摘要

> # 多模态知识图谱补全（MMKGC）旨在通过结合多模态信息和结构数据，预测多模态知识图谱（MMKG）中的缺失链接。现有的MMKGC方法大多基于传统的知识图谱嵌入（KGE）模型，这些模型通常需要为每个实体生成嵌入，导致模型规模庞大且多模态信息整合效率低下，尤其是在处理现实世界图谱时。与此同时，基于Transformer的模型在知识图谱补全（KGC）中表现出色，但其对单模态知识的依赖限制了跨模态信息的利用。最近，大型视觉语言模型（VLMs）在跨模态任务中展现了潜力，但高昂的训练成本成为其瓶颈。在本研究中，我们提出了一种创新方法，将基于Transformer的KGE模型与预训练VLMs生成的跨模态上下文相结合，从而扩展了其在MMKGC中的应用。具体而言，我们利用预训练的VLM将实体及其邻居的视觉信息转化为文本序列，并将KGC任务框架化为序列到序列问题，通过生成的跨模态上下文对模型进行微调。这种简洁高效的方法显著缩小了模型规模，同时在多个大规模数据集上实现了优异的性能，且仅需少量超参数调整。

> Multimodal knowledge graph completion (MMKGC) aims to predict missing links in multimodal knowledge graphs (MMKGs) by leveraging information from various modalities alongside structural data. Existing MMKGC approaches primarily extend traditional knowledge graph embedding (KGE) models, which often require creating an embedding for every entity. This results in large model sizes and inefficiencies in integrating multimodal information, particularly for real-world graphs. Meanwhile, Transformer-based models have demonstrated competitive performance in knowledge graph completion (KGC). However, their focus on single-modal knowledge limits their capacity to utilize cross-modal information. Recently, Large vision-language models (VLMs) have shown potential in cross-modal tasks but are constrained by the high cost of training. In this work, we propose a novel approach that integrates Transformer-based KGE models with cross-modal context generated by pre-trained VLMs, thereby extending their applicability to MMKGC. Specifically, we employ a pre-trained VLM to transform relevant visual information from entities and their neighbors into textual sequences. We then frame KGC as a sequence-to-sequence task, fine-tuning the model with the generated cross-modal context. This simple yet effective method significantly reduces model size compared to traditional KGE approaches while achieving competitive performance across multiple large-scale datasets with minimal hyperparameter tuning.

[Arxiv](https://arxiv.org/abs/2501.15688)