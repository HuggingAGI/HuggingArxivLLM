# 人类与LLM生成的代码对比：胜负未定！

发布时间：2025年01月28日

`LLM应用

理由：这篇论文主要研究了大型语言模型（LLMs）在软件开发中的应用，特别是GPT-4在生成Python代码方面的表现。论文通过对比人类程序员和GPT-4生成的代码，评估了LLMs在代码质量、编码标准、安全性、复杂性和功能正确性等方面的表现。虽然论文涉及LLMs的理论基础，但其核心关注点是LLMs在实际软件开发中的应用效果，因此更适合归类为“LLM应用”。` `软件开发` `人工智能`

> Comparing Human and LLM Generated Code: The Jury is Still Out!

# 摘要

> AI支持的软件开发前景广阔，但对其实际效用的研究评估却相对有限，尤其是在与人类编码输出对比时。为此，我们通过一个包含72个软件工程任务的基准数据集，对比了大型语言模型（LLMs）与人类程序员在生成Python代码上的表现。GPT-4作为代表性LLM，其生成的代码与人类代码在质量、编码标准、安全性、复杂性和功能正确性等方面进行了全面评估。我们使用了Pylint、Radon、Bandit等静态分析工具以及测试用例。结果显示，人类代码在编码标准遵守上优于GPT-4。尽管两者生成的代码都存在安全缺陷，但人类代码问题种类更多，而GPT-4代码则包含更严重的异常值。GPT-4生成的代码虽然功能强大，但复杂度较高，维护成本可能更高。然而，GPT-4代码在通过测试用例的数量上表现更佳。不过，GPT-4在处理需要深入领域知识的复杂问题时仍显不足。研究表明，LLMs在软件开发中具有潜力，但对于需要创新、非常规解决方案或精细调试的任务，人类程序员仍更具优势。我们为软件工程社区提出了未来研究方向。

> Much is promised in relation to AI-supported software development. However, there has been limited evaluation effort in the research domain aimed at validating the true utility of such techniques, especially when compared to human coding outputs. We bridge this gap, where a benchmark dataset comprising 72 distinct software engineering tasks is used to compare the effectiveness of large language models (LLMs) and human programmers in producing Python software code. GPT-4 is used as a representative LLM, where for the code generated by humans and this LLM, we evaluate code quality and adherence to Python coding standards, code security and vulnerabilities, code complexity and functional correctness. We use various static analysis benchmarks, including Pylint, Radon, Bandit and test cases. Among the notable outcomes, results show that human-generated code recorded higher ratings for adhering to coding standards than GPT-4. We observe security flaws in code generated by both humans and GPT-4, however, code generated by humans shows a greater variety of problems, but GPT-4 code included more severe outliers. Our results show that although GPT-4 is capable of producing coding solutions, it frequently produces more complex code that may need more reworking to ensure maintainability. On the contrary however, our outcomes show that a higher number of test cases passed for code generated by GPT-4 across a range of tasks than code that was generated by humans. That said, GPT-4 frequently struggles with complex problem-solving that involve in-depth domain knowledge. This study highlights the potential utility of LLMs for supporting software development, however, tasks requiring comprehensive, innovative or unconventional solutions, and careful debugging and error correction seem to be better developed by human programmers. We plot an agenda for the software engineering community.

[Arxiv](https://arxiv.org/abs/2501.16857)