# 通过人类监督增强LLMs的治理能力：评估并调整LLMs在专家分类气候错误信息上的表现，以识别气候变化的虚假或误导性声明

发布时间：2025年01月23日

`LLM应用

理由：这篇论文主要探讨了大型语言模型（LLMs）在气候错误信息分类任务中的应用，比较了专有与开源模型的表现，并讨论了如何通过专家注释数据集来提升模型性能。论文的核心是LLMs在特定领域（气候错误信息）中的应用，因此属于LLM应用类别。` `气候治理` `社交媒体`

> Enhancing LLMs for Governance with Human Oversight: Evaluating and Aligning LLMs on Expert Classification of Climate Misinformation for Detecting False or Misleading Claims about Climate Change

# 摘要

> # 摘要
气候错误信息可能因大型语言模型（LLMs）的发展而加剧。本研究评估了LLMs在缓解在线虚假/错误信息方面的潜力，而非成为问题的一部分。通过使用公开的专家注释数据集和精选的社交媒体内容样本，我们比较了专有与开源LLMs在气候错误信息分类任务中的表现，并与现有的气候相关计算机辅助工具和专家评估进行了对比。结果显示：（1）最先进的开源模型在气候错误信息分类上远不及专有模型，（2）现有的利用专家注释数据集的气候相关计算机辅助工具仍优于许多专有模型，包括GPT-4o，（3）在专家注释数据集上微调GPT-3.5-turbo在分类气候变化声明方面表现出色，其能力相当于具有20年以上气候传播经验的专家。这些发现表明：（1）在需要领域专业知识的治理任务（如气候错误信息分类）中，将人类监督（如专家注释数据集）纳入LLMs训练至关重要，（2）LLMs在促进民间社会组织参与各类治理任务（如分类气候变化以外的政治和健康科学领域的虚假或误导性声明）方面具有巨大潜力。

> Climate misinformation is a problem that has the potential to be substantially aggravated by the development of Large Language Models (LLMs). In this study we evaluate the potential for LLMs to be part of the solution for mitigating online dis/misinformation rather than the problem. Employing a public expert annotated dataset and a curated sample of social media content we evaluate the performance of proprietary vs. open source LLMs on climate misinformation classification task, comparing them to existing climate-focused computer-assisted tools and expert assessments. Results show (1) state-of-the-art (SOTA) open-source models substantially under-perform in classifying climate misinformation compared to proprietary models, (2) existing climate-focused computer-assisted tools leveraging expert-annotated datasets continues to outperform many of proprietary models, including GPT-4o, and (3) demonstrate the efficacy and generalizability of fine-tuning GPT-3.5-turbo on expert annotated dataset in classifying claims about climate change at the equivalency of climate change experts with over 20 years of experience in climate communication. These findings highlight 1) the importance of incorporating human-oversight, such as incorporating expert-annotated datasets in training LLMs, for governance tasks that require subject-matter expertise like classifying climate misinformation, and 2) the potential for LLMs in facilitating civil society organizations to engage in various governance tasks such as classifying false or misleading claims in domains beyond climate change such as politics and health science.

[Arxiv](https://arxiv.org/abs/2501.13802)