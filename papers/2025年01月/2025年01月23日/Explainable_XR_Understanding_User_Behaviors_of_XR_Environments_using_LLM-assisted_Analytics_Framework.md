# 可解释的XR：借助LLM辅助分析框架，洞察XR环境中的用户行为

发布时间：2025年01月23日

`LLM应用

理由：这篇论文介绍了一个名为Explainable XR的框架，该框架利用大型语言模型（LLMs）来辅助数据解释和分析扩展现实（XR）环境中的用户行为。虽然框架本身涉及多个组件和技术，但其核心是利用LLMs来提供数据解释和分析功能，这属于LLM在实际应用中的使用场景。因此，将其分类为LLM应用是合适的。` `扩展现实` `用户行为分析`

> Explainable XR: Understanding User Behaviors of XR Environments using LLM-assisted Analytics Framework

# 摘要

> 我们推出了Explainable XR，这是一个端到端框架，利用大型语言模型（LLMs）辅助数据解释，分析各种扩展现实（XR）环境中的用户行为。现有XR用户分析框架在处理跨虚拟性（AR、VR、MR）转换、多用户协作场景以及多模态数据复杂性方面存在挑战。Explainable XR通过提供虚拟性无关的解决方案，解决了沉浸式会话的收集、分析和可视化问题。框架包含三大核心组件：（1）用户动作描述符（UAD），一种新颖的用户数据记录方案，能够捕捉用户的多模态动作及其意图和上下文；（2）平台无关的XR会话记录器；（3）视觉分析界面，提供基于分析师视角的LLM辅助见解，助力探索和分析记录的XR会话数据。我们通过五个跨虚拟性的个人和协作XR应用场景，展示了Explainable XR的多功能性。技术评估和用户研究表明，Explainable XR为理解用户行为、提供多维度可操作见解提供了高效的分析解决方案。

> We present Explainable XR, an end-to-end framework for analyzing user behavior in diverse eXtended Reality (XR) environments by leveraging Large Language Models (LLMs) for data interpretation assistance. Existing XR user analytics frameworks face challenges in handling cross-virtuality - AR, VR, MR - transitions, multi-user collaborative application scenarios, and the complexity of multimodal data. Explainable XR addresses these challenges by providing a virtuality-agnostic solution for the collection, analysis, and visualization of immersive sessions. We propose three main components in our framework: (1) A novel user data recording schema, called User Action Descriptor (UAD), that can capture the users' multimodal actions, along with their intents and the contexts; (2) a platform-agnostic XR session recorder, and (3) a visual analytics interface that offers LLM-assisted insights tailored to the analysts' perspectives, facilitating the exploration and analysis of the recorded XR session data. We demonstrate the versatility of Explainable XR by demonstrating five use-case scenarios, in both individual and collaborative XR applications across virtualities. Our technical evaluation and user studies show that Explainable XR provides a highly usable analytics solution for understanding user actions and delivering multifaceted, actionable insights into user behaviors in immersive environments.

[Arxiv](https://arxiv.org/abs/2501.13778)