# 大型语言模型在人工通用智能（AGI）中的应用：基础原则与方法综述

发布时间：2025年01月06日

`LLM理论

理由：这篇论文主要探讨了大规模预训练基础模型（如LLMs）在实现人工通用智能（AGI）过程中需要解决的基础问题，如具身化、符号基础、因果性和记忆等。这些内容属于对LLMs的理论研究和未来发展方向的探讨，因此归类为LLM理论。` `人工智能` `认知科学`

> Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches

# 摘要

> # 摘要
基于大规模预训练基础模型（PFMs）的生成式AI系统，如视觉语言模型、LLMs、扩散模型和VLA模型，已在多个领域展示了解决复杂AI问题的能力。特别是多模态LLMs（MLLMs），它们从海量多样化数据中学习，能够对世界进行细致入微的表示，从而具备推理、对话、协作以及理解人类情感等多方面能力。然而，尽管这些模型表现出色，其认知能力仍显浅薄且脆弱，通用能力受限。要实现人类水平的通用智能，LLMs需解决具身化、符号基础、因果性和记忆等基础问题。这些概念更贴近人类认知，赋予LLMs类人的认知属性，使其能够生成物理合理、语义明确、灵活且可推广的知识与智能。本文探讨了这些基础问题，并综述了在LLMs中实现这些概念的最新方法，特别是如何通过具身化、符号基础、因果性和记忆等原则，以有机方式迈向人工通用智能（AGI）。

> Generative artificial intelligence (AI) systems based on large-scale pretrained foundation models (PFMs) such as vision-language models, large language models (LLMs), diffusion models and vision-language-action (VLA) models have demonstrated the ability to solve complex and truly non-trivial AI problems in a wide variety of domains and contexts. Multimodal large language models (MLLMs), in particular, learn from vast and diverse data sources, allowing rich and nuanced representations of the world and, thereby, providing extensive capabilities, including the ability to reason, engage in meaningful dialog; collaborate with humans and other agents to jointly solve complex problems; and understand social and emotional aspects of humans. Despite this impressive feat, the cognitive abilities of state-of-the-art LLMs trained on large-scale datasets are still superficial and brittle. Consequently, generic LLMs are severely limited in their generalist capabilities. A number of foundational problems -- embodiment, symbol grounding, causality and memory -- are required to be addressed for LLMs to attain human-level general intelligence. These concepts are more aligned with human cognition and provide LLMs with inherent human-like cognitive properties that support the realization of physically-plausible, semantically meaningful, flexible and more generalizable knowledge and intelligence. In this work, we discuss the aforementioned foundational issues and survey state-of-the art approaches for implementing these concepts in LLMs. Specifically, we discuss how the principles of embodiment, symbol grounding, causality and memory can be leveraged toward the attainment of artificial general intelligence (AGI) in an organic manner.

[Arxiv](https://arxiv.org/abs/2501.03151)