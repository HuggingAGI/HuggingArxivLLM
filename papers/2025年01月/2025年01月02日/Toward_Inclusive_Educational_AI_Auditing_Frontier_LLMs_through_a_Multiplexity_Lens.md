# # 迈向包容性教育AI：多重性视角下的前沿大型语言模型审计

发布时间：2025年01月02日

`LLM应用

理由：这篇论文主要讨论了大型语言模型（LLMs）在教育领域的应用，特别是如何通过多重性框架来评估和缓解LLMs中的文化偏见。论文提出了两种策略来改进LLMs的输出，使其更具文化包容性。这些内容涉及到LLMs在实际应用中的改进和优化，因此归类为“LLM应用”。` `文化研究`

> Toward Inclusive Educational AI: Auditing Frontier LLMs through a Multiplexity Lens

# 摘要

> 随着 GPT-4 和 Llama 3 等大型语言模型（LLMs）在教育领域的广泛应用，人们对其内部的文化偏见、权力失衡和伦理限制的担忧日益加剧。尽管生成式 AI 工具旨在提升学习体验，但它们往往反映了西方、教育化、工业化、富裕和民主（WEIRD）文化范式的价值观，可能忽视了全球多样化的视角。本文提出了一种基于多重性（multiplexity）的框架，用于评估和缓解 LLMs 中的文化偏见。多重性源自 Senturk 等人的研究，并根植于伊斯兰及其他智慧传统，强调不同文化观点的共存，支持一种融合经验科学与规范价值的多层次认识论。我们的分析表明，LLMs 常常表现出文化极化，偏见不仅体现在显性回应中，也隐藏在微妙的上下文线索中。为了应对这些固有偏见并将多重性融入 LLMs，我们提出了两种策略：	extit{上下文实现的多重性 LLMs}，它将多重性原则直接嵌入系统提示中，从根本上影响 LLM 的输出，而不依赖于单个提示；以及 	extit{多代理系统（MAS）实现的多重性 LLMs}，其中多个 LLM 代理，每个代表不同的文化视角，协作生成一个平衡的综合回应。研究结果显示，随着缓解策略从上下文提示发展到 MAS 实现，文化包容性显著提升，Perspectives Distribution Score (PDS) 显著上升，PDS 熵从基线的 3.25\% 增加到 MAS 实现的多重性 LLMs 的 98\%。情感分析进一步表明，跨文化的情感趋向积极，...

> As large language models (LLMs) like GPT-4 and Llama 3 become integral to educational contexts, concerns are mounting over the cultural biases, power imbalances, and ethical limitations embedded within these technologies. Though generative AI tools aim to enhance learning experiences, they often reflect values rooted in Western, Educated, Industrialized, Rich, and Democratic (WEIRD) cultural paradigms, potentially sidelining diverse global perspectives. This paper proposes a framework to assess and mitigate cultural bias within LLMs through the lens of applied multiplexity. Multiplexity, inspired by Senturk et al. and rooted in Islamic and other wisdom traditions, emphasizes the coexistence of diverse cultural viewpoints, supporting a multi-layered epistemology that integrates both empirical sciences and normative values. Our analysis reveals that LLMs frequently exhibit cultural polarization, with biases appearing in both overt responses and subtle contextual cues. To address inherent biases and incorporate multiplexity in LLMs, we propose two strategies: \textit{Contextually-Implemented Multiplex LLMs}, which embed multiplex principles directly into the system prompt, influencing LLM outputs at a foundational level and independent of individual prompts, and \textit{Multi-Agent System (MAS)-Implemented Multiplex LLMs}, where multiple LLM agents, each representing distinct cultural viewpoints, collaboratively generate a balanced, synthesized response. Our findings demonstrate that as mitigation strategies evolve from contextual prompting to MAS-implementation, cultural inclusivity markedly improves, evidenced by a significant rise in the Perspectives Distribution Score (PDS) and a PDS Entropy increase from 3.25\% at baseline to 98\% with the MAS-Implemented Multiplex LLMs. Sentiment analysis further shows a shift towards positive sentiment across cultures,...

[Arxiv](https://arxiv.org/abs/2501.03259)