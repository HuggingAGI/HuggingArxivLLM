# 大型多模态模型能否解决科学图表字幕生成问题？2023年SCICAP挑战的启示

发布时间：2025年01月31日

`LLM应用

**理由**：这篇论文主要讨论了大型多模态模型（LMMs）在科学图表标题生成任务中的应用，特别是GPT-4V在该任务中的表现。论文的重点在于模型的应用效果和实际表现，而不是理论探讨或模型架构的改进。因此，将其归类为LLM应用是合适的。` `学术研究` `图表生成`

> Do Large Multimodal Models Solve Caption Generation for Scientific Figures? Lessons Learned from SCICAP Challenge 2023

# 摘要

> 自2021年SCICAP数据集发布以来，研究界在学术图表标题生成方面取得了显著进展。2023年，首届SCICAP挑战赛成功举办，全球团队利用扩展的SCICAP数据集开发模型，为跨学科的各种图表生成标题。与此同时，文本生成模型飞速发展，众多强大的预训练大型多模态模型（LMMs）崭露头角，在多种视觉与语言任务中表现卓越。本文回顾了首届SCICAP挑战赛，并详细分析了各模型在数据集上的表现，展现了该领域的最新进展。我们发现，专业编辑们普遍更青睐GPT-4V生成的图表标题，甚至超过了作者撰写的原始标题。基于这一发现，我们深入探讨了一个关键问题：先进的LMMs是否已经攻克了科学图表标题生成这一难题？

> Since the SCICAP datasets launch in 2021, the research community has made significant progress in generating captions for scientific figures in scholarly articles. In 2023, the first SCICAP Challenge took place, inviting global teams to use an expanded SCICAP dataset to develop models for captioning diverse figure types across various academic fields. At the same time, text generation models advanced quickly, with many powerful pre-trained large multimodal models (LMMs) emerging that showed impressive capabilities in various vision-and-language tasks. This paper presents an overview of the first SCICAP Challenge and details the performance of various models on its data, capturing a snapshot of the fields state. We found that professional editors overwhelmingly preferred figure captions generated by GPT-4V over those from all other models and even the original captions written by authors. Following this key finding, we conducted detailed analyses to answer this question: Have advanced LMMs solved the task of generating captions for scientific figures?

[Arxiv](https://arxiv.org/abs/2501.19353)