# 语言游戏：通向人工超人类智能的桥梁

发布时间：2025年01月31日

`LLM理论

理由：这篇论文讨论了大型语言模型（LLMs）向人工超级智能（ASI）进化的过程，特别是通过数据再生产来提升模型能力。论文提出了语言游戏的概念，通过角色流动性、奖励多样性和规则可塑性等机制来打破数据再生产的循环，推动模型的开放式探索。这些内容主要涉及LLM的理论发展和进化机制，因此归类为LLM理论。` `人工智能` `数据科学`

> Language Games as the Pathway to Artificial Superhuman Intelligence

# 摘要

> 大型语言模型（LLMs）向人工超级智能（ASI）的进化依赖于数据再生产，这是一个模型通过生成、筛选和重新训练新数据来提升能力的循环过程。然而，当前方法可能陷入数据再生产陷阱：在固定的人类生成分布中优化输出，导致模型停滞不前，因为它们只是重新组合现有知识，而非探索新领域。本文提出语言游戏作为扩展数据再生产的途径，通过三种机制打破这一循环：（1）角色流动性，使多智能体系统在任务中动态切换角色，增强数据多样性和覆盖范围；（2）奖励多样性，嵌入多种反馈标准，驱动复杂智能行为；（3）规则可塑性，迭代演化交互约束，促进可学习性，注入持续新颖性。通过将语言游戏扩展到全球社会技术生态系统中，人类与AI的共同进化生成无限数据流，推动开放式探索。这一框架将数据再生产重新定义为超级智能的引擎，而非封闭循环。

> The evolution of large language models (LLMs) toward artificial superhuman intelligence (ASI) hinges on data reproduction, a cyclical process in which models generate, curate and retrain on novel data to refine capabilities. Current methods, however, risk getting stuck in a data reproduction trap: optimizing outputs within fixed human-generated distributions in a closed loop leads to stagnation, as models merely recombine existing knowledge rather than explore new frontiers. In this paper, we propose language games as a pathway to expanded data reproduction, breaking this cycle through three mechanisms: (1) \textit{role fluidity}, which enhances data diversity and coverage by enabling multi-agent systems to dynamically shift roles across tasks; (2) \textit{reward variety}, embedding multiple feedback criteria that can drive complex intelligent behaviors; and (3) \textit{rule plasticity}, iteratively evolving interaction constraints to foster learnability, thereby injecting continual novelty. By scaling language games into global sociotechnical ecosystems, human-AI co-evolution generates unbounded data streams that drive open-ended exploration. This framework redefines data reproduction not as a closed loop but as an engine for superhuman intelligence.

[Arxiv](https://arxiv.org/abs/2501.18924)