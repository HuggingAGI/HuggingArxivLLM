# # 多智能体LLM协作中的角色不一致性：顺从性、虚构和冒充

发布时间：2024年08月14日

`Agent` `多智能体系统` `聊天机器人`

> Persona Inconstancy in Multi-Agent LLM Collaboration: Conformity, Confabulation, and Impersonation

# 摘要

> 多智能体AI系统在模拟集体决策和提升聊天机器人文化敏感性方面具有潜力，但其应用依赖于AI角色可靠地模仿人类互动的能力。我们通过分析跨国协作与辩论中的AI角色表现发现，尽管多智能体讨论能反映多元观点，但角色易受同伴压力影响且难以保持一致，导致不一致增加。要充分发挥其潜力，需解决这些关键问题。

> Multi-agent AI systems can be used for simulating collective decision-making in scientific and practical applications. They can also be used to introduce a diverse group discussion step in chatbot pipelines, enhancing the cultural sensitivity of the chatbot's responses. These applications, however, are predicated on the ability of AI agents to reliably adopt assigned personas and mimic human interactions. To see whether LLM agents satisfy these requirements, we examine AI agent ensembles engaged in cross-national collaboration and debate by analyzing their private responses and chat transcripts. Our findings suggest that multi-agent discussions can support collective AI decisions that more often reflect diverse perspectives, yet this effect is tempered by the agents' susceptibility to conformity due to perceived peer pressure and occasional challenges in maintaining consistent personas and opinions. Instructions that encourage debate in support of one's opinions rather than collaboration increase the rate of inconstancy. Without addressing the factors we identify, the full potential of multi-agent frameworks for producing more culturally diverse AI outputs or more realistic simulations of group decision-making may remain untapped.

[Arxiv](https://arxiv.org/abs/2405.03862)