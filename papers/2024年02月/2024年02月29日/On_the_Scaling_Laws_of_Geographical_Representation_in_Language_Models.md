# 探究语言模型中地理表示随模型规模变化的规律

发布时间：2024年02月29日

`LLM理论`

> On the Scaling Laws of Geographical Representation in Language Models

# 摘要

> 研究表明，语言模型自始便在内部隐藏层捕捉地理信息，这一结论近期在LLMs领域得到了进一步验证。本篇论文致力于通过探索地理知识随语言模型扩大的演变过程，从而连接起经典理论与最新研究成果。我们揭示了即便是微小的语言模型也能体现地理知识，并且随着模型规模的增长，这种知识表现得愈发显著。然而，一个引人注意的现象是，尽管模型增大，却无法有效减轻训练数据内在的地理偏倚问题。

> Language models have long been shown to embed geographical information in their hidden representations. This line of work has recently been revisited by extending this result to Large Language Models (LLMs). In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when scaling language models. We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size. Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data.

[Arxiv](https://arxiv.org/abs/2402.19406)