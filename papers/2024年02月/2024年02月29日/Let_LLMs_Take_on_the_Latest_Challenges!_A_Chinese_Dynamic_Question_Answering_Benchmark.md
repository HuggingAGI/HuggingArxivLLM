# 面对最新挑战，让大型语言模型 (LLMs) 大显身手！本研究提出了一项针对中文动态问题回答的权威基准。

发布时间：2024年02月29日

`LLM应用`

> Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark

# 摘要

> 目前，针对大型语言模型（LLMs）能力的评估方法成为研究焦点，其中关注的重点是如何应对LLMs在解答最新动态问题时表现欠佳的问题。为此，本文提出了CDQA——一个基于中文互联网最新新闻构建的中文动态问答评测基准，该基准包含了大量高质量的问答对。我们借助人机协作的方式筛选并整理数据，巧妙地依据答案变更频率对样本进行细分，以利于对LLMs能力进行精细化考察。同时，我们在CDQA上对一系列主流及尖端的中文LLMs进行了详尽的评估和分析，所得丰富实验结果和深刻见解揭示了CDQA颇具挑战性，亟待更多后续探究。我们坚信，这一基准将有望成为未来提升LLMs中文问答性能的关键数据宝库。

> How to better evaluate the capabilities of Large Language Models (LLMs) is the focal point and hot topic in current LLMs research. Previous work has noted that due to the extremely high cost of iterative updates of LLMs, they are often unable to answer the latest dynamic questions well. To promote the improvement of Chinese LLMs' ability to answer dynamic questions, in this paper, we introduce CDQA, a Chinese Dynamic QA benchmark containing question-answer pairs related to the latest news on the Chinese Internet. We obtain high-quality data through a pipeline that combines humans and models, and carefully classify the samples according to the frequency of answer changes to facilitate a more fine-grained observation of LLMs' capabilities. We have also evaluated and analyzed mainstream and advanced Chinese LLMs on CDQA. Extensive experiments and valuable insights suggest that our proposed CDQA is challenging and worthy of more further study. We believe that the benchmark we provide will become the key data resource for improving LLMs' Chinese question-answering ability in the future.

[Arxiv](https://arxiv.org/abs/2402.19248)