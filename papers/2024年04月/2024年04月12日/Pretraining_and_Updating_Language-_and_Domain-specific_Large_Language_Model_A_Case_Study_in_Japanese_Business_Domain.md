# 探索日本商业领域：预训练与更新特定语言和领域大型语言模型的案例分析

发布时间：2024年04月12日

`LLM应用` `日本商业` `问答系统`

> Pretraining and Updating Language- and Domain-specific Large Language Model: A Case Study in Japanese Business Domain

# 摘要

> 以往的研究往往将特定语言或特定领域的大型语言模型（LLMs）分开讨论。本研究则将视角转向结合日语与热门行业领域，特别是打造一个针对日本商业领域的LLM。构建此类模型需具备深厚的商业知识、扎实的语言能力，以及不断更新的知识库。我们从零开始，利用一套全新的商业文本与专利数据集，训练了一个参数量达130亿的LLM，并持续用最新商业文件进行预训练。我们还推出了一个针对日本商业领域问答的新基准，并在此基准上对我们的模型进行了测试。结果表明，经过预训练的模型在提升问答准确率的同时，并未牺牲通识能力，而且持续的预训练进一步强化了模型对新信息的适应力。目前，我们的预训练模型和商业领域问答基准已向公众开放。

> Several previous studies have considered language- and domain-specific large language models (LLMs) as separate topics. This study explores the combination of a non-English language and a high-demand industry domain, focusing on a Japanese business-specific LLM. This type of a model requires expertise in the business domain, strong language skills, and regular updates of its knowledge. We trained a 13-billion-parameter LLM from scratch using a new dataset of business texts and patents, and continually pretrained it with the latest business documents. Further we propose a new benchmark for Japanese business domain question answering (QA) and evaluate our models on it. The results show that our pretrained model improves QA accuracy without losing general knowledge, and that continual pretraining enhances adaptation to new information. Our pretrained model and business domain benchmark are publicly available.

[Arxiv](https://arxiv.org/abs/2404.08262)