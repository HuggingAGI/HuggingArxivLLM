# 小型语言模型能否助力大型语言模型提升推理能力？——通过LM引导的思维链条探究

发布时间：2024年04月04日

`LLM应用` `问答系统` `多跳问答`

> Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought

# 摘要

> 我们提出了一个创新的框架——LM引导的CoT，它使用一个小型（参数量小于10亿）的语言模型来引导一个大型黑盒（参数量超过100亿）的语言模型完成推理任务。在这个框架中，小型LM先为每个输入生成一个推理依据，然后大型LM根据这个依据来预测任务的答案。这种方法资源消耗低，因为它仅需要对小型LM进行训练。通过知识蒸馏和基于理由及任务的奖励信号进行强化学习，我们对模型进行了优化。在多跳问答任务的基准测试中，如HotpotQA和2WikiMultiHopQA，我们的实验结果显示，这种方法在答案预测的准确性上超越了所有对比基准。此外，我们还发现强化学习有助于提升理由的质量，进而改善问答任务的表现。

> We introduce a novel framework, LM-Guided CoT, that leverages a lightweight (i.e., <1B) language model (LM) for guiding a black-box large (i.e., >10B) LM in reasoning tasks. Specifically, the lightweight LM first generates a rationale for each input instance. The Frozen large LM is then prompted to predict a task output based on the rationale generated by the lightweight LM. Our approach is resource-efficient in the sense that it only requires training the lightweight LM. We optimize the model through 1) knowledge distillation and 2) reinforcement learning from rationale-oriented and task-oriented reward signals. We assess our method with multi-hop extractive question answering (QA) benchmarks, HotpotQA, and 2WikiMultiHopQA. Experimental results show that our approach outperforms all baselines regarding answer prediction accuracy. We also find that reinforcement learning helps the model to produce higher-quality rationales with improved QA performance.

![小型语言模型能否助力大型语言模型提升推理能力？——通过LM引导的思维链条探究](../../../paper_images/2404.03414/x1.png)

![小型语言模型能否助力大型语言模型提升推理能力？——通过LM引导的思维链条探究](../../../paper_images/2404.03414/reward_new2.png)

![小型语言模型能否助力大型语言模型提升推理能力？——通过LM引导的思维链条探究](../../../paper_images/2404.03414/annotation_example.png)

![小型语言模型能否助力大型语言模型提升推理能力？——通过LM引导的思维链条探究](../../../paper_images/2404.03414/barplot_annotation.png)

[Arxiv](https://arxiv.org/abs/2404.03414)