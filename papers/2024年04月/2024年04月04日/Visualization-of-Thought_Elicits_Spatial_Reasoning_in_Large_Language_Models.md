# 在大型语言模型中，通过思维可视化能够激发空间推理能力。

发布时间：2024年04月04日

`LLM应用` `空间推理` `可视化`

> Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models

# 摘要

> 大型语言模型（LLMs）在理解和处理语言、完成各类推理任务上展现了非凡的能力。然而，它们在空间推理这一人类认知的核心领域，尚待深入挖掘。人类能够借助“心灵之眼”将未知的物体和行为在心中形成清晰图像，从而想象出未见的世界。借鉴这一认知功能，我们提出了一种新的思维可视化（VoT）提示法。VoT通过可视化LLMs的推理路径来激发其空间推理能力，并引导后续的推理过程。我们在包括自然语言导航、视觉导航和2D网格世界的视觉平铺等多跳空间推理任务中应用了VoT。实验结果显示，VoT显著提升了LLMs的空间推理技能，并且在这些任务中超越了现有的多模态大型语言模型（MLLMs）。VoT在LLMs中的应用效果出人意料地好，其促进空间推理的“心理图像”生成能力，让人联想到心灵之眼的作用，这也预示着其在MLLMs中的巨大潜力。

> Large language models (LLMs) have exhibited impressive performance in language comprehension and various reasoning tasks. However, their abilities in spatial reasoning, a crucial aspect of human cognition, remain relatively unexplored. Human possess a remarkable ability to create mental images of unseen objects and actions through a process known as \textbf{the Mind's Eye}, enabling the imagination of the unseen world. Inspired by this cognitive capacity, we propose Visualization-of-Thought (\textbf{VoT}) prompting. VoT aims to elicit spatial reasoning of LLMs by visualizing their reasoning traces, thereby guiding subsequent reasoning steps. We employed VoT for multi-hop spatial reasoning tasks, including natural language navigation, visual navigation, and visual tiling in 2D grid worlds. Experimental results demonstrated that VoT significantly enhances the spatial reasoning abilities of LLMs. Notably, VoT outperformed existing multimodal large language models (MLLMs) in these tasks. While VoT works surprisingly well on LLMs, the ability to generate \textit{mental images} to facilitate spatial reasoning resembles the mind's eye process, suggesting its potential viability in MLLMs.

[Arxiv](https://arxiv.org/abs/2404.03622)