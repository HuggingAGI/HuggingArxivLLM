# 并非存在一套放之四海而皆准的道德准则：在人工智能心理辅导领域，我们需深思熟虑的伦理问题。

发布时间：2024年04月22日

`LLM应用` `人工智能伦理` `心理健康`

> No General Code of Ethics for All: Ethical Considerations in Human-bot Psycho-counseling

# 摘要

> 人工智能（AI）应用的广泛应用正深刻塑造着我们的决策过程。然而，AI引发的伦理问题超越了传统伦理范畴和单一学科的解决方案。本文提出了一套高标准的伦理原则，专为AI时代的人工心理辅导量身定制。我们对EVA2.0、GPT-3.5和GPT-4.0在心理辅导和心理健康咨询场景下生成的回应进行了审视。分析重点放在了心理辅导的伦理准则（尊重个体自主、避免伤害、行善、公平和责任感）和危机干预策略（风险评估、紧急服务介入和转介至人类专家）。研究结果显示，尽管大型语言模型（LLMs）在遵循常规伦理准则方面取得了进步，但在应对危机情境时的能力仍有待提高。同时，我们对生成回应的语言质量进行了评估，发现模型仍会产生误导性的回答。此外，LLMs在心理辅导环境中激发个体自我反思的能力尚未充分发展。

> The pervasive use of AI applications is increasingly influencing our everyday decisions. However, the ethical challenges associated with AI transcend conventional ethics and single-discipline approaches. In this paper, we propose aspirational ethical principles specifically tailored for human-bot psycho-counseling during an era when AI-powered mental health services are continually emerging. We examined the responses generated by EVA2.0, GPT-3.5, and GPT-4.0 in the context of psycho-counseling and mental health inquiries. Our analysis focused on standard psycho-counseling ethical codes (respect for autonomy, non-maleficence, beneficence, justice, and responsibility) as well as crisis intervention strategies (risk assessment, involvement of emergency services, and referral to human professionals). The results indicate that although there has been progress in adhering to regular ethical codes as large language models (LLMs) evolve, the models' capabilities in handling crisis situations need further improvement. Additionally, we assessed the linguistic quality of the generated responses and found that misleading responses are still produced by the models. Furthermore, the ability of LLMs to encourage individuals to introspect in the psycho-counseling setting remains underdeveloped.

[Arxiv](https://arxiv.org/abs/2404.14070)