# LLMChain：一个利用区块链技术构建的声誉系统，旨在促进大型语言模型的共享与评估。

发布时间：2024年04月19日

`LLM应用` `法律援助` `医疗诊断`

> LLMChain: Blockchain-based Reputation System for Sharing and Evaluating Large Language Models

# 摘要

> 大型语言模型（LLMs）在语言理解、生成和推理的新挑战与能力上迅猛发展。尽管它们在自然语言处理应用中表现卓越，却也容易表现出不良和不稳定的行为，如幻觉、推理不可靠和生成有害内容。这些问题削弱了人们对LLMs的信任，对于需要极高精确度、可靠性和道德考量的应用领域，如法律援助和医学诊断，构成了重大障碍。此外，用户不满情绪的评估和捕捉目前尚未得到充分重视。为了有效且透明地评估用户与LLMs互动时的满意度和信任度，我们构建了LLMChain——一个去中心化的区块链声誉系统，它结合了自动化评估和人工反馈，为LLMs的行为提供准确的情境声誉评分。LLMChain旨在帮助用户和机构找到最适合其需求的可信LLM，并为LLM开发者提供改进模型的宝贵数据。据我们所知，这是首个引入基于区块链的分布式框架来共享和评估LLMs的尝试。LLMChain利用最新工具构建，并在两个基准数据集上进行了测试，证明了其在评估七种不同LLMs时的有效性和可扩展性。

> Large Language Models (LLMs) have witnessed rapid growth in emerging challenges and capabilities of language understanding, generation, and reasoning. Despite their remarkable performance in natural language processing-based applications, LLMs are susceptible to undesirable and erratic behaviors, including hallucinations, unreliable reasoning, and the generation of harmful content. These flawed behaviors undermine trust in LLMs and pose significant hurdles to their adoption in real-world applications, such as legal assistance and medical diagnosis, where precision, reliability, and ethical considerations are paramount. These could also lead to user dissatisfaction, which is currently inadequately assessed and captured. Therefore, to effectively and transparently assess users' satisfaction and trust in their interactions with LLMs, we design and develop LLMChain, a decentralized blockchain-based reputation system that combines automatic evaluation with human feedback to assign contextual reputation scores that accurately reflect LLM's behavior. LLMChain not only helps users and entities identify the most trustworthy LLM for their specific needs, but also provides LLM developers with valuable information to refine and improve their models. To our knowledge, this is the first time that a blockchain-based distributed framework for sharing and evaluating LLMs has been introduced. Implemented using emerging tools, LLMChain is evaluated across two benchmark datasets, showcasing its effectiveness and scalability in assessing seven different LLMs.

[Arxiv](https://arxiv.org/abs/2404.13236)