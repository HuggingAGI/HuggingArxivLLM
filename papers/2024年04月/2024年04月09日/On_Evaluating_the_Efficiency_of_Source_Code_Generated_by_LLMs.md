# 探讨大型语言模型生成源代码的效率评估

发布时间：2024年04月09日

`LLM应用` `代码生成`

> On Evaluating the Efficiency of Source Code Generated by LLMs

# 摘要

> 近年来，大型语言模型（LLMs）在代码生成领域展现出卓越才能。不同于以往仅关注代码正确性，我们进一步探讨其效率问题。高效代码意味着更优的程序性能和软件运行效率，尤其在LLM辅助编程方面。我们先在HumanEval和MBPP基准测试中评估了LLMs所生成代码的效率，接着从LeetCode平台挑选了一系列编程难题进行深入测试。最终，我们研究了多种提示技巧，旨在让LLMs能够编写出更加高效的代码。

> Recent years have seen the remarkable capabilities of large language models (LLMs) for code generation. Different from existing work that evaluate the correctness of the code generated by LLMs, we propose to further evaluate its efficiency. More efficient code can lead to higher performance and execution efficiency of programs and software completed by LLM-assisted programming. First, we evaluate the efficiency of the code generated by LLMs on two benchmarks, HumanEval and MBPP. Then, we choose a set of programming problems from the online judge platform LeetCode to conduct a more difficult evaluation. Finally, we explore several prompts that would enable LLMs to generate more efficient code.

[Arxiv](https://arxiv.org/abs/2404.06041)