# 挖掘深层能力：对大型语言模型进行黑盒优化性能评估

发布时间：2024年04月09日

`LLM应用` `人工智能`

> Exploring the True Potential: Evaluating the Black-box Optimization Capability of Large Language Models

# 摘要

> 大型语言模型（LLMs）在自然语言处理（NLP）任务上表现卓越，同时在非语言类领域也大放异彩，展现出作为人工通用智能的广阔前景。它们在多样化的优化场景中展现出巨大的潜力。然而，关于将LLMs应用于这些黑盒优化问题是否真的有益，尚待深入探讨。本文致力于通过全面研究，揭示LLMs在优化任务中的潜力及其独特优势。我们采取了一种全面评估的方法，覆盖了离散和连续的优化问题，以评估LLMs为优化领域带来的新动力和特性。研究发现，尽管LLMs在处理纯数值任务时存在局限，但在非数值领域解决问题的能力不容忽视，并且能够通过提示中的启发式方法提升性能。这是首次对LLMs在数值优化方面的系统性评估，为理解LLMs在优化领域的应用角色提供了新的视角，并为未来在不同场景下的应用提供了指导。

> Large language models (LLMs) have gained widespread popularity and demonstrated exceptional performance not only in natural language processing (NLP) tasks but also in non-linguistic domains. Their potential as artificial general intelligence extends beyond NLP, showcasing promising capabilities in diverse optimization scenarios. Despite this rising trend, whether the integration of LLMs into these black-box optimization problems is genuinely beneficial remains unexplored. This paper endeavors to tackle this issue by offering deeper insights into the potential of LLMs in optimization tasks through a comprehensive investigation. Our approach involves a comprehensive evaluation, covering both discrete and continuous optimization problems, aiming to assess the efficacy and distinctive characteristics that LLMs bring to the realm of optimization. Our findings reveal both the limitations and advantages of LLMs in optimization. On one hand, despite consuming the significant power required to run the model, LLMs exhibit subpar performance and lack desirable properties in pure numerical tasks, primarily due to a mismatch between the problem domain and their processing capabilities. On the other hand, although LLMs may not be ideal for traditional numerical optimization, their potential in broader optimization contexts remains promising. LLMs exhibit the ability to solve problems in non-numerical domains and can leverage heuristics from the prompt to enhance their performance. To the best of our knowledge, this work presents the first systematic evaluation of LLMs for numerical optimization, offering a progressive, wide-coverage, and behavioral analysis. Our findings pave the way for a deeper understanding of LLMs' role in optimization and guide future application in diverse scenarios for LLMs.

[Arxiv](https://arxiv.org/abs/2404.06290)