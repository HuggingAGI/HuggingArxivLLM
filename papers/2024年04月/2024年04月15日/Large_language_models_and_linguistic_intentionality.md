# 在探讨大型语言模型时，我们不可忽视语言的意图性。

发布时间：2024年04月15日

`LLM理论` `人工智能`

> Large language models and linguistic intentionality

# 摘要

> 像 Chat-GPT 和 LLaMa 这样的大型语言模型，它们所生成的词汇真的有其独特的意义，还是仅仅作为智能预测器，通过制造看似合理的文本来模仿语言的使用？之前已经有人尝试通过元语义理论的标准来证明这些模型能够达到有意义的状态，以回答上述问题。在本文中，我提出另一种观点——我们应该评估这些模型是否达到了我们最前沿的元语义理论对语言内容的要求。为此，我将选取加雷斯·埃文斯关于命名实践的论述和露丝·米利坎的目的语义学理论，将它们应用于语言模型的分析中。我认为，认为大型语言模型因为不满足心理意向性的标准条件而使得它们的输出毫无意义，这是一种误解。语言意向性的独特之处在于它依赖于一个已存在的语言系统，这一特点恰恰使得大型语言模型的输出具有意义。

> Do large language models like Chat-GPT or LLaMa meaningfully use the words they produce? Or are they merely clever prediction machines, simulating language use by producing statistically plausible text? There have already been some initial attempts to answer this question by showing that these models meet the criteria for entering meaningful states according to metasemantic theories of mental content. In this paper, I will argue for a different approach - that we should instead consider whether language models meet the criteria given by our best metasemantic theories of linguistic content. In that vein, I will illustrate how this can be done by applying two such theories to the case of language models: Gareth Evans' (1982) account of naming practices and Ruth Millikan's (1984, 2004, 2005) teleosemantics. In doing so, I will argue that it is a mistake to think that the failure of LLMs to meet plausible conditions for mental intentionality thereby renders their outputs meaningless, and that a distinguishing feature of linguistic intentionality - dependency on a pre-existing linguistic system - allows for the plausible result LLM outputs are meaningful.

[Arxiv](https://arxiv.org/abs/2404.09576)