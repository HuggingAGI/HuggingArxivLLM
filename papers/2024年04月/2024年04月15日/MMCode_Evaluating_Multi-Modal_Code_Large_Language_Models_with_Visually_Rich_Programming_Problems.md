# MMCode：利用视觉丰富的编程挑战，评估融合多模态信息的大型语言模型。

发布时间：2024年04月15日

`LLM应用` `多模态学习`

> MMCode: Evaluating Multi-Modal Code Large Language Models with Visually Rich Programming Problems

# 摘要

> 编程过程中，将繁复的规范转换成代码是常有的事，开发者们通常会借助视觉辅助工具来更好地传递思想。尽管最新的大型多模态模型在视觉推理和数学问题上表现出色，但这些模型在解读视觉元素以生成代码方面的能力尚未得到充分研究。因此，我们推出了MMCode——首个旨在评估视觉丰富环境下算法问题解决能力的多模态编码数据集。该数据集囊括了3,548个问题和6,620张图像，均源自真实世界的编程挑战，这些挑战因其对推理能力的高要求而显得尤为艰巨。实验结果显示，现有的顶尖模型在解决这些问题上仍显吃力。这一发现凸显了在视觉-代码领域缺乏强大模型的现状，我们期望MMCode能激发未来研究的灵感。相关数据和代码已在 https://github.com/happylkx/MMCode 上公开。

> Programming often involves converting detailed and complex specifications into code, a process during which developers typically utilize visual aids to more effectively convey concepts. While recent developments in Large Multimodal Models have demonstrated remarkable abilities in visual reasoning and mathematical tasks, there is little work on investigating whether these models can effectively interpret visual elements for code generation. To this end, we present MMCode, the first multi-modal coding dataset for evaluating algorithmic problem-solving skills in visually rich contexts. MMCode contains 3,548 questions and 6,620 images collected from real-world programming challenges harvested from 10 code competition websites, presenting significant challenges due to the extreme demand for reasoning abilities. Our experiment results show that current state-of-the-art models struggle to solve these problems. The results highlight the lack of powerful vision-code models, and we hope MMCode can serve as an inspiration for future works in this domain. The data and code are publicly available at https://github.com/happylkx/MMCode.

[Arxiv](https://arxiv.org/abs/2404.09486)