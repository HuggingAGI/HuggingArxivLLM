# 大型语言模型能否成为值得信赖的论证质量评价者？

发布时间：2024年04月15日

`LLM应用` `论点挖掘` `自动化评估`

> Are Large Language Models Reliable Argument Quality Annotators?

# 摘要

> 在论点挖掘领域，对论点质量的准确评估至关重要，但要获取稳定且可信的质量评价却非易事，因为这往往需要注释者具备相关领域的深厚知识。即便专家们对此进行评定，也会因评价标准的主观性而意见不一。本研究探讨了运用最新大型语言模型（LLMs）来充当论点质量评价者的可行性。通过对比模型与人类专家及新手注释者在论点质量维度上的共识度，我们发现LLMs能够带来相对一致的注释结果，并在多数质量维度上与人类专家保持适度高度的一致性。研究还表明，引入LLMs作为辅助注释者能显著提升不同注释者间的共识度。这一发现意味着LLMs有望成为自动化评估论点质量的有力工具，进而促进对大规模论点数据集的快速、高效评估。

> Evaluating the quality of arguments is a crucial aspect of any system leveraging argument mining. However, it is a challenge to obtain reliable and consistent annotations regarding argument quality, as this usually requires domain-specific expertise of the annotators. Even among experts, the assessment of argument quality is often inconsistent due to the inherent subjectivity of this task. In this paper, we study the potential of using state-of-the-art large language models (LLMs) as proxies for argument quality annotators. To assess the capability of LLMs in this regard, we analyze the agreement between model, human expert, and human novice annotators based on an established taxonomy of argument quality dimensions. Our findings highlight that LLMs can produce consistent annotations, with a moderately high agreement with human experts across most of the quality dimensions. Moreover, we show that using LLMs as additional annotators can significantly improve the agreement between annotators. These results suggest that LLMs can serve as a valuable tool for automated argument quality assessment, thus streamlining and accelerating the evaluation of large argument datasets.

[Arxiv](https://arxiv.org/abs/2404.09696)