# 《安全提示：大型语言模型安全性评估与提升的开放数据集系统综述》

发布时间：2024年04月08日

`RAG` `安全性评估` `数据集`

> SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety

# 摘要

> 近两年，大型语言模型（LLM）安全性问题日益受到重视。研究者和实践者通过推出众多新数据集来评估和增强LLM的安全性，以应对这些挑战。然而，这些工作往往目标各异，从减轻偏见和有害内容的短期风险，到评估可能的长期灾难性风险。这导致研究者和实践者在特定应用场景中难以找到最合适的数据集，并发现未来研究可能补充的数据集覆盖的缺失。为了解决这些问题，我们进行了首次系统性审视，评估和提升LLM安全性的开放数据集。经过数月的迭代和社区共同推动，我们审查了102个数据集。我们发现了一些趋势，比如向完全合成数据集的发展，以及数据集覆盖的不足，特别是缺少非英语数据集。我们还研究了LLM安全性数据集在实际中的应用——在LLM发布和流行的基准测试中——发现当前的评估方法非常个性化，仅利用了现有数据集的一小部分。我们的成果基于SafetyPrompts.com，这是一个持续更新的LLM安全性开放数据集目录，随着LLM安全领域的进步，我们将持续更新。

> The last two years have seen a rapid growth in concerns around the safety of large language models (LLMs). Researchers and practitioners have met these concerns by introducing an abundance of new datasets for evaluating and improving LLM safety. However, much of this work has happened in parallel, and with very different goals in mind, ranging from the mitigation of near-term risks around bias and toxic content generation to the assessment of longer-term catastrophic risk potential. This makes it difficult for researchers and practitioners to find the most relevant datasets for a given use case, and to identify gaps in dataset coverage that future work may fill. To remedy these issues, we conduct a first systematic review of open datasets for evaluating and improving LLM safety. We review 102 datasets, which we identified through an iterative and community-driven process over the course of several months. We highlight patterns and trends, such as a a trend towards fully synthetic datasets, as well as gaps in dataset coverage, such as a clear lack of non-English datasets. We also examine how LLM safety datasets are used in practice -- in LLM release publications and popular LLM benchmarks -- finding that current evaluation practices are highly idiosyncratic and make use of only a small fraction of available datasets. Our contributions are based on SafetyPrompts.com, a living catalogue of open datasets for LLM safety, which we commit to updating continuously as the field of LLM safety develops.

![《安全提示：大型语言模型安全性评估与提升的开放数据集系统综述》](../../../paper_images/2404.05399/purpose_type.png)

[Arxiv](https://arxiv.org/abs/2404.05399)