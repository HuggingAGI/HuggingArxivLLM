# Xiwu：一款适应高能物理领域的基础性、灵活性强且具备学习能力的大型语言模型

发布时间：2024年04月08日

`LLM应用` `高能物理` `大型语言模型`

> Xiwu: A Basis Flexible and Learnable LLM for High Energy Physics

# 摘要

> 大型语言模型（LLMs）正迅速演进，尖端模型不断更迭。在特定科学领域如高能物理（HEP）中运用LLMs时，挑战在于如何融合独到的领域知识并维持模型的前沿性。为解决这一问题，我们推出了一款名为Xiwu的先进大型语言模型系统，它支持在尖端基础模型间灵活切换，并能迅速吸收新领域知识。本文将分享在HEP领域运用LLMs的高效策略，涵盖：创新的种子裂变技术、高效的数据采集与清洗工具，以及基于向量存储技术的即时学习系统和即时微调系统，旨在实现快速训练。Xiwu系统能流畅切换于LLaMA、Vicuna、ChatGLM和Grok-1等模型，其在HEP知识问答和代码生成任务上的表现远超行业标准。这一策略极大提升了模型性能的增长潜力，期望随着开源模型的进步，未来能超越GPT-4。此外，本研究还为HEP领域量身定制了LLM，并为其他领域的LLM应用提供了借鉴，相关代码已在Github上线。

> Large Language Models (LLMs) are undergoing a period of rapid updates and changes, with state-of-the-art (SOTA) model frequently being replaced. When applying LLMs to a specific scientific field, it's challenging to acquire unique domain knowledge while keeping the model itself advanced. To address this challenge, a sophisticated large language model system named as Xiwu has been developed, allowing you switch between the most advanced foundation models and quickly teach the model domain knowledge. In this work, we will report on the best practices for applying LLMs in the field of high-energy physics (HEP), including: a seed fission technology is proposed and some data collection and cleaning tools are developed to quickly obtain domain AI-Ready dataset; a just-in-time learning system is implemented based on the vector store technology; an on-the-fly fine-tuning system has been developed to facilitate rapid training under a specified foundation model. The results show that Xiwu can smoothly switch between foundation models such as LLaMA, Vicuna, ChatGLM and Grok-1. The trained Xiwu model is significantly outperformed the benchmark model on the HEP knowledge question-and-answering and code generation. This strategy significantly enhances the potential for growth of our model's performance, with the hope of surpassing GPT-4 as it evolves with the development of open-source models. This work provides a customized LLM for the field of HEP, while also offering references for applying LLM to other fields, the corresponding codes are available on Github.

[Arxiv](https://arxiv.org/abs/2404.08001)