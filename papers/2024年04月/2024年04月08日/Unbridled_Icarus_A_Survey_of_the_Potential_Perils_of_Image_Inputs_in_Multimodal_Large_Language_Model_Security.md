# 伊卡洛斯之翼：探究多模态大型语言模型安全性中图像输入可能带来的风险

发布时间：2024年04月08日

`RAG` `安全性` `人工智能`

> Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in Multimodal Large Language Model Security

# 摘要

> 多模态大型语言模型（MLLMs）正以其卓越能力改变我们的日常生活，不断拓展人工通用智能（AGI）的新境界。图像模态，以其深邃的语义信息和与其他模态相比更为连贯的数学特性，为MLLMs的功能带来了质的飞跃。然而，这种融合也带来了风险，攻击者可能利用这些漏洞发起隐蔽且有害的攻击。因此，研究强大而可靠的AI系统，如MLLMs，已成为研究的热点。本文旨在探讨将图像模态整合到MLLMs中所带来的复杂风险。我们首先梳理了MLLMs的基本构成和训练流程，接着构建了威胁模型，揭示了MLLMs内在的安全漏洞。我们还分析并概括了现有关于MLLMs攻防机制的学术讨论，并提出了未来研究方向的建议。我们希望通过这项深入分析，增进学术界对MLLMs安全挑战的理解，并推动构建更加值得信赖的MLLMs系统。

> Multimodal Large Language Models (MLLMs) demonstrate remarkable capabilities that increasingly influence various aspects of our daily lives, constantly defining the new boundary of Artificial General Intelligence (AGI). Image modalities, enriched with profound semantic information and a more continuous mathematical nature compared to other modalities, greatly enhance the functionalities of MLLMs when integrated. However, this integration serves as a double-edged sword, providing attackers with expansive vulnerabilities to exploit for highly covert and harmful attacks. The pursuit of reliable AI systems like powerful MLLMs has emerged as a pivotal area of contemporary research. In this paper, we endeavor to demostrate the multifaceted risks associated with the incorporation of image modalities into MLLMs. Initially, we delineate the foundational components and training processes of MLLMs. Subsequently, we construct a threat model, outlining the security vulnerabilities intrinsic to MLLMs. Moreover, we analyze and summarize existing scholarly discourses on MLLMs' attack and defense mechanisms, culminating in suggestions for the future research on MLLM security. Through this comprehensive analysis, we aim to deepen the academic understanding of MLLM security challenges and propel forward the development of trustworthy MLLM systems.

![伊卡洛斯之翼：探究多模态大型语言模型安全性中图像输入可能带来的风险](../../../paper_images/2404.05264/Fig1.png)

[Arxiv](https://arxiv.org/abs/2404.05264)