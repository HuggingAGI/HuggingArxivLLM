# 反事实任务的证据表明，大型语言模型能够展现出类比推理的能力。

发布时间：2024年04月14日

`LLM理论` `人工智能`

> Evidence from counterfactual tasks supports emergent analogical reasoning in large language models

# 摘要

> 我们最近的研究显示，大型语言模型具备在零样本情况下解决多种文本类比问题的能力，这暗示了它们拥有自发的类比推理能力。然而，两篇评论对此提出质疑，他们指出在“反事实”任务中，字母表的标准顺序被随机打乱，以降低与模型训练数据中可能存在的材料的相似度。作为回应，我们在此澄清了对我们原始研究中使用测试材料的一些误解，并进一步证明语言模型同样能够适应这些新的反事实任务变种。

> We recently reported evidence that large language models are capable of solving a wide range of text-based analogy problems in a zero-shot manner, indicating the presence of an emergent capacity for analogical reasoning. Two recent commentaries have challenged these results, citing evidence from so-called `counterfactual' tasks in which the standard sequence of the alphabet is arbitrarily permuted so as to decrease similarity with materials that may have been present in the language model's training data. Here, we reply to these critiques, clarifying some misunderstandings about the test materials used in our original work, and presenting evidence that language models are also capable of generalizing to these new counterfactual task variants.

![反事实任务的证据表明，大型语言模型能够展现出类比推理的能力。](../../../paper_images/2404.13070/x1.png)

![反事实任务的证据表明，大型语言模型能够展现出类比推理的能力。](../../../paper_images/2404.13070/x2.png)

![反事实任务的证据表明，大型语言模型能够展现出类比推理的能力。](../../../paper_images/2404.13070/x3.png)

![反事实任务的证据表明，大型语言模型能够展现出类比推理的能力。](../../../paper_images/2404.13070/x4.png)

[Arxiv](https://arxiv.org/abs/2404.13070)