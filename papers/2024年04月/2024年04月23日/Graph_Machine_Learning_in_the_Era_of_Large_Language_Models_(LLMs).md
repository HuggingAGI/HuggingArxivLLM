# 在大型语言模型（LLMs）盛行的时代，图机器学习正发挥着重要作用。

发布时间：2024年04月23日

`LLM应用` `社交网络` `知识图谱`

> Graph Machine Learning in the Era of Large Language Models (LLMs)

# 摘要

> 图在展示社交网络、知识图谱和分子发现等众多领域中的复杂联系方面起着关键作用。深度学习技术的兴起使得图神经网络（GNN）成为图机器学习（Graph ML）的核心技术，极大地促进了图结构的表示与处理。近期，大型语言模型（LLM）在处理语言任务上展现了卓越的能力，并已广泛应用于计算机视觉、推荐系统等多个领域。这一突破性进展激发了将LLM技术应用于图领域的研究兴趣。为了推动Graph ML在泛化能力、迁移学习能力和少量样本学习方面的进一步发展，研究者们投入了大量努力。同时，图结构，尤其是知识图谱，蕴含着丰富的事实性知识，这些知识有助于提升LLM的推理能力，可能还能解决如幻觉和解释性不足等问题。面对这一研究领域的迅猛发展，进行系统性的回顾，梳理LLM时代Graph ML的最新进展，对于科研人员和业界实践者来说显得尤为重要。在本篇综述中，我们首先回顾了Graph ML的最新进展，接着探讨了LLM如何提升图特征的质量，减少对标记数据的依赖，以及如何应对图的异质性和分布外泛化等挑战。此外，我们还深入分析了图结构如何增强LLM的性能，包括提升预训练和推理过程。最后，我们审视了LLM在图领域的多种应用，并对未来的潜在发展方向进行了讨论。

> Graphs play an important role in representing complex relationships in various domains like social networks, knowledge graphs, and molecular discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have emerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the representation and processing of graph structures. Recently, LLMs have demonstrated unprecedented capabilities in language tasks and are widely adopted in a variety of applications such as computer vision and recommender systems. This remarkable success has also attracted interest in applying LLMs to the graph domain. Increasing efforts have been made to explore the potential of LLMs in advancing Graph ML's generalization, transferability, and few-shot learning ability. Meanwhile, graphs, especially knowledge graphs, are rich in reliable factual knowledge, which can be utilized to enhance the reasoning capabilities of LLMs and potentially alleviate their limitations such as hallucinations and the lack of explainability. Given the rapid progress of this research direction, a systematic review summarizing the latest advancements for Graph ML in the era of LLMs is necessary to provide an in-depth understanding to researchers and practitioners. Therefore, in this survey, we first review the recent developments in Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and address challenges such as graph heterogeneity and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications and discuss the potential future directions in this promising field.

[Arxiv](https://arxiv.org/abs/2404.14928)