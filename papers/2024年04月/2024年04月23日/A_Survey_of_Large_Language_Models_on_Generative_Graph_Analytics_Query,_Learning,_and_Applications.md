# 大型语言模型在生成图分析领域的研究综述：探讨查询、学习及应用

发布时间：2024年04月23日

`LLM应用` `图数据分析`

> A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications

# 摘要

> 图作为基本的数据模型，广泛用于描绘社会和自然界中的实体及其错综复杂的联系，如社交网络、交通系统、金融体系和生物医学网络。近期，大型语言模型（LLMs）在处理多样化的自然语言处理（NLP）和多模态任务方面展现出了卓越的泛化能力，能够响应用户的随机查询和特定领域的内容创作。相较于传统的图学习模型，LLMs在处理图任务时更具优势，它们避免了图学习模型的训练需求，同时降低了手动标注的成本。本篇综述深入探讨了LLM在图数据分析领域的研究进展，归纳了高级LLM模型解决的图分析任务，并指出了当前面临的挑战与未来的研究趋势。具体而言，我们聚焦于基于LLM的生成图分析（LLM-GGA）的三大核心问题：基于LLM的图查询处理（LLM-GQP）、基于LLM的图推理与学习（LLM-GIL），以及图与LLM结合的应用。LLM-GQP着重于图分析技术与LLM提示的融合，涵盖图理解及基于知识图谱的增强检索；LLM-GIL则专注于图上的学习和推理，包括图学习、图形态推理和图表示。我们归纳了LLM在处理各类图任务时采用的有效提示。此外，我们还总结了LLM模型的评估方法、基准数据集/任务，并深入剖析了LLM模型的优势与局限。同时，我们也探讨了LLM与图分析这一激动人心的跨学科研究领域的未解之谜及未来可能的研究方向。

> A graph is a fundamental data model to represent various entities and their complex relationships in society and nature, such as social networks, transportation networks, financial networks, and biomedical systems. Recently, large language models (LLMs) have showcased a strong generalization ability to handle various NLP and multi-mode tasks to answer users' arbitrary questions and specific-domain content generation. Compared with graph learning models, LLMs enjoy superior advantages in addressing the challenges of generalizing graph tasks by eliminating the need for training graph learning models and reducing the cost of manual annotation. In this survey, we conduct a comprehensive investigation of existing LLM studies on graph data, which summarizes the relevant graph analytics tasks solved by advanced LLM models and points out the existing remaining challenges and future directions. Specifically, we study the key problems of LLM-based generative graph analytics (LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP), LLM-based graph inference and learning (LLM-GIL), and graph-LLM-based applications. LLM-GQP focuses on an integration of graph analytics techniques and LLM prompts, including graph understanding and knowledge graph (KG) based augmented retrieval, while LLM-GIL focuses on learning and reasoning over graphs, including graph learning, graph-formed reasoning and graph representation. We summarize the useful prompts incorporated into LLM to handle different graph downstream tasks. Moreover, we give a summary of LLM model evaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM models. We also explore open problems and future directions in this exciting interdisciplinary research area of LLMs and graph analytics.

[Arxiv](https://arxiv.org/abs/2404.14809)