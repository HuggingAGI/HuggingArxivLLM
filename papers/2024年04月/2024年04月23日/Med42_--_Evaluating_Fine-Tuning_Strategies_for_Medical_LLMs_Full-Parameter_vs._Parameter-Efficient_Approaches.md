# Med42 -- 探讨医学领域大型语言模型的微调技巧：全面参数调整与高效参数利用策略的对决

发布时间：2024年04月23日

`LLM应用` `人工智能`

> Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter vs. Parameter-Efficient Approaches

# 摘要

> 本研究深入分析并对比了医学领域大型语言模型（LLMs）中两种主流的微调方法：全参数微调和参数高效微调。我们基于Llama-2架构，开发并优化了多款专门用于提升医学知识检索、推理和问答能力的LLMs。通过一系列系统实验，我们评估了这些微调策略在多个知名医学基准测试中的有效性。特别值得一提的是，我们的医学LLM Med42在美国医学执照考试（USMLE）数据集上达到了72%的准确率，刷新了公开可用医学LLMs的性能记录。我们的目标是通过这项比较研究，找出在医学领域微调LLMs的最有效和最高效方法，为推动AI在医疗保健应用中的发展做出显著贡献。

> This study presents a comprehensive analysis and comparison of two predominant fine-tuning methodologies - full-parameter fine-tuning and parameter-efficient tuning - within the context of medical Large Language Models (LLMs). We developed and refined a series of LLMs, based on the Llama-2 architecture, specifically designed to enhance medical knowledge retrieval, reasoning, and question-answering capabilities. Our experiments systematically evaluate the effectiveness of these tuning strategies across various well-known medical benchmarks. Notably, our medical LLM Med42 showed an accuracy level of 72% on the US Medical Licensing Examination (USMLE) datasets, setting a new standard in performance for openly available medical LLMs. Through this comparative analysis, we aim to identify the most effective and efficient method for fine-tuning LLMs in the medical domain, thereby contributing significantly to the advancement of AI-driven healthcare applications.

[Arxiv](https://arxiv.org/abs/2404.14779)