# 合作还是崩溃：探究大型语言模型（LLM）代理社会中可持续性行为的兴起

发布时间：2024年04月25日

`Agent` `人工智能` `资源管理`

> Cooperate or Collapse: Emergence of Sustainability Behaviors in a Society of LLM Agents

# 摘要

> 在日新月异的人工智能世界中，保障大型语言模型（LLMs）的决策安全无疑是一项艰巨任务。本文提出了“公共资源治理模拟”（GovSim），一个专为研究LLMs中战略互动与合作决策而设计的模拟平台。该平台让我们得以深入探讨AI代理间资源共享的机制，同时凸显了道德考量、战略规划和谈判技巧的关键作用。GovSim的通用性使其能够支持包括LLMs在内的所有文本型代理。利用生成代理框架，我们开发了一个标准化代理，以促进不同LLMs的融合。研究发现，在GovSim平台上，15个受测的LLMs中仅有两个能够达成可持续的成果，这暴露了模型在共享资源管理上的能力不足。更进一步，当代理失去沟通能力时，会出现共享资源的过度使用，这强调了沟通在促进合作中的核心作用。值得注意的是，大多数LLMs在进行普遍化假设方面存在缺陷，这反映了它们在推理能力上的一个明显弱点。我们已经将研究成果的全套内容开源，包括模拟环境、代理提示和全面的网页界面。

> In the rapidly evolving field of artificial intelligence, ensuring safe decision-making of Large Language Models (LLMs) is a significant challenge. This paper introduces Governance of the Commons Simulation (GovSim), a simulation platform designed to study strategic interactions and cooperative decision-making in LLMs. Through this simulation environment, we explore the dynamics of resource sharing among AI agents, highlighting the importance of ethical considerations, strategic planning, and negotiation skills. GovSim is versatile and supports any text-based agent, including LLMs agents. Using the Generative Agent framework, we create a standard agent that facilitates the integration of different LLMs. Our findings reveal that within GovSim, only two out of 15 tested LLMs managed to achieve a sustainable outcome, indicating a significant gap in the ability of models to manage shared resources. Furthermore, we find that by removing the ability of agents to communicate, they overuse the shared resource, highlighting the importance of communication for cooperation. Interestingly, most LLMs lack the ability to make universalized hypotheses, which highlights a significant weakness in their reasoning skills. We open source the full suite of our research results, including the simulation environment, agent prompts, and a comprehensive web interface.

[Arxiv](https://arxiv.org/abs/2404.16698)