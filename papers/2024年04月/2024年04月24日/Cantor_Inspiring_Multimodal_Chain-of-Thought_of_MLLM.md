# Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链

发布时间：2024年04月24日

`分类：LLM应用` `视觉推理` `人工智能`

> Cantor: Inspiring Multimodal Chain-of-Thought of MLLM

# 摘要

> 随着思维链（CoT）方法加持的大型语言模型（LLMs）的出现，视觉推理问题被细化为易于管理的子任务，并借助多种外部工具逐步攻克。然而，这种模式在决策过程中可能会遇到“确定性幻觉”的问题，这源于视觉信息的不足以及低级感知工具无法提供进行综合推理所需的抽象总结。本文强调，将视觉上下文获取与逻辑推理相结合，对于解决视觉推理任务至关重要。本研究深入探讨了利用多模态大型语言模型（MLLMs）及其认知能力来解决复杂视觉推理任务的多模态CoT领域。我们提出了一个创新的多模态CoT框架——Cantor，它采用感知-决策架构。Cantor首先作为决策生成器，整合视觉输入以分析图像和问题，确保与实际情境的紧密结合。此外，Cantor还利用MLLMs的高级认知功能，充当多面手专家，以获取更高层次的信息，从而提升CoT生成过程。我们广泛的实验验证了所提框架的有效性，显示出在两个复杂的视觉推理数据集上，多模态CoT性能有了显著提升，且无需进行微调或依赖真实理由。项目页面：https://ggg0919.github.io/cantor/ 。

> With the advent of large language models(LLMs) enhanced by the chain-of-thought(CoT) methodology, visual reasoning problem is usually decomposed into manageable sub-tasks and tackled sequentially with various external tools. However, such a paradigm faces the challenge of the potential "determining hallucinations" in decision-making due to insufficient visual information and the limitation of low-level perception tools that fail to provide abstract summaries necessary for comprehensive reasoning. We argue that converging visual context acquisition and logical reasoning is pivotal for tackling visual reasoning tasks. This paper delves into the realm of multimodal CoT to solve intricate visual reasoning tasks with multimodal large language models(MLLMs) and their cognitive capability. To this end, we propose an innovative multimodal CoT framework, termed Cantor, characterized by a perception-decision architecture. Cantor first acts as a decision generator and integrates visual inputs to analyze the image and problem, ensuring a closer alignment with the actual context. Furthermore, Cantor leverages the advanced cognitive functions of MLLMs to perform as multifaceted experts for deriving higher-level information, enhancing the CoT generation process. Our extensive experiments demonstrate the efficacy of the proposed framework, showing significant improvements in multimodal CoT performance across two complex visual reasoning datasets, without necessitating fine-tuning or ground-truth rationales. Project Page: https://ggg0919.github.io/cantor/ .

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x2.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x3.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x4.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x5.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x6.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x7.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x8.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x9.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x10.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x11.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x12.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x13.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x14.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x15.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x16.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x17.png)

![Cantor：激发机器学习大型语言模型（MLLM）的多模态思维链](../../..//opt/data/Projects/HuggingArxiv/paper_images/2404.16033/x18.png)

[Arxiv](https://arxiv.org/abs/2404.16033)