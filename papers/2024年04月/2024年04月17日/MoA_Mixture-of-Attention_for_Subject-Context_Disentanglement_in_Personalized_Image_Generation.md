# MoA：一种注意力混合机制，专为个性化图像生成中的主体与上下文解耦而设计。

发布时间：2024年04月17日

`分类：LLM应用` `图像生成` `个性化推荐`

> MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation

# 摘要

> 我们提出了一种创新的个性化文本到图像扩散模型架构，名为“混合注意力”（MoA）。这一架构借鉴了大型语言模型中采用的专家混合机制，通过两个注意力路径分担图像生成任务：个性化分支与非个性化的先验分支。MoA的设计理念是在保留原始模型先验知识的同时，通过个性化分支对生成过程进行最小干预，该分支负责学习如何将主体嵌入到由先验分支生成的布局和上下文中。此外，MoA采用了一种创新的路由机制，用以优化各层像素在分支间的分配，从而实现个性化与通用内容创造的和谐融合。训练完成后，MoA能够辅助生成高质量、个性化的图像，这些图像不仅包含多个主体，而且在构图和互动上与原始模型生成的图像一样丰富多彩。尤为重要的是，MoA在模型原有能力和新增的个性化干预之间划出了更清晰的界限，提供了一种前所未有的、更为解耦的主体与上下文控制方式。项目详情：https://snap-research.github.io/mixture-of-attention

> We introduce a new architecture for personalization of text-to-image diffusion models, coined Mixture-of-Attention (MoA). Inspired by the Mixture-of-Experts mechanism utilized in large language models (LLMs), MoA distributes the generation workload between two attention pathways: a personalized branch and a non-personalized prior branch. MoA is designed to retain the original model's prior by fixing its attention layers in the prior branch, while minimally intervening in the generation process with the personalized branch that learns to embed subjects in the layout and context generated by the prior branch. A novel routing mechanism manages the distribution of pixels in each layer across these branches to optimize the blend of personalized and generic content creation. Once trained, MoA facilitates the creation of high-quality, personalized images featuring multiple subjects with compositions and interactions as diverse as those generated by the original model. Crucially, MoA enhances the distinction between the model's pre-existing capability and the newly augmented personalized intervention, thereby offering a more disentangled subject-context control that was previously unattainable. Project page: https://snap-research.github.io/mixture-of-attention

[Arxiv](https://arxiv.org/abs/2404.11565)