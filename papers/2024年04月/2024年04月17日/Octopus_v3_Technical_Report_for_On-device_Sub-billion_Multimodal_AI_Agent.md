# 章鱼 v3：设备端十亿级以下多模态人工智能代理技术报告

发布时间：2024年04月17日

`Agent` `人工智能` `边缘计算`

> Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent

# 摘要

> 多模态AI代理擅长处理和学习多种数据类型，如自然语言、视觉和音频输入，以指导其决策。尽管在整合视觉信息的大型语言模型（如GPT-4V）上取得了进步，但将图像数据有效转换为AI代理的可执行结果仍是一大挑战。本文提出了一个专为AI代理设计、包含功能性标记概念的多模态模型，并针对边缘设备进行了优化，模型大小精简至不到10亿参数。与GPT-4相似，我们的模型能够处理英文和中文，且能在各种边缘设备上，包括资源受限的Raspberry Pi，高效运行。

> A multimodal AI agent is characterized by its ability to process and learn from various types of data, including natural language, visual, and audio inputs, to inform its actions. Despite advancements in large language models that incorporate visual data, such as GPT-4V, effectively translating image-based data into actionable outcomes for AI agents continues to be challenging. In this paper, we introduce a multimodal model that incorporates the concept of functional token specifically designed for AI agent applications. To ensure compatibility with edge devices, our model is optimized to a compact size of less than 1B parameters. Like GPT-4, our model can process both English and Chinese. We demonstrate that this model is capable of operating efficiently on a wide range of edge devices, including as constrained as a Raspberry Pi.

![章鱼 v3：设备端十亿级以下多模态人工智能代理技术报告](../../../paper_images/2404.11459/x1.png)

[Arxiv](https://arxiv.org/abs/2404.11459)