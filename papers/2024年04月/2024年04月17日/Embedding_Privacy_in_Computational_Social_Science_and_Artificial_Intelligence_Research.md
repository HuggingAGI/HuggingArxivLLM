# 将隐私保护融入计算社会科学与人工智能研究的实践

发布时间：2024年04月17日

`分类：LLM应用` `社会科学` `数据科学`

> Embedding Privacy in Computational Social Science and Artificial Intelligence Research

# 摘要

> 隐私乃人之基本权利，它保障人们无论线上线下，都能自由地交流思想、参与社团活动、建立人际关系，而无需担心个人信息被不当收集、分析或利用，从而受到伤害。在计算社会科学、人工智能和数据科学等研究领域，保护隐私的重要性日益凸显，因为这些领域在获取新知时高度依赖个人数据。随着高级计算模型的广泛应用，如果使用不当，可能加剧隐私侵犯，对个人尤其是弱势群体，以及整个社会造成负面影响。大型语言模型（如ChatGPT）的出现已经引发了一系列隐私问题，这进一步凸显了从研究之初就应考虑隐私保护的必要性。本文旨在探讨隐私在这些领域中的作用，以及研究人员可能遇到的主要问题，并提出关键的考虑点，以确保在研究设计、数据收集与使用、分析及研究成果发布过程中，最大程度地维护参与者的隐私权益。

> Privacy is a human right. It ensures that individuals are free to engage in discussions, participate in groups, and form relationships online or offline without fear of their data being inappropriately harvested, analyzed, or otherwise used to harm them. Preserving privacy has emerged as a critical factor in research, particularly in the computational social science (CSS), artificial intelligence (AI) and data science domains, given their reliance on individuals' data for novel insights. The increasing use of advanced computational models stands to exacerbate privacy concerns because, if inappropriately used, they can quickly infringe privacy rights and lead to adverse effects for individuals - especially vulnerable groups - and society. We have already witnessed a host of privacy issues emerge with the advent of large language models (LLMs), such as ChatGPT, which further demonstrate the importance of embedding privacy from the start. This article contributes to the field by discussing the role of privacy and the primary issues that researchers working in CSS, AI, data science and related domains are likely to face. It then presents several key considerations for researchers to ensure participant privacy is best preserved in their research design, data collection and use, analysis, and dissemination of research results.

[Arxiv](https://arxiv.org/abs/2404.11515)