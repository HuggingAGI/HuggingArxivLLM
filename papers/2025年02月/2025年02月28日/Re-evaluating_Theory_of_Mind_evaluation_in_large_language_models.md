# 重新审视大型语言模型中的“心智理论”评估

发布时间：2025年02月28日

`LLM理论

摘要讨论了大型语言模型（LLMs）是否具备“心智理论”（ToM），即推理他人心理状态的能力，并分析了评估中的分歧和未来研究方向，属于LLM的理论探讨。` `认知科学` `人工智能`

> Re-evaluating Theory of Mind evaluation in large language models

# 摘要

> 大型语言模型（LLMs）是否具备“心智理论”（ToM）——即推理他人心理状态的能力——这一问题引发了科学界和公众的浓厚兴趣。然而，关于LLMs是否具备ToM的证据并不一致，近期评估数量的激增也未能达成共识。我们从认知科学中汲取灵感，重新评估LLMs中ToM评估的现状。我们认为，关于LLMs是否具备ToM存在分歧的主要原因是缺乏明确的共识：模型是否应被期望去匹配人类行为，还是去模拟支撑这些行为的计算过程。我们还指出了当前评估可能偏离“纯粹”衡量ToM能力的方式，这也加剧了混淆。最后，我们讨论了未来研究的几个方向，包括ToM与语用沟通之间的关系，这可能有助于我们更好地理解人工系统以及人类认知。

> The question of whether large language models (LLMs) possess Theory of Mind (ToM) -- often defined as the ability to reason about others' mental states -- has sparked significant scientific and public interest. However, the evidence as to whether LLMs possess ToM is mixed, and the recent growth in evaluations has not resulted in a convergence. Here, we take inspiration from cognitive science to re-evaluate the state of ToM evaluation in LLMs. We argue that a major reason for the disagreement on whether LLMs have ToM is a lack of clarity on whether models should be expected to match human behaviors, or the computations underlying those behaviors. We also highlight ways in which current evaluations may be deviating from "pure" measurements of ToM abilities, which also contributes to the confusion. We conclude by discussing several directions for future research, including the relationship between ToM and pragmatic communication, which could advance our understanding of artificial systems as well as human cognition.

[Arxiv](https://arxiv.org/abs/2502.21098)