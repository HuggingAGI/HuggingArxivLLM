# 评估个体对大型语言模型的信任并分析其影响因素

发布时间：2025年02月28日

`LLM应用` `人工智能` `人机交互`

> Measuring and identifying factors of individuals' trust in Large Language Models

# 摘要

> 大型语言模型 (LLMs) 能够进行看似人类的对话交流。尽管对话可以在用户与 LLMs 之间建立信任，但关于人类与 LLMs 互动中信任形成的实证研究仍然十分有限。为此，我们提出了一个新的框架——信任-LLMs 指数 (TILLMI)，用于衡量个人对 LLMs 的信任，并将 McAllister 的认知和情感信任维度扩展到 LLM 与人类的互动中。我们通过创新性地设计了一种名为 LLM 模拟效度的协议，开发了 TILLMI 作为一个心理测量量表。随后，基于 LLM 的量表在 1,000 名美国受访者样本中进行了验证。探索性因子分析确定了两个因子结构，最终移除了两个冗余的项目，得到了一个包含 6 个项目、具有两个因子结构的量表。在独立的子样本上进行的验证性因子分析显示了良好的模型拟合度（$CFI = .995$，$TLI = .991$，$RMSEA = .046$，$p_{X^2} > .05$）。聚合效度分析表明，对 LLMs 的信任与开放性、外向性和认知灵活性呈正相关，而与神经质呈负相关。基于这些发现，我们将 TILLMI 的因子解释为“与 LLMs 的亲密感”（情感维度）和“对 LLMs 的依赖”（认知维度）。研究发现，与年长女性相比，年轻男性表现出更高的与 LLMs 的亲密感和依赖度。此外，没有直接使用过 LLMs 的个体相比 LLMs 用户表现出较低的信任水平。这些发现为衡量基于 AI 的语言交流中的信任提供了新的实证基础，为负责任的设计提供了指导，并促进了平衡的人工智能与人类协作。

> Large Language Models (LLMs) can engage in human-looking conversational exchanges. Although conversations can elicit trust between users and LLMs, scarce empirical research has examined trust formation in human-LLM contexts, beyond LLMs' trustworthiness or human trust in AI in general. Here, we introduce the Trust-In-LLMs Index (TILLMI) as a new framework to measure individuals' trust in LLMs, extending McAllister's cognitive and affective trust dimensions to LLM-human interactions. We developed TILLMI as a psychometric scale, prototyped with a novel protocol we called LLM-simulated validity. The LLM-based scale was then validated in a sample of 1,000 US respondents. Exploratory Factor Analysis identified a two-factor structure. Two items were then removed due to redundancy, yielding a final 6-item scale with a 2-factor structure. Confirmatory Factor Analysis on a separate subsample showed strong model fit ($CFI = .995$, $TLI = .991$, $RMSEA = .046$, $p_{X^2} > .05$). Convergent validity analysis revealed that trust in LLMs correlated positively with openness to experience, extraversion, and cognitive flexibility, but negatively with neuroticism. Based on these findings, we interpreted TILLMI's factors as "closeness with LLMs" (affective dimension) and "reliance on LLMs" (cognitive dimension). Younger males exhibited higher closeness with- and reliance on LLMs compared to older women. Individuals with no direct experience with LLMs exhibited lower levels of trust compared to LLMs' users. These findings offer a novel empirical foundation for measuring trust in AI-driven verbal communication, informing responsible design, and fostering balanced human-AI collaboration.

[Arxiv](https://arxiv.org/abs/2502.21028)