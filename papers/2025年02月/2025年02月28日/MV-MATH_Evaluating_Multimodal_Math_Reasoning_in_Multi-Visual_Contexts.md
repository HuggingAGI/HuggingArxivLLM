# MV-MATH：测评多模态数学推理在多视觉情境下的表现

发布时间：2025年02月28日

`LLM应用` `数学教育` `教育数据集`

> MV-MATH: Evaluating Multimodal Math Reasoning in Multi-Visual Contexts

# 摘要

> 多模态大语言模型 (MLLMs) 在视觉环境下的数学推理能力在各类数据集中展现出了令人鼓舞的潜力。然而，现有的大多数多模态数学基准测试仅限于单一视觉环境，这与现实世界中数学应用中常见的多视觉场景相去甚远。为了解决这一差距，我们引入了 MV-MATH：一个精心策划的包含 2,009 个高质量数学问题的 dataset。每个问题都集成了多张图像与文本交织，源自真实的 K-12 场景，并配有详细的注释。MV-MATH 包括选择题、自由形式和多步骤问题，涵盖 11 个学科领域，分为 3 个难度级别，作为评估 MLLMs 在多视觉环境下的数学推理能力的全面且严格的基准。通过广泛的实验，我们发现 MLLMs 在多视觉数学任务中面临重大挑战，在 MV-MATH 上与人类能力相比存在显著的性能差距。此外，我们分析了各种模型的性能和错误模式，为理解 MLLMs 在多视觉环境下的数学推理能力提供了见解。

> Multimodal Large Language Models (MLLMs) have shown promising capabilities in mathematical reasoning within visual contexts across various datasets. However, most existing multimodal math benchmarks are limited to single-visual contexts, which diverges from the multi-visual scenarios commonly encountered in real-world mathematical applications. To address this gap, we introduce MV-MATH: a meticulously curated dataset of 2,009 high-quality mathematical problems. Each problem integrates multiple images interleaved with text, derived from authentic K-12 scenarios, and enriched with detailed annotations. MV-MATH includes multiple-choice, free-form, and multi-step questions, covering 11 subject areas across 3 difficulty levels, and serves as a comprehensive and rigorous benchmark for assessing MLLMs' mathematical reasoning in multi-visual contexts. Through extensive experimentation, we observe that MLLMs encounter substantial challenges in multi-visual math tasks, with a considerable performance gap relative to human capabilities on MV-MATH. Furthermore, we analyze the performance and error patterns of various models, providing insights into MLLMs' mathematical reasoning capabilities within multi-visual settings.

[Arxiv](https://arxiv.org/abs/2502.20808)