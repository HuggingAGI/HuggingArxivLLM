# # 摘要
利用多智能体大语言模型模拟合作利他行为：为AI智能体提供支持政策决策的证据与机制

发布时间：2025年02月17日

`Agent` `社会学` `人工智能`

> Simulating Cooperative Prosocial Behavior with Multi-Agent LLMs: Evidence and Mechanisms for AI Agents to Inform Policy Decisions

# 摘要

> 人类的亲社会合作行为对集体健康、教育和福利至关重要。然而，设计能够维持或激励亲社会行为的社会系统充满挑战，因为人们往往出于自私心理，追求个人利益最大化。这种复杂且难以预测的行为特征让政策制定者难以预见其设计的后果。最近，多智能体LLM系统在模拟人类行为和复制部分实验室实验方面展现出了非凡的能力。本文研究了多智能体系统在模拟亲社会行为（如公共物品博弈（PGG）中所见的行为）方面的表现，以及它们是否能够展现出与现实世界中实验室外所见的“无界行为”。我们发现，多智能体LLM系统成功地复制了公共物品博弈实验中三种实验处理（启动、透明度和不同初始禀赋）下的人类行为。除了复制现有实验外，我们还发现，当结合不同的实验处理时，多智能体LLM系统能够复制预期的亲社会行为，即使之前没有研究将这些特定的处理结合在一起。最后，我们发现，多智能体系统能够展现出一系列丰富的无界行为，这些行为与人们在现实世界中实验室外的行为相似，例如合作甚至作弊。总之，这些研究为未来利用LLMs辅助制定鼓励亲社会行为的政策奠定了基础。

> Human prosocial cooperation is essential for our collective health, education, and welfare. However, designing social systems to maintain or incentivize prosocial behavior is challenging because people can act selfishly to maximize personal gain. This complex and unpredictable aspect of human behavior makes it difficult for policymakers to foresee the implications of their designs. Recently, multi-agent LLM systems have shown remarkable capabilities in simulating human-like behavior, and replicating some human lab experiments. This paper studies how well multi-agent systems can simulate prosocial human behavior, such as that seen in the public goods game (PGG), and whether multi-agent systems can exhibit ``unbounded actions'' seen outside the lab in real world scenarios. We find that multi-agent LLM systems successfully replicate human behavior from lab experiments of the public goods game with three experimental treatments - priming, transparency, and varying endowments. Beyond replicating existing experiments, we find that multi-agent LLM systems can replicate the expected human behavior when combining experimental treatments, even if no previous study combined those specific treatments. Lastly, we find that multi-agent systems can exhibit a rich set of unbounded actions that people do in the real world outside of the lab -- such as collaborating and even cheating. In sum, these studies are steps towards a future where LLMs can be used to inform policy decisions that encourage people to act in a prosocial manner.

[Arxiv](https://arxiv.org/abs/2502.12504)