# AI拟仿与尊严：聊天机器人使用或冒犯自尊

发布时间：2025年02月17日

`LLM应用` `伦理学`

> AI Mimicry and Human Dignity: Chatbot Use as a Violation of Self-Respect

# 摘要

> 本文探讨了人类与AI驱动的聊天机器人互动可能冒犯人类尊严的方式。目前由大型语言模型（LLMs）驱动的聊天机器人模仿了人类的语言行为，但却缺乏实现真正人际尊重所需的关键道德和理性能力。人类倾向于将聊天机器人拟人化，而聊天机器人的设计似乎有意引发这种反应。因此，人类与聊天机器人的互动往往呈现出道德主体之间典型互动的行为模式。基于一种二阶关系尊严观，我们认为以这种方式与聊天机器人互动与用户的尊严不符。由于二阶尊重建立在对二阶权威的相互认可基础上，而缺乏这种相互性，因此以表达二阶尊重的方式对待聊天机器人注定会以道德上令人困扰的方式失败。因此，这种聊天机器人互动构成了对自我尊重的微妙但严重的侵犯：即我们有义务对自己的尊严表示尊重。通过讨论四个实际的聊天机器人使用案例（信息检索、客户服务、咨询和陪伴），我们说明了这一点，并提出观点：社会日益增长的与聊天机器人进行此类互动的压力，构成了一个迄今未被充分认识到的人类尊严威胁。

> This paper investigates how human interactions with AI-powered chatbots may offend human dignity. Current chatbots, driven by large language models (LLMs), mimic human linguistic behaviour but lack the moral and rational capacities essential for genuine interpersonal respect. Human beings are prone to anthropomorphise chatbots. Indeed, chatbots appear to be deliberately designed to elicit that response. As a result, human beings' behaviour toward chatbots often resembles behaviours typical of interaction between moral agents. Drawing on a second-personal, relational account of dignity, we argue that interacting with chatbots in this way is incompatible with the dignity of users. We show that, since second-personal respect is premised on reciprocal recognition of second-personal authority, behaving towards chatbots in ways that convey second-personal respect is bound to misfire in morally problematic ways, given the lack of reciprocity. Consequently, such chatbot interactions amount to subtle but significant violations of self-respect: the respect we are dutybound to show for our own dignity. We illustrate this by discussing four actual chatbot use cases (information retrieval, customer service, advising, and companionship), and propound that the increasing societal pressure to engage in such interactions with chatbots poses a hitherto underappreciated threat to human dignity.

[Arxiv](https://arxiv.org/abs/2503.05723)