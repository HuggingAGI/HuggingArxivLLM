# 探索大型语言模型在医疗领域的潜力：洞察语料来源、定制策略与评估指标

发布时间：2025年02月17日

`LLM应用` `医疗AI`

> Exploring Large Language Models in Healthcare: Insights into Corpora Sources, Customization Strategies, and Evaluation Metrics

# 摘要

> 本研究全面梳理了大型语言模型（LLMs）在医疗领域的应用现状，重点关注训练语料库构建、模型定制技术和评估指标体系。通过对2021年至2024年的相关研究进行系统性检索，最终筛选出61篇文献。研究发现，医疗领域LLMs的训练语料来源主要包括临床资源、学术文献、开源数据集以及网络爬取数据四大类。在模型构建技术方面，预训练、提示工程和增强检索生成是最常见的三大技术，其中44项研究采用了多技术融合方案。从评估体系来看，现有指标可分为过程性指标、可用性指标和效果性指标三大类，其中效果性指标又可细分为模型自动生成结果和专家人工评估结果。研究还揭示了当前医疗领域LLMs应用中存在的两大关键性问题：一是语料库公平性不足，导致模型存在地理、文化和社会经济等多重偏见；二是对未经验证或非结构化数据的过度依赖，凸显了将循证医学指南与模型开发更好结合的迫切需求。未来研究应着重开发基于分层架构的语料库体系，采用经过严格筛选的来源和动态权重机制，同时确保模型的可解释性。此外，鉴于当前领域专用模型缺乏统一的评估框架，建议在真实医疗场景中对LLMs进行全面验证和评估。

> This study reviewed the use of Large Language Models (LLMs) in healthcare, focusing on their training corpora, customization techniques, and evaluation metrics. A systematic search of studies from 2021 to 2024 identified 61 articles. Four types of corpora were used: clinical resources, literature, open-source datasets, and web-crawled data. Common construction techniques included pre-training, prompt engineering, and retrieval-augmented generation, with 44 studies combining multiple methods. Evaluation metrics were categorized into process, usability, and outcome metrics, with outcome metrics divided into model-based and expert-assessed outcomes. The study identified critical gaps in corpus fairness, which contributed to biases from geographic, cultural, and socio-economic factors. The reliance on unverified or unstructured data highlighted the need for better integration of evidence-based clinical guidelines. Future research should focus on developing a tiered corpus architecture with vetted sources and dynamic weighting, while ensuring model transparency. Additionally, the lack of standardized evaluation frameworks for domain-specific models called for comprehensive validation of LLMs in real-world healthcare settings.

[Arxiv](https://arxiv.org/abs/2502.11861)