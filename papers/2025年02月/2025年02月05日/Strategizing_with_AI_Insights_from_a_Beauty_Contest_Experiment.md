# AI策略制定：选美比赛实验的启示

发布时间：2025年02月05日

`LLM应用

理由：这篇论文主要探讨了大型语言模型（LLMs）在凯恩斯选美比赛中的行为表现，并与人类玩家进行了对比。研究通过虚拟实验测试了LLMs在不同情境下的策略调整能力，展示了LLMs在识别和适应战略环境方面的能力。这属于LLM在实际应用场景中的表现研究，因此归类为LLM应用。` `行为经济学` `人工智能`

> Strategizing with AI: Insights from a Beauty Contest Experiment

# 摘要

> 凯恩斯选美比赛是一类广泛的游戏，玩家需猜测其他玩家中最受欢迎的策略。特别是，猜测所有玩家所选数字平均值的一部分，是一个经典的行为实验，旨在测试不同人群的迭代推理模式。以往研究表明，对手的复杂程度是影响游戏结果的关键因素。更聪明的决策者会选择更接近理论纳什均衡的策略，并在信息揭示的迭代比赛中更快收敛。我们通过虚拟实验复制了一系列经典实验，使用现代大型语言模型（LLMs）与不同虚拟玩家群体对抗。我们测试了LLMs的行为与人类玩家相比的先进性。结果显示，LLMs通常会考虑对手的复杂程度，并通过调整策略来适应。在各种设置中，大多数LLMs（除Llama外）比人类玩家更复杂，且选择更低的数字。我们的结果表明，LLMs（除Llama外）在识别潜在战略环境并适应游戏参数变化方面相当成功，与人类玩家类似。然而，所有LLMs在双人游戏中仍无法采用主导策略。这些结果为讨论人工智能对人类经济代理的建模准确性提供了新的视角。

> A Keynesian beauty contest is a wide class of games of guessing the most popular strategy among other players. In particular, guessing a fraction of a mean of numbers chosen by all players is a classic behavioral experiment designed to test iterative reasoning patterns among various groups of people. The previous literature reveals that the level of sophistication of the opponents is an important factor affecting the outcome of the game. Smarter decision makers choose strategies that are closer to theoretical Nash equilibrium and demonstrate faster convergence to equilibrium in iterated contests with information revelation. We replicate a series of classic experiments by running virtual experiments with modern large language models (LLMs) who play against various groups of virtual players. We test how advanced the LLMs' behavior is compared to the behavior of human players. We show that LLMs typically take into account the opponents' level of sophistication and adapt by changing the strategy. In various settings, most LLMs (with the exception of Llama) are more sophisticated and play lower numbers compared to human players. Our results suggest that LLMs (except Llama) are rather successful in identifying the underlying strategic environment and adopting the strategies to the changing set of parameters of the game in the same way that human players do. All LLMs still fail to play dominant strategies in a two-player game. Our results contribute to the discussion on the accuracy of modeling human economic agents by artificial intelligence.

[Arxiv](https://arxiv.org/abs/2502.03158)