# 大型语言模型 (LLMs) 中的后门威胁综述：攻击、防御与评估

发布时间：2025年02月05日

`LLM理论` `网络安全` `大型语言模型`

> A Survey on Backdoor Threats in Large Language Models (LLMs): Attacks, Defenses, and Evaluations

# 摘要

> 大型语言模型（LLMs）在理解和生成人类语言文本方面已展现出卓越的能力，近年来备受关注。除了其在自然语言处理（NLP）领域的顶尖表现，考虑到其在医疗、金融、教育等行业的广泛应用，对其使用的安全问题也日益受到重视。近年来，随着防御机制的提升以及大型语言模型功能的完善，后门攻击的演变也在持续发展。本文基于机器学习攻击的通用分类法，专注于其中一种细分类型——训练时间白盒后门攻击进行分类研究。我们不仅系统地梳理了攻击方法，还探讨了相应的防御策略。通过全面总结现有研究成果，我们希望这项调查能为未来研究提供指导，进一步拓展攻击场景，并为更强大的大型语言模型构建更 robust 的防御体系。

> Large Language Models (LLMs) have achieved significantly advanced capabilities in understanding and generating human language text, which have gained increasing popularity over recent years. Apart from their state-of-the-art natural language processing (NLP) performance, considering their widespread usage in many industries, including medicine, finance, education, etc., security concerns over their usage grow simultaneously. In recent years, the evolution of backdoor attacks has progressed with the advancement of defense mechanisms against them and more well-developed features in the LLMs. In this paper, we adapt the general taxonomy for classifying machine learning attacks on one of the subdivisions - training-time white-box backdoor attacks. Besides systematically classifying attack methods, we also consider the corresponding defense methods against backdoor attacks. By providing an extensive summary of existing works, we hope this survey can serve as a guideline for inspiring future research that further extends the attack scenarios and creates a stronger defense against them for more robust LLMs.

[Arxiv](https://arxiv.org/abs/2502.05224)