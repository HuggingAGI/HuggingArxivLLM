# # 非人类实体的专门化探讨

发布时间：2025年02月05日

`其他` `人工智能` `系统工程`

> A case for specialisation in non-human entities

# 摘要

> 随着大型多模态AI模型的兴起，人工通用智能（AGI）的概念已从边缘社区的专有领域，逐渐主导了主流大型AI开发计划。然而，本文的观点截然不同。我们通过回顾通用性带来的陷阱，并强调专业化系统在工业上的价值，来为专业化而辩护。我们的贡献有三方面。首先，我们回顾了最被广泛接受的反对专业化的论点，并讨论了这些论点在人类劳动背景下的相关性，实际上是对非人类代理（无论是算法还是人类组织）专业化的论点。其次，我们提出了四个支持专业化的论点，涵盖了机器学习稳健性、计算机安全、社会科学和文化进化。最后，我们为具体化（specification）而辩护，讨论了机器学习在AI中的方法迄今为止未能跟上安全工程和软件形式化验证的良好实践，以及机器学习中的一些新兴良好实践如何有助于缩小这一差距。特别地，我们论证了对难以具体化的系统进行具体化治理的必要性。

> With the rise of large multi-modal AI models, fuelled by recent interest in large language models (LLMs), the notion of artificial general intelligence (AGI) went from being restricted to a fringe community, to dominate mainstream large AI development programs.
  In contrast, in this paper, we make a \emph{case for specialisation}, by reviewing the pitfalls of generality and stressing the industrial value of specialised
  systems.
  Our contribution is threefold. First, we review the most widely accepted arguments \emph{against} specialisation, and discuss how their relevance in the context of human labour is actually an argument \emph{for} specialisation in the case of non human agents, be they algorithms or human organisations. Second, we propose four arguments \emph{in favor of} specialisation, ranging from machine learning robustness, to computer security, social sciences and cultural evolution.
  Third, we finally make a case for \emph{specification}, discuss how the machine learning approach to AI has so far failed to catch up with good practices from safety-engineering and formal verification of software, and discuss how some emerging good practices in machine learning help reduce this gap.
  In particular, we justify the need for \emph{specified governance} for hard-to-specify systems.

[Arxiv](https://arxiv.org/abs/2503.04742)