# # 系统化权重评估：优化大型语言模型性能与可持续性
系统化权重评估是提升大型语言模型性能与可持续性的关键方法。通过系统化的权重评估，我们可以有效优化模型的性能表现，同时确保其在实际应用中的可持续性。这种方法不仅能够提升模型的效率，还能降低资源消耗，为实际应用提供更高效的解决方案。

发布时间：2025年02月24日

`LLM理论` `可持续发展` `人工智能`

> Systematic Weight Evaluation for Pruning Large Language Models: Enhancing Performance and Sustainability

# 摘要

> 像ChatGPT这样的大型语言模型（LLMs）的指数级增长，引领了人工智能领域的革命性变革，赋予了我们在自然语言处理方面前所未有的能力。然而，这些模型的训练需要消耗大量计算资源，带来了显著的环境影响，包括高碳排放、能源消耗和用水量。本研究提出了一种新型的LLM剪枝方法，通过系统性地评估训练过程中每个权重的重要性，我们提出了一种有效减小模型规模而不降低性能的方法。通过监控参数随时间的演变，我们在缩小版的LLM和大型多模态模型上进行了广泛实验，发现适度的剪枝不仅提高了效率，还减少了损失，而过度的剪枝则会导致模型性能严重下降。这些发现强调了优化AI模型的紧迫性，以确保可持续发展，平衡技术进步与环境责任。

> The exponential growth of large language models (LLMs) like ChatGPT has revolutionized artificial intelligence, offering unprecedented capabilities in natural language processing. However, the extensive computational resources required for training these models have significant environmental implications, including high carbon emissions, energy consumption, and water usage. This research presents a novel approach to LLM pruning, focusing on the systematic evaluation of individual weight importance throughout the training process. By monitoring parameter evolution over time, we propose a method that effectively reduces model size without compromising performance. Extensive experiments with both a scaled-down LLM and a large multimodal model reveal that moderate pruning enhances efficiency and reduces loss, while excessive pruning drastically deteriorates model performance. These findings highlight the critical need for optimized AI models to ensure sustainable development, balancing technological advancement with environmental responsibility.

[Arxiv](https://arxiv.org/abs/2502.17071)