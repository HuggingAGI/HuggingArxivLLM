# STRIDE：人形机器人运动中奖励设计、深度强化学习训练与反馈优化的自动化方法

发布时间：2025年02月07日

`Agent` `人形机器人` `人工智能`

> STRIDE: Automating Reward Design, Deep Reinforcement Learning Training and Feedback Optimization in Humanoid Robotics Locomotion

# 摘要

> 人形机器人领域在人工智能中面临诸多挑战，需要对高自由度系统进行精确的协调与控制。在深度强化学习（DRL）领域中，为该领域设计有效的奖励函数仍然是一个关键瓶颈，需要大量手动 effort、领域专业知识和迭代优化。为了解决这些挑战，我们引入了STRIDE，一个基于智能体工程的全新框架，旨在为人形机器人运动任务自动设计奖励函数、训练DRL模型并优化反馈机制。通过结合智能体工程的结构化原则与大型语言模型（LLMs）在代码编写、零样本生成和上下文优化方面的功能，STRIDE能够自动生成、评估并迭代优化奖励函数，无需依赖特定任务的提示或模板。在多种不同的人形机器人形态学环境中，STRIDE的表现优于现有的奖励设计框架EUREKA，在效率和任务性能上实现了显著提升。通过使用STRIDE生成的奖励函数，模拟的人形机器人能够在复杂地形上实现竞速级别的运动，凸显了其在推动DRL工作流程和人形机器人研究方面的能力。

> Humanoid robotics presents significant challenges in artificial intelligence, requiring precise coordination and control of high-degree-of-freedom systems. Designing effective reward functions for deep reinforcement learning (DRL) in this domain remains a critical bottleneck, demanding extensive manual effort, domain expertise, and iterative refinement. To overcome these challenges, we introduce STRIDE, a novel framework built on agentic engineering to automate reward design, DRL training, and feedback optimization for humanoid robot locomotion tasks. By combining the structured principles of agentic engineering with large language models (LLMs) for code-writing, zero-shot generation, and in-context optimization, STRIDE generates, evaluates, and iteratively refines reward functions without relying on task-specific prompts or templates. Across diverse environments featuring humanoid robot morphologies, STRIDE outperforms the state-of-the-art reward design framework EUREKA, achieving significant improvements in efficiency and task performance. Using STRIDE-generated rewards, simulated humanoid robots achieve sprint-level locomotion across complex terrains, highlighting its ability to advance DRL workflows and humanoid robotics research.

[Arxiv](https://arxiv.org/abs/2502.04692)