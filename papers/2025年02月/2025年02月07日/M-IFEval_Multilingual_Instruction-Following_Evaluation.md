# M-IFEval: 多语言指令执行评估

发布时间：2025年02月07日

`LLM应用

理由：这篇论文主要讨论了多语言指令遵循评估（M-IFEval）基准的开发和应用，用于评估大型语言模型（LLMs）在多语言环境下的性能。这属于LLM在实际应用中的评估和改进，因此归类为LLM应用。` `多语言评估`

> M-IFEval: Multilingual Instruction-Following Evaluation

# 摘要

> 指令遵循是现代大型语言模型（LLMs）的核心能力，评估这一能力对理解模型至关重要。文献中的指令遵循评估（IFEval）基准通过客观标准衡量LLM性能，无需主观判断。然而，它仅支持英语指令，限制了多语言评估能力。我们提出了多语言指令遵循评估（M-IFEval）基准，涵盖法语、日语和西班牙语，包括通用和特定语言的指令。应用于8个顶尖LLMs后，我们发现不同语言和指令类型的性能差异显著，凸显了多语言基准在多样化文化背景下评估LLMs的重要性。

> Instruction following is a core capability of modern Large language models (LLMs), making evaluating this capability essential to understanding these models. The Instruction Following Evaluation (IFEval) benchmark from the literature does this using objective criteria, offering a measure of LLM performance without subjective AI or human judgement. However, it only includes English instructions, limiting its ability to assess LLMs in other languages.
  We propose the Multilingual Instruction Following Evaluation (M-IFEval) benchmark, expanding the evaluation to French, Japanese, and Spanish, with both general and language-specific instructions. Applying this benchmark to 8 state-of-the-art LLMs, we find that benchmark performance across languages and instruction types can vary widely, underscoring the importance of a multilingual benchmark for evaluating LLMs in a diverse cultural context.

[Arxiv](https://arxiv.org/abs/2502.04688)