# ## 专为6G设计的移动网络专用大型语言模型：架构、创新、挑战与未来趋势

发布时间：2025年02月07日

`LLM应用` `6G网络`

> Mobile Network-specialized Large Language Models for 6G: Architectures, Innovations, Challenges, and Future Trends

# 摘要

> 传统5G网络管理机制在各自为战的孤立模式下运行，难以应对6G网络的超复杂性和大规模化。因此，整体智能和端到端自动化成为6G网络的关键使能者。大型语言模型（LLM）作为生成AI领域的重大突破，具备类人语言处理、上下文推理和多模态能力，助力网络行为的整体理解与自主决策。本文探讨了四种集成LLM与6G网络的架构设计，分析了每种设计的技术挑战、优势与局限。作为6G网络的功能模块，LLM将从设计初期受益于更完善的安全策略。通过切片冲突场景，我们验证了架构框架在自主处理网络异常方面的有效性。最后，我们总结了移动网络专用LLM的关键挑战与研究趋势，为移动网络运营商（MNOs）拥抱LLM技术提供全面指导。

> Conventional 5G network management mechanisms, that operate in isolated silos across different network segments, will experience significant limitations in handling the unprecedented hyper-complexity and massive scale of the sixth generation (6G). Holistic intelligence and end-to-end automation are, thus, positioned as key enablers of forthcoming 6G networks. The Large Language Model (LLM) technology, a major breakthrough in the Generative Artificial Intelligence (AI) field, enjoys robust human-like language processing, advanced contextual reasoning and multi-modal capabilities. These features foster a holistic understanding of network behavior and an autonomous decision-making. This paper investigates four possible architectural designs for integrated LLM and 6G networks, detailing the inherent technical intricacies, the merits and the limitations of each design. As an internal functional building block of future 6G networks, the LLM will natively benefit from their improved design-driven security policies from the early design and specification stages. An illustrative scenario of slicing conflicts is used to prove the effectiveness of our architectural framework in autonomously dealing with complicated network anomalies. We finally conclude the paper with an overview of the key challenges and the relevant research trends for enabling Mobile Networkspecialized LLMs. This study is intended to provide Mobile Network Operators (MNOs) with a comprehensive guidance in their paths towards embracing the LLM technology.

[Arxiv](https://arxiv.org/abs/2502.04933)