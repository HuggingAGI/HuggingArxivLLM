# 挑战者：一个对抗学习增强的文本摘要框架

发布时间：2025年02月07日

`LLM应用

摘要中提到论文讨论了大型语言模型在协作任务中的应用，特别是通过对抗学习的提示框架来解决内容生成的幻觉问题和缺乏具体性的问题。该研究主要关注如何在实际应用中改进LLM的表现，属于LLM的应用层面。` `文本摘要`

> ChallengeMe: An Adversarial Learning-enabled Text Summarization Framework

# 摘要

> 大型语言模型 (LLMs) 凭借其卓越性能与实际应用中的突出表现，在协作任务中得到了广泛应用。然而，这些模型在垂直领域任务中仍面临内容生成的幻觉问题和缺乏具体性等挑战。受人类认知过程中对比与分类机制的启发，本文提出了一种基于对抗学习的提示框架 ChallengeMe，该框架包含生成提示、评估提示和反馈优化三个级联解决方案。研究过程中，我们设计了七个核心优化维度，并为对抗学习设定了阈值。实验结果表明，在文本摘要任务中，与当前先进的主流 LLM 相比，ChallengeMe 框架能够生成更加准确和流畅的文本摘要。

> The astonishing performance of large language models (LLMs) and their remarkable achievements in production and daily life have led to their widespread application in collaborative tasks. However, current large models face challenges such as hallucination and lack of specificity in content generation in vertical domain tasks. Inspired by the contrast and classification mechanisms in human cognitive processes, this paper constructs an adversarial learning-based prompt framework named ChallengeMe, which includes three cascaded solutions: generation prompts, evaluation prompts, and feedback optimization. In this process, we designed seven core optimization dimensions and set the threshold for adversarial learning. The results of mixed case studies on the text summarization task show that the proposed framework can generate more accurate and fluent text summaries compared to the current advanced mainstream LLMs.

[Arxiv](https://arxiv.org/abs/2502.05084)