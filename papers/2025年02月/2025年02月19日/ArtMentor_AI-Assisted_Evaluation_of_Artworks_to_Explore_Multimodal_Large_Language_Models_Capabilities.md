# ArtMentor: 利用AI辅助艺术作品评估，深入探索多模态大型语言模型的能力

发布时间：2025年02月19日

`LLM应用` `艺术教育`

> ArtMentor: AI-Assisted Evaluation of Artworks to Explore Multimodal Large Language Models Capabilities

# 摘要

> MLLMs能否在艺术评估对话中独立担任助手角色？当前依赖主观评分或昂贵访谈的MLLM评估方法难以覆盖各类场景。本文提出了一种流程导向的人机交互（HCI）空间设计方案，旨在提升MLLM评估的准确性和开发效率。该方案不仅助力教师高效完成艺术评估，还能通过记录交互过程来评估MLLM的能力。我们推出了ArtMentor，一个集数据集与三大系统于一体的综合平台，专为优化MLLM评估而设计。该数据集收录了五位艺术教师在九个关键维度上的380个对话记录。模块化系统包含实体识别、评论生成和建议生成三大功能模块，支持持续迭代升级。借助机器学习和自然语言处理技术，评估结果更具可靠性。实验证明，GPT-4o在协助教师进行艺术评估对话方面表现优异。更多成果请访问https://artmentor.github.io/。

> Can Multimodal Large Language Models (MLLMs), with capabilities in perception, recognition, understanding, and reasoning, function as independent assistants in art evaluation dialogues? Current MLLM evaluation methods, which rely on subjective human scoring or costly interviews, lack comprehensive coverage of various scenarios. This paper proposes a process-oriented Human-Computer Interaction (HCI) space design to facilitate more accurate MLLM assessment and development. This approach aids teachers in efficient art evaluation while also recording interactions for MLLM capability assessment. We introduce ArtMentor, a comprehensive space that integrates a dataset and three systems to optimize MLLM evaluation. The dataset consists of 380 sessions conducted by five art teachers across nine critical dimensions. The modular system includes agents for entity recognition, review generation, and suggestion generation, enabling iterative upgrades. Machine learning and natural language processing techniques ensure the reliability of evaluations. The results confirm GPT-4o's effectiveness in assisting teachers in art evaluation dialogues. Our contributions are available at https://artmentor.github.io/.

[Arxiv](https://arxiv.org/abs/2502.13832)