# AI 软件工程师：以信任为本的编程

发布时间：2025年02月19日

`LLM应用` `软件工程` `可信编程`

> AI Software Engineer: Programming with Trust

# 摘要

> 大型语言模型 (LLMs) 在生成代码片段方面表现出了惊人的熟练程度，有望通过人工智能 (AI) 自动化软件工程的大部分工作。我们认为，成功部署 AI 软件工程师需要与人类驱动的软件工程实践建立的相同甚至更高的信任水平。最近向 LLM 代理发展的趋势提供了一条将 LLM 创建新代码的能力与分析工具增强代码信任的能力相结合的途径。本文探讨了 LLM 代理是否可能在未来主导软件工程工作流，以及编程的焦点是否将从大规模编程转向可信编程。

> Large Language Models (LLMs) have shown surprising proficiency in generating code snippets, promising to automate large parts of software engineering via artificial intelligence (AI). We argue that successfully deploying AI software engineers requires a level of trust equal to or even greater than the trust established by human-driven software engineering practices. The recent trend toward LLM agents offers a path toward integrating the power of LLMs to create new code with the power of analysis tools to increase trust in the code. This opinion piece comments on whether LLM agents could dominate software engineering workflows in the future and whether the focus of programming will shift from programming at scale to programming with trust.

[Arxiv](https://arxiv.org/abs/2502.13767)