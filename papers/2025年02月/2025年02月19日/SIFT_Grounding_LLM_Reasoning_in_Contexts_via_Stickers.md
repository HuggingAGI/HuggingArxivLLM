# SIFT：通过贴纸将 LLM 推理植根于上下文情境中

发布时间：2025年02月19日

`LLM理论` `人工智能`

> SIFT: Grounding LLM Reasoning in Contexts via Stickers

# 摘要

> 本文发现，从较小的模型Llama3.2-3B-Instruct到最先进的模型DeepSeek-R1，大型语言模型（LLM）在推理过程中对上下文的误读是一个普遍存在的重大问题。例如，在短语“10美元每公斤”中，模型可能未能识别“per”意为“每个”，从而导致计算错误。为此，我们提出了一种名为**Stick to the Facts (SIFT)**的创新后训练方法。SIFT通过增加推理时的计算资源，使模型推理更紧密地基于上下文。其核心是*Sticker*，由模型自身生成，以明确强调上下文中的关键信息。基于精心整理的Sticker，SIFT会生成两个预测结果——一个来自原始查询，另一个来自通过Sticker增强的查询。如果两者存在差异，则通过*forward*优化（以更好地使提取的事实与查询对齐）和*inverse*生成（以符合模型的内在倾向）逐步优化Sticker，从而获得更忠实的推理结果。在不同规模的模型（从3B到100B+）和多个基准测试（如GSM8K、MATH-500）上的研究表明，SIFT均能带来一致的性能提升。值得注意的是，SIFT将DeepSeek-R1在AIME2024上的pass@1准确率从78.33%提升至**85.67**%，在开源社区中树立了新的标杆。代码可在https://github.com/zhijie-group/SIFT获取。

> This paper identifies the misinterpretation of the context can be a significant issue during the reasoning process of large language models, spanning from smaller models like Llama3.2-3B-Instruct to cutting-edge ones like DeepSeek-R1. For example, in the phrase "10 dollars per kilo," LLMs might not recognize that "per" means "for each," leading to calculation errors. We introduce a novel, post-training approach called **Stick to the Facts (SIFT)** to tackle this. SIFT leverages increasing inference-time compute to ground LLM reasoning in contexts. At the core of SIFT lies the *Sticker*, which is generated by the model itself to explicitly emphasize the key information within the context. Given the curated Sticker, SIFT generates two predictions -- one from the original query and one from the query augmented with the Sticker. If they differ, the Sticker is sequentially refined via *forward* optimization (to better align the extracted facts with the query) and *inverse* generation (to conform with the model's inherent tendencies) for more faithful reasoning outcomes. Studies across diverse models (from 3B to 100B+) and benchmarks (e.g., GSM8K, MATH-500) reveal consistent performance improvements. Notably, SIFT improves the pass@1 accuracy of DeepSeek-R1 on AIME2024 from 78.33% to **85.67**%, establishing a new state-of-the-art in the open-source community. The code is available at https://github.com/zhijie-group/SIFT.

[Arxiv](https://arxiv.org/abs/2502.14922)