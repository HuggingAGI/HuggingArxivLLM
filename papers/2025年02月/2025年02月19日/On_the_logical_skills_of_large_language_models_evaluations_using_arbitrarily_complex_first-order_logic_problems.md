# 大型语言模型的逻辑能力评估：基于任意复杂度的命题逻辑问题

发布时间：2025年02月19日

`LLM应用` `人工智能`

> On the logical skills of large language models: evaluations using arbitrarily complex first-order logic problems

# 摘要

> 我们提出了一种沿多维度控制复杂度的一阶逻辑语句生成方法，并利用该方法自动创建了多个数据集，这些问题涉及一阶逻辑语句在策梅洛-弗兰克尔集合论中的真假判断。尽管解决这些问题无需超出一阶逻辑和集合论基础符号的知识，但需要一定程度的规划与逻辑推理能力，而这种能力可借助生成语句的复杂度提升至任意难度。我们还对包括DeepSeek-R1和OpenAI o3-mini在内的多种大型语言模型在这些数据集上的表现进行了全面评估。所有数据集、生成代码及评估数据均已公开，可访问https://github.com/bkuckuck/logical-skills-of-llms获取。

> We present a method of generating first-order logic statements whose complexity can be controlled along multiple dimensions. We use this method to automatically create several datasets consisting of questions asking for the truth or falsity of first-order logic statements in Zermelo-Fraenkel set theory. While the resolution of these questions does not require any knowledge beyond basic notation of first-order logic and set theory, it does require a degree of planning and logical reasoning, which can be controlled up to arbitrarily high difficulty by the complexity of the generated statements. Furthermore, we do extensive evaluations of the performance of various large language models, including recent models such as DeepSeek-R1 and OpenAI's o3-mini, on these datasets. All of the datasets along with the code used for generating them, as well as all data from the evaluations is publicly available at https://github.com/bkuckuck/logical-skills-of-llms.

[Arxiv](https://arxiv.org/abs/2502.14180)