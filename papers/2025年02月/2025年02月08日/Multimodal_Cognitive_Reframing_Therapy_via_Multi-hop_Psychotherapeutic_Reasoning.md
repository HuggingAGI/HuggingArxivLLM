# # 多模式认知重构疗法：基于多跳心理治疗推理的新方法

发布时间：2025年02月08日

`LLM应用` `心理健康` `计算机视觉`

> Multimodal Cognitive Reframing Therapy via Multi-hop Psychotherapeutic Reasoning

# 摘要

> 先前研究发现大型语言模型（LLMs）在支持认知重构疗法方面具有潜力，但主要集中在文本方法上，忽视了非语言证据在实际治疗中的重要性。为弥补这一不足，我们将文本认知重构扩展至多模态领域，引入视觉线索。具体来说，我们推出了一款名为多模态认知支持对话（M2CoSC）的新数据集，将每个GPT-4生成的对话与一张反映虚拟客户面部表情的图像配对。为了更贴近真实心理治疗场景，其中面部表情引导对隐含情感证据的解读，我们提出了一种多跳心理治疗推理方法，能够显式识别并整合微妙证据。我们的实验表明，使用M2CoSC数据集，视觉-语言模型（VLMs）作为心理治疗师的表现得到显著提升。此外，多跳心理治疗推理方法使VLMs能够提供更加深思熟虑和富有同理心的建议，超越了传统提示方法的表现。


> Previous research has revealed the potential of large language models (LLMs) to support cognitive reframing therapy; however, their focus was primarily on text-based methods, often overlooking the importance of non-verbal evidence crucial in real-life therapy. To alleviate this gap, we extend the textual cognitive reframing to multimodality, incorporating visual clues. Specifically, we present a new dataset called Multi Modal-Cognitive Support Conversation (M2CoSC), which pairs each GPT-4-generated dialogue with an image that reflects the virtual client's facial expressions. To better mirror real psychotherapy, where facial expressions lead to interpreting implicit emotional evidence, we propose a multi-hop psychotherapeutic reasoning approach that explicitly identifies and incorporates subtle evidence. Our comprehensive experiments with both LLMs and vision-language models (VLMs) demonstrate that the VLMs' performance as psychotherapists is significantly improved with the M2CoSC dataset. Furthermore, the multi-hop psychotherapeutic reasoning method enables VLMs to provide more thoughtful and empathetic suggestions, outperforming standard prompting methods.

[Arxiv](https://arxiv.org/abs/2502.06873)