# 面向低资源语言的大型多模态模型：综述

发布时间：2025年02月08日

`LLM应用` `多模态技术`

> Large Multimodal Models for Low-Resource Languages: A Survey

# 摘要

> 本次综述系统性分析了将大规模多模态模型（LMMs）应用于低资源（LR）语言的技术，涵盖视觉增强、数据创建、跨模态迁移与融合策略等多个方面。通过对75种低资源语言的106项研究的全面分析，我们揭示了研究者在应对数据和计算资源有限挑战时的关键策略。研究发现，视觉信息常作为提升低资源环境下模型性能的重要桥梁，但幻觉缓解和计算效率等问题仍具挑战性。本综述旨在帮助研究人员清晰理解当前方法及其在提升LMMs对低资源语言支持方面的挑战。我们还为此创建了开源仓库：https://github.com/marianlupascu/LMM4LRL-Survey。

> In this survey, we systematically analyze techniques used to adapt large multimodal models (LMMs) for low-resource (LR) languages, examining approaches ranging from visual enhancement and data creation to cross-modal transfer and fusion strategies. Through a comprehensive analysis of 106 studies across 75 LR languages, we identify key patterns in how researchers tackle the challenges of limited data and computational resources. We find that visual information often serves as a crucial bridge for improving model performance in LR settings, though significant challenges remain in areas such as hallucination mitigation and computational efficiency. We aim to provide researchers with a clear understanding of current approaches and remaining challenges in making LMMs more accessible to speakers of LR (understudied) languages. We complement our survey with an open-source repository available at: https://github.com/marianlupascu/LMM4LRL-Survey.

[Arxiv](https://arxiv.org/abs/2502.05568)