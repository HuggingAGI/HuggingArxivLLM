# 视觉语言模型在情绪识别中的性能评测

发布时间：2025年02月08日

`LLM应用` `情感计算` `计算机视觉`

> Evaluating Vision-Language Models for Emotion Recognition

# 摘要

> 大型视觉语言模型（VLMs）在多模态推理任务中取得了突破性进展。然而，要进一步提升其与人类共情沟通的能力，改进VLMs对情感的处理与理解至关重要。尽管情感理解研究已取得显著进展，但针对情感相关任务的VLMs详细评估仍存在空白。在本研究中，我们首次对图像诱发情绪识别能力进行了全面评估。我们创建了一个情绪识别基准，并从准确性和鲁棒性两个角度研究了VLMs的表现。通过实验，我们揭示了影响情绪识别性能的关键因素，并详细分析了VLMs在这一过程中的错误类型。最后，我们通过人类评估研究，深入探讨了这些错误的潜在原因。我们的研究结果为未来VLMs的情感研究提供了重要参考。


> Large Vision-Language Models (VLMs) have achieved unprecedented success in several objective multimodal reasoning tasks. However, to further enhance their capabilities of empathetic and effective communication with humans, improving how VLMs process and understand emotions is crucial. Despite significant research attention on improving affective understanding, there is a lack of detailed evaluations of VLMs for emotion-related tasks, which can potentially help inform downstream fine-tuning efforts. In this work, we present the first comprehensive evaluation of VLMs for recognizing evoked emotions from images. We create a benchmark for the task of evoked emotion recognition and study the performance of VLMs for this task, from perspectives of correctness and robustness. Through several experiments, we demonstrate important factors that emotion recognition performance depends on, and also characterize the various errors made by VLMs in the process. Finally, we pinpoint potential causes for errors through a human evaluation study. We use our experimental results to inform recommendations for the future of emotion research in the context of VLMs.

[Arxiv](https://arxiv.org/abs/2502.05660)