# LLM 交易：深入探究 LLM 智能体在实验性资产市场中的交易行为

发布时间：2025年02月18日

`LLM应用` `金融市场`

> LLM Trading: Analysis of LLM Agent Behavior in Experimental Asset Markets

# 摘要

> 本文探讨了大型语言模型（LLMs）在经典实验金融范式中的行为表现，该范式以引发人类参与者中的泡沫和崩盘而著称。我们采用了一种已有的交易设计，其中交易者买入和卖出一种具有已知基本面价值的风险资产，并引入了多个基于LLM的交易代理，分别在单一模型市场（所有交易者都是同一LLM的实例）和混合模型“大逃杀”设置（多个LLMs在同一市场中竞争）中进行测试。研究发现，LLMs通常表现出一种“教科书理性”的方法，将资产价格定在其基本价值附近，并仅表现出轻微的泡沫形成倾向。进一步的分析表明，与人类相比，基于LLM的代理显示出更少的交易策略变化。综合来看，这些结果突显了仅依赖LLM数据来复制由人类驱动的市场现象的风险，因为关键行为特征，如大规模突发泡沫，并未能被稳健地再现。尽管LLMs显然具备战略决策的能力，但其相对一致性和理性表明，它们并不能准确模仿人类的市场动态。

> This paper explores how Large Language Models (LLMs) behave in a classic experimental finance paradigm widely known for eliciting bubbles and crashes in human participants. We adapt an established trading design, where traders buy and sell a risky asset with a known fundamental value, and introduce several LLM-based agents, both in single-model markets (all traders are instances of the same LLM) and in mixed-model "battle royale" settings (multiple LLMs competing in the same market). Our findings reveal that LLMs generally exhibit a "textbook-rational" approach, pricing the asset near its fundamental value, and show only a muted tendency toward bubble formation. Further analyses indicate that LLM-based agents display less trading strategy variance in contrast to humans. Taken together, these results highlight the risk of relying on LLM-only data to replicate human-driven market phenomena, as key behavioral features, such as large emergent bubbles, were not robustly reproduced. While LLMs clearly possess the capacity for strategic decision-making, their relative consistency and rationality suggest that they do not accurately mimic human market dynamics.

[Arxiv](https://arxiv.org/abs/2502.15800)