# G-Refer: 基于图检索增强的大型语言模型，实现可解释推荐

发布时间：2025年02月18日

`LLM应用

理由：这篇论文探讨了如何将大型语言模型（LLMs）应用于推荐系统，特别是通过结合协同过滤信息来提高推荐的可解释性。尽管提到了检索增强，但核心在于应用LLMs到推荐系统中，属于LLM的应用层面。因此，归类为LLM应用。` `推荐系统` `图结构`

> G-Refer: Graph Retrieval-Augmented Large Language Model for Explainable Recommendation

# 摘要

> 解释性推荐在提升系统透明度、有效性和可信度方面表现出显著优势，尤其在向用户传达推荐背后的逻辑方面。现有方法通常结合大型语言模型（LLMs）的生成能力和协同过滤（CF）信息，以提供个性化且可解释的推荐。从用户-项目交互图中提取的CF信息能够捕捉用户行为和偏好，这对于生成有信息量的解释至关重要。然而，图结构的复杂性使得有效提取CF信息仍具挑战。此外，现有方法在整合CF信息与LLMs时常常面临困难，这主要是由于CF信息的隐式表示以及图结构与自然语言解释之间的模态差距。为解决这些问题，我们提出了G-Refer框架，该框架利用基于图检索增强的大型语言模型（LLMs）进行解释性推荐。具体来说，我们采用一种混合图检索机制，从结构和语义两个角度检索显式的CF信号。检索到的CF信息通过图翻译机制被明确转化为人类可理解的文本，并为LLMs生成的解释提供依据。为了弥合模态差距，我们引入知识剪枝和检索增强的微调方法，以提升LLMs处理和利用CF信息生成解释的能力。大量实验表明，G-Refer在可解释性和稳定性方面均优于现有方法。代码和数据可在https://github.com/Yuhan1i/G-Refer获取。

> Explainable recommendation has demonstrated significant advantages in informing users about the logic behind recommendations, thereby increasing system transparency, effectiveness, and trustworthiness. To provide personalized and interpretable explanations, existing works often combine the generation capabilities of large language models (LLMs) with collaborative filtering (CF) information. CF information extracted from the user-item interaction graph captures the user behaviors and preferences, which is crucial for providing informative explanations. However, due to the complexity of graph structure, effectively extracting the CF information from graphs still remains a challenge. Moreover, existing methods often struggle with the integration of extracted CF information with LLMs due to its implicit representation and the modality gap between graph structures and natural language explanations. To address these challenges, we propose G-Refer, a framework using graph retrieval-augmented large language models (LLMs) for explainable recommendation. Specifically, we first employ a hybrid graph retrieval mechanism to retrieve explicit CF signals from both structural and semantic perspectives. The retrieved CF information is explicitly formulated as human-understandable text by the proposed graph translation and accounts for the explanations generated by LLMs. To bridge the modality gap, we introduce knowledge pruning and retrieval-augmented fine-tuning to enhance the ability of LLMs to process and utilize the retrieved CF information to generate explanations. Extensive experiments show that G-Refer achieves superior performance compared with existing methods in both explainability and stability. Codes and data are available at https://github.com/Yuhan1i/G-Refer.

[Arxiv](https://arxiv.org/abs/2502.12586)