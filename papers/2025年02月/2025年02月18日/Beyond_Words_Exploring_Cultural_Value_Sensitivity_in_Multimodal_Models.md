# 超越文字：探索多模态模型中的文化价值敏感性

发布时间：2025年02月18日

`LLM应用` `人工智能` `文化研究`

> Beyond Words: Exploring Cultural Value Sensitivity in Multimodal Models

# 摘要

> 基于文化背景研究大型语言模型（LLMs）中的价值对齐已成为关键研究领域。然而，类似的文化偏见在大型视觉-语言模型（VLMs）中尚未得到充分探索。随着多模态模型规模的不断扩大，评估图像是否能作为可靠的文化代理以及通过整合视觉和文本数据如何嵌入这些价值观变得日益重要。本文对不同规模的多模态模型进行了全面评估，重点关注其与文化价值观的对齐情况。我们的研究发现，与LLMs类似，VLMs对文化价值观表现出敏感性，但其在对齐这些价值观方面的表现高度依赖于上下文。尽管VLMs通过使用图像在提升价值理解方面显示出潜力，但这种对齐在不同上下文中差异显著，突显了多模态模型对齐的复杂性和尚未探索的挑战。

> Investigating value alignment in Large Language Models (LLMs) based on cultural context has become a critical area of research. However, similar biases have not been extensively explored in large vision-language models (VLMs). As the scale of multimodal models continues to grow, it becomes increasingly important to assess whether images can serve as reliable proxies for culture and how these values are embedded through the integration of both visual and textual data. In this paper, we conduct a thorough evaluation of multimodal model at different scales, focusing on their alignment with cultural values. Our findings reveal that, much like LLMs, VLMs exhibit sensitivity to cultural values, but their performance in aligning with these values is highly context-dependent. While VLMs show potential in improving value understanding through the use of images, this alignment varies significantly across contexts highlighting the complexities and underexplored challenges in the alignment of multimodal models.

[Arxiv](https://arxiv.org/abs/2502.14906)