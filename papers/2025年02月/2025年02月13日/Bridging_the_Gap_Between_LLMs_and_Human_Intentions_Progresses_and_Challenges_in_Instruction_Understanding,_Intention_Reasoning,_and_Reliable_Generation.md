# 弥合大型语言模型与人类意图之间的差距：指令理解、意图推理与可靠生成的进展与挑战

发布时间：2025年02月13日

`LLM理论` `基准测试`

> Bridging the Gap Between LLMs and Human Intentions: Progresses and Challenges in Instruction Understanding, Intention Reasoning, and Reliable Generation

# 摘要

> 大型语言模型 (LLMs) 在理解和生成方面表现出色，但在现实场景中与人类指令交互时，仍面临三大核心挑战：准确理解指令、合理推理意图以及稳定生成内容。针对复杂指令，LLMs在处理长上下文和多轮对话时表现欠佳。在意图推理方面，LLMs存在推理不一致、难以处理错误信息指令、理解模糊语言困难以及意图捕捉能力较弱等问题。就生成质量而言，LLMs可能出现内容不稳定或不道德生成的情况。本文系统分析了LLMs在这些挑战性场景中的表现，评估现有解决方案，并基于上述三大核心挑战构建了基准测试体系。最后，我们展望了未来研究方向，致力于提升LLMs在实际应用中的可靠性和适应性。

> Large language models (LLMs) have demonstrated exceptional capabilities in understanding and generation. However, when interacting with human instructions in real-world scenarios, LLMs still face significant challenges, particularly in accurately capturing and comprehending human instructions and intentions. This paper focuses on three challenges in LLM-based text generation tasks: instruction understanding, intention reasoning, and reliable generation. Regarding human complex instruction, LLMs have deficiencies in understanding long contexts and instructions in multi-round conversations. For intention reasoning, LLMs may have inconsistent command reasoning, difficulty reasoning about commands containing incorrect information, difficulty understanding user ambiguous language commands, and a weak understanding of user intention in commands. Besides, In terms of reliable generation, LLMs may have unstable generated content and unethical generation. To this end, we classify and analyze the performance of LLMs in challenging scenarios and conduct a comprehensive evaluation of existing solutions. Furthermore, we introduce benchmarks and categorize them based on the aforementioned three core challenges. Finally, we explore potential directions for future research to enhance the reliability and adaptability of LLMs in real-world applications.

[Arxiv](https://arxiv.org/abs/2502.09101)