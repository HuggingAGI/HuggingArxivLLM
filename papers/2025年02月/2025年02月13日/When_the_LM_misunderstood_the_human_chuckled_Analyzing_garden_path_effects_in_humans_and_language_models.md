# 当语言模型误解了人类的笑声：研究人类与语言模型中的花园径现象

发布时间：2025年02月13日

`LLM应用` `心理语言学`

> When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models

# 摘要

> 现代大型语言模型（LLMs）在语言任务中展现出类似人类的能力，这激发了人们比较LLMs与人类语言处理的兴趣。本文通过极具挑战性的花园小径句（garden-path constructions）对两者进行了详细对比。基于心理语言学研究，我们提出了关于为何花园小径句难以理解的假设，并通过理解性问题测试了这些假设在人类和LLMs上的表现。结果显示，LLMs和人类在特定句法复杂性上均面临挑战，某些模型的表现甚至与人类高度相关。我们还通过改写和文本到图像生成任务进一步验证了LLMs对花园小径句的理解能力，结果与句子理解测试一致，这进一步证实了我们的研究发现。

> Modern Large Language Models (LLMs) have shown human-like abilities in many language tasks, sparking interest in comparing LLMs' and humans' language processing. In this paper, we conduct a detailed comparison of the two on a sentence comprehension task using garden-path constructions, which are notoriously challenging for humans. Based on psycholinguistic research, we formulate hypotheses on why garden-path sentences are hard, and test these hypotheses on human participants and a large suite of LLMs using comprehension questions. Our findings reveal that both LLMs and humans struggle with specific syntactic complexities, with some models showing high correlation with human comprehension. To complement our findings, we test LLM comprehension of garden-path constructions with paraphrasing and text-to-image generation tasks, and find that the results mirror the sentence comprehension question results, further validating our findings on LLM understanding of these constructions.

[Arxiv](https://arxiv.org/abs/2502.09307)