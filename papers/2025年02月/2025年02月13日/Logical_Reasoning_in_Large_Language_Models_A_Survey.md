# 大型语言模型的逻辑推理能力：综述研究

发布时间：2025年02月13日

`LLM理论

这篇论文探讨了大型语言模型在逻辑推理方面的理论基础、现有能力、评估基准以及提升策略，属于LLM理论的研究范畴。` `人工智能` `逻辑推理`

> Logical Reasoning in Large Language Models: A Survey

# 摘要

> 随着 OpenAI o3 和 DeepSeek-R1 等先进推理模型的出现，大型语言模型 (LLMs) 已经展现出卓越的推理能力。然而，它们在严谨逻辑推理方面的能力仍是一个开放性问题。本综述旨在整合 LLMs 在逻辑推理领域的最新进展，这一领域是 AI 研究中的关键方向。我们详细探讨了 LLMs 中逻辑推理的范围、理论基础以及评估推理能力的基准。通过对演绎推理、归纳推理、 abduction 推理和类比推理等不同推理范式的现有能力进行分析，我们评估了包括数据-centric 调优、强化学习、解码策略和神经符号方法在内的一系列提升推理性能的策略。最后，本综述提出了未来的研究方向，强调了进一步探索以加强 AI 系统中逻辑推理能力的必要性。

> With the emergence of advanced reasoning models like OpenAI o3 and DeepSeek-R1, large language models (LLMs) have demonstrated remarkable reasoning capabilities. However, their ability to perform rigorous logical reasoning remains an open question. This survey synthesizes recent advancements in logical reasoning within LLMs, a critical area of AI research. It outlines the scope of logical reasoning in LLMs, its theoretical foundations, and the benchmarks used to evaluate reasoning proficiency. We analyze existing capabilities across different reasoning paradigms - deductive, inductive, abductive, and analogical - and assess strategies to enhance reasoning performance, including data-centric tuning, reinforcement learning, decoding strategies, and neuro-symbolic approaches. The review concludes with future directions, emphasizing the need for further exploration to strengthen logical reasoning in AI systems.

[Arxiv](https://arxiv.org/abs/2502.09100)