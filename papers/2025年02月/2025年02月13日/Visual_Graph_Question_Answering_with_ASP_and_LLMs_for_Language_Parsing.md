# 基于自动机规划系统与大型语言模型的视觉图问答与语言解析

发布时间：2025年02月13日

`LLM应用` `计算机视觉` `问答系统`

> Visual Graph Question Answering with ASP and LLMs for Language Parsing

# 摘要

> 视觉问答（VQA）是一项需要处理多模态输入的具有挑战性的问题。答案集编程（ASP）在此方面展现了巨大潜力，可以为模块化VQA架构增加可解释性和可说明性。我们提出了一种全新的模块化神经符号方法，专注于解决基于图像的图结构化VQA问题。该方法结合了光学图识别、预训练的光学字符识别神经网络、大型语言模型（LLMs）和ASP推理技术。在新型数据集上，该方法实现了73%的平均准确率，展示了模块化神经符号系统在解决复杂VQA任务方面的潜力。

> Visual Question Answering (VQA) is a challenging problem that requires to process multimodal input. Answer-Set Programming (ASP) has shown great potential in this regard to add interpretability and explainability to modular VQA architectures. In this work, we address the problem of how to integrate ASP with modules for vision and natural language processing to solve a new and demanding VQA variant that is concerned with images of graphs (not graphs in symbolic form). Images containing graph-based structures are an ubiquitous and popular form of visualisation. Here, we deal with the particular problem of graphs inspired by transit networks, and we introduce a novel dataset that amends an existing one by adding images of graphs that resemble metro lines. Our modular neuro-symbolic approach combines optical graph recognition for graph parsing, a pretrained optical character recognition neural network for parsing labels, Large Language Models (LLMs) for language processing, and ASP for reasoning. This method serves as a first baseline and achieves an overall average accuracy of 73% on the dataset. Our evaluation provides further evidence of the potential of modular neuro-symbolic systems, in particular with pretrained models that do not involve any further training and logic programming for reasoning, to solve complex VQA tasks.

[Arxiv](https://arxiv.org/abs/2502.09211)