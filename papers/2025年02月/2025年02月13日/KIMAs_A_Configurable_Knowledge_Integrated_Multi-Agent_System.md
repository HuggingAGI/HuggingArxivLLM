# KIMAs：一款可配置的知识集成多智能体系统

发布时间：2025年02月13日

`LLM应用`

> KIMAs: A Configurable Knowledge Integrated Multi-Agent System

# 摘要

> 大型语言模型（LLMs）支持的知识密集型对话已成为最受欢迎且最有帮助的应用之一，能够在多个方面协助人们。当前许多知识密集型应用都围绕着检索增强生成（RAG）技术展开。尽管开源的RAG框架促进了基于RAG的应用开发，但它们在处理异构数据、对话上下文管理以及低延迟响应的实际场景时往往表现不足。本技术报告提出了一种可配置的知识集成多智能体系统KIMAs，旨在解决这些挑战。KIMAs具备以下特点：1）上下文管理和查询改写机制，以提高检索准确性和多轮对话的连贯性；2）高效的知識路由和检索；3）简单而有效的过滤和引用生成机制；4）优化的可并行化多智能体管道执行。我们的工作提供了一个可扩展的框架，推动了大型语言模型在现实环境中的部署。为了展示KIMAs如何帮助开发者构建不同规模和重点的知识密集型应用，我们展示了如何将该系统配置到三个已在实际中运行且表现出可靠性能的应用中。

> Knowledge-intensive conversations supported by large language models (LLMs) have become one of the most popular and helpful applications that can assist people in different aspects. Many current knowledge-intensive applications are centered on retrieval-augmented generation (RAG) techniques. While many open-source RAG frameworks facilitate the development of RAG-based applications, they often fall short in handling practical scenarios complicated by heterogeneous data in topics and formats, conversational context management, and the requirement of low-latency response times. This technical report presents a configurable knowledge integrated multi-agent system, KIMAs, to address these challenges. KIMAs features a flexible and configurable system for integrating diverse knowledge sources with 1) context management and query rewrite mechanisms to improve retrieval accuracy and multi-turn conversational coherency, 2) efficient knowledge routing and retrieval, 3) simple but effective filter and reference generation mechanisms, and 4) optimized parallelizable multi-agent pipeline execution. Our work provides a scalable framework for advancing the deployment of LLMs in real-world settings. To show how KIMAs can help developers build knowledge-intensive applications with different scales and emphases, we demonstrate how we configure the system to three applications already running in practice with reliable performance.

[Arxiv](https://arxiv.org/abs/2502.09596)