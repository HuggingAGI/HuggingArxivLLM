# # 提升基于LLM的自动作文评分效果：语言特征的应用

发布时间：2025年02月13日

`LLM应用`

> Improve LLM-based Automatic Essay Scoring with Linguistic Features

# 摘要

> 自动作文评分系统（AES）为学生的作文打分，有效减轻教师的评分负担。开发一个能够处理不同题目作文的评分系统颇具挑战性，因为写作任务本身具有高度的灵活性和多样性。现有的方法通常分为两类：监督式特征方法和基于大语言模型（LLM）的方法。监督式特征方法通常能取得更好的性能，但需要资源密集型的训练过程。相比之下，基于LLM的方法在推理阶段计算效率较高，但往往性能较低。本文将这两种方法结合起来，通过在基于LLM的评分中融入语言学特征。实验结果表明，这种混合方法在处理域内和跨域写作题目时均优于基线模型。

> Automatic Essay Scoring (AES) assigns scores to student essays, reducing the grading workload for instructors. Developing a scoring system capable of handling essays across diverse prompts is challenging due to the flexibility and diverse nature of the writing task. Existing methods typically fall into two categories: supervised feature-based approaches and large language model (LLM)-based methods. Supervised feature-based approaches often achieve higher performance but require resource-intensive training. In contrast, LLM-based methods are computationally efficient during inference but tend to suffer from lower performance. This paper combines these approaches by incorporating linguistic features into LLM-based scoring. Experimental results show that this hybrid method outperforms baseline models for both in-domain and out-of-domain writing prompts.

[Arxiv](https://arxiv.org/abs/2502.09497)