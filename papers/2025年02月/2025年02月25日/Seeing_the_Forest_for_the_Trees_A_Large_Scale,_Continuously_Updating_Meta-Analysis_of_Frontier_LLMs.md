# 不要只见树木，不见森林：大规模持续更新的前沿大语言模型元分析

发布时间：2025年02月25日

`LLM应用` `学术研究` `元分析`

> Seeing the Forest for the Trees: A Large Scale, Continuously Updating Meta-Analysis of Frontier LLMs

# 摘要

> LLM研究的激增使得整合它们的发现变得具有挑战性。元分析虽然能够揭示研究中的重要趋势，但其应用受限于手动数据提取的耗时性。我们提出了一种半自动化方法，利用LLMs加速数据提取，从而推动元分析的发展。该方法能够自动识别相关arXiv论文，提取实验结果及相关属性，并将它们组织成结构化的数据集。我们使用一个自动提取的数据集对前沿LLMs进行了全面的元分析，与传统手动方法相比，将论文调研和数据提取的工作量减少了93%以上。我们通过验证我们的数据集，展示了它可以重现关于Chain-of-Thought (CoT) 的最新手动元分析的关键发现，同时也揭示了新的见解，例如在上下文示例对多模态任务有益，但在数学任务上的增益与CoT相比有限。我们的自动更新数据集通过提取新的可用数据来持续跟踪目标模型。通过我们的科学成果和实证分析，我们为理解LLMs提供了新的见解，同时促进了对其行为的持续元分析。

> The surge of LLM studies makes synthesizing their findings challenging. Meta-analysis can uncover important trends across studies, but its use is limited by the time-consuming nature of manual data extraction. Our study presents a semi-automated approach for meta-analysis that accelerates data extraction using LLMs. It automatically identifies relevant arXiv papers, extracts experimental results and related attributes, and organizes them into a structured dataset. We conduct a comprehensive meta-analysis of frontier LLMs using an automatically extracted dataset, reducing the effort of paper surveying and data extraction by more than 93\% compared to manual approaches. We validate our dataset by showing that it reproduces key findings from a recent manual meta-analysis about Chain-of-Thought (CoT), and also uncovers new insights that go beyond it, showing for example that in-context examples benefit multimodal tasks but offer limited gains in mathematical tasks compared to CoT. Our automatically updatable dataset enables continuous tracking of target models by extracting evaluation studies as new data becomes available. Through our scientific artifacts and empirical analysis, we provide novel insights into LLMs while facilitating ongoing meta-analyses of their behavior.

[Arxiv](https://arxiv.org/abs/2502.18791)