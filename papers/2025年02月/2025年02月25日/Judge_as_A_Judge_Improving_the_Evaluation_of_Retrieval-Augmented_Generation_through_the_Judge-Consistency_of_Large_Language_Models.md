# 法官视角：利用大型语言模型的法官一致性提升检索增强生成的评估效果

发布时间：2025年02月25日

`RAG` `人工智能` `模型评估`

> Judge as A Judge: Improving the Evaluation of Retrieval-Augmented Generation through the Judge-Consistency of Large Language Models

# 摘要

> 检索增强生成（RAG）在缓解大语言模型（LLMs）幻觉方面表现出显著效果。然而，现有自动化评估指标无法公平评估RAG模型输出。基于LLMs的判断模型虽能生成高质量判断，但因其对评估提示高度敏感，导致在评估RAG模型时出现不一致。本文提出Judge-Consistency（ConsJudge）方法，旨在提升LLMs对RAG模型的评估准确性。具体而言，ConsJudge通过多维度组合生成不同判断，利用判断一致性评估并筛选判断进行DPO训练。实验表明，ConsJudge能为多种RAG模型和数据集提供更精准的优化判断。进一步分析显示，ConsJudge生成的判断与优质LLM高度一致。所有代码已开源，访问地址为https://github.com/OpenBMB/ConsJudge。

> Retrieval-Augmented Generation (RAG) has proven its effectiveness in alleviating hallucinations for Large Language Models (LLMs). However, existing automated evaluation metrics cannot fairly evaluate the outputs generated by RAG models during training and evaluation. LLM-based judgment models provide the potential to produce high-quality judgments, but they are highly sensitive to evaluation prompts, leading to inconsistencies when judging the output of RAG models. This paper introduces the Judge-Consistency (ConsJudge) method, which aims to enhance LLMs to generate more accurate evaluations for RAG models. Specifically, ConsJudge prompts LLMs to generate different judgments based on various combinations of judgment dimensions, utilize the judge-consistency to evaluate these judgments and select the accepted and rejected judgments for DPO training. Our experiments show that ConsJudge can effectively provide more accurate judgments for optimizing RAG models across various RAG models and datasets. Further analysis reveals that judgments generated by ConsJudge have a high agreement with the superior LLM. All codes are available at https://github.com/OpenBMB/ConsJudge.

[Arxiv](https://arxiv.org/abs/2502.18817)