# 打造负责任的AI代理，构建值得信赖的智能未来

发布时间：2025年02月25日

`Agent` `人工智能`

> Responsible AI Agents

# 摘要

> 大型语言模型的进步催生了一种新型软件——人工智能（AI）代理。OpenAI、谷歌、微软和Salesforce等公司承诺，其AI代理将从文本生成发展到任务执行。与传统方式不同，AI代理不仅会为你规划旅行，还会自动预订所有行程细节；不仅会生成社交媒体内容，还会自动发布到多个平台。AI代理的强大功能引发了法律学者的担忧，他们担心AI代理可能引发流氓商业行为、人类操纵、肆意诽谤和知识产权损害。这些学者呼吁在AI代理造成破坏前对其进行监管。本文直面这些担忧，提出软件间交互的核心特性为约束AI代理提供了独特方法，使流氓行为和不受欢迎的操作更难发生，也许比规范人类代理的规则更有效。本文还提出了一种利用计算机科学的价值对齐方法，提升用户预防或纠正AI代理操作的能力。这种方法不仅有助于AI代理与用户交互规范保持一致，还能实现预期经济成果并缓解感知风险。本文还主张，无论AI代理多么像人类代理，它们无需、也不应被赋予法律人格。简言之，人类对AI代理行为负责，本文为构建和维护负责任的AI代理提供了指南。

> Thanks to advances in large language models, a new type of software agent, the artificial intelligence (AI) agent, has entered the marketplace. Companies such as OpenAI, Google, Microsoft, and Salesforce promise their AI Agents will go from generating passive text to executing tasks. Instead of a travel itinerary, an AI Agent would book all aspects of your trip. Instead of generating text or images for social media post, an AI Agent would post the content across a host of social media outlets. The potential power of AI Agents has fueled legal scholars' fears that AI Agents will enable rogue commerce, human manipulation, rampant defamation, and intellectual property harms. These scholars are calling for regulation before AI Agents cause havoc.
  This Article addresses the concerns around AI Agents head on. It shows that core aspects of how one piece of software interacts with another creates ways to discipline AI Agents so that rogue, undesired actions are unlikely, perhaps more so than rules designed to govern human agents. It also develops a way to leverage the computer-science approach to value-alignment to improve a user's ability to take action to prevent or correct AI Agent operations. That approach offers and added benefit of helping AI Agents align with norms around user-AI Agent interactions. These practices will enable desired economic outcomes and mitigate perceived risks. The Article also argues that no matter how much AI Agents seem like human agents, they need not, and should not, be given legal personhood status. In short, humans are responsible for AI Agents' actions, and this Article provides a guide for how humans can build and maintain responsible AI Agents.

[Arxiv](https://arxiv.org/abs/2502.18359)