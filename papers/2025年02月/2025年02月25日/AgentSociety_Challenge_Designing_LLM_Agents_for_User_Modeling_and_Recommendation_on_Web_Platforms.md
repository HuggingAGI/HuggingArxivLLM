# AgentSociety 挑战：为网络平台设计 LLM 代理，用于用户建模与推荐

发布时间：2025年02月25日

`Agent` `电子商务` `推荐系统`

> AgentSociety Challenge: Designing LLM Agents for User Modeling and Recommendation on Web Platforms

# 摘要

> # 摘要
AgentSociety Challenge 是 Web Conference 首个专注于探索大型语言模型 (LLM) 代理在用户行为建模和网络平台推荐系统增强方面潜力的比赛。挑战分为用户建模和推荐两大赛道，要求参赛者结合 Yelp、Amazon 和 Goodreads 的数据集，借助交互环境模拟器，开发创新的 LLM 代理。在为期 37 天的比赛中，吸引了全球 295 支队伍，共提交作品 1,400 余份。开发阶段，赛道 1 和赛道 2 的性能分别提升了 21.9% 和 20.3%；决赛阶段则分别达到了 9.1% 和 15.9% 的提升，这是一次令人瞩目的成就。本文将详细介绍挑战的设计思路，深入分析比赛成果，并重点展示最成功的 LLM 代理设计方案。为助力后续研究与开发，我们已开源基准环境，详情请访问 https://tsinghua-fib-lab.github.io/AgentSocietyChallenge。


> The AgentSociety Challenge is the first competition in the Web Conference that aims to explore the potential of Large Language Model (LLM) agents in modeling user behavior and enhancing recommender systems on web platforms. The Challenge consists of two tracks: the User Modeling Track and the Recommendation Track. Participants are tasked to utilize a combined dataset from Yelp, Amazon, and Goodreads, along with an interactive environment simulator, to develop innovative LLM agents. The Challenge has attracted 295 teams across the globe and received over 1,400 submissions in total over the course of 37 official competition days. The participants have achieved 21.9% and 20.3% performance improvement for Track 1 and Track 2 in the Development Phase, and 9.1% and 15.9% in the Final Phase, representing a significant accomplishment. This paper discusses the detailed designs of the Challenge, analyzes the outcomes, and highlights the most successful LLM agent designs. To support further research and development, we have open-sourced the benchmark environment at https://tsinghua-fib-lab.github.io/AgentSocietyChallenge.

[Arxiv](https://arxiv.org/abs/2502.18754)