# TextGames：通过语言模型推理实现文本解谜游戏的自我对战学习

发布时间：2025年02月25日

`LLM应用` `人工智能` `评估测试`

> TextGames: Learning to Self-Play Text-Based Puzzle Games via Language Model Reasoning

# 摘要

> 推理是大型语言模型 (LLMs) 的核心能力，使其能够理解、分析和解决复杂问题。本文中，我们介绍了 TextGames——一个专为评估 LLMs 而设计的创新基准测试工具，通过需要高级模式识别、空间感知、算术和逻辑推理技能的高要求文本游戏来评估模型。我们的分析考察了 LLMs 在单轮和多轮推理中的表现，以及它们通过自我反思利用反馈来纠正后续答案的能力。研究发现，尽管 LLMs 在解决大部分简单和中等难度的问题上表现出色，但面对更复杂的任务时仍然面临巨大挑战。相比之下，人类在获得足够时间的情况下能够解决所有任务。此外，我们观察到 LLMs 在通过自我反思进行多轮预测时表现有所提升，但在序列处理、计数和遵循复杂规则方面仍然存在困难。值得注意的是，专门针对推理优化的模型在解决高度复杂问题时的表现优于侧重指令遵循的预训练 LLMs，这突显了推理技能在处理复杂问题中的关键作用。


> Reasoning is a fundamental capability of large language models (LLMs), enabling them to comprehend, analyze, and solve complex problems. In this paper, we introduce TextGames, an innovative benchmark specifically crafted to assess LLMs through demanding text-based games that require advanced skills in pattern recognition, spatial awareness, arithmetic, and logical reasoning. Our analysis probes LLMs' performance in both single-turn and multi-turn reasoning, and their abilities in leveraging feedback to correct subsequent answers through self-reflection. Our findings reveal that, although LLMs exhibit proficiency in addressing most easy and medium-level problems, they face significant challenges with more difficult tasks. In contrast, humans are capable of solving all tasks when given sufficient time. Moreover, we observe that LLMs show improved performance in multi-turn predictions through self-reflection, yet they still struggle with sequencing, counting, and following complex rules consistently. Additionally, models optimized for reasoning outperform pre-trained LLMs that prioritize instruction following, highlighting the crucial role of reasoning skills in addressing highly complex problems.

[Arxiv](https://arxiv.org/abs/2502.18431)