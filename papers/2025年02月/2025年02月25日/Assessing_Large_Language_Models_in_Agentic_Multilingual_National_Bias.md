# 评估大型语言模型在多语言国家偏见中的表现

发布时间：2025年02月25日

`LLM应用

摘要主要探讨了大型语言模型在多语言环境下的应用，特别是在提供个性化建议时的偏见问题。研究涉及模型在实际场景中的应用，如大学申请、旅行和搬迁，分析了多语言偏见及其影响因素，因此属于LLM应用类别。`

> Assessing Large Language Models in Agentic Multilingual National Bias

# 摘要

> 大型语言模型在多语言自然语言处理方面表现出色，但关于跨语言偏见风险的研究目前仅限于即时上下文偏好。基于推理的跨语言推荐差异尚未得到充分探索，甚至缺乏基本的描述性分析。本研究是首个填补这一空白的研究。我们测试了大型语言模型在大学申请、旅行和搬迁这三个关键场景中提供个性化建议的适用性和能力。通过分析先进大型语言模型在多语言环境下的决策任务响应，我们研究了其中的多语言偏见。我们对模型生成评分中的偏见进行了量化，并评估了人口统计因素和推理策略（如链式思考提示）对偏见模式的影响。研究发现，本地语言偏见在不同任务中普遍存在。与GPT-3.5相比，GPT-4和Sonnet在英语国家减少了偏见，但未能实现稳健的多语言对齐。这一发现对多语言AI代理和教育等应用具有更广泛的启示意义。

> Large Language Models have garnered significant attention for their capabilities in multilingual natural language processing, while studies on risks associated with cross biases are limited to immediate context preferences. Cross-language disparities in reasoning-based recommendations remain largely unexplored, with a lack of even descriptive analysis. This study is the first to address this gap. We test LLM's applicability and capability in providing personalized advice across three key scenarios: university applications, travel, and relocation. We investigate multilingual bias in state-of-the-art LLMs by analyzing their responses to decision-making tasks across multiple languages. We quantify bias in model-generated scores and assess the impact of demographic factors and reasoning strategies (e.g., Chain-of-Thought prompting) on bias patterns. Our findings reveal that local language bias is prevalent across different tasks, with GPT-4 and Sonnet reducing bias for English-speaking countries compared to GPT-3.5 but failing to achieve robust multilingual alignment, highlighting broader implications for multilingual AI agents and applications such as education.

[Arxiv](https://arxiv.org/abs/2502.17945)