# 对话大脑：以大型语言模型为代理建模脑语义表征

发布时间：2025年02月25日

`LLM应用` `认知科学` `神经科学`

> Talking to the brain: Using Large Language Models as Proxies to Model Brain Semantic Representation

# 摘要

> 传统心理实验在使用自然刺激物时，常面临人工标注繁琐和生态效度不足的挑战。针对这一问题，我们提出了一种创新方法，借助多模态大型语言模型（LLMs）作为分析工具，通过视觉问答（VQA）策略从自然图像中提取丰富语义信息，深入探究人类视觉语义表征机制。实验结果表明，基于LLM推导出的语义表征成功预测了fMRI测量的典型神经活动模式（如面部、建筑识别），不仅验证了该方法的可行性，还揭示了大脑皮层区域间层次化的语义组织特性。进一步构建的大脑语义网络发现了多个有意义的功能聚类，反映了大脑在功能和语境上的关联特性。这一突破性方法为利用自然刺激物研究大脑语义组织提供了强有力工具，不仅克服了传统标注方法的局限性，更为深入探索人类认知机制提供了新思路。

> Traditional psychological experiments utilizing naturalistic stimuli face challenges in manual annotation and ecological validity. To address this, we introduce a novel paradigm leveraging multimodal large language models (LLMs) as proxies to extract rich semantic information from naturalistic images through a Visual Question Answering (VQA) strategy for analyzing human visual semantic representation. LLM-derived representations successfully predict established neural activity patterns measured by fMRI (e.g., faces, buildings), validating its feasibility and revealing hierarchical semantic organization across cortical regions. A brain semantic network constructed from LLM-derived representations identifies meaningful clusters reflecting functional and contextual associations. This innovative methodology offers a powerful solution for investigating brain semantic organization with naturalistic stimuli, overcoming limitations of traditional annotation methods and paving the way for more ecologically valid explorations of human cognition.

[Arxiv](https://arxiv.org/abs/2502.18725)