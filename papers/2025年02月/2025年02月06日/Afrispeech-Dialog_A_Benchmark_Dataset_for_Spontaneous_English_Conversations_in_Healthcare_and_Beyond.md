# Afrispeech-Dialog: 医疗保健及其他领域自发英语对话的基准数据集

发布时间：2025年02月06日

`LLM应用

理由：这篇论文主要探讨了大型语言模型（LLMs）在医疗对话摘要中的应用，并分析了自动语音识别（ASR）错误对下游任务的影响。虽然论文也涉及语音技术和数据集开发，但其核心关注点是LLMs在特定应用场景（医疗对话摘要）中的表现和挑战，因此应归类为“LLM应用”。` `语音技术`

> Afrispeech-Dialog: A Benchmark Dataset for Spontaneous English Conversations in Healthcare and Beyond

# 摘要

> # 摘要
语音技术正在重塑从医疗到呼叫中心和机器人等多个领域的交互方式，但它们在非洲口音对话中的表现仍鲜有研究。我们推出了Afrispeech-Dialog，一个包含50个模拟医疗和非医疗非洲口音英语对话的基准数据集，用于评估自动语音识别（ASR）及相关技术。我们测试了最先进的说话人分离和ASR系统在长格式、带口音语音上的表现，发现其性能比母语口音下降了10%以上。此外，我们还探索了大型语言模型（LLMs）在医疗对话摘要中的能力，揭示了ASR错误对下游医疗摘要的影响，为全球南方的语音技术挑战和机遇提供了洞见。我们的研究强调了开发更多包容性数据集以推动低资源环境中对话AI进步的必要性。

> Speech technologies are transforming interactions across various sectors, from healthcare to call centers and robots, yet their performance on African-accented conversations remains underexplored. We introduce Afrispeech-Dialog, a benchmark dataset of 50 simulated medical and non-medical African-accented English conversations, designed to evaluate automatic speech recognition (ASR) and related technologies. We assess state-of-the-art (SOTA) speaker diarization and ASR systems on long-form, accented speech, comparing their performance with native accents and discover a 10%+ performance degradation. Additionally, we explore medical conversation summarization capabilities of large language models (LLMs) to demonstrate the impact of ASR errors on downstream medical summaries, providing insights into the challenges and opportunities for speech technologies in the Global South. Our work highlights the need for more inclusive datasets to advance conversational AI in low-resource settings.

[Arxiv](https://arxiv.org/abs/2502.03945)