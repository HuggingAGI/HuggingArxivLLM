# LLMs 能否攻破企业网络？自主假设漏洞渗透测试活动目录网络

发布时间：2025年02月06日

`Agent

理由：这篇论文探讨了利用LLM驱动的自主系统在企业网络中进行假设性漏洞渗透测试的可行性与效果。它描述了一个由大型语言模型驱动的自主系统原型，能够在真实的Active Directory测试环境中执行攻击。这种自主系统可以被视为一种智能代理（Agent），因为它能够自主执行任务（如渗透测试）并做出决策。因此，这篇论文更适合归类为Agent。` `网络安全` `企业网络`

> Can LLMs Hack Enterprise Networks? Autonomous Assumed Breach Penetration-Testing Active Directory Networks

# 摘要

> 我们探讨了利用LLM驱动的自主系统在企业网络中进行假设性漏洞渗透测试的可行性与效果。我们推出了一款创新原型，该原型由大型语言模型（LLMs）驱动，能够在真实的Active Directory测试环境中成功入侵账户。研究全面评估了原型的能力，并揭示了其在执行攻击时的优势与局限。评估采用了一个高度仿真的模拟环境（Active Directory游戏，GOAD），以捕捉实时网络场景中复杂的交互、随机结果及时间依赖性。研究结果表明，自主LLMs能够有效执行假设性漏洞模拟，有望为预算有限的组织普及渗透测试。原型的源代码、跟踪记录及分析日志已开源，旨在提升集体网络安全，并推动LLM驱动的网络安全自动化研究。

> We explore the feasibility and effectiveness of using LLM-driven autonomous systems for Assumed Breach penetration testing in enterprise networks. We introduce a novel prototype that, driven by Large Language Models (LLMs), can compromise accounts within a real-life Active Directory testbed. Our research provides a comprehensive evaluation of the prototype's capabilities, and highlights both strengths and limitations while executing attack. The evaluation uses a realistic simulation environment (Game of Active Directory, GOAD) to capture intricate interactions, stochastic outcomes, and timing dependencies that characterize live network scenarios. The study concludes that autonomous LLMs are able to conduct Assumed Breach simulations, potentially democratizing access to penetration testing for organizations facing budgetary constraints.
  The prototype's source code, traces, and analyzed logs are released as open-source to enhance collective cybersecurity and facilitate future research in LLM-driven cybersecurity automation.

[Arxiv](https://arxiv.org/abs/2502.04227)