# EmoBench-M：多模态大语言模型情感智能评测基准。

发布时间：2025年02月06日

`LLM应用` `机器人` `人工智能`

> EmoBench-M: Benchmarking Emotional Intelligence for Multimodal Large Language Models

# 摘要

> 多模态大型语言模型（MLLMs）与机器人系统及AI应用的融合，使嵌入情感智能（EI）能力变得尤为重要。这不仅能让机器人更好地满足人类情感需求，还能实现与人类在现实场景中的无缝交互。然而，现有的静态、基于文本或图文的基准测试未能充分考虑现实交互的多模态复杂性，也无法准确捕捉情感表达的动态多模态特性，因此无法有效评估MLLMs的情感智能。基于情感智能的心理学理论，我们开发了EmoBench-M，这是一个全新的基准测试平台，旨在从基础情感识别、对话情感理解和社会复杂情感分析三大维度，全面评估MLLMs的情感智能能力，覆盖13种实际应用场景。通过对开源和闭源MLLMs在EmoBench-M上的评估，我们发现它们与人类在情感智能方面仍存在显著差距，这凸显了进一步提升MLLMs情感智能能力的迫切需求。所有相关资源，包括代码和数据集，均可在https://emo-gml.github.io/公开访问。

> With the integration of Multimodal large language models (MLLMs) into robotic systems and various AI applications, embedding emotional intelligence (EI) capabilities into these models is essential for enabling robots to effectively address human emotional needs and interact seamlessly in real-world scenarios. Existing static, text-based, or text-image benchmarks overlook the multimodal complexities of real-world interactions and fail to capture the dynamic, multimodal nature of emotional expressions, making them inadequate for evaluating MLLMs' EI. Based on established psychological theories of EI, we build EmoBench-M, a novel benchmark designed to evaluate the EI capability of MLLMs across 13 valuation scenarios from three key dimensions: foundational emotion recognition, conversational emotion understanding, and socially complex emotion analysis. Evaluations of both open-source and closed-source MLLMs on EmoBench-M reveal a significant performance gap between them and humans, highlighting the need to further advance their EI capabilities. All benchmark resources, including code and datasets, are publicly available at https://emo-gml.github.io/.

[Arxiv](https://arxiv.org/abs/2502.04424)