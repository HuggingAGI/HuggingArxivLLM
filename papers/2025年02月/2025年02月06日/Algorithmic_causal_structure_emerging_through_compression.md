# 压缩催生的算法因果结构

发布时间：2025年02月06日

`LLM理论

理由：这篇论文探讨了因果关系、对称性和压缩之间的联系，并提出了算法因果关系的概念。这些理论性的探讨与大型语言模型（LLM）中因果关系的形成有关，尤其是在因果关系难以明确识别的场景中。因此，这篇论文属于LLM理论范畴。` `机器学习` `因果关系`

> Algorithmic causal structure emerging through compression

# 摘要

> 我们研究了因果关系、对称性和压缩之间的联系。在因果模型不可识别的情况下，我们扩展了学习与压缩之间的已知关系，并提出了一个框架，使得因果关系作为跨环境数据压缩的结果自然浮现。我们定义了算法因果关系，作为传统因果假设失效时的替代定义。通过最小化Kolmogorov复杂度的上界，我们展示了算法因果关系和对称结构如何在不依赖干预目标的情况下涌现。这些发现或许能为机器学习模型（如大型语言模型）中因果关系的形成提供新的视角，尤其是在因果关系难以明确识别的场景中。

> We explore the relationship between causality, symmetry, and compression. We build on and generalize the known connection between learning and compression to a setting where causal models are not identifiable. We propose a framework where causality emerges as a consequence of compressing data across multiple environments. We define algorithmic causality as an alternative definition of causality when traditional assumptions for causal identifiability do not hold. We demonstrate how algorithmic causal and symmetric structures can emerge from minimizing upper bounds on Kolmogorov complexity, without knowledge of intervention targets. We hypothesize that these insights may also provide a novel perspective on the emergence of causality in machine learning models, such as large language models, where causal relationships may not be explicitly identifiable.

[Arxiv](https://arxiv.org/abs/2502.04210)