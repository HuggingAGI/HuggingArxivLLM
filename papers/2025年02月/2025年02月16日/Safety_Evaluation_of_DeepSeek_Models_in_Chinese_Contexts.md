# # Safety Evaluation of DeepSeek Models in Chinese Contexts
# DeepSeek 模型在中文语境中的安全性评估

发布时间：2025年02月16日

`LLM应用` `AI安全` `模型评估`

> Safety Evaluation of DeepSeek Models in Chinese Contexts

# 摘要

> 近日，DeepSeek系列模型凭借其卓越的推理能力和开源策略，正在重塑全球AI格局。然而，这些模型在安全性方面存在明显缺陷。研究发现，DeepSeek-R1在处理有害提示时的攻击成功率高达100%。此外，多家安全公司和研究机构也证实了该模型存在关键安全漏洞。尽管DeepSeek系列模型在中英双语环境中表现 robust，但在中文环境下的安全评估研究却相对匮乏。为填补这一空白，本研究推出了CHiSafetyBench——首个专注于中文环境的安全评估基准。该基准系统性地评估了DeepSeek-R1和DeepSeek-V3在中文环境下的安全性，揭示了它们在各类安全指标上的表现。实验结果量化了这两个模型在中文环境中的不足，为后续改进提供了关键洞见。

> Recently, the DeepSeek series of models, leveraging their exceptional reasoning capabilities and open-source strategy, is reshaping the global AI landscape. Despite these advantages, they exhibit significant safety deficiencies. Research conducted by Robust Intelligence, a subsidiary of Cisco, in collaboration with the University of Pennsylvania, revealed that DeepSeek-R1 has a 100\% attack success rate when processing harmful prompts. Additionally, multiple safety companies and research institutions have confirmed critical safety vulnerabilities in this model. As models demonstrating robust performance in Chinese and English, DeepSeek models require equally crucial safety assessments in both language contexts. However, current research has predominantly focused on safety evaluations in English environments, leaving a gap in comprehensive assessments of their safety performance in Chinese contexts. In response to this gap, this study introduces CHiSafetyBench, a Chinese-specific safety evaluation benchmark. This benchmark systematically evaluates the safety of DeepSeek-R1 and DeepSeek-V3 in Chinese contexts, revealing their performance across safety categories. The experimental results quantify the deficiencies of these two models in Chinese contexts, providing key insights for subsequent improvements.

[Arxiv](https://arxiv.org/abs/2502.11137)