# 多模态表示中的多面单义性

发布时间：2025年02月16日

`其他

摘要主要探讨了多模态模型的解释性，特别是CLIP模型的特征分析及其应用，属于多模态模型的研究，而非专注于LLM的应用或理论，因此归类为“其他”。` `多模态` `人工智能伦理`

> The Multi-Faceted Monosemanticity in Multimodal Representations

# 摘要

> 本文利用特征单义性的最新进展，从深度多模态模型中提取可解释特征，深入解析模态差距。我们以CLIP（对比语言-图像预训练）为研究对象，这是个基于海量图像-文本对训练的优秀视觉-语言模型。基于单模态模型的解释性工具，我们扩展方法评估CLIP特征的多模态解释性，并引入模态主导分数（MDS）量化各特征的模态归属。通过将CLIP特征映射至更易解释的空间，我们成功将其划分为视觉特征、语言特征和视觉-语言特征三类。研究发现，这种分类与人类对不同模态的认知高度契合。此外，我们展示了这些特定模态特征在检测性别偏见、防御对抗攻击和编辑文本到图像模型中的重要应用。结果表明，配备任务无关解释性工具的大规模多模态模型，能为不同模态间的关联与差异提供深刻洞见。

> In this paper, we leverage recent advancements in feature monosemanticity to extract interpretable features from deep multimodal models, offering a data-driven understanding of modality gaps. Specifically, we investigate CLIP (Contrastive Language-Image Pretraining), a prominent visual-language representation model trained on extensive image-text pairs. Building upon interpretability tools developed for single-modal models, we extend these methodologies to assess multi-modal interpretability of CLIP features. Additionally, we introduce the Modality Dominance Score (MDS) to attribute the interpretability of each feature to its respective modality. Next, we transform CLIP features into a more interpretable space, enabling us to categorize them into three distinct classes: vision features (single-modal), language features (single-modal), and visual-language features (cross-modal). Our findings reveal that this categorization aligns closely with human cognitive understandings of different modalities. We also demonstrate significant use cases of this modality-specific features including detecting gender bias, adversarial attack defense and text-to-image model editing. These results indicate that large-scale multimodal models, equipped with task-agnostic interpretability tools, offer valuable insights into key connections and distinctions between different modalities.

[Arxiv](https://arxiv.org/abs/2502.14888)