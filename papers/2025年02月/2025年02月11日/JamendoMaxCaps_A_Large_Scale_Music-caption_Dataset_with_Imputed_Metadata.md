# JamendoMaxCaps：一个大规模的音乐-字幕数据集，内含补全的元数据信息。

发布时间：2025年02月11日

`其他

理由：这篇论文主要介绍了一个大型音乐字幕数据集的构建和应用，虽然提到了使用大型语言模型（LLLM）来填补缺失的元数据，但其核心内容是关于数据集的创建、检索系统的开发以及对音乐语言理解任务的支持。因此，它更适合归类为其他，因为它主要关注数据集的构建和应用，而不是深入探讨LLM的理论或应用。` `音乐检索`

> JamendoMaxCaps: A Large Scale Music-caption Dataset with Imputed Metadata

# 摘要

> 我们推出了 JamendoMaxCaps，一个包含超过 200,000 首免费许可器乐曲目的大型音乐字幕数据集，所有曲目均来自著名的 Jamendo 平台。该数据集不仅包含由先进字幕生成模型生成的字幕，还通过补充元数据进行了丰富。我们还开发了一种结合音乐特征和元数据的检索系统，用于识别相似歌曲，并借助本地大型语言模型（LLLM）填补缺失的元数据。这一创新方法使我们能够为音乐语言理解任务的研究者提供一个更全面且信息丰富的数据集。我们通过五种不同的测量方法对这一方法进行了严格的定量验证。通过公开 JamendoMaxCaps 数据集，我们为音乐检索、多模态表示学习和生成式音乐模型等领域的研究提供了宝贵的高质量资源。


> We introduce JamendoMaxCaps, a large-scale music-caption dataset featuring over 200,000 freely licensed instrumental tracks from the renowned Jamendo platform. The dataset includes captions generated by a state-of-the-art captioning model, enhanced with imputed metadata. We also introduce a retrieval system that leverages both musical features and metadata to identify similar songs, which are then used to fill in missing metadata using a local large language model (LLLM). This approach allows us to provide a more comprehensive and informative dataset for researchers working on music-language understanding tasks. We validate this approach quantitatively with five different measurements. By making the JamendoMaxCaps dataset publicly available, we provide a high-quality resource to advance research in music-language understanding tasks such as music retrieval, multimodal representation learning, and generative music models.

[Arxiv](https://arxiv.org/abs/2502.07461)