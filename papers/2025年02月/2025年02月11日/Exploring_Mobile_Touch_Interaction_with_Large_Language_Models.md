# 探索大型语言模型与移动触控交互的结合

发布时间：2025年02月11日

`LLM应用` `移动设备` `交互设计`

> Exploring Mobile Touch Interaction with Large Language Models

# 摘要

> 在移动设备上与大型语言模型（LLMs）进行文本编辑时，用户目前需要跳出当前的写作环境，切换到对话式AI界面。本文提出通过触控手势直接在文本上操作来控制LLM。我们首先规划了一个设计空间，涵盖基础触控输入和文本转换。在此空间中，我们具体探索了两种控制映射：展开生成（spread-to-generate）和捏合缩短（pinch-to-shorten），并结合视觉反馈循环。我们通过用户研究（N=14）评估了这一概念，比较了三种反馈设计：无可视化、文本长度指示器和长度+单词指示器。结果显示，通过触控操作LLM是可行且用户友好的，其中长度+单词指示器在管理文本生成方面最为有效。这项工作为未来在触控设备上研究基于手势与LLM的交互奠定了基础。

> Interacting with Large Language Models (LLMs) for text editing on mobile devices currently requires users to break out of their writing environment and switch to a conversational AI interface. In this paper, we propose to control the LLM via touch gestures performed directly on the text. We first chart a design space that covers fundamental touch input and text transformations. In this space, we then concretely explore two control mappings: spread-to-generate and pinch-to-shorten, with visual feedback loops. We evaluate this concept in a user study (N=14) that compares three feedback designs: no visualisation, text length indicator, and length + word indicator. The results demonstrate that touch-based control of LLMs is both feasible and user-friendly, with the length + word indicator proving most effective for managing text generation. This work lays the foundation for further research into gesture-based interaction with LLMs on touch devices.

[Arxiv](https://arxiv.org/abs/2502.07629)