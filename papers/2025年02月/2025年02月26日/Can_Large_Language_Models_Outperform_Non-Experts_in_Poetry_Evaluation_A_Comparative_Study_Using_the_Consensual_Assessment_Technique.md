# 大型语言模型能否胜过非专家进行诗歌评估？基于共识评估法的比较研究

发布时间：2025年02月26日

`LLM应用` `创意评估`

> Can Large Language Models Outperform Non-Experts in Poetry Evaluation? A Comparative Study Using the Consensual Assessment Technique

# 摘要

> 共识评估技术（CAT）通过整体专家判断来评估创造力。我们研究了使用两种先进的大型语言模型（LLMs），Claude-3-Opus 和 GPT-4o，通过一种受 CAT 启发的方法来评估诗歌。基于一个包含 90 首诗歌的数据集，我们发现这些 LLMs 在基于出版 venue 匹配地面真实结果时，能够超越非专家人类评委的表现，尤其是在评估较小的诗歌子集时。Claude-3-Opus 的表现略胜一筹。我们证明了 LLMs 是准确评估诗歌的可行工具，为它们在其他创意领域的广泛应用铺平了道路。

> The Consensual Assessment Technique (CAT) evaluates creativity through holistic expert judgments. We investigate the use of two advanced Large Language Models (LLMs), Claude-3-Opus and GPT-4o, to evaluate poetry by a methodology inspired by the CAT. Using a dataset of 90 poems, we found that these LLMs can surpass the results achieved by non-expert human judges at matching a ground truth based on publication venue, particularly when assessing smaller subsets of poems. Claude-3-Opus exhibited slightly superior performance than GPT-4o. We show that LLMs are viable tools for accurately assessing poetry, paving the way for their broader application into other creative domains.

[Arxiv](https://arxiv.org/abs/2502.19064)