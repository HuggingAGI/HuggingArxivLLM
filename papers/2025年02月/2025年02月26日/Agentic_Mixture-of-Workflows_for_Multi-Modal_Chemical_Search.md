# # 摘要
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年02月26日

`LLM应用` `材料科学` `人工智能`

> Agentic Mixture-of-Workflows for Multi-Modal Chemical Search

# 摘要

> 材料设计空间广阔而复杂，亟需创新策略整合多学科知识并优化材料发现。尽管大型语言模型（LLMs）在多个领域展现出强大的推理与自动化能力，但其在材料科学中的应用仍受制于基准标准和实施框架的缺失。为应对这一挑战，我们提出了一种基于开源LLMs的全新范式——CRAG-MoW（基于工作流混合的自我纠错检索增强生成），它能够编排采用不同CRAG策略的多个智能体工作流。与传统方法不同，CRAG-MoW通过编排代理综合多样化输出，实现在同一问题域内直接评估多个LLMs。我们在小分子、聚合物、化学反应及多模态核磁共振（NMR）光谱检索等多个领域对CRAG-MoW进行了基准测试。结果显示，CRAG-MoW不仅性能媲美GPT-4，更在比较评估中更常被优选，凸显了结构化检索与多智能体综合的优势。通过揭示不同数据类型的表现差异，CRAG-MoW提供了一种可扩展、可解释且基于基准的方法，用于优化材料发现的人工智能架构。这些发现对于填补科学应用中LLMs及自主AI代理基准测试的基本空白具有重要意义。


> The vast and complex materials design space demands innovative strategies to integrate multidisciplinary scientific knowledge and optimize materials discovery. While large language models (LLMs) have demonstrated promising reasoning and automation capabilities across various domains, their application in materials science remains limited due to a lack of benchmarking standards and practical implementation frameworks. To address these challenges, we introduce Mixture-of-Workflows for Self-Corrective Retrieval-Augmented Generation (CRAG-MoW) - a novel paradigm that orchestrates multiple agentic workflows employing distinct CRAG strategies using open-source LLMs. Unlike prior approaches, CRAG-MoW synthesizes diverse outputs through an orchestration agent, enabling direct evaluation of multiple LLMs across the same problem domain. We benchmark CRAG-MoWs across small molecules, polymers, and chemical reactions, as well as multi-modal nuclear magnetic resonance (NMR) spectral retrieval. Our results demonstrate that CRAG-MoWs achieve performance comparable to GPT-4o while being preferred more frequently in comparative evaluations, highlighting the advantage of structured retrieval and multi-agent synthesis. By revealing performance variations across data types, CRAG-MoW provides a scalable, interpretable, and benchmark-driven approach to optimizing AI architectures for materials discovery. These insights are pivotal in addressing fundamental gaps in benchmarking LLMs and autonomous AI agents for scientific applications.

[Arxiv](https://arxiv.org/abs/2502.19629)