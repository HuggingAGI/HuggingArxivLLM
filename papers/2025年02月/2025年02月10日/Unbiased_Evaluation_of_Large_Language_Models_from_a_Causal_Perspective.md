# 大型语言模型的因果视角无偏评估

发布时间：2025年02月10日

`LLM理论` `人工智能`

> Unbiased Evaluation of Large Language Models from a Causal Perspective

# 摘要

> 基准污染已成为大型语言模型评估领域的重要问题。先前的Agent作为评估者方法通过让智能体参与问题生成来应对这一挑战。尽管取得了成功，但Agent作为评估者方法中存在的偏见仍未得到充分探索。本文中，我们提出了评估偏见的理论框架，为设计无偏评估协议提供了宝贵的见解。此外，我们通过在简化版的Agent作为评估者设置中精心设计的探测任务，识别出两种类型的偏见。为了解决这些问题，我们提出了无偏评估器，这是一种能够提供更全面、无偏且可解释的大型语言模型评估协议。大量实验表明，当前的大型语言模型仍有显著的改进空间。此外，我们还证明，无偏评估器不仅为基准污染提供了强有力的证据，还提供了可解释的评估结果。

> Benchmark contamination has become a significant concern in the LLM evaluation community. Previous Agents-as-an-Evaluator address this issue by involving agents in the generation of questions. Despite their success, the biases in Agents-as-an-Evaluator methods remain largely unexplored. In this paper, we present a theoretical formulation of evaluation bias, providing valuable insights into designing unbiased evaluation protocols. Furthermore, we identify two type of bias in Agents-as-an-Evaluator through carefully designed probing tasks on a minimal Agents-as-an-Evaluator setup. To address these issues, we propose the Unbiased Evaluator, an evaluation protocol that delivers a more comprehensive, unbiased, and interpretable assessment of LLMs.Extensive experiments reveal significant room for improvement in current LLMs. Additionally, we demonstrate that the Unbiased Evaluator not only offers strong evidence of benchmark contamination but also provides interpretable evaluation results.

[Arxiv](https://arxiv.org/abs/2502.06655)