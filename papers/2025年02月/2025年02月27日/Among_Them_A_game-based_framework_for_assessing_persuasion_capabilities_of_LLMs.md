# 在他们之中：一个评估大型语言模型 (LLMs) 劝说能力的游戏化框架

发布时间：2025年02月27日

`LLM应用` `人工智能伦理` `社会心理学`

> Among Them: A game-based framework for assessing persuasion capabilities of LLMs

# 摘要

> 大型语言模型（LLMs）和自主AI代理的普及引发了人们对它们自动劝说和社会影响力的担忧。尽管现有研究已探讨了基于LLM的孤立操纵案例，但对不同模型在劝说能力方面的系统性评估仍十分有限。本文中，我们提出了一种受《Among Us》启发的游戏框架，用于在受控环境中评估LLM的欺骗技能。该框架使我们能够通过游戏统计数据比较不同LLM模型，并根据社会心理学和修辞学中的25种劝说策略量化游戏中的操纵行为。在8种不同规模和类型的流行语言模型之间的实验表明，所有测试的模型都表现出劝说能力，并成功运用了25种预期技术中的22种。我们还发现，与小型模型相比，大型模型在劝说方面并无优势，且模型输出越长，赢得游戏的数量反而越少。本研究揭示了LLMs的欺骗能力，并为未来在此领域的研究提供了工具和数据支持。

> The proliferation of large language models (LLMs) and autonomous AI agents has raised concerns about their potential for automated persuasion and social influence. While existing research has explored isolated instances of LLM-based manipulation, systematic evaluations of persuasion capabilities across different models remain limited. In this paper, we present an Among Us-inspired game framework for assessing LLM deception skills in a controlled environment. The proposed framework makes it possible to compare LLM models by game statistics, as well as quantify in-game manipulation according to 25 persuasion strategies from social psychology and rhetoric. Experiments between 8 popular language models of different types and sizes demonstrate that all tested models exhibit persuasive capabilities, successfully employing 22 of the 25 anticipated techniques. We also find that larger models do not provide any persuasion advantage over smaller models and that longer model outputs are negatively correlated with the number of games won. Our study provides insights into the deception capabilities of LLMs, as well as tools and data for fostering future research on the topic.

[Arxiv](https://arxiv.org/abs/2502.20426)