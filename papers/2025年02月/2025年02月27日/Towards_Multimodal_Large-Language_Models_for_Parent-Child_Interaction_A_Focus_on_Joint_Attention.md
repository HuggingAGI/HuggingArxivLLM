# # 摘要  
    最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年02月27日

`LLM应用

理由：这篇论文探讨了多模态大语言模型（MLLMs）在分析亲子互动中的应用，特别是联合注意力的检测与分析。研究评估了当前模型在理解联合注意力方面的表现，并指出模型在关键动态成分（如眼神交流）方面的不足。这属于将大语言模型应用于具体领域（亲子互动分析）的研究，因此归类为LLM应用。` `儿童发展` `心理学`

> Towards Multimodal Large-Language Models for Parent-Child Interaction: A Focus on Joint Attention

# 摘要

> 联合注意力是早期语言发展的重要组成部分，也是亲子互动质量的关键指标。然而，关于联合注意力的检测与分析研究仍然十分有限，尤其是针对多模态大语言模型（MLLMs）。本研究通过分析26段由两位语言病理学家标注的亲子互动视频，评估了MLLMs对联合注意力的理解能力。这些标注识别了强联合注意力和弱联合注意力的片段，作为评估模型解释能力的基准。研究发现，当前的MLLMs难以准确解读联合注意力，主要因为缺乏对儿童发起的眼神交流这一关键动态成分的细致理解。本研究强调了在MLLMs的多模态推理中加入详细眼神交流数据的重要性。填补这些研究空白对于未来利用MLLMs分析并支持亲子互动至关重要。

> Joint attention is a critical component of early speech-language development and a key indicator of effective parent-child interaction. However, research on detecting and analysing joint attention remains limited, particularly for Multimodal Large Language Models (MLLMs). This study evaluates MLLMs' ability to comprehend joint attention by analysing 26 parent-child interaction videos annotated by two speech-language pathologists. These annotations identify strong and poor joint attention segments, serving as benchmarks for evaluating the models' interpretive capabilities. Our findings reveal that current MLLMs struggle to accurately interpret joint attention due to a lack of nuanced understanding of child-initiated eye contact, a crucial component of joint attention dynamics. This study highlights the importance of incorporating detailed eye contact to enhance MLLMs' multimodal reasoning. Addressing these gaps is essential for future research to advance the use of MLLMs in analysing and supporting parent-child interactions.

[Arxiv](https://arxiv.org/abs/2502.19877)