# 基于LLM的规划器信任评估：初步研究

发布时间：2025年02月27日

`LLM应用` `人工智能`

> Evaluating Human Trust in LLM-Based Planners: A Preliminary Study

# 摘要

> 大型语言模型（LLMs）在规划任务中的应用日益广泛，其独特优势如解释生成与迭代优化是经典规划器所不具备的。然而，尽管信任是规划系统被采用的关键因素，但在基于LLMs的规划任务中，这一方面却鲜有研究。本研究通过在规划领域定义语言（PDDL）领域中进行用户研究，将人类对基于LLMs的规划器与经典规划器的信任进行比较，从而弥补这一研究空白。通过结合主观指标（如信任问卷）和客观指标（如评估准确性），我们的研究发现，正确性是信任和性能的主要驱动因素。LLMs提供的解释虽然提高了评估准确性，但对信任的影响有限；而规划优化则在不显著提升评估准确性的同时，展现出提升信任的潜力。

> Large Language Models (LLMs) are increasingly used for planning tasks, offering unique capabilities not found in classical planners such as generating explanations and iterative refinement. However, trust--a critical factor in the adoption of planning systems--remains underexplored in the context of LLM-based planning tasks. This study bridges this gap by comparing human trust in LLM-based planners with classical planners through a user study in a Planning Domain Definition Language (PDDL) domain. Combining subjective measures, such as trust questionnaires, with objective metrics like evaluation accuracy, our findings reveal that correctness is the primary driver of trust and performance. Explanations provided by the LLM improved evaluation accuracy but had limited impact on trust, while plan refinement showed potential for increasing trust without significantly enhancing evaluation accuracy.

[Arxiv](https://arxiv.org/abs/2502.20284)