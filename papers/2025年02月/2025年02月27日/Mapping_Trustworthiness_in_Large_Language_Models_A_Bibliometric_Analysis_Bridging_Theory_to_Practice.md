# 大型语言模型可信度图谱：文献计量分析助力理论与实践的融合

发布时间：2025年02月27日

`LLM应用` `大型语言模型` `可信度`

> Mapping Trustworthiness in Large Language Models: A Bibliometric Analysis Bridging Theory to Practice

# 摘要

> 大型语言模型（LLMs）的迅速普及引发了对其可信度的迫切关注，涉及可靠性、透明性、公平性和伦理一致性等问题。尽管LLMs在各个领域的采用率不断提高，但如何在实践中操作可信度仍缺乏共识。本研究通过分析2019年至2025年的2006篇出版物，进行了一项计量学映射分析，以弥合理论讨论与实施之间的差距。通过合作作者网络、关键词共现分析和主题演变追踪，我们确定了关键研究趋势、有影响力的作者以及LLM可信度的盛行定义。此外，还对68篇核心论文进行了系统性审查，以探讨信任的概念及其实际影响。我们的研究发现，LLMs的可信度通常通过现有的组织信任框架来界定，强调能力、善意和正直等维度。然而，将这些原则转化为具体的开发策略仍存在显著差距。为了解决这一问题，我们提出了一个结构化的映射，涵盖LLM生命周期中的20种增强信任的技术，包括检索增强生成（RAG）、可解释性技术以及训练后审核。通过将计量学见解与实际策略相结合，本研究致力于促进更加透明、可问责且符合伦理的LLMs，确保其在现实世界应用中的负责任部署。

> The rapid proliferation of Large Language Models (LLMs) has raised pressing concerns regarding their trustworthiness, spanning issues of reliability, transparency, fairness, and ethical alignment. Despite the increasing adoption of LLMs across various domains, there remains a lack of consensus on how to operationalize trustworthiness in practice. This study bridges the gap between theoretical discussions and implementation by conducting a bibliometric mapping analysis of 2,006 publications from 2019 to 2025. Through co-authorship networks, keyword co-occurrence analysis, and thematic evolution tracking, we identify key research trends, influential authors, and prevailing definitions of LLM trustworthiness. Additionally, a systematic review of 68 core papers is conducted to examine conceptualizations of trust and their practical implications. Our findings reveal that trustworthiness in LLMs is often framed through existing organizational trust frameworks, emphasizing dimensions such as ability, benevolence, and integrity. However, a significant gap exists in translating these principles into concrete development strategies. To address this, we propose a structured mapping of 20 trust-enhancing techniques across the LLM lifecycle, including retrieval-augmented generation (RAG), explainability techniques, and post-training audits. By synthesizing bibliometric insights with practical strategies, this study contributes towards fostering more transparent, accountable, and ethically aligned LLMs, ensuring their responsible deployment in real-world applications.

[Arxiv](https://arxiv.org/abs/2503.04785)