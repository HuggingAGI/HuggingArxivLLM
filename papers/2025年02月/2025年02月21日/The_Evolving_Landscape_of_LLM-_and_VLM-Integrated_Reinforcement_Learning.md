# LLM与VLM融合的强化学习发展现状

发布时间：2025年02月21日

`LLM应用` `人工智能` `机器人领域`

> The Evolving Landscape of LLM- and VLM-Integrated Reinforcement Learning

# 摘要

> 强化学习（RL）在序列决策任务中表现卓越。与此同时，大型语言模型（LLMs）和视觉语言模型（VLMs）的崛起，展现出强大的多模态理解和推理能力。这些进展推动了将LLMs和VLMs与RL结合的研究热潮。本综述系统梳理了利用LLMs和VLMs解决RL关键挑战的代表性工作，如先验知识缺失、长时段规划和奖励设计难题。我们构建了一个分类框架，将这些LLM/VLM辅助的RL方法归纳为三种角色：代理、规划者和奖励。最后，我们深入探讨了当前仍具挑战性的开放问题，包括模型的 grounding、偏差缓解、表示优化和动作建议。通过整合现有研究成果并展望未来方向，本综述为将LLMs和VLMs融入RL提供了系统性框架，为自然语言和视觉理解与序列决策的深度融合开辟了新思路。

> Reinforcement learning (RL) has shown impressive results in sequential decision-making tasks. Meanwhile, Large Language Models (LLMs) and Vision-Language Models (VLMs) have emerged, exhibiting impressive capabilities in multimodal understanding and reasoning. These advances have led to a surge of research integrating LLMs and VLMs into RL. In this survey, we review representative works in which LLMs and VLMs are used to overcome key challenges in RL, such as lack of prior knowledge, long-horizon planning, and reward design. We present a taxonomy that categorizes these LLM/VLM-assisted RL approaches into three roles: agent, planner, and reward. We conclude by exploring open problems, including grounding, bias mitigation, improved representations, and action advice. By consolidating existing research and identifying future directions, this survey establishes a framework for integrating LLMs and VLMs into RL, advancing approaches that unify natural language and visual understanding with sequential decision-making.

[Arxiv](https://arxiv.org/abs/2502.15214)