# 观点：标准基准失效——LLM智能体为金融应用带来被忽视的风险

发布时间：2025年02月21日

`LLM应用` `评估方法`

> Position: Standard Benchmarks Fail -- LLM Agents Present Overlooked Risks for Financial Applications

# 摘要

> 现有金融LLM代理基准存在重大缺陷。它们过分关注任务表现，却忽视了安全风险这一关键问题。在金融领域，幻觉、时间错配、对抗漏洞等威胁可能带来系统性风险，但现有评估框架未能有效识别这些风险。我们明确指出：传统评估基准不足以保障金融场景下LLM代理的可靠性。针对这一问题，我们深入分析了现有金融LLM代理基准，发现其中的安全性漏洞，并提出了十个全新的风险感知评估指标。通过实证研究，我们对基于API和开源权重的LLM代理进行了全面评估，揭示了传统评估方法未能发现的潜在风险。为推动该领域发展，我们提出了一种基于三级评估框架的安全感知评估代理（SAEA）。该框架从模型能力、工作流程可靠性及系统集成稳健性三个维度全面评估代理性能。我们的研究发现表明，重新定义LLM代理评估标准势在必行，评估重点应从单纯追求性能转向对安全、稳健性和现实世界适应性的关注。

> Current financial LLM agent benchmarks are inadequate. They prioritize task performance while ignoring fundamental safety risks. Threats like hallucinations, temporal misalignment, and adversarial vulnerabilities pose systemic risks in high-stakes financial environments, yet existing evaluation frameworks fail to capture these risks. We take a firm position: traditional benchmarks are insufficient to ensure the reliability of LLM agents in finance. To address this, we analyze existing financial LLM agent benchmarks, finding safety gaps and introducing ten risk-aware evaluation metrics. Through an empirical evaluation of both API-based and open-weight LLM agents, we reveal hidden vulnerabilities that remain undetected by conventional assessments. To move the field forward, we propose the Safety-Aware Evaluation Agent (SAEA), grounded in a three-level evaluation framework that assesses agents at the model level (intrinsic capabilities), workflow level (multi-step process reliability), and system level (integration robustness). Our findings highlight the urgent need to redefine LLM agent evaluation standards by shifting the focus from raw performance to safety, robustness, and real world resilience.

[Arxiv](https://arxiv.org/abs/2502.15865)