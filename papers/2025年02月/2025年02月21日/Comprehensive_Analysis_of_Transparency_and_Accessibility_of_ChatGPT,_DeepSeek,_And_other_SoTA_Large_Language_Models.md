# # ChatGPT、DeepSeek 及其他先进大语言模型的透明度与可访问性全面分析

发布时间：2025年02月21日

`LLM理论` `开源软件`

> Comprehensive Analysis of Transparency and Accessibility of ChatGPT, DeepSeek, And other SoTA Large Language Models

# 摘要

> 尽管关于开源AI的讨论日益增多，但现有研究尚未深入探讨最新（SoTA）大规模语言模型（LLMs）的透明度和可访问性。开源软件倡议（OSI） recently发布了首个正式的开源软件定义。这一定义，结合标准词典定义和少量已发表文献，为支持如LLMs等AI模型的更广泛应用提供了初步框架。然而，还需进一步研究以捕捉AI领域开源的独特动态。此外，关于“开源漂绿”（open-washing）的担忧也浮现，即某些模型声称开源但缺乏充分透明度，这限制了这些模型的可复现性、偏见缓解和领域适应性。在此背景下，本研究对过去五年内的SoTA LLMs进行了批判性分析，包括ChatGPT、DeepSeek、LLaMA等，以评估它们对透明度标准的遵循情况，以及部分开源带来的影响。具体而言，我们从开源模型与开放权重模型两个角度审视透明度和可访问性。研究发现，尽管某些模型被标记为开源，但这并不必然意味着它们完全开源。即便在最佳情况下，开源模型通常也不报告模型训练数据、代码以及关键指标，如权重可访问性和碳排放量。据我们所知，这是首个通过开源与开放权重模型的双重视角，系统性考察逾100种不同SoTA LLMs透明度与可访问性的研究。这些发现为未来研究开辟了新方向，并呼吁负责任和可持续的AI实践，以确保这些模型更高的透明度、问责制和道德部署。

> Despite increasing discussions on open-source Artificial Intelligence (AI), existing research lacks a discussion on the transparency and accessibility of state-of-the-art (SoTA) Large Language Models (LLMs). The Open Source Initiative (OSI) has recently released its first formal definition of open-source software. This definition, when combined with standard dictionary definitions and the sparse published literature, provide an initial framework to support broader accessibility to AI models such as LLMs, but more work is essential to capture the unique dynamics of openness in AI. In addition, concerns about open-washing, where models claim openness but lack full transparency, has been raised, which limits the reproducibility, bias mitigation, and domain adaptation of these models. In this context, our study critically analyzes SoTA LLMs from the last five years, including ChatGPT, DeepSeek, LLaMA, and others, to assess their adherence to transparency standards and the implications of partial openness. Specifically, we examine transparency and accessibility from two perspectives: open-source vs. open-weight models. Our findings reveal that while some models are labeled as open-source, this does not necessarily mean they are fully open-sourced. Even in the best cases, open-source models often do not report model training data, and code as well as key metrics, such as weight accessibility, and carbon emissions. To the best of our knowledge, this is the first study that systematically examines the transparency and accessibility of over 100 different SoTA LLMs through the dual lens of open-source and open-weight models. The findings open avenues for further research and call for responsible and sustainable AI practices to ensure greater transparency, accountability, and ethical deployment of these models.(DeepSeek transparency, ChatGPT accessibility, open source, DeepSeek open source)

[Arxiv](https://arxiv.org/abs/2502.18505)