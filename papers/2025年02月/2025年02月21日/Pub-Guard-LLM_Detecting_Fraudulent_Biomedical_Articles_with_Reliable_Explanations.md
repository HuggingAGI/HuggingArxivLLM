# Pub-Guard-LLM：检测欺诈性生物医学文章并提供可靠解释

发布时间：2025年02月21日

`LLM应用

理由：这篇论文提出了Pub-Guard-LLM，一个用于生物医学科学文章欺诈检测的大型语言模型系统，并展示了其在实际应用中的有效性。因此，它属于LLM应用类别。` `生物医学` `科学欺诈检测`

> Pub-Guard-LLM: Detecting Fraudulent Biomedical Articles with Reliable Explanations

# 摘要

> 一项研究发现，越来越多已发表的科学文章涉及欺诈行为，这在医学等领域对研究的可信度和安全性构成严重威胁。我们提出了Pub-Guard-LLM，这是首个专门用于生物医学科学文章欺诈检测的大型语言模型系统。我们提供了三种Pub-Guard-LLM的应用模式：基础推理模式、检索增强生成模式和多智能体辩论模式，每种模式都支持对预测结果进行文本解释。为了评估系统性能，我们引入了一个开源基准PubMed撤稿数据集，包含超过11,000篇真实生物医学文章，包括元数据和撤稿标签。我们展示了，在所有模式下，Pub-Guard-LLM的性能均优于各种基线系统，并提供更可靠的解释，即通过多种评估方法验证，其解释比基线生成的解释更具相关性和连贯性。通过在科学欺诈检测中同时提升检测性能和可解释性，Pub-Guard-LLM为维护研究诚信提供了一个新颖、有效且开源的工具。

> A significant and growing number of published scientific articles is found to involve fraudulent practices, posing a serious threat to the credibility and safety of research in fields such as medicine. We propose Pub-Guard-LLM, the first large language model-based system tailored to fraud detection of biomedical scientific articles. We provide three application modes for deploying Pub-Guard-LLM: vanilla reasoning, retrieval-augmented generation, and multi-agent debate. Each mode allows for textual explanations of predictions. To assess the performance of our system, we introduce an open-source benchmark, PubMed Retraction, comprising over 11K real-world biomedical articles, including metadata and retraction labels. We show that, across all modes, Pub-Guard-LLM consistently surpasses the performance of various baselines and provides more reliable explanations, namely explanations which are deemed more relevant and coherent than those generated by the baselines when evaluated by multiple assessment methods. By enhancing both detection performance and explainability in scientific fraud detection, Pub-Guard-LLM contributes to safeguarding research integrity with a novel, effective, open-source tool.

[Arxiv](https://arxiv.org/abs/2502.15429)