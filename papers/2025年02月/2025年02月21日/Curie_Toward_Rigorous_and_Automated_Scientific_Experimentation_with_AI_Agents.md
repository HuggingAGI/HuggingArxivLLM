# Curie：迈向严谨且自动化的科学实验——AI代理的探索之路

发布时间：2025年02月21日

`Agent` `科学实验` `计算机科学`

> Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents

# 摘要

> 科学实验作为人类文明进步的基石，其严谨性、系统控制和可解释性是产生有意义成果的关键。尽管大型语言模型（LLMs）在科学过程的自动化方面取得了显著进展，但实现严谨的自动化实验仍是一项重大挑战。为解决这一难题，我们提出了Curie，一个AI代理框架，通过三大核心组件将严谨性融入实验过程：代理内部严谨性模块提升可靠性，代理间严谨性模块确保系统性控制，以及实验知识模块增强可解释性。为验证Curie的效果，我们设计了一个包含四个计算机科学领域共46个问题的新型实验基准，这些问题源自具有影响力的论文和广泛采用的开源项目。与最强的基线模型相比，我们在正确回答实验问题上实现了3.4倍的性能提升。Curie现已开源，地址为https://github.com/Just-Curieous/Curie。

> Scientific experimentation, a cornerstone of human progress, demands rigor in reliability, methodical control, and interpretability to yield meaningful results. Despite the growing capabilities of large language models (LLMs) in automating different aspects of the scientific process, automating rigorous experimentation remains a significant challenge. To address this gap, we propose Curie, an AI agent framework designed to embed rigor into the experimentation process through three key components: an intra-agent rigor module to enhance reliability, an inter-agent rigor module to maintain methodical control, and an experiment knowledge module to enhance interpretability. To evaluate Curie, we design a novel experimental benchmark composed of 46 questions across four computer science domains, derived from influential research papers, and widely adopted open-source projects. Compared to the strongest baseline tested, we achieve a 3.4$\times$ improvement in correctly answering experimental questions.Curie is open-sourced at https://github.com/Just-Curieous/Curie.

[Arxiv](https://arxiv.org/abs/2502.16069)