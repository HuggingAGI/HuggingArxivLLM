# 多智能体多模态模型在多文化文本到图像生成中的应用

发布时间：2025年02月21日

`Agent` `计算机视觉` `人工智能`

> Multi-Agent Multimodal Models for Multicultural Text to Image Generation

# 摘要

> 大型语言模型（LLMs）在多模态任务中表现优异，但受限于现有数据和模型以西方为中心的特点，其在跨文化场景中的效果仍有待提升。与此同时，多智能体模型在解决复杂任务方面展现出强大能力。本文聚焦于跨文化图像生成这一新兴任务，评估了LLMs在多智能体交互环境中的表现。我们的主要贡献包括：(1) 提出了MosAIG框架，通过赋予LLMs不同文化人设，显著提升了跨文化图像生成效果；(2) 构建了一个包含9,000张跨文化图像的数据集，覆盖五个国家、三个年龄段、两个性别、25个历史地标和五种语言；(3) 实验表明，多智能体交互模型在多个评估维度上均优于传统无智能体模型，为未来研究提供了重要参考。我们的数据集和模型已开源，访问地址为https://github.com/OanaIgnat/MosAIG。

> Large Language Models (LLMs) demonstrate impressive performance across various multimodal tasks. However, their effectiveness in cross-cultural contexts remains limited due to the predominantly Western-centric nature of existing data and models. Meanwhile, multi-agent models have shown strong capabilities in solving complex tasks. In this paper, we evaluate the performance of LLMs in a multi-agent interaction setting for the novel task of multicultural image generation. Our key contributions are: (1) We introduce MosAIG, a Multi-Agent framework that enhances multicultural Image Generation by leveraging LLMs with distinct cultural personas; (2) We provide a dataset of 9,000 multicultural images spanning five countries, three age groups, two genders, 25 historical landmarks, and five languages; and (3) We demonstrate that multi-agent interactions outperform simple, no-agent models across multiple evaluation metrics, offering valuable insights for future research. Our dataset and models are available at https://github.com/OanaIgnat/MosAIG.

[Arxiv](https://arxiv.org/abs/2502.15972)