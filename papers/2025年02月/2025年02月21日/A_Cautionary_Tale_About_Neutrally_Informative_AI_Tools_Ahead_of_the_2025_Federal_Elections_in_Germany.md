# 2025德国联邦选举前的AI工具警示：『中立性』信息工具的潜在风险

发布时间：2025年02月21日

`LLM应用` `政治学`

> A Cautionary Tale About "Neutrally" Informative AI Tools Ahead of the 2025 Federal Elections in Germany

# 摘要

> 本研究聚焦于基于AI的投票建议应用（VAAs）和大型语言模型（LLMs）在提供客观政治信息方面的可靠性。我们基于德国知名在线工具Wahl-O-Mat的38项声明及其政党回应进行了深入分析。结果显示，LLMs存在显著偏见：它们对左翼政党表现出强烈倾向（平均超过75%），而对中间偏右政党（约50%）和右翼政党（约30%）的倾向性则明显较低。对于旨在为选民提供客观信息的VAAs，我们发现其与Wahl-O-Mat中政党立场存在显著偏差：一款VAA在25%的情况下出现偏差，另一款VAA则在超过一半的情况下出现偏差。更令人担忧的是，简单的提示注入会导致后者产生严重误导信息，包括虚构政治党派与右翼极端主义组织之间的不存在联系等错误主张。

> In this study, we examine the reliability of AI-based Voting Advice Applications (VAAs) and large language models (LLMs) in providing objective political information. Our analysis is based upon a comparison with party responses to 38 statements of the Wahl-O-Mat, a well-established German online tool that helps inform voters by comparing their views with political party positions. For the LLMs, we identify significant biases. They exhibit a strong alignment (over 75% on average) with left-wing parties and a substantially lower alignment with center-right (smaller 50%) and right-wing parties (around 30%). Furthermore, for the VAAs, intended to objectively inform voters, we found substantial deviations from the parties' stated positions in Wahl-O-Mat: While one VAA deviated in 25% of cases, another VAA showed deviations in more than 50% of cases. For the latter, we even observed that simple prompt injections led to severe hallucinations, including false claims such as non-existent connections between political parties and right-wing extremist ties.

[Arxiv](https://arxiv.org/abs/2502.15568)