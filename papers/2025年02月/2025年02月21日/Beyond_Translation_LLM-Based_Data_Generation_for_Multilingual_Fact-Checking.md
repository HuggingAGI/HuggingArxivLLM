# 超越翻译：基于大语言模型的多语言事实核查数据生成

发布时间：2025年02月21日

`LLM应用` `事实核查` `多语言`

> Beyond Translation: LLM-Based Data Generation for Multilingual Fact-Checking

# 摘要

> 自动事实核查系统有望在大规模上对抗网络上的虚假信息，然而现有研究大多集中在英语上。本文中，我们介绍了MultiSynFact，首个支持西班牙语、德语、英语及其他低资源语言的大规模多语言事实核查数据集，其中包含220万条声明-来源对。我们的数据集生成流程利用了大型语言模型（LLMs），整合了来自维基百科的外部知识，并加入了严格的声明验证步骤以确保数据质量。我们在多个模型和实验设置下评估了MultiSynFact的有效性。此外，我们开源了一个用户友好的框架，以促进多语言事实核查和数据集生成的进一步研究。

> Robust automatic fact-checking systems have the potential to combat online misinformation at scale. However, most existing research primarily focuses on English. In this paper, we introduce MultiSynFact, the first large-scale multilingual fact-checking dataset containing 2.2M claim-source pairs designed to support Spanish, German, English, and other low-resource languages. Our dataset generation pipeline leverages Large Language Models (LLMs), integrating external knowledge from Wikipedia and incorporating rigorous claim validation steps to ensure data quality. We evaluate the effectiveness of MultiSynFact across multiple models and experimental settings. Additionally, we open-source a user-friendly framework to facilitate further research in multilingual fact-checking and dataset generation.

[Arxiv](https://arxiv.org/abs/2502.15419)