# 大型语言模型的内在机制与人类思维相似。

发布时间：2025年02月03日

`LLM理论

理由：这篇论文主要探讨了大型语言模型（LMs）的认知可信性，特别是通过机制可解释性的视角来分析LMs内部层的下一个词概率与人类句子处理数据的对齐效果。论文还揭示了LMs层与人类测量之间的关联，这些内容都属于对LLM内部机制和理论的研究，因此应归类为LLM理论。` `认知科学`

> Large Language Models Are Human-Like Internally

# 摘要

> # 摘要
近期认知建模研究指出，较大的语言模型（LMs）对人类阅读行为的拟合效果较差，引发了对它们认知可信性的质疑。本文通过机制可解释性的视角重新审视了这一观点，发现之前的结论因过度关注LMs的最终层而存在偏差。我们的分析显示，较大LMs内部层的下一个词概率与人类句子处理数据的对齐效果与较小LMs相当甚至更优。这种一致性在行为（如自定步速阅读时间、注视持续时间、MAZE任务处理时间）和神经生理（如N400脑电位）测量中均得到验证，挑战了早期的混合结果，表明较大LMs的认知可信性被低估。此外，我们首次揭示了LMs层与人类测量之间的有趣关联：较早的层与快速注视持续时间更相关，而较晚的层则与较慢的信号（如N400电位和MAZE处理时间）更匹配。这一发现为机制可解释性与认知建模的跨学科研究开辟了新方向。

> Recent cognitive modeling studies have reported that larger language models (LMs) exhibit a poorer fit to human reading behavior, leading to claims of their cognitive implausibility. In this paper, we revisit this argument through the lens of mechanistic interpretability and argue that prior conclusions were skewed by an exclusive focus on the final layers of LMs. Our analysis reveals that next-word probabilities derived from internal layers of larger LMs align with human sentence processing data as well as, or better than, those from smaller LMs. This alignment holds consistently across behavioral (self-paced reading times, gaze durations, MAZE task processing times) and neurophysiological (N400 brain potentials) measures, challenging earlier mixed results and suggesting that the cognitive plausibility of larger LMs has been underestimated. Furthermore, we first identify an intriguing relationship between LM layers and human measures: earlier layers correspond more closely with fast gaze durations, while later layers better align with relatively slower signals such as N400 potentials and MAZE processing times. Our work opens new avenues for interdisciplinary research at the intersection of mechanistic interpretability and cognitive modeling.

[Arxiv](https://arxiv.org/abs/2502.01615)