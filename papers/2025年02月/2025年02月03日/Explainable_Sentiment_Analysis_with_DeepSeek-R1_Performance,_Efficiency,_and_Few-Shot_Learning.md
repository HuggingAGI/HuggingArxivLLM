# 基于 DeepSeek-R1 的可解释情感分析：性能、效率与小样本学习能力

发布时间：2025年02月03日

`LLM应用` `情感分析`

> Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning

# 摘要

> 大型语言模型（LLMs）的最新进展极大地提升了情感分析能力。然而，部分最新模型在性能、效率和可解释性之间的权衡仍待深入研究。本研究首次对具备推理能力的开源LLM——DeepSeek-R1系列模型在情感分析任务中的表现进行了全面评估，并将其与OpenAI的GPT-4和GPT-4-mini进行了对比。我们系统性地分析了这些模型在少量样本提示条件下的表现，并扩展至50样本配置以评估其上下文学习效果。实验结果显示，DeepSeek-R1在多分类情感分析任务中展现出极具竞争力的准确性，同时通过其详细的推理过程提升了可解释性。此外，我们还探讨了增加少量样本对模型性能的影响，并讨论了可解释性与计算效率之间的关键权衡。

> Recent advancements in large language models (LLMs) have significantly enhanced sentiment analysis capabilities. However, the trade-offs between model performance, efficiency, and explainability of some latest models remain underexplored. This study presents the first comprehensive evaluation of the DeepSeek-R1 series of models, reasoning open-source LLMs, for sentiment analysis, comparing them against OpenAI's GPT-4 and GPT-4-mini. We systematically analyze their performance under few-shot prompting conditions, scaling up to 50-shot configurations to assess in-context learning effectiveness. Our experiments reveal that DeepSeek-R1 demonstrates competitive accuracy, particularly in multi-class sentiment tasks, while offering enhanced interpretability through its detailed reasoning process. Additionally, we highlight the impact of increasing few-shot examples on model performance and discuss key trade-offs between explainability and computational efficiency.

[Arxiv](https://arxiv.org/abs/2503.11655)