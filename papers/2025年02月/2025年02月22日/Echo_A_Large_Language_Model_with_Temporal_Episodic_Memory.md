# # Echo: A Large Language Model with Temporal Episodic Memory  
回声：具备时间情景记忆的大型语言模型

发布时间：2025年02月22日

`LLM应用` `人工智能` `对话系统`

> Echo: A Large Language Model with Temporal Episodic Memory

# 摘要

> 大型语言模型（LLMs）在数学、编程和文学创作等领域展现了卓越的表现。然而，现有研究大多聚焦于基于语义记忆的问题回答，忽视了LLMs在情节记忆（EM）相关查询方面的潜力。这种忽视导致在需要EM的应用中表现不尽如人意，包括情感陪伴、个人AI助手和AI教师等。为解决这一问题，我们引入了增强情节记忆的LLM——Echo。我们提出了一种多智能体数据生成框架，指导模型生成多轮复杂情节记忆对话数据（EM-Train）。创新地将时间信息融入LLM训练过程，并使用EM-Train训练Echo。此外，我们开发了专门用于评估LLMs情节记忆能力的EM-Test基准测试。EM-Test评估了在不同时间跨度和难度水平下的性能，提供了对多轮情节记忆对话的全面评估。实验结果表明，Echo在EM-Test中显著优于现有的先进LLMs。定性分析进一步揭示了Echo展现类人情节记忆能力的潜力。我们承诺开源所有数据集、代码和模型权重。

> Research on large language models (LLMs) has shown remarkable performance in domains such as mathematics, programming, and literary creation. However, most studies have focused on semantic memory-based question answering, neglecting LLMs' potential to handle episodic memory (EM)-related queries. This oversight has led to suboptimal performance in applications requiring EM, including emotional companionship, personal AI assistants, and AI teachers. To address this gap, we introduce Echo, a LLM enhanced with temporal episodic memory. We propose a Multi-Agent Data Generation Framework that guides the model in generating multi-turn, complex scenario episodic memory dialogue data (EM-Train). Temporal information is innovatively incorporated into the LLM training process, and Echo is trained using the EM-Train. Furthermore, We develop an EM-Test benchmark specifically designed to evaluate LLMs' episodic memory capabilities. The EM-Test assesses performance across various time spans and difficulty levels, providing a comprehensive evaluation of multi-turn episodic memory dialogues. Our experiments demonstrate that Echo significantly outperforms state-of-the-art LLMs on EM-Test. Additionally, a qualitative analysis reveals Echo's potential to exhibit human-like episodic memory capabilities. We will open-source all datasets, code, and model weights.

[Arxiv](https://arxiv.org/abs/2502.16090)