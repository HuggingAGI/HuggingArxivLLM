# InterFeedback：人工反馈揭示大型多模态模型的交互智能

发布时间：2025年02月20日

`其他` `AI助手` `人工智能`

> InterFeedback: Unveiling Interactive Intelligence of Large Multimodal Models via Human Feedback

# 摘要

> 现有基准测试尚未针对大型多模态模型（LMMs）与人类用户的交互智能进行评估，而这对于开发通用型AI助手至关重要。为此，我们设计了InterFeedback交互框架，能够应用于任何LMM和数据集，实现自主评估。在此基础上，我们推出了InterFeedback-Bench，该基准采用MMMU-Pro和MathVerse两个代表性数据集，评估交互智能并测试了10个开源LMM。此外，我们还发布了InterFeedback-Human，这是一个全新收集的包含120个案例的数据集，专为手动测试OpenAI-o1和Claude-3.5-Sonnet等领先模型的交互性能而设计。我们的评估结果显示，即使是目前最先进的LMM（如OpenAI-o1），通过人类反馈修正结果的比例也低于50%。这一发现表明，我们需要开发能够增强LMM解读和利用反馈能力的新方法。

> Existing benchmarks do not test Large Multimodal Models (LMMs) on their interactive intelligence with human users which is vital for developing general-purpose AI assistants. We design InterFeedback, an interactive framework, which can be applied to any LMM and dataset to assess this ability autonomously. On top of this, we introduce InterFeedback-Bench which evaluates interactive intelligence using two representative datasets, MMMU-Pro and MathVerse, to test 10 different open-source LMMs. Additionally, we present InterFeedback-Human, a newly collected dataset of 120 cases designed for manually testing interactive performance in leading models such as OpenAI-o1 and Claude-3.5-Sonnet. Our evaluation results show that even state-of-the-art LMM (like OpenAI-o1) can correct their results through human feedback less than 50%. Our findings point to the need for methods that can enhance the LMMs' capability to interpret and benefit from feedback.

[Arxiv](https://arxiv.org/abs/2502.15027)