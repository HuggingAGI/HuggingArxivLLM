# # 摘要  
构建具有地理文化根基的大型语言模型生成方法。

发布时间：2025年02月20日

`RAG` `人工智能` `跨文化`

> Towards Geo-Culturally Grounded LLM Generations

# 摘要

> 生成式大型语言模型（LLMs）在跨文化知识的多样性方面存在差距。我们研究了检索增强生成和搜索定位技术对LLMs展示多样化国家文化熟悉度能力的影响。具体而言，我们比较了标准LLMs、基于定制知识库检索增强的LLMs（即KB定位）以及基于网络搜索检索增强的LLMs（即搜索定位）在一系列文化熟悉度基准测试中的表现。我们发现，搜索定位显著提升了LLMs在多项选择题基准测试中的表现，这些测试考察了关于国家文化的知识（如规范、人工制品和制度），而KB定位的效果受限于知识库覆盖范围不足和检索器性能不佳。然而，搜索定位也增加了语言模型做出刻板印象判断的风险，同时未能在具有足够统计效力的人类评估中改善评估者对文化熟悉度的判断。这些结果突显了在评估生成式LLMs的文化熟悉度时，关于文化的知识与开放式的文化流畅性之间的区别。

> Generative large language models (LLMs) have been demonstrated to have gaps in diverse, cultural knowledge across the globe. We investigate the effect of retrieval augmented generation and search-grounding techniques on the ability of LLMs to display familiarity with a diverse range of national cultures. Specifically, we compare the performance of standard LLMs, LLMs augmented with retrievals from a bespoke knowledge base (i.e., KB grounding), and LLMs augmented with retrievals from a web search (i.e., search grounding) on a series of cultural familiarity benchmarks. We find that search grounding significantly improves the LLM performance on multiple-choice benchmarks that test propositional knowledge (e.g., the norms, artifacts, and institutions of national cultures), while KB grounding's effectiveness is limited by inadequate knowledge base coverage and a suboptimal retriever. However, search grounding also increases the risk of stereotypical judgments by language models, while failing to improve evaluators' judgments of cultural familiarity in a human evaluation with adequate statistical power. These results highlight the distinction between propositional knowledge about a culture and open-ended cultural fluency when it comes to evaluating the cultural familiarity of generative LLMs.

[Arxiv](https://arxiv.org/abs/2502.13497)