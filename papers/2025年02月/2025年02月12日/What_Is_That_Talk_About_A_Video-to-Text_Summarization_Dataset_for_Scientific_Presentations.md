# 这场演讲讲了啥？一个用于科学演示的视频到文本摘要数据集

发布时间：2025年02月12日

`LLM应用

摘要中提到视频到文本摘要属于多模态学习，使用了大型模型进行基准测试，并应用了基于计划的框架。这些都属于将大型语言模型应用于具体任务的范畴，因此归类为LLM应用。` `多模态学习`

> What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations

# 摘要

> 视频到文本摘要在多模态学习中是一个日益增长的挑战。本文介绍了VISTA，一个专为科学领域设计的视频到文本摘要数据集。VISTA包含18,599个AI会议演讲视频及其对应的论文摘要。我们对当前最先进的大型模型进行了基准测试，并采用基于计划的框架来更好地捕捉摘要的结构化特性。人工和自动化评估均证实，显式规划可提升摘要质量和事实一致性。然而，模型与人类表现之间仍存在显著差距，凸显了科学视频摘要的挑战性。

> Transforming recorded videos into concise and accurate textual summaries is a growing challenge in multimodal learning. This paper introduces VISTA, a dataset specifically designed for video-to-text summarization in scientific domains. VISTA contains 18,599 recorded AI conference presentations paired with their corresponding paper abstracts. We benchmark the performance of state-of-the-art large models and apply a plan-based framework to better capture the structured nature of abstracts. Both human and automated evaluations confirm that explicit planning enhances summary quality and factual consistency. However, a considerable gap remains between models and human performance, highlighting the challenges of scientific video summarization.

[Arxiv](https://arxiv.org/abs/2502.08279)