# 可信的GNNs结合LLMs：系统性综述与分类框架

发布时间：2025年02月12日

`其他` `人工智能` `可信计算`

> Trustworthy GNNs with LLMs: A Systematic Review and Taxonomy

# 摘要

> 图神经网络（GNNs）在多领域的广泛应用使其可信度成为研究热点。现有研究表明，大型语言模型（LLMs）的引入能显著提升GNNs在语义理解与生成方面的能力，从而从多个维度增强GNNs的可信度。本综述提出了一种分类法，为研究人员提供清晰的框架，帮助理解不同方法的原理与应用场景，并阐明了各种方法之间的联系与差异。随后，我们根据分类法的四个类别，系统性地梳理了具有代表性的方法。借助我们的分类法，研究人员能够深入理解每种方法在实现GNNs与LLMs可信结合时的适用场景、潜在优势及局限性。最后，我们展望了LLMs与GNNs结合的前沿方向与未来趋势，助力提升模型可信度。

> With the extensive application of Graph Neural Networks (GNNs) across various domains, their trustworthiness has emerged as a focal point of research. Some existing studies have shown that the integration of large language models (LLMs) can improve the semantic understanding and generation capabilities of GNNs, which in turn improves the trustworthiness of GNNs from various aspects. Our review introduces a taxonomy that offers researchers a clear framework for comprehending the principles and applications of different methods and helps clarify the connections and differences among various approaches. Then we systematically survey representative approaches along the four categories of our taxonomy. Through our taxonomy, researchers can understand the applicable scenarios, potential advantages, and limitations of each approach for the the trusted integration of GNNs with LLMs. Finally, we present some promising directions of work and future trends for the integration of LLMs and GNNs to improve model trustworthiness.

[Arxiv](https://arxiv.org/abs/2502.08353)