# 重新定义简洁之道：从词汇级到文档级的简化任务评测

发布时间：2025年02月12日

`LLM应用` `文本简化`

> Redefining Simplicity: Benchmarking Large Language Models from Lexical to Document Simplification

# 摘要

> 文本简化（TS）是一种在保持原文本的核心意义和关键信息的同时，降低文本复杂性的过程。目前的研究仅表明，大型语言模型（LLMs）在句子简化任务中表现优于监督式非LLM方法。本研究首次对LLM在四个文本简化任务中的表现进行了全面分析，这四个任务分别是词汇简化、句法简化、句子简化和文档简化。我们通过自动评估指标和人工评估，将轻量级、闭源和开源的LLM与传统非LLM方法进行了对比。实验结果表明，LLMs不仅在所有四个任务中表现优于非LLM方法，还经常生成比现有标注参考更高质量的输出。最后，我们探讨了LLM时代下文本简化的未来发展方向。

> Text simplification (TS) refers to the process of reducing the complexity of a text while retaining its original meaning and key information. Existing work only shows that large language models (LLMs) have outperformed supervised non-LLM-based methods on sentence simplification. This study offers the first comprehensive analysis of LLM performance across four TS tasks: lexical, syntactic, sentence, and document simplification. We compare lightweight, closed-source and open-source LLMs against traditional non-LLM methods using automatic metrics and human evaluations. Our experiments reveal that LLMs not only outperform non-LLM approaches in all four tasks but also often generate outputs that exceed the quality of existing human-annotated references. Finally, we present some future directions of TS in the era of LLMs.

[Arxiv](https://arxiv.org/abs/2502.08281)