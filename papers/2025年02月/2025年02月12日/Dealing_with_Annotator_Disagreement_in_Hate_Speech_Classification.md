# 解决标注者意见分歧在仇恨言论分类中的问题

发布时间：2025年02月12日

`LLM应用` `社交媒体`

> Dealing with Annotator Disagreement in Hate Speech Classification

# 摘要

> 仇恨言论检测至关重要，尤其在社交媒体上，有害内容迅速传播。通过机器学习模型自动识别仇恨言论，可有效减轻其影响和防止扩散。开发高效检测模型的第一步是获取高质量的训练数据集。标注数据是自然语言处理的基础，但仇恨言论分类因多样性和主观性而困难，常导致标注者意见分歧。本文探讨了应对这一问题的策略，特别是针对土耳其推文，基于微调BERT模型评估不同方法。研究强调了问题重要性，并为在线仇恨言论检测提供了最新基准结果。

> Hate speech detection is a crucial task, especially on social media, where harmful content can spread quickly. Implementing machine learning models to automatically identify and address hate speech is essential for mitigating its impact and preventing its proliferation. The first step in developing an effective hate speech detection model is to acquire a high-quality dataset for training. Labeled data is foundational for most natural language processing tasks, but categorizing hate speech is difficult due to the diverse and often subjective nature of hate speech, which can lead to varying interpretations and disagreements among annotators. This paper examines strategies for addressing annotator disagreement, an issue that has been largely overlooked. In particular, we evaluate different approaches to deal with annotator disagreement regarding hate speech classification in Turkish tweets, based on a fine-tuned BERT model. Our work highlights the importance of the problem and provides state-of-art benchmark results for detection and understanding of hate speech in online discourse.

[Arxiv](https://arxiv.org/abs/2502.08266)