# LLMER: 用大型语言模型生成的 JSON 数据打造交互式扩展现实世界

发布时间：2025年02月04日

`LLM应用

**理由**：该论文主要探讨了如何将大型语言模型（如GPT-4）与扩展现实（XR）技术结合，以构建沉浸式的XR环境。论文提出了一个名为LLMER的框架，利用LLMs生成的JSON数据来构建交互式XR世界，并优化了处理延迟和错误率。这些内容主要涉及LLM在实际应用中的使用和优化，因此归类为“LLM应用”。` `扩展现实`

> LLMER: Crafting Interactive Extended Reality Worlds with JSON Data Generated by Large Language Models

# 摘要

> 将GPT-4等大型语言模型（LLMs）与扩展现实（XR）技术结合，有望打造真正沉浸式的XR环境，通过自然语言与用户互动，例如从音频生成并动画化3D场景。然而，XR环境的复杂性使得从海量XR数据中精准提取上下文和场景/对象参数变得困难，这不仅增加了按使用付费的成本，还导致更高的生成错误率。此外，现有专注于生成代码脚本的方法常因错误导致脚本失效、应用崩溃，最终影响用户体验。为此，我们提出了LLMER框架，它利用LLMs生成的JSON数据构建交互式XR世界。与以往方法不同，LLMER将自然语言输入转换为JSON数据，大幅降低了应用崩溃和处理延迟的风险。它采用多阶段策略，仅提供用户所需的关键上下文信息，并设计了多个模块应对不同XR任务。初步用户研究表明，该系统显著优于现有方法，令牌消耗减少80%以上，任务完成时间缩短约60%。用户反馈也为进一步优化提供了方向。

> The integration of Large Language Models (LLMs) like GPT-4 with Extended Reality (XR) technologies offers the potential to build truly immersive XR environments that interact with human users through natural language, e.g., generating and animating 3D scenes from audio inputs. However, the complexity of XR environments makes it difficult to accurately extract relevant contextual data and scene/object parameters from an overwhelming volume of XR artifacts. It leads to not only increased costs with pay-per-use models, but also elevated levels of generation errors. Moreover, existing approaches focusing on coding script generation are often prone to generation errors, resulting in flawed or invalid scripts, application crashes, and ultimately a degraded user experience. To overcome these challenges, we introduce LLMER, a novel framework that creates interactive XR worlds using JSON data generated by LLMs. Unlike prior approaches focusing on coding script generation, LLMER translates natural language inputs into JSON data, significantly reducing the likelihood of application crashes and processing latency. It employs a multi-stage strategy to supply only the essential contextual information adapted to the user's request and features multiple modules designed for various XR tasks. Our preliminary user study reveals the effectiveness of the proposed system, with over 80% reduction in consumed tokens and around 60% reduction in task completion time compared to state-of-the-art approaches. The analysis of users' feedback also illuminates a series of directions for further optimization.

[Arxiv](https://arxiv.org/abs/2502.02441)