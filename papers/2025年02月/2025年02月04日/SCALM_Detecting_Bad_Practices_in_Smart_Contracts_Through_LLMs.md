# SCALM：利用LLMs识别智能合约中的不良实践

发布时间：2025年02月04日

`RAG` `区块链` `智能合约`

> SCALM: Detecting Bad Practices in Smart Contracts Through LLMs

# 摘要

> 随着以太坊平台的日益成熟和广泛应用，保持高水平的智能合约编写实践至关重要。尽管智能合约中的不良实践未必直接引发安全问题，但它们显著增加了潜在风险。因此，本研究旨在深入理解和规避这些不良实践，首次系统性地探讨了35个具体问题。我们提出了一种基于大型语言模型（LLMs）的框架SCALM，结合Step-Back Prompting和检索增强生成（RAG）技术，有效识别并解决各种不良实践。通过多轮实验验证，SCALM在检测智能合约不良实践方面超越现有工具，展现出显著优势。

> As the Ethereum platform continues to mature and gain widespread usage, it is crucial to maintain high standards of smart contract writing practices. While bad practices in smart contracts may not directly lead to security issues, they do elevate the risk of encountering problems. Therefore, to understand and avoid these bad practices, this paper introduces the first systematic study of bad practices in smart contracts, delving into over 35 specific issues. Specifically, we propose a large language models (LLMs)-based framework, SCALM. It combines Step-Back Prompting and Retrieval-Augmented Generation (RAG) to identify and address various bad practices effectively. Our extensive experiments using multiple LLMs and datasets have shown that SCALM outperforms existing tools in detecting bad practices in smart contracts.

[Arxiv](https://arxiv.org/abs/2502.04347)