# VidLBEval：视频相关的大语言模型中语言偏见的基准测试及缓解方法

发布时间：2025年02月23日

`LLM应用` `视频处理` `计算机视觉`

> VidLBEval: Benchmarking and Mitigating Language Bias in Video-Involved LVLMs

# 摘要

> 大型视觉-语言模型（LVLMs）在多模态任务和基准测试中取得了显著进展。然而，我们发现现有涉及视频的LVLMs中存在一个尚未充分探索的问题——语言偏见，即模型往往优先考虑语言而非视频，导致错误响应。为解决这一问题，我们构建了视频语言偏见评估基准，通过模糊视频对比和疑问句探查两大任务，专门用于评估涉及视频的LVLMs中的语言偏见。同时，我们设计了配套的评估指标，旨在惩罚因语言而产生的偏见。此外，我们提出了多分支对比解码（MCD），通过引入两个专家分支，有效抵消业余文本-only分支可能产生的语言偏见。实验结果表明，i) 现有的涉及视频的LVLMs，无论是专有还是开源，都严重受限于语言偏见问题；ii) 我们的MCD能够有效缓解这一问题，并在各种涉及视频的LVLMs中保持通用能力，且无需额外的重新训练或修改模型架构。

> Recently, Large Vision-Language Models (LVLMs) have made significant strides across diverse multimodal tasks and benchmarks. This paper reveals a largely under-explored problem from existing video-involved LVLMs - language bias, where models tend to prioritize language over video and thus result in incorrect responses. To address this research gap, we first collect a Video Language Bias Evaluation Benchmark, which is specifically designed to assess the language bias in video-involved LVLMs through two key tasks: ambiguous video contrast and interrogative question probing. Accordingly, we design accompanied evaluation metrics that aim to penalize LVLMs being biased by language. In addition, we also propose Multi-branch Contrastive Decoding (MCD), introducing two expert branches to simultaneously counteract language bias potentially generated by the amateur text-only branch. Our experiments demonstrate that i) existing video-involved LVLMs, including both proprietary and open-sourced, are largely limited by the language bias problem; ii) our MCD can effectively mitigate this issue and maintain general-purpose capabilities in various video-involved LVLMs without any additional retraining or alteration to model architectures.

[Arxiv](https://arxiv.org/abs/2502.16602)