# LLM 能否诚实地生成让普通人能理解的“自我”？：高风险领域的案例探析

发布时间：2024年11月25日

`LLM应用`

> Can LLMs faithfully generate their layperson-understandable 'self'?: A Case Study in High-Stakes Domains

# 摘要

> 大型语言模型（LLMs）对人类知识的几乎每个领域都产生了显著影响。然而，这些模型对于非专业人士的可解释性（这对于建立信任至关重要），已从各种怀疑的角度进行了审视。在本文中，我们借助多个先进的LLMs，在法律、健康和金融这三个重要应用领域，为非专业人士引入了一种新的LLM可解释性概念，称为$	extit{ReQuesting}$。该概念通过高度的可重复性，在多个任务上展现出了忠实生成非专业人士能理解的可解释算法。而且，我们发现可解释算法与LLMs的内在推理有明显的契合。

> Large Language Models (LLMs) have significantly impacted nearly every domain of human knowledge. However, the explainability of these models esp. to laypersons, which are crucial for instilling trust, have been examined through various skeptical lenses. In this paper, we introduce a novel notion of LLM explainability to laypersons, termed $\textit{ReQuesting}$, across three high-priority application domains -- law, health and finance, using multiple state-of-the-art LLMs. The proposed notion exhibits faithful generation of explainable layman-understandable algorithms on multiple tasks through high degree of reproducibility. Furthermore, we observe a notable alignment of the explainable algorithms with intrinsic reasoning of the LLMs.

[Arxiv](https://arxiv.org/abs/2412.07781)