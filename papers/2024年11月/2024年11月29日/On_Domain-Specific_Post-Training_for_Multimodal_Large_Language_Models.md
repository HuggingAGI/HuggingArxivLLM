# 有关多模态大型语言模型的特定领域后训练

发布时间：2024年11月29日

`LLM应用`

> On Domain-Specific Post-Training for Multimodal Large Language Models

# 摘要

> 近年来，通用多模态大型语言模型（MLLMs）发展迅猛。然而，将通用 MLLMs 适配到特定领域，比如科学领域和工业应用，仍探索不足。本文通过后训练对 MLLMs 的领域适配展开了系统研究，重点聚焦于数据合成、训练流程和任务评估。（1）数据合成：借助开源模型，我们研发了一种视觉指令合成器，能有效地从特定领域的图像-标题对生成多样的视觉指令任务。我们的合成任务在提升 MLLMs 的特定领域性能方面，比手动规则、GPT-4 以及 GPT-4V 生成的任务更出色。（2）训练流程：开发通用 MLLMs 通常采用两阶段训练，即先基于图像-标题对，再进行视觉指令任务，而我们采用单阶段训练流程，以增强特定领域后训练的任务多样性。（3）任务评估：我们在生物医学和食品这两个领域开展实验，对不同来源和规模的 MLLMs（如 Qwen2-VL-2B、LLaVA-v1.6-8B、Llama-3.2-11B）进行后训练，然后评估 MLLM 在各类特定领域任务上的表现。为助力 MLLM 领域适配的进一步研究，我们会将我们的实现开源。

> Recent years have witnessed the rapid development of general multimodal large language models (MLLMs). However, adapting general MLLMs to specific domains, such as scientific fields and industrial applications, remains less explored. This paper systematically investigates domain adaptation of MLLMs through post-training, focusing on data synthesis, training pipelines, and task evaluation. (1) Data Synthesis: Using open-source models, we develop a visual instruction synthesizer that effectively generates diverse visual instruction tasks from domain-specific image-caption pairs. Our synthetic tasks surpass those generated by manual rules, GPT-4, and GPT-4V in enhancing the domain-specific performance of MLLMs. (2) Training Pipeline: While the two-stage training--initially on image-caption pairs followed by visual instruction tasks--is commonly adopted for developing general MLLMs, we apply a single-stage training pipeline to enhance task diversity for domain-specific post-training. (3) Task Evaluation: We conduct experiments in two domains, biomedicine and food, by post-training MLLMs of different sources and scales (e.g., Qwen2-VL-2B, LLaVA-v1.6-8B, Llama-3.2-11B), and then evaluating MLLM performance on various domain-specific tasks. To support further research in MLLM domain adaptation, we will open-source our implementations.

[Arxiv](https://arxiv.org/abs/2411.19930)