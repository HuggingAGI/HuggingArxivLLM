# ElectroVizQA：多模态LLMs在电子视觉问答方面表现怎样？

发布时间：2024年11月27日

`LLM应用` `电子工程`

> ElectroVizQA: How well do Multi-modal LLMs perform in Electronics Visual Question Answering?

# 摘要

> 多模态大型语言模型（MLLMs）因能处理多模态数据、为复杂问题提供更优的上下文理解而备受瞩目。MLLMs 在视觉问答（VQA）等任务中表现出色，但在基础工程问题上常遇难题，且数字电子等主题的训练专用数据集稀缺。为弥补这一不足，我们推出了名为 ElectroVizQA 的基准数据集，专门用于评测 MLLMs 在本科课程常见数字电子电路问题上的表现。此数据集是数字电子领域 VQA 任务的首个此类定制数据集，约含 626 个视觉问题，全面涵盖了数字电子主题。本文严格考量了 MLLMs 理解和解决数字电子电路问题的水平，深入探究了它们在这一专业领域的能力与局限。通过引入这一基准数据集，我们期望促进 MLLMs 在工程教育应用中的进一步研究与开发，最终缩小性能差距，提升这些模型在技术领域的效能。

> Multi-modal Large Language Models (MLLMs) are gaining significant attention for their ability to process multi-modal data, providing enhanced contextual understanding of complex problems. MLLMs have demonstrated exceptional capabilities in tasks such as Visual Question Answering (VQA); however, they often struggle with fundamental engineering problems, and there is a scarcity of specialized datasets for training on topics like digital electronics. To address this gap, we propose a benchmark dataset called ElectroVizQA specifically designed to evaluate MLLMs' performance on digital electronic circuit problems commonly found in undergraduate curricula. This dataset, the first of its kind tailored for the VQA task in digital electronics, comprises approximately 626 visual questions, offering a comprehensive overview of digital electronics topics. This paper rigorously assesses the extent to which MLLMs can understand and solve digital electronic circuit questions, providing insights into their capabilities and limitations within this specialized domain. By introducing this benchmark dataset, we aim to motivate further research and development in the application of MLLMs to engineering education, ultimately bridging the performance gap and enhancing the efficacy of these models in technical fields.

[Arxiv](https://arxiv.org/abs/2412.00102)