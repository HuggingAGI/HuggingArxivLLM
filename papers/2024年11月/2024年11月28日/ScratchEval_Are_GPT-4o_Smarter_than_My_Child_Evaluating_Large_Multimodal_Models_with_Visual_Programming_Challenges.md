# ScratchEval: GPT-4o真的比我的孩子更聪明吗？用视觉编程挑战评估大型多模态模型

发布时间：2024年11月28日

`其他` `编程教育` `视觉编程`

> ScratchEval: Are GPT-4o Smarter than My Child? Evaluating Large Multimodal Models with Visual Programming Challenges

# 摘要

> 大型多模态模型（LMMs）近期在代码生成领域取得了显著进展，主要通过图像到代码的基准测试进行评估。然而，现有基准测试局限于特定的视觉编程场景，导致逻辑推理与多模态理解能力被割裂。为解决这一问题，我们提出了ScratchEval——一个全新的基准测试，专为评估LMMs的视觉编程推理能力而设计。基于Scratch（一种广泛应用于儿童编程教育的基于块的视觉编程语言），ScratchEval通过整合视觉元素和嵌入式编程逻辑，要求模型同时处理视觉信息和代码结构，从而全面评估其对编程意图的理解能力。我们的评估方法突破了传统图像到代码的映射模式，专注于统一的逻辑思维与问题解决能力，为评估LMMs的视觉编程能力提供了更全面、更具挑战性的框架。ScratchEval不仅弥补了现有评估方法的不足，还为未来LMMs在视觉编程领域的开发提供了新的研究方向。我们的基准测试已在GitHub上开源，欢迎访问https://github.com/HKBUNLP/ScratchEval。


> Recent advancements in large multimodal models (LMMs) have showcased impressive code generation capabilities, primarily evaluated through image-to-code benchmarks. However, these benchmarks are limited to specific visual programming scenarios where the logic reasoning and the multimodal understanding capacities are split apart. To fill this gap, we propose ScratchEval, a novel benchmark designed to evaluate the visual programming reasoning ability of LMMs. ScratchEval is based on Scratch, a block-based visual programming language widely used in children's programming education. By integrating visual elements and embedded programming logic, ScratchEval requires the model to process both visual information and code structure, thereby comprehensively evaluating its programming intent understanding ability. Our evaluation approach goes beyond the traditional image-to-code mapping and focuses on unified logical thinking and problem-solving abilities, providing a more comprehensive and challenging framework for evaluating the visual programming ability of LMMs. ScratchEval not only fills the gap in existing evaluation methods, but also provides new insights for the future development of LMMs in the field of visual programming. Our benchmark can be accessed at https://github.com/HKBUNLP/ScratchEval .

[Arxiv](https://arxiv.org/abs/2411.18932)