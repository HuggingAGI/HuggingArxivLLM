# # 摘要
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年04月07日

`LLM应用` `问答系统`

> A Lightweight Large Vision-language Model for Multimodal Medical Images

# 摘要

> 医学视觉问答（VQA）通过解读医学影像并回答临床问题，显著提升了临床决策能力。然而，由于医学影像的复杂性和多样的模态，开发高效且高性能的VQA模型颇具挑战性。本文提出了一种轻量级多模态VQA模型，整合了BiomedCLIP用于图像特征提取和LLaMA-3用于文本处理。专为医学VQA任务设计，该模型在OmniMedVQA数据集上实现了最先进的性能。尽管拥有80亿参数，该模型仅需两块NVIDIA 40 GB A100 GPU，相较于更大规模的模型展现了更优的效率。实验结果表明，在开放性问题上达到了73.4%的准确率，超越现有模型，验证了其在真实医疗场景中的应用潜力。主要贡献包括：一种专门针对医学领域的多模态VQA模型、资源高效的架构设计，以及在开放性临床问题解答上的出色表现。

> Medical Visual Question Answering (VQA) enhances clinical decision-making by enabling systems to interpret medical images and answer clinical queries. However, developing efficient, high-performance VQA models is challenging due to the complexity of medical imagery and diverse modalities. In this paper, we introduce a lightweight, multimodal VQA model integrating BiomedCLIP for image feature extraction and LLaMA-3 for text processing. Designed for medical VQA tasks, our model achieves state-of-the-art performance on the OmniMedVQA dataset. With approximately 8 billion parameters, it requires only two NVIDIA 40 GB A100 GPUs, demonstrating superior efficiency over larger models. Our results show 73.4% accuracy for open-end questions, surpassing existing models and validating its potential for real-world medical applications. Key contributions include a specialized multimodal VQA model, a resource-efficient architecture, and strong performance in answering open-ended clinical questions.

[Arxiv](https://arxiv.org/abs/2504.05575)