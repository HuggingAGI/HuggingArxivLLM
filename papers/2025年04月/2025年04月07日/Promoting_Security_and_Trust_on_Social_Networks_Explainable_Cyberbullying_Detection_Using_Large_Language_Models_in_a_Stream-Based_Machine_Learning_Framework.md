# 构建安全可信的社交网络环境：基于流式机器学习框架，利用大型语言模型实现可解释的网络欺凌行为检测

发布时间：2025年04月07日

`LLM应用` `社交媒体`

> Promoting Security and Trust on Social Networks: Explainable Cyberbullying Detection Using Large Language Models in a Stream-Based Machine Learning Framework

# 摘要

> 社交媒体平台实现了即时且无处不在的连接，对我们在科技社会中的社交互动与交流至关重要。然而，这些平台也催生了在线社区中的负面行为——网络欺凌。尽管近期文献中有很多关于生成式人工智能（AI）的研究，但仍有机会研究其在零/少样本学习策略之外的性能表现。因此，我们提出了一种创新的实时网络欺凌检测方案，该方案利用流式机器学习（ML）模型逐步处理传入样本，并借助大型语言模型（LLMs）进行特征工程，以应对在线虐待和仇恨言论的不断演变。我们还提供了一个可解释性仪表盘，以增强系统的可信度、可靠性和可问责性。实验数据的结果显示，所有评估指标的性能均接近90%，超过了文献中现有工作的表现。最终，我们的提案通过及时检测虐待行为，有助于保护在线社区的安全，防止长期骚扰，减少社会中的负面影响。

> Social media platforms enable instant and ubiquitous connectivity and are essential to social interaction and communication in our technological society. Apart from its advantages, these platforms have given rise to negative behaviors in the online community, the so-called cyberbullying. Despite the many works involving generative Artificial Intelligence (AI) in the literature lately, there remain opportunities to study its performance apart from zero/few-shot learning strategies. Accordingly, we propose an innovative and real-time solution for cyberbullying detection that leverages stream-based Machine Learning (ML) models able to process the incoming samples incrementally and Large Language Models (LLMS) for feature engineering to address the evolving nature of abusive and hate speech online. An explainability dashboard is provided to promote the system's trustworthiness, reliability, and accountability. Results on experimental data report promising performance close to 90 % in all evaluation metrics and surpassing those obtained by competing works in the literature. Ultimately, our proposal contributes to the safety of online communities by timely detecting abusive behavior to prevent long-lasting harassment and reduce the negative consequences in society.

[Arxiv](https://arxiv.org/abs/2505.03746)