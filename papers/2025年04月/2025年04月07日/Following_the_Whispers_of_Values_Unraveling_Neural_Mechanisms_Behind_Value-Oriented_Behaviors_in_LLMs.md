# # 摘要
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年04月07日

`LLM理论` `人工智能` `社会学`

> Following the Whispers of Values: Unraveling Neural Mechanisms Behind Value-Oriented Behaviors in LLMs

# 摘要

> 尽管大型语言模型（LLMs）表现出色，但它们可能表现出由编码价值观驱动的意外偏差和有害行为，这凸显了理解其背后价值机制的紧迫性。然而，当前研究主要通过外部响应评估这些价值观，重点关注AI安全，缺乏可解释性，并未能在现实场景中评估社会价值观。本文提出了一种名为ValueExploration的新框架，旨在从神经元层面探索LLMs中行为驱动的国家社会价值观机制。以个案研究为例，我们聚焦于中国社会价值观，首先构建了C-voice，这是一个大规模的双语基准测试，用于识别和评估LLMs中的中国社会价值观。借助C-voice，我们随后识别并定位了负责编码这些价值观的神经元，依据激活差异进行分类。最后，通过去活化这些神经元，我们分析了模型行为的变化，揭示了价值观影响LLMs决策的内部机制。在四个代表性的LLMs上进行的广泛实验验证了我们框架的有效性。该基准测试和代码即将公开。

> Despite the impressive performance of large language models (LLMs), they can present unintended biases and harmful behaviors driven by encoded values, emphasizing the urgent need to understand the value mechanisms behind them. However, current research primarily evaluates these values through external responses with a focus on AI safety, lacking interpretability and failing to assess social values in real-world contexts. In this paper, we propose a novel framework called ValueExploration, which aims to explore the behavior-driven mechanisms of National Social Values within LLMs at the neuron level. As a case study, we focus on Chinese Social Values and first construct C-voice, a large-scale bilingual benchmark for identifying and evaluating Chinese Social Values in LLMs. By leveraging C-voice, we then identify and locate the neurons responsible for encoding these values according to activation difference. Finally, by deactivating these neurons, we analyze shifts in model behavior, uncovering the internal mechanism by which values influence LLM decision-making. Extensive experiments on four representative LLMs validate the efficacy of our framework. The benchmark and code will be available.

[Arxiv](https://arxiv.org/abs/2504.04994)