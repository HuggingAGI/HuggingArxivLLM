# 视觉-语言预训练在放射学中的现实检验：文本应用的进展如何？

发布时间：2025年04月07日

`其他` `计算机视觉`

> A Reality Check of Vision-Language Pre-training in Radiology: Have We Progressed Using Text?

# 摘要

> 视觉-语言预训练因其能够利用大规模数据源学习丰富的特征表示而备受关注。这一范式迅速在医学图像分析领域得到应用，尤其是放射学领域，近期已有大量相关研究。然而，现有的医学图像-文本数据集十分有限，且医学概念精细复杂，现有视觉-语言模型难以有效编码这些专业知识。本文提出，应从现有文献中暂退一步，重新审视有监督的单模态预训练方法，采用精细标签进行研究。通过广泛比较，我们发现单模态预训练不仅极具竞争力，而且更适合整合异构数据源。此外，我们的研究结果还对近期视觉-语言模型在开放词汇泛化方面的潜力提出了质疑，这些模型的评估往往基于过于乐观的实验设置。最后，我们探讨了更优地整合精细标签和噪声文本监督的新方法。

> Vision-language pre-training has recently gained popularity as it allows learning rich feature representations using large-scale data sources. This paradigm has quickly made its way into the medical image analysis community. In particular, there is an impressive amount of recent literature developing vision-language models for radiology. However, the available medical datasets with image-text supervision are scarce, and medical concepts are fine-grained, involving expert knowledge that existing vision-language models struggle to encode. In this paper, we propose to take a prudent step back from the literature and revisit supervised, unimodal pre-training, using fine-grained labels instead. We conduct an extensive comparison demonstrating that unimodal pre-training is highly competitive and better suited to integrating heterogeneous data sources. Our results also question the potential of recent vision-language models for open-vocabulary generalization, which have been evaluated using optimistic experimental settings. Finally, we study novel alternatives to better integrate fine-grained labels and noisy text supervision.

[Arxiv](https://arxiv.org/abs/2504.05227)