# 微调对抗扩展

发布时间：2025年04月23日

`LLM理论` `计算社会科学` `算法批判研究`

> Tinkering Against Scaling

# 摘要

> 人工智能研究中规模化发展的兴起在过去十年间彻底改变了这一领域，但也给学术研究者带来了重大挑战，尤其是在计算社会科学和算法批判研究领域。大型语言模型的主导地位，体现在其庞大的参数规模和高昂的训练成本，导致只有与产业界挂钩的研究者才能获取这些资源。这种失衡使得学术研究者难以完全理解他们的研究工具，从而引发计算社会科学中的可重复性问题以及算法批判研究中对“黑箱”比喻的过度依赖。
    为应对这些挑战，我们提出了一种受现有研究启发的“修补”方法。这种方法涉及使用小型模型或普通研究者可管理的组件，促进与算法的直接互动。我们认为，修补不仅是计算社会科学中的一种制作与认知方式，也是算法批判研究中的一种认知方式，从根本上说，它是一种具有更广泛影响的关怀方式。

> The ascent of scaling in artificial intelligence research has revolutionized the field over the past decade, yet it presents significant challenges for academic researchers, particularly in computational social science and critical algorithm studies. The dominance of large language models, characterized by their extensive parameters and costly training processes, creates a disparity where only industry-affiliated researchers can access these resources. This imbalance restricts academic researchers from fully understanding their tools, leading to issues like reproducibility in computational social science and a reliance on black-box metaphors in critical studies.
  To address these challenges, we propose a "tinkering" approach that is inspired by existing works. This method involves engaging with smaller models or components that are manageable for ordinary researchers, fostering hands-on interaction with algorithms. We argue that tinkering is both a way of making and knowing for computational social science and a way of knowing for critical studies, and fundamentally, it is a way of caring that has broader implications for both fields.

[Arxiv](https://arxiv.org/abs/2504.16546)