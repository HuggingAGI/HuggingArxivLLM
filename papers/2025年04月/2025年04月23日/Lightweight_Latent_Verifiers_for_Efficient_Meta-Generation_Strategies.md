# 轻量级潜在验证器：高效元生成策略的研究

发布时间：2025年04月23日

`LLM应用` `人工智能`

> Lightweight Latent Verifiers for Efficient Meta-Generation Strategies

# 摘要

> 验证器作为辅助模型，用于评估基础大型语言模型 (LLMs) 生成输出的正确性。在利用 LLM 解决推理密集型问题的众多策略中，验证器扮演着重要角色。通常，验证器本身也是 LLM，规模与（或大于）支持的基础模型，这使得它们计算成本高昂。在本研究中，我们提出了一种名为 LiLaVe 的新颖轻量级验证方法，它能够可靠地从基础 LLM 的隐藏状态中提取正确性信号。LiLaVe 的关键优势在于，其运行所需的计算预算仅为传统基于 LLM 的验证器的一小部分。为了展示其实际应用价值，我们将 LiLaVe 与流行的元生成策略（如 best-of-n 或自洽性）相结合。此外，我们还设计了新颖的 LiLaVe 基础方法，如条件自我修正或条件多数投票，这些方法在使用较小规模 LLM 的生成任务中显著提升了准确性和效率。本研究展示了从 LLM 隐藏状态中提取潜藏信息的丰富性，并为推理密集型应用提供了可扩展且资源高效的解决方案。

> Verifiers are auxiliary models that assess the correctness of outputs generated by base large language models (LLMs). They play a crucial role in many strategies for solving reasoning-intensive problems with LLMs. Typically, verifiers are LLMs themselves, often as large (or larger) than the base model they support, making them computationally expensive. In this work, we introduce a novel lightweight verification approach, LiLaVe, which reliably extracts correctness signals from the hidden states of the base LLM. A key advantage of LiLaVe is its ability to operate with only a small fraction of the computational budget required by traditional LLM-based verifiers. To demonstrate its practicality, we couple LiLaVe with popular meta-generation strategies, like best-of-n or self-consistency. Moreover, we design novel LiLaVe-based approaches, like conditional self-correction or conditional majority voting, that significantly improve both accuracy and efficiency in generation tasks with smaller LLMs. Our work demonstrates the fruitfulness of extracting latent information from the hidden states of LLMs, and opens the door to scalable and resource-efficient solutions for reasoning-intensive applications.

[Arxiv](https://arxiv.org/abs/2504.16760)