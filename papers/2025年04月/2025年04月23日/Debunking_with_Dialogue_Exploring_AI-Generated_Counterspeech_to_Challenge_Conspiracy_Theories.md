# 对话式辟谣？探索AI生成的反言论在挑战阴谋论中的应用

发布时间：2025年04月23日

`LLM应用` `内容安全`

> Debunking with Dialogue? Exploring AI-Generated Counterspeech to Challenge Conspiracy Theories

# 摘要

> 反言论是应对有害在线内容的重要策略，但要规模化专家驱动的努力却充满挑战。大型语言模型（LLMs）提供了一个潜在的解决方案，尽管它们在应对阴谋论方面的应用研究尚不充分。与仇恨言论不同，目前没有将阴谋论评论与专家设计的反言论配对的数据集。我们通过评估GPT-4o、Llama 3和Mistral在结构化提示下应用基于心理学研究的反言论策略的能力，来填补这一空白。我们的结果显示，这些模型往往生成通用、重复或浅显的结果。此外，它们过度承认恐惧，并经常编造事实、来源或数据，这使得它们在实际应用中基于提示的使用存在问题。


> Counterspeech is a key strategy against harmful online content, but scaling expert-driven efforts is challenging. Large Language Models (LLMs) present a potential solution, though their use in countering conspiracy theories is under-researched. Unlike for hate speech, no datasets exist that pair conspiracy theory comments with expert-crafted counterspeech. We address this gap by evaluating the ability of GPT-4o, Llama 3, and Mistral to effectively apply counterspeech strategies derived from psychological research provided through structured prompts. Our results show that the models often generate generic, repetitive, or superficial results. Additionally, they over-acknowledge fear and frequently hallucinate facts, sources, or figures, making their prompt-based use in practical applications problematic.

[Arxiv](https://arxiv.org/abs/2504.16604)