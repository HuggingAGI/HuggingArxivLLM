# LLMCode：评估及提升研究者与AI在定性分析中的对齐

发布时间：2025年04月23日

`LLM应用` `人工智能`

> LLMCode: Evaluating and Enhancing Researcher-AI Alignment in Qualitative Analysis

# 摘要

> 在定性分析中运用大型语言模型 (LLMs) 虽然能显著提升效率，但也引发了关于其与设计研究 (RfD) 中情境性质契合度的疑问。本研究旨在探讨 LLM 驱动设计见解的可信度，以定性编码为例，深入分析了 RfD 中的核心解释过程。我们开发了开源工具 LLMCode，结合交集与并集的比值 (IoU) 和修改 Hausdorff 距离两项指标，用于评估人类与 LLM 生成见解之间的契合度。在两项涉及 26 名设计师的研究中发现，模型在演绎编码方面表现出色，但在模拟设计师对数据的深度解释能力方面存在局限，这进一步凸显了人机协作的重要性。研究结果揭示了一种互惠的动态关系：用户通过模型的建议不断优化 LLM 输出，同时调整自身视角。这些发现强调了设计工具的重要性，这些工具应在促进设计师与 AI 之间直观协作的同时，保持解释的深度，从而培养对 LLM 的适当依赖性。

> The use of large language models (LLMs) in qualitative analysis offers enhanced efficiency but raises questions about their alignment with the contextual nature of research for design (RfD). This research examines the trustworthiness of LLM-driven design insights, using qualitative coding as a case study to explore the interpretive processes central to RfD. We introduce LLMCode, an open-source tool integrating two metrics, namely Intersection over Union (IoU) and Modified Hausdorff Distance, to assess the alignment between human and LLM-generated insights. Across two studies involving 26 designers, we find that while the model performs well with deductive coding, its ability to emulate a designer's deeper interpretive lens over the data is limited, emphasising the importance of human-AI collaboration. Our results highlight a reciprocal dynamic where users refine LLM outputs and adapt their own perspectives based on the model's suggestions. These findings underscore the importance of fostering appropriate reliance on LLMs by designing tools that preserve interpretive depth while facilitating intuitive collaboration between designers and AI.

[Arxiv](https://arxiv.org/abs/2504.16671)