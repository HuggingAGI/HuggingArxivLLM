# 基于大语言模型的增强上下文漏洞检测

发布时间：2025年04月23日

`LLM应用` `软件安全` `人工智能`

> Context-Enhanced Vulnerability Detection Based on Large Language Model

# 摘要

> 漏洞检测是软件安全的关键环节。准确识别漏洞不仅能预防潜在的安全威胁，还能有效保护软件系统免受恶意攻击。近年来，基于深度学习和大型语言模型（LLMs）的漏洞检测方法吸引了广泛关注。然而，现有方法多聚焦于分析单个文件或函数，难以获取足够的上下文信息。尽管分析整个代码仓库有助于获取上下文，但会带来显著的噪声和计算开销。为解决这一问题，我们提出了一种结合程序分析与LLMs的上下文增强漏洞检测方法。具体而言，我们通过程序分析在不同抽象层次提取上下文信息，有效过滤无关噪声。将抽象后的上下文与源代码共同输入LLM进行漏洞检测。我们深入研究了不同层次的上下文粒度对基于LLM漏洞检测性能的影响。我们的目标是在提供足够细节以准确捕捉漏洞与避免增加不必要的复杂性之间找到平衡。通过基于GPT-4、DeepSeek和CodeLLaMA等模型的广泛研究，并采用多种提示策略，我们得出以下关键发现：(1)引入抽象后的上下文显著提升了漏洞检测的有效性；(2)不同模型受益于不同层次的抽象，这取决于它们对代码的理解能力；(3)通过程序分析捕捉程序行为，为通用的基于LLM的代码分析任务提供了一种值得深入探索的方向。

> Vulnerability detection is a critical aspect of software security. Accurate detection is essential to prevent potential security breaches and protect software systems from malicious attacks. Recently, vulnerability detection methods leveraging deep learning and large language models (LLMs) have garnered increasing attention. However, existing approaches often focus on analyzing individual files or functions, which limits their ability to gather sufficient contextual information. Analyzing entire repositories to gather context introduces significant noise and computational overhead. To address these challenges, we propose a context-enhanced vulnerability detection approach that combines program analysis with LLMs. Specifically, we use program analysis to extract contextual information at various levels of abstraction, thereby filtering out irrelevant noise. The abstracted context along with source code are provided to LLM for vulnerability detection. We investigate how different levels of contextual granularity improve LLM-based vulnerability detection performance. Our goal is to strike a balance between providing sufficient detail to accurately capture vulnerabilities and minimizing unnecessary complexity that could hinder model performance. Based on an extensive study using GPT-4, DeepSeek, and CodeLLaMA with various prompting strategies, our key findings includes: (1) incorporating abstracted context significantly enhances vulnerability detection effectiveness; (2) different models benefit from distinct levels of abstraction depending on their code understanding capabilities; and (3) capturing program behavior through program analysis for general LLM-based code analysis tasks can be a direction that requires further attention.

[Arxiv](https://arxiv.org/abs/2504.16877)