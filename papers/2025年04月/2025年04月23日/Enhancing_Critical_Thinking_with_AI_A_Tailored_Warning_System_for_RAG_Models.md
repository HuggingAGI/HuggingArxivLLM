# 借助AI提升批判性思维：为RAG模型打造的专属警示系统

发布时间：2025年04月23日

`RAG` `人工智能`

> Enhancing Critical Thinking with AI: A Tailored Warning System for RAG Models

# 摘要

> 检索增强生成（RAG）系统通过整合经过事实核查且上下文相关的资讯，为提升大型语言模型（LLM）的输出提供了一种强大的方法。然而，公平性和可靠性问题仍然存在，因为在检索和生成阶段都可能出现幻觉，从而影响用户的推理和决策。我们的研究探讨了定制化警告信息——其内容依据幻觉的具体上下文而定——如何在教育测验场景中塑造用户的推理和行动。初步研究结果表明，尽管警告信息能够提升对高层幻觉的准确性和认知度，但它们也可能引发认知摩擦，导致混淆并降低用户对系统的信任。通过探究这些交互作用，本研究为人工智能增强推理的更广泛目标做出了贡献：即开发能够积极支持人类反思、批判性思考和基于信息的决策制定，而非被动接受信息的系统。

> Retrieval-Augmented Generation (RAG) systems offer a powerful approach to enhancing large language model (LLM) outputs by incorporating fact-checked, contextually relevant information. However, fairness and reliability concerns persist, as hallucinations can emerge at both the retrieval and generation stages, affecting users' reasoning and decision-making. Our research explores how tailored warning messages -- whose content depends on the specific context of hallucination -- shape user reasoning and actions in an educational quiz setting. Preliminary findings suggest that while warnings improve accuracy and awareness of high-level hallucinations, they may also introduce cognitive friction, leading to confusion and diminished trust in the system. By examining these interactions, this work contributes to the broader goal of AI-augmented reasoning: developing systems that actively support human reflection, critical thinking, and informed decision-making rather than passive information consumption.

[Arxiv](https://arxiv.org/abs/2504.16883)