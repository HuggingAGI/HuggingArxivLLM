# # 超越自我报告：大型语言模型中多观察者代理在个性评估中的应用
超越传统的自我报告方法，我们提出了一种基于多观察者代理的框架，用于在大型语言模型中进行个性评估。

发布时间：2025年04月11日

`LLM理论` `心理学` `人工智能`

> Beyond Self-Reports: Multi-Observer Agents for Personality Assessment in Large Language Models

# 摘要

> 评估大型语言模型（LLMs）的人格特质正引起越来越多的关注。然而，传统基于自评问卷的人格评估方法可能因固有偏见和元知识污染而无法准确捕捉其行为细节。本文提出了一种受心理学中 informant-report 方法启发的多观察者框架，用于评估 LLM 的人格特质。与传统自评方法不同，我们的方法通过配置多个观察者代理在特定关系情境（如家庭、朋友或职场）中，模拟与目标 LLM 的互动场景。观察者通过对话后，对目标 LLM 的五大人格维度进行评分。实验表明，LLMs 的自评人格评分存在系统性偏差。聚合观察者评分能有效降低非系统性偏差，并在 5-7 个观察者时达到最佳可靠性。研究结果表明，关系情境显著影响人格认知，而多观察者范式能实现对 LLM 人格特质的更稳健、更具情境敏感性的评估。

> There is a growing interest in assessing the personality traits of Large language models (LLMs). However, traditional personality assessments based on self-report questionnaires may fail to capture their true behavioral nuances due to inherent biases and meta-knowledge contamination. This paper introduces a novel multi-observer framework for LLM personality assessment that draws inspiration from informant-report methods in psychology. Instead of relying solely on self-assessments, our approach employs multiple observer agents configured with a specific relationship context (e.g., family, friend, or workplace) to simulate interactive scenarios with a subject LLM. These observers engage in dialogues and subsequently provide ratings across the Big Five personality dimensions. Our experiments reveal that LLMs possess systematic biases in self-report personality ratings. Moreover, aggregating observer ratings effectively reduces non-systematic biases and achieves optimal reliability with 5-7 observers. The findings highlight the significant impact of relationship context on personality perception and demonstrate that a multi-observer paradigm yields a more robust and context-sensitive evaluation of LLM personality traits.

[Arxiv](https://arxiv.org/abs/2504.08399)