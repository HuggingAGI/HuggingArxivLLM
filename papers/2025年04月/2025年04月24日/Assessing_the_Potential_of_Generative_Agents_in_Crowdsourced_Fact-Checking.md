# 探索生成式智能体在众包事实核查中的潜力

发布时间：2025年04月24日

`Agent` `信息核实` `人工智能`

> Assessing the Potential of Generative Agents in Crowdsourced Fact-Checking

# 摘要

> 在线虚假信息的蔓延亟需可扩展、可靠的事实核查方案。众包事实核查——由非专家评估声明真实性——提供了一种更具成本效益的替代方案，尽管质量不一致和偏见问题仍存。在某些背景下取得的积极成果激励下，X（前身为Twitter）、Facebook和Instagram等平台已开始从集中式审核转向分散式、基于众包的模式。

与此同时，大型语言模型（LLMs）在事实核查的核心任务（如声明检测和证据评估）中表现出色。然而，其在众包工作流程中的潜力尚未被挖掘。本研究探讨了LLM驱动的生成型代理——模拟人类行为与决策的自主实体——能否为传统上由人类众包执行的事实核查任务贡献力量。基于La Barbera等人（2024）的协议，我们模拟了具有多样化人口统计和意识形态背景的生成型代理群体。这些代理负责检索证据、从多维度评估声明，并做出最终真实性判断。

研究结果显示，生成型代理群体在真实性分类上超越人类群体，展现出更高的内部一致性和更低的偏见易感性。与人类相比，代理更系统地依赖准确度、精确度和信息量等标准，表明其决策过程更加结构化。总体而言，我们的发现凸显了生成型代理在基于众包的事实核查系统中作为可扩展、一致且偏见较少的贡献者的潜力。

> The growing spread of online misinformation has created an urgent need for scalable, reliable fact-checking solutions. Crowdsourced fact-checking - where non-experts evaluate claim veracity - offers a cost-effective alternative to expert verification, despite concerns about variability in quality and bias. Encouraged by promising results in certain contexts, major platforms such as X (formerly Twitter), Facebook, and Instagram have begun shifting from centralized moderation to decentralized, crowd-based approaches.
  In parallel, advances in Large Language Models (LLMs) have shown strong performance across core fact-checking tasks, including claim detection and evidence evaluation. However, their potential role in crowdsourced workflows remains unexplored. This paper investigates whether LLM-powered generative agents - autonomous entities that emulate human behavior and decision-making - can meaningfully contribute to fact-checking tasks traditionally reserved for human crowds. Using the protocol of La Barbera et al. (2024), we simulate crowds of generative agents with diverse demographic and ideological profiles. Agents retrieve evidence, assess claims along multiple quality dimensions, and issue final veracity judgments.
  Our results show that agent crowds outperform human crowds in truthfulness classification, exhibit higher internal consistency, and show reduced susceptibility to social and cognitive biases. Compared to humans, agents rely more systematically on informative criteria such as Accuracy, Precision, and Informativeness, suggesting a more structured decision-making process. Overall, our findings highlight the potential of generative agents as scalable, consistent, and less biased contributors to crowd-based fact-checking systems.

[Arxiv](https://arxiv.org/abs/2504.19940)