# JurisCTC：跨域迁移与对比学习助力法律判决预测

发布时间：2025年04月24日

`LLM应用`

> JurisCTC: Enhancing Legal Judgment Prediction via Cross-Domain Transfer and Contrastive Learning

# 摘要

> 近年来，无监督领域适应（UDA）在自然语言处理（NLP）领域备受关注，因其能显著提升模型在不同领域的泛化能力。然而，其在法律领域间的知识迁移应用尚待探索。为应对长篇复杂法律文本及标注数据集匮乏的挑战，我们提出JurisCTC，一款专为提升法律判决预测（LJP）任务准确性而设计的新型模型。与现有方法不同，JurisCTC不仅实现了跨法律领域的有效知识迁移，还通过对比学习区分不同领域的样本。具体而言，在LJP任务中，我们实现了民事与刑事法律领域间的知识迁移。相较于其他模型及特定的大语言模型（LLMs），JurisCTC表现优异，分别达到了76.59%和78.83%的峰值准确率。

> In recent years, Unsupervised Domain Adaptation (UDA) has gained significant attention in the field of Natural Language Processing (NLP) owing to its ability to enhance model generalization across diverse domains. However, its application for knowledge transfer between distinct legal domains remains largely unexplored. To address the challenges posed by lengthy and complex legal texts and the limited availability of large-scale annotated datasets, we propose JurisCTC, a novel model designed to improve the accuracy of Legal Judgment Prediction (LJP) tasks. Unlike existing approaches, JurisCTC facilitates effective knowledge transfer across various legal domains and employs contrastive learning to distinguish samples from different domains. Specifically, for the LJP task, we enable knowledge transfer between civil and criminal law domains. Compared to other models and specific large language models (LLMs), JurisCTC demonstrates notable advancements, achieving peak accuracies of 76.59% and 78.83%, respectively.

[Arxiv](https://arxiv.org/abs/2504.17264)