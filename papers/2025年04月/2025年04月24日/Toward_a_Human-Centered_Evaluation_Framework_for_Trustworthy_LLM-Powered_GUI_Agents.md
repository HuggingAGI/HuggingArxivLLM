# 构建以人为本的可信LLM驱动GUI代理评估框架

发布时间：2025年04月24日

`LLM应用` `图形用户界面` `自动化`

> Toward a Human-Centered Evaluation Framework for Trustworthy LLM-Powered GUI Agents

# 摘要

> 大型语言模型（LLMs）的崛起彻底改变了图形用户界面（GUI）自动化领域，LLM驱动的GUI代理功不可没。然而，这些代理在有限的人类监督下处理敏感数据的能力，带来了重大的隐私与安全风险。本文阐述了GUI代理的三大核心风险，并深入探讨了它们与传统GUI自动化及通用自主代理之间的根本差异。尽管面临这些风险，现有研究却主要聚焦于性能评估，对隐私与安全的评估几乎未有涉足。我们系统回顾了当前针对GUI和通用LLM代理的评估指标，并明确指出了在GUI代理评估中整合人类评估者所面临的五大核心挑战。为填补这些空白，我们倡议构建一个以人为中心的评估框架，该框架将风险评估纳入其中，通过上下文同意提升用户意识，并将隐私与安全考量深度融入GUI代理的设计与评估流程。

> The rise of Large Language Models (LLMs) has revolutionized Graphical User Interface (GUI) automation through LLM-powered GUI agents, yet their ability to process sensitive data with limited human oversight raises significant privacy and security risks. This position paper identifies three key risks of GUI agents and examines how they differ from traditional GUI automation and general autonomous agents. Despite these risks, existing evaluations focus primarily on performance, leaving privacy and security assessments largely unexplored. We review current evaluation metrics for both GUI and general LLM agents and outline five key challenges in integrating human evaluators for GUI agent assessments. To address these gaps, we advocate for a human-centered evaluation framework that incorporates risk assessments, enhances user awareness through in-context consent, and embeds privacy and security considerations into GUI agent design and evaluation.

[Arxiv](https://arxiv.org/abs/2504.17934)