# 协同行动，步步为营：用于具身推理的多智能体LLM框架

发布时间：2025年04月24日

`LLM应用` `协作智能体`

> Collaborating Action by Action: A Multi-agent LLM Framework for Embodied Reasoning

# 摘要

> 协作在日常生活中随处可见，从交流想法、分配任务到共同制定计划，无一不需要协作。本研究探索了大型语言模型 (LLMs) 如何实现灵活协作，以完成复杂的具身推理任务。为此，我们推出了MINDcraft——一个易于扩展的平台，让LLM代理能够控制《Minecraft》开放世界游戏中的角色；以及MineCollab——一个基准测试，用于评估具身协作推理的不同维度。实验研究表明，当前最先进的代理在有效协作中的主要瓶颈是高效的自然语言沟通，当代理需要沟通详细的任务完成计划时，其性能最多下降15%。我们得出结论，现有的LLM代理在多智能体协作，尤其是在具身场景中，尚未得到良好优化，并强调了采用超越in-context和模仿学习的方法的必要性。我们的项目网站在此：https://mindcraft-minecollab.github.io/

> Collaboration is ubiquitous and essential in day-to-day life -- from exchanging ideas, to delegating tasks, to generating plans together. This work studies how LLMs can adaptively collaborate to perform complex embodied reasoning tasks. To this end we introduce MINDcraft, an easily extensible platform built to enable LLM agents to control characters in the open-world game of Minecraft; and MineCollab, a benchmark to test the different dimensions of embodied and collaborative reasoning. An experimental study finds that the primary bottleneck in collaborating effectively for current state-of-the-art agents is efficient natural language communication, with agent performance dropping as much as 15% when they are required to communicate detailed task completion plans. We conclude that existing LLM agents are ill-optimized for multi-agent collaboration, especially in embodied scenarios, and highlight the need to employ methods beyond in-context and imitation learning. Our website can be found here: https://mindcraft-minecollab.github.io/

[Arxiv](https://arxiv.org/abs/2504.17950)