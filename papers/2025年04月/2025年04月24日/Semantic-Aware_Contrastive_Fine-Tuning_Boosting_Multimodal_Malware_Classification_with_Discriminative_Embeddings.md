# 语义感知的对比微调：通过判别式嵌入助力多模态恶意软件分类

发布时间：2025年04月24日

`LLM应用

论文摘要：本文研究了如何利用对比式微调方法，提升大型语言模型在恶意软件分类中的准确性。通过优化模型的嵌入表示，使其能够更好地区分相似的恶意软件家族。该方法结合了高相似度和中等相似度的负样本，以提高分类精度和泛化能力。实验结果表明，该方法在多个数据集上表现优异，并且能够生成属性感知的描述，适用于已知和未知的恶意软件变种。这项研究展示了大型语言模型在网络安全中的实际应用潜力。

LLM应用` `网络安全`

> Semantic-Aware Contrastive Fine-Tuning: Boosting Multimodal Malware Classification with Discriminative Embeddings

# 摘要

> 如何利用对比式微调方法，让大型语言模型更精准地区分相似的恶意软件家族？我们提出了一个创新解决方案！在网络安全领域，恶意软件变种的快速演变对分类方法提出了更高要求。虽然大型语言模型（LLMs）在生成恶意软件描述方面展现出潜力，但其效果受限于语义嵌入的重叠以及与二进制行为特征的不匹配。

我们提出了一种对比式微调（CFT）方法，通过基于余弦相似度选择困难负样本，优化LLMs的嵌入表示，使其能够区分密切相关恶意软件家族。我们的方法有两大创新点：结合高相似度负样本增强辨别能力，同时引入中等相似度负样本增加嵌入多样性，从而在精度和泛化能力之间取得平衡。

实验结果令人振奋！在CIC-AndMal-2020和BODMAS数据集上进行评估，我们的方法仅需20个样本就实现了63.15%的分类准确率，显著优于基线方法（高出11-21个百分点），同时也超越了先前的负采样策略。消融实验进一步证明，基于相似度的负样本选择优于随机采样，提升幅度达10-23%。

此外，微调后的LLMs能够生成具备属性感知的描述，不仅能够准确分类已知恶意软件，还能有效应对未知变种，弥合了文本与二进制特征之间的鸿沟。这项研究不仅推动了恶意软件分类技术的发展，实现了语义区分的精细化，更为将LLMs应用于网络安全挑战提供了一个可扩展的框架。


> The rapid evolution of malware variants requires robust classification methods to enhance cybersecurity. While Large Language Models (LLMs) offer potential for generating malware descriptions to aid family classification, their utility is limited by semantic embedding overlaps and misalignment with binary behavioral features. We propose a contrastive fine-tuning (CFT) method that refines LLM embeddings via targeted selection of hard negative samples based on cosine similarity, enabling LLMs to distinguish between closely related malware families. Our approach combines high-similarity negatives to enhance discriminative power and mid-tier negatives to increase embedding diversity, optimizing both precision and generalization. Evaluated on the CIC-AndMal-2020 and BODMAS datasets, our refined embeddings are integrated into a multimodal classifier within a Model-Agnostic Meta-Learning (MAML) framework on a few-shot setting. Experiments demonstrate significant improvements: our method achieves 63.15% classification accuracy with as few as 20 samples on CIC-AndMal-2020, outperforming baselines by 11--21 percentage points and surpassing prior negative sampling strategies. Ablation studies confirm the superiority of similarity-based selection over random sampling, with gains of 10-23%. Additionally, fine-tuned LLMs generate attribute-aware descriptions that generalize to unseen variants, bridging textual and binary feature gaps. This work advances malware classification by enabling nuanced semantic distinctions and provides a scalable framework for adapting LLMs to cybersecurity challenges.

[Arxiv](https://arxiv.org/abs/2504.21028)