# 基于 LLMs 实现理性选择函数，并评估其与用户偏好的一致性

发布时间：2025年04月22日

`LLM应用

理由：该论文探讨了大型语言模型在智能用户界面中的应用，特别是如何确保模型的决策与用户的偏好对齐。它提出了使用LLMs实现理性选择函数的设计原则，并通过实际应用验证了其有效性。因此，它属于LLM应用的范畴。`

> Implementing Rational Choice Functions with LLMs and Measuring their Alignment with User Preferences

# 摘要

> 大型语言模型 (LLMs) 在智能用户界面 (IUIs) 中扮演着越来越重要的角色，但其作为决策代理的对齐性问题亟待解决。尽管已有大量研究关注事实性、偏见和毒性等问题，但对与用户偏好对齐程度的测量却相对较少，这一概念在决策、经济学和社会选择理论中具有重要意义。然而，可靠的决策代理应始终做出与用户偏好高度对齐的选择。
本文通过将对齐性与更广泛、更灵活的用户偏好概念相结合，推广了现有利用 LLMs 对替代结果进行排序的方法。为此，我们提出了使用 LLMs 实现理性选择函数的设计原则，并提供了衡量偏好满意度的必要工具。通过在汽车领域 IUI 的实际应用中进行实证研究，我们验证了该方法的有效性。

> As large language models (LLMs) become integral to intelligent user interfaces (IUIs), their role as decision-making agents raises critical concerns about alignment. Although extensive research has addressed issues such as factuality, bias, and toxicity, comparatively little attention has been paid to measuring alignment to preferences, i.e., the relative desirability of different alternatives, a concept used in decision making, economics, and social choice theory. However, a reliable decision-making agent makes choices that align well with user preferences.
  In this paper, we generalize existing methods that exploit LLMs for ranking alternative outcomes by addressing alignment with the broader and more flexible concept of user preferences, which includes both strict preferences and indifference among alternatives. To this end, we put forward design principles for using LLMs to implement rational choice functions, and provide the necessary tools to measure preference satisfaction. We demonstrate the applicability of our approach through an empirical study in a practical application of an IUI in the automotive domain.

[Arxiv](https://arxiv.org/abs/2504.15719)