# 提升自动化安全代码审查：用于代码漏洞的合成数据集

发布时间：2025年04月22日

`LLM应用` `软件工程` `信息安全`

> Improving Automated Secure Code Reviews: A Synthetic Dataset for Code Vulnerability Flaws

# 摘要

> AI 模型驱动的代码审查自动化在软件工程领域备受关注，成为降低传统同行评审成本与精力的有效策略。这些模型通过处理涵盖测试、重构、错误修复、性能优化及提升可维护性等广泛议题的真实代码审查数据进行训练。然而，现有数据集在代码漏洞方面的代表性不足，安全-focused的审查仅占少数，这限制了 AI 模型在识别与评论安全关键代码上的效果。为解决这一问题，我们提出创建一个专注于安全漏洞的合成数据集。我们的方法借助大型语言模型（LLMs），通过分析代码差异与提交信息，生成针对漏洞的人类-like审查评论。为评估合成数据集的实用性，我们将用其微调现有三个代码审查模型，预期此举将显著提升模型性能。


> Automation of code reviews using AI models has garnered substantial attention in the software engineering community as a strategy to reduce the cost and effort associated with traditional peer review processes. These models are typically trained on extensive datasets of real-world code reviews that address diverse software development concerns, including testing, refactoring, bug fixes, performance optimization, and maintainability improvements. However, a notable limitation of these datasets is the under representation of code vulnerabilities, critical flaws that pose significant security risks, with security-focused reviews comprising a small fraction of the data. This scarcity of vulnerability-specific data restricts the effectiveness of AI models in identifying and commenting on security-critical code. To address this issue, we propose the creation of a synthetic dataset consisting of vulnerability-focused reviews that specifically comment on security flaws. Our approach leverages Large Language Models (LLMs) to generate human-like code review comments for vulnerabilities, using insights derived from code differences and commit messages. To evaluate the usefulness of the generated synthetic dataset, we plan to use it to fine-tune three existing code review models. We anticipate that the synthetic dataset will improve the performance of the original code review models.

[Arxiv](https://arxiv.org/abs/2504.16310)