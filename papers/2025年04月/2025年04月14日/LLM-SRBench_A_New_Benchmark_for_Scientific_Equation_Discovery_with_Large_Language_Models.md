# # LLM-SRBench：利用大型语言模型进行科学方程发现的新基准测试平台

发布时间：2025年04月14日

`LLM应用` `科学研究` `人工智能`

> LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models

# 摘要

> 科学方程发现是科学史上的一项基础任务，它帮助我们推导出自然现象的规律。近期，大型语言模型（LLMs）因其能够利用嵌入的科学知识进行假设生成而受到广泛关注。然而，评估这些方法的真实发现能力仍具挑战性，因为现有基准往往依赖于常见方程，容易被LLMs记住，导致虚高但不真实的性能指标。本文提出LLM-SRBench，一个涵盖四个科学领域的全面基准测试，包含239个难题，专为评估基于LLM的科学方程发现方法而设计，并防止简单的记忆行为。该基准分为两类：LSR-Transform，将常见物理模型转换为不常见数学表达，测试推理能力；LSR-Synth，引入需要数据驱动推理的合成发现驱动问题。通过对多种先进方法的全面评估，使用开放和闭合的LLMs，我们发现目前表现最佳的系统仅达到31.5%的符号准确率。这些发现凸显了科学方程发现的挑战，并将LLM-SRBench确立为未来研究的重要资源。

> Scientific equation discovery is a fundamental task in the history of scientific progress, enabling the derivation of laws governing natural phenomena. Recently, Large Language Models (LLMs) have gained interest for this task due to their potential to leverage embedded scientific knowledge for hypothesis generation. However, evaluating the true discovery capabilities of these methods remains challenging, as existing benchmarks often rely on common equations that are susceptible to memorization by LLMs, leading to inflated performance metrics that do not reflect discovery. In this paper, we introduce LLM-SRBench, a comprehensive benchmark with 239 challenging problems across four scientific domains specifically designed to evaluate LLM-based scientific equation discovery methods while preventing trivial memorization. Our benchmark comprises two main categories: LSR-Transform, which transforms common physical models into less common mathematical representations to test reasoning beyond memorized forms, and LSR-Synth, which introduces synthetic, discovery-driven problems requiring data-driven reasoning. Through extensive evaluation of several state-of-the-art methods, using both open and closed LLMs, we find that the best-performing system so far achieves only 31.5% symbolic accuracy. These findings highlight the challenges of scientific equation discovery, positioning LLM-SRBench as a valuable resource for future research.

[Arxiv](https://arxiv.org/abs/2504.10415)