# LLM驱动的攻击性安全基准测试方法：测试床、指标与实验设计

发布时间：2025年04月14日

`LLM应用` `网络安全` `攻击性技术`

> Benchmarking Practices in LLM-driven Offensive Security: Testbeds, Metrics, and Experiment Design

# 摘要

> 大型语言模型（LLMs）已成为推动进攻性渗透测试工具开发的强大方法。本文聚焦于LLMs在网络安全中的进攻性应用，分析了评估基于LLM攻击的方法论和基准测试实践。我们系统回顾了16篇研究论文，详细描述了15种原型及其测试床。基于研究发现，我们提出了未来研究的可操作建议：应注重扩展现有测试床、创建基准、纳入全面指标和定性分析。同时，我们指出安全研究与实践的差异，认为基于CTF的挑战可能无法完全代表真实世界中的渗透测试场景。

> Large Language Models (LLMs) have emerged as a powerful approach for driving offensive penetration-testing tooling. This paper analyzes the methodology and benchmarking practices used for evaluating Large Language Model (LLM)-driven attacks, focusing on offensive uses of LLMs in cybersecurity. We review 16 research papers detailing 15 prototypes and their respective testbeds.
  We detail our findings and provide actionable recommendations for future research, emphasizing the importance of extending existing testbeds, creating baselines, and including comprehensive metrics and qualitative analysis. We also note the distinction between security research and practice, suggesting that CTF-based challenges may not fully represent real-world penetration testing scenarios.

[Arxiv](https://arxiv.org/abs/2504.10112)