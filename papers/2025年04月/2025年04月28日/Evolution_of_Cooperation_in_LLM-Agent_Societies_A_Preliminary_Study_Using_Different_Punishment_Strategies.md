# 在大型语言模型与智能体社会中的合作演化：基于不同惩罚策略的初步研究

发布时间：2025年04月28日

`LLM应用` `社会学` `人工智能`

> Evolution of Cooperation in LLM-Agent Societies: A Preliminary Study Using Different Punishment Strategies

# 摘要

> 合作的演化一直是研究热点，通过抽象数学模型和模拟深入探讨。近年来，大型语言模型（LLM）及其代理的崛起，展现了社会推理的能力，为在更贴近现实的代理模拟中测试规范的出现提供了新途径。本研究聚焦于Boyd和Richerson的经典合作动力学模型，探讨其在基于LLM代理的用餐者困境模拟中是否依然适用。研究发现，LLM代理遵循Boyd和Richerson模型的策略，且明确的惩罚机制成为规范形成的关键驱动力，即使在代理策略配置变化时，仍能强化合作行为。更重要的是，基于LLM的多智能体模拟不仅验证了传统数学模型的预测，还通过自然语言推理和策略模仿方法，构建了更贴近现实的合作行为研究框架。这表明，LLM驱动的多智能体模拟为合作研究开辟了新的可能。

> The evolution of cooperation has been extensively studied using abstract mathematical models and simulations. Recent advances in Large Language Models (LLM) and the rise of LLM agents have demonstrated their ability to perform social reasoning, thus providing an opportunity to test the emergence of norms in more realistic agent-based simulations with human-like reasoning using natural language. In this research, we investigate whether the cooperation dynamics presented in Boyd and Richerson's model persist in a more realistic simulation of the diner's dilemma using LLM agents compared to the abstract mathematical nature in the work of Boyd and Richerson. Our findings indicate that agents follow the strategies defined in the Boyd and Richerson model, and explicit punishment mechanisms drive norm emergence, reinforcing cooperative behaviour even when the agent strategy configuration varies. Our results suggest that LLM-based Multi-Agent System simulations, in fact, can replicate the evolution of cooperation predicted by the traditional mathematical models. Moreover, our simulations extend beyond the mathematical models by integrating natural language-driven reasoning and a pairwise imitation method for strategy adoption, making them a more realistic testbed for cooperative behaviour in MASs.

[Arxiv](https://arxiv.org/abs/2504.19487)