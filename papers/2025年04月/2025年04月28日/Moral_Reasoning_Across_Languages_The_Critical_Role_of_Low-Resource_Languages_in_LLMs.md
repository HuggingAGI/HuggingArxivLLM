# # 道德推理跨越语言：低资源语言在大语言模型中至关重要

发布时间：2025年04月28日

`LLM应用` `多语言`

> Moral Reasoning Across Languages: The Critical Role of Low-Resource Languages in LLMs

# 摘要

> 本文引入了多语言道德推理基准测试（MMRB），旨在评估大型语言模型（LLMs）在五种类型学差异显著的语言以及三种上下文复杂度水平（句子、段落和文档）下的道德推理能力。研究发现，随着上下文复杂度的增加，道德推理性能逐渐下降，尤其在越南语等低资源语言中表现明显。我们进一步利用精选的单语数据对开源LLaMA-3-8B模型进行了微调，以实现对齐和防止数据中毒。令人惊讶的是，低资源语言对多语言推理能力的影响比高资源语言更为显著，这凸显了它们在多语言NLP中的关键作用。

> In this paper, we introduce the Multilingual Moral Reasoning Benchmark (MMRB) to evaluate the moral reasoning abilities of large language models (LLMs) across five typologically diverse languages and three levels of contextual complexity: sentence, paragraph, and document. Our results show moral reasoning performance degrades with increasing context complexity, particularly for low-resource languages such as Vietnamese. We further fine-tune the open-source LLaMA-3-8B model using curated monolingual data for alignment and poisoning. Surprisingly, low-resource languages have a stronger impact on multilingual reasoning than high-resource ones, highlighting their critical role in multilingual NLP.

[Arxiv](https://arxiv.org/abs/2504.19759)