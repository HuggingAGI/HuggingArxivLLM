# 越南语叙事文本的核心ference解析

发布时间：2025年04月28日

`LLM应用` `新闻媒体`

> Coreference Resolution for Vietnamese Narrative Texts

# 摘要

> 指代消解是自然语言处理 (NLP) 中的关键任务，旨在识别并链接文本中指向同一实体的不同表达。对于越南语这种低资源语言，这一任务极具挑战性，因为其标注数据十分有限。为了解决这些难题，我们基于越南知名在线新闻平台 VnExpress 的叙事文本，开发了一个全面的标注数据集。我们制定了详尽的实体标注指南，重点确保标注的一致性和准确性。此外，我们评估了 GPT-3.5-Turbo 和 GPT-4 等大型语言模型 (LLMs) 在该数据集上的表现。结果显示，GPT-4 在准确性和响应一致性方面均显著优于 GPT-3.5-Turbo，使其成为越南语指代消解更具可靠性的工具。

> Coreference resolution is a vital task in natural language processing (NLP) that involves identifying and linking different expressions in a text that refer to the same entity. This task is particularly challenging for Vietnamese, a low-resource language with limited annotated datasets. To address these challenges, we developed a comprehensive annotated dataset using narrative texts from VnExpress, a widely-read Vietnamese online news platform. We established detailed guidelines for annotating entities, focusing on ensuring consistency and accuracy. Additionally, we evaluated the performance of large language models (LLMs), specifically GPT-3.5-Turbo and GPT-4, on this dataset. Our results demonstrate that GPT-4 significantly outperforms GPT-3.5-Turbo in terms of both accuracy and response consistency, making it a more reliable tool for coreference resolution in Vietnamese.

[Arxiv](https://arxiv.org/abs/2504.19606)