# 提升基于机器学习的跨站脚本检测能力，借助大型语言模型的力量

发布时间：2025年04月28日

`LLM应用` `网络安全`

> Leveraging LLM to Strengthen ML-Based Cross-Site Scripting Detection

# 摘要

> 跨站脚本（XSS）攻击是开放Web应用程序安全项目（OWASP）定义的关键安全威胁。尽管经过数十年的研究，XSS仍是十大安全漏洞之一。面对这一令人头疼的问题，研究者提出了多种防护技术，其中机器学习（ML）是最广泛应用的方法之一。通过训练ML模型识别潜在XSS威胁，其检测效果高度依赖于训练数据的质量和多样性。

XSS攻击中有一种特殊的变体——混淆XSS。攻击者通过使用混淆技术改变代码结构，使得安全系统难以识别其恶意意图。我们的随机森林模型在传统XSS数据上达到了99.8%的准确率，但在面对混淆XSS样本时，准确率下降至81.9%，凸显了在模型训练中引入混淆数据的重要性。然而，生成高度复杂的混淆代码一直是道难题，尽管市面上不乏相关工具，但它们的混淆效果往往有限。

在我们提出的系统中，我们对大型语言模型（LLM）进行了微调，使其能够自动生成复杂的混淆XSS有效载荷。通过将原始XSS样本转化为多样化的混淆变体，我们为模型评估创建了更具挑战性的训练数据。实验结果显示，我们的方法在混淆数据集上达到了99.5%的准确率。值得注意的是，LLM生成的混淆样本比其他工具创建的样本复杂度提升了28.1%，这一提升显著增强了模型对高级XSS攻击的识别能力，使其在实际应用中更具价值。

> According to the Open Web Application Security Project (OWASP), Cross-Site Scripting (XSS) is a critical security vulnerability. Despite decades of research, XSS remains among the top 10 security vulnerabilities. Researchers have proposed various techniques to protect systems from XSS attacks, with machine learning (ML) being one of the most widely used methods. An ML model is trained on a dataset to identify potential XSS threats, making its effectiveness highly dependent on the size and diversity of the training data. A variation of XSS is obfuscated XSS, where attackers apply obfuscation techniques to alter the code's structure, making it challenging for security systems to detect its malicious intent. Our study's random forest model was trained on traditional (non-obfuscated) XSS data achieved 99.8% accuracy. However, when tested against obfuscated XSS samples, accuracy dropped to 81.9%, underscoring the importance of training ML models with obfuscated data to improve their effectiveness in detecting XSS attacks. A significant challenge is to generate highly complex obfuscated code despite the availability of several public tools. These tools can only produce obfuscation up to certain levels of complexity.
  In our proposed system, we fine-tune a Large Language Model (LLM) to generate complex obfuscated XSS payloads automatically. By transforming original XSS samples into diverse obfuscated variants, we create challenging training data for ML model evaluation. Our approach achieved a 99.5% accuracy rate with the obfuscated dataset. We also found that the obfuscated samples generated by the LLMs were 28.1% more complex than those created by other tools, significantly improving the model's ability to handle advanced XSS attacks and making it more effective for real-world application security.

[Arxiv](https://arxiv.org/abs/2504.21045)