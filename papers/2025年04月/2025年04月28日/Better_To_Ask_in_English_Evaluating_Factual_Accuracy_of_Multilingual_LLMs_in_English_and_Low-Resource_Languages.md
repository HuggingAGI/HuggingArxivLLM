# # 在英语和低资源语言中评估多语言LLM的事实准确性：是否用英语提问更好？
本研究探讨了在英语和资源较少的语言中，多语言LLM的事实准确性。

发布时间：2025年04月28日

`LLM应用`

> Better To Ask in English? Evaluating Factual Accuracy of Multilingual LLMs in English and Low-Resource Languages

# 摘要

> 多语言大型语言模型 (LLMs) 在英语等高资源语言中表现优异，但在印地语等低资源语言中的事实准确性仍待深入研究。本研究通过 IndicQuest 数据集，比较了 GPT-4o、Gemma-2-9B、Gemma-2-2B 和 Llama-3.1-8B 等模型在英语和 19 种印地语中的表现，评估其事实准确性。我们发现，尽管问题根植于印地语背景，LLMs 在英语中的表现通常更佳。值得注意的是，印地语生成的回答中幻觉现象更为突出，这凸显了当前 LLMs 在多语言理解上的挑战。

> Multilingual Large Language Models (LLMs) have demonstrated significant effectiveness across various languages, particularly in high-resource languages such as English. However, their performance in terms of factual accuracy across other low-resource languages, especially Indic languages, remains an area of investigation. In this study, we assess the factual accuracy of LLMs - GPT-4o, Gemma-2-9B, Gemma-2-2B, and Llama-3.1-8B - by comparing their performance in English and Indic languages using the IndicQuest dataset, which contains question-answer pairs in English and 19 Indic languages. By asking the same questions in English and their respective Indic translations, we analyze whether the models are more reliable for regional context questions in Indic languages or when operating in English. Our findings reveal that LLMs often perform better in English, even for questions rooted in Indic contexts. Notably, we observe a higher tendency for hallucination in responses generated in low-resource Indic languages, highlighting challenges in the multilingual understanding capabilities of current LLMs.

[Arxiv](https://arxiv.org/abs/2504.20022)