# 文言GPT：专为古典中文任务打造的大语言模型

发布时间：2025年04月29日

`LLM应用

理由：这篇论文专注于改进大语言模型在处理文言文方面的应用，通过预训练和微调构建了专门针对文言文的模型，并开发了评估基准。这属于模型在特定领域的应用研究，因此归类为LLM应用。` `文化传承` `古代文献`

> WenyanGPT: A Large Language Model for Classical Chinese Tasks

# 摘要

> 文言文作为中华文化的核心载体，在古代文献的传承与研究中具有重要作用。但现有自然语言处理模型主要针对现代汉语优化，导致在文言文处理上表现不佳。本文提出了一套全面的文言文处理解决方案。我们基于LLaMA3-8B-Chinese模型继续进行预训练和指令微调，构建了一个专门针对文言文任务的大语言模型——文言GPT。此外，我们还开发了一个评估基准数据集文言BENCH。在文言BENCH上的实验结果表明，文言GPT在多种文言文任务中显著优于当前先进的LLMs。我们公开了模型的训练数据、指令微调数据ootnote和评估基准数据集，以促进文言文处理领域的进一步研究与开发。

> Classical Chinese, as the core carrier of Chinese culture, plays a crucial role in the inheritance and study of ancient literature. However, existing natural language processing models primarily optimize for Modern Chinese, resulting in inadequate performance on Classical Chinese. This paper presents a comprehensive solution for Classical Chinese language processing. By continuing pre-training and instruction fine-tuning on the LLaMA3-8B-Chinese model, we construct a large language model, WenyanGPT, which is specifically designed for Classical Chinese tasks. Additionally, we develop an evaluation benchmark dataset, WenyanBENCH. Experimental results on WenyanBENCH demonstrate that WenyanGPT significantly outperforms current advanced LLMs in various Classical Chinese tasks. We make the model's training data, instruction fine-tuning data\footnote, and evaluation benchmark dataset publicly available to promote further research and development in the field of Classical Chinese processing.

[Arxiv](https://arxiv.org/abs/2504.20609)