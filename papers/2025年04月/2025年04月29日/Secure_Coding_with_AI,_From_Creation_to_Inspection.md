# # AI驱动的安全编码：从编码到检测的全生命周期管理

发布时间：2025年04月29日

`LLM应用

理由：这篇论文研究了大型语言模型（如ChatGPT）在代码生成和漏洞修复中的实际应用，评估了其安全性和有效性，属于LLM应用的范畴。` `软件开发` `信息安全`

> Secure Coding with AI, From Creation to Inspection

# 摘要

> 尽管先前研究探讨了 ChatGPT 和其他大型语言模型生成代码的安全性，但这些研究是在受控实验环境中进行的，且未使用实际开发人员交互生成或提供的代码。本文不仅基于实际开发人员交互、整理于 DevGPT 数据集，研究了 ChatGPT 生成代码的安全性，还评估了其发现和修复漏洞的能力。

我们使用静态扫描工具分析了 1,586 个 C、C++ 和 C# 代码片段，检测到 124 个文件中存在潜在问题。经过人工分析后，我们选择了 26 个文件（共 32 个已确认漏洞）进行深入研究。将这些文件通过 OpenAI API 提交给 ChatGPT，要求其检测安全问题、识别相应常见漏洞枚举编号并提出修复方案。人工审查了 ChatGPT 的回复和修改后的代码，并重新进行了漏洞扫描。

结果显示，ChatGPT 成功检测并修复了 32 个安全问题中的 17 个，但未能识别或修复剩余问题。值得注意的是，只有 10 个漏洞源于用户提示，而 ChatGPT 本身引入了 22 个漏洞。我们提醒开发者，ChatGPT 生成的代码相比他们自己编写的代码更有可能包含漏洞。此外，ChatGPT 有时会自信满满地报告错误信息，这可能会误导经验不足的开发者。

我们的研究结果证实了之前的发现，即 ChatGPT 并不可靠用于生成安全代码或识别所有漏洞。这进一步凸显了静态扫描工具和人工审查的重要性。


> While prior studies have explored security in code generated by ChatGPT and other Large Language Models, they were conducted in controlled experimental settings and did not use code generated or provided from actual developer interactions. This paper not only examines the security of code generated by ChatGPT based on real developer interactions, curated in the DevGPT dataset, but also assesses ChatGPT's capability to find and fix these vulnerabilities. We analysed 1,586 C, C++, and C# code snippets using static scanners, which detected potential issues in 124 files. After manual analysis, we selected 26 files with 32 confirmed vulnerabilities for further investigation.
  We submitted these files to ChatGPT via the OpenAI API, asking it to detect security issues, identify the corresponding Common Weakness Enumeration numbers, and propose fixes. The responses and modified code were manually reviewed and re-scanned for vulnerabilities. ChatGPT successfully detected 18 out of 32 security issues and resolved 17 issues but failed to recognize or fix the remainder. Interestingly, only 10 vulnerabilities were resulted from the user prompts, while 22 were introduced by ChatGPT itself.
  We highlight for developers that code generated by ChatGPT is more likely to contain vulnerabilities compared to their own code. Furthermore, at times ChatGPT reports incorrect information with apparent confidence, which may mislead less experienced developers. Our findings confirm previous studies in demonstrating that ChatGPT is not sufficiently reliable for generating secure code nor identifying all vulnerabilities, highlighting the continuing importance of static scanners and manual review.

[Arxiv](https://arxiv.org/abs/2504.20814)