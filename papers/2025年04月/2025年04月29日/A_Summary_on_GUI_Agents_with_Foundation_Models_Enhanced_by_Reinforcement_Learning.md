# 强化学习增强的基础模型在GUI代理中的研究综述

发布时间：2025年04月29日

`Agent` `人工智能` `人机交互`

> A Summary on GUI Agents with Foundation Models Enhanced by Reinforcement Learning

# 摘要

> 由多模态大语言模型（MLLMs）驱动的图形用户界面（GUI）代理，作为实现与数字系统智能交互的有前景范式，已崭露头角。本文针对基于强化学习（RL）增强的架构，系统梳理了GUI代理领域的最新进展。我们首先将GUI代理任务形式化为马尔可夫决策过程，并探讨了典型的执行环境和评估指标。随后，我们回顾了基于（多模态）大语言模型的GUI代理模块化架构，涵盖感知、规划和行动模块，并通过代表性工作追踪其演进历程。此外，我们将GUI代理的训练方法分为基于提示、基于监督微调（SFT）和基于RL的三类，凸显了从简单的提示工程到通过RL实现动态策略学习的进步。我们的综述展示了多模态感知、决策推理和自适应动作生成领域的最新创新如何显著提升了GUI代理在复杂现实环境中的泛化能力和鲁棒性。最后，我们指出了构建更强大、更可靠的GUI代理所面临的关键挑战和未来发展方向。

> Graphical User Interface (GUI) agents, driven by Multi-modal Large Language Models (MLLMs), have emerged as a promising paradigm for enabling intelligent interaction with digital systems. This paper provides a structured summary of recent advances in GUI agents, focusing on architectures enhanced by Reinforcement Learning (RL). We first formalize GUI agent tasks as Markov Decision Processes and discuss typical execution environments and evaluation metrics. We then review the modular architecture of (M)LLM-based GUI agents, covering Perception, Planning, and Acting modules, and trace their evolution through representative works. Furthermore, we categorize GUI agent training methodologies into Prompt-based, Supervised Fine-Tuning (SFT)-based, and RL-based approaches, highlighting the progression from simple prompt engineering to dynamic policy learning via RL. Our summary illustrates how recent innovations in multimodal perception, decision reasoning, and adaptive action generation have significantly improved the generalization and robustness of GUI agents in complex real-world environments. We conclude by identifying key challenges and future directions for building more capable and reliable GUI agents.

[Arxiv](https://arxiv.org/abs/2504.20464)