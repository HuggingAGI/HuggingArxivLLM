# 利用大型语言模型生成设计依据在软件架构决策中的应用

发布时间：2025年04月29日

`LLM应用` `软件开发` `软件架构`

> Using LLMs in Generating Design Rationale for Software Architecture Decisions

# 摘要

> 软件架构决策的设计理由（DR）是支撑架构选择的核心推理过程，为软件开发中的架构设计提供了多阶段的深入见解。然而，由于开发者的动力和投入不足，DR 在实际开发中往往记录不充分。借助大型语言模型（LLMs）的最新进展，其在文本理解、推理和生成方面的强大能力可能为架构决策的生成和恢复提供支持。本研究旨在评估 LLMs 在生成架构决策 DR 方面的性能。我们首先从 Stack Overflow（SO）收集了 50 个帖子、GitHub 上收集了 25 个问题和 25 个讨论，构建了一个包含 100 个架构相关问题的数据集。接着，我们选择了五种 LLM，并采用三种提示策略（零-shot、链式思维（CoT）和基于 LLM 的代理）来生成架构决策的 DR。以人类专家提供的 DR 作为基准，三种提示策略下 LLM 生成的 DR 的精确度范围为 0.267 至 0.278，召回率为 0.627 至 0.715，F1 值为 0.351 至 0.389。此外，64.45% 至 69.42% 的 DR 论点对人类专家未提及的部分也有帮助，4.12% 至 4.87% 的论点正确性存疑，1.59% 至 3.24% 的论点可能具有误导性。基于这些结果，我们进一步探讨了三种提示策略的优缺点，以及 LLM 生成的 DR 的优势与局限性。

> Design Rationale (DR) for software architecture decisions refers to the reasoning underlying architectural choices, which provides valuable insights into the different phases of the architecting process throughout software development. However, in practice, DR is often inadequately documented due to a lack of motivation and effort from developers. With the recent advancements in Large Language Models (LLMs), their capabilities in text comprehension, reasoning, and generation may enable the generation and recovery of DR for architecture decisions. In this study, we evaluated the performance of LLMs in generating DR for architecture decisions. First, we collected 50 Stack Overflow (SO) posts, 25 GitHub issues, and 25 GitHub discussions related to architecture decisions to construct a dataset of 100 architecture-related problems. Then, we selected five LLMs to generate DR for the architecture decisions with three prompting strategies, including zero-shot, chain of thought (CoT), and LLM-based agents. With the DR provided by human experts as ground truth, the Precision of LLM-generated DR with the three prompting strategies ranges from 0.267 to 0.278, Recall from 0.627 to 0.715, and F1-score from 0.351 to 0.389. Additionally, 64.45% to 69.42% of the arguments of DR not mentioned by human experts are also helpful, 4.12% to 4.87% of the arguments have uncertain correctness, and 1.59% to 3.24% of the arguments are potentially misleading. Based on the results, we further discussed the pros and cons of the three prompting strategies and the strengths and limitations of the DR generated by LLMs.

[Arxiv](https://arxiv.org/abs/2504.20781)