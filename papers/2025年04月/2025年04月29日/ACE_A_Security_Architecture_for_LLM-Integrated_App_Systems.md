# ACE：集成LLM的应用系统安全架构

发布时间：2025年04月29日

`LLM应用` `应用安全`

> ACE: A Security Architecture for LLM-Integrated App Systems

# 摘要

> LLM集成的应用系统通过第三方应用扩展了大型语言模型（LLMs）的实用性，这些应用由系统LLM通过交错的规划和执行阶段调用来回答用户查询。这些系统引入了新的攻击向量，其中恶意应用可能在规划或执行阶段导致完整性违规、可用性故障或隐私泄露。

    在这项工作中，我们识别了影响LLM集成应用系统中规划完整性以及执行完整性和可用性的新攻击，并在IsolateGPT上进行了演示，IsolateGPT是一种旨在缓解恶意应用攻击的近期解决方案。我们提出了Abstract-Concrete-Execute (ACE)，一种新的安全架构，为LLM集成应用系统的规划和执行提供安全保证。具体而言，ACE将规划分为两个阶段：首先使用仅受信任的信息创建抽象执行计划，然后将抽象计划映射到使用已安装系统应用的具体计划。我们通过结构化计划输出的静态分析验证，我们的系统生成的计划满足用户指定的安全信息流约束。在执行过程中，ACE在应用之间实施数据和能力屏障，并确保执行是根据受信任的抽象计划进行的。我们通过实验表明，我们的系统能够抵御来自INJECAGENT基准的攻击，这是一个在间接提示注入攻击面前保障控制流完整性的标准基准，以及我们新引入的攻击。我们的架构代表了在强化包含不同可信度系统功能的LLM系统方面的重要进展。
    

> LLM-integrated app systems extend the utility of Large Language Models (LLMs) with third-party apps that are invoked by a system LLM using interleaved planning and execution phases to answer user queries. These systems introduce new attack vectors where malicious apps can cause integrity violation of planning or execution, availability breakdown, or privacy compromise during execution.
  In this work, we identify new attacks impacting the integrity of planning, as well as the integrity and availability of execution in LLM-integrated apps, and demonstrate them against IsolateGPT, a recent solution designed to mitigate attacks from malicious apps. We propose Abstract-Concrete-Execute (ACE), a new secure architecture for LLM-integrated app systems that provides security guarantees for system planning and execution. Specifically, ACE decouples planning into two phases by first creating an abstract execution plan using only trusted information, and then mapping the abstract plan to a concrete plan using installed system apps. We verify that the plans generated by our system satisfy user-specified secure information flow constraints via static analysis on the structured plan output. During execution, ACE enforces data and capability barriers between apps, and ensures that the execution is conducted according to the trusted abstract plan. We show experimentally that our system is secure against attacks from the INJECAGENT benchmark, a standard benchmark for control flow integrity in the face of indirect prompt injection attacks, and our newly introduced attacks. Our architecture represents a significant advancement towards hardening LLM-based systems containing system facilities of varying levels of trustworthiness.

[Arxiv](https://arxiv.org/abs/2504.20984)