# LLM生成的Web应用代码中的隐藏风险：从安全视角评估LLM代码生成能力

发布时间：2025年04月29日

`LLM应用

摘要讨论了大型语言模型在生成代码方面的应用及其安全性问题，属于LLM在软件开发中的具体应用。` `软件开发` `代码安全`

> The Hidden Risks of LLM-Generated Web Application Code: A Security-Centric Evaluation of Code Generation Capabilities in Large Language Models

# 摘要

> 大型语言模型（LLMs）的迅猛发展显著提升了软件开发效率，减少了编码时间和精力，助力开发者实现更高生产力。然而，尽管LLMs生成代码展现出巨大潜力，但研究发现其在受控环境中生成的代码可能存在安全隐患，这引发了对其实际应用中可靠性和安全性的严重担忧。本研究采用预定义安全参数，评估了包括ChatGPT、DeepSeek、Claude、Gemini和Grok在内的多个LLM生成代码的安全合规性。结果发现，这些模型在身份认证机制、会话管理、输入验证和HTTP安全头等方面存在关键漏洞。尽管部分模型在一定程度上采取了安全措施，但无一完全符合行业最佳实践标准，凸显了自动化软件开发中的潜在风险。我们的研究发现表明，确保LLM生成代码的安全部署或审核，离不开人类专业知识的参与。此外，建立强大的安全评估框架势在必行，以增强LLM生成代码在实际应用中的可靠性。

> The rapid advancement of Large Language Models (LLMs) has enhanced software development processes, minimizing the time and effort required for coding and enhancing developer productivity. However, despite their potential benefits, code generated by LLMs has been shown to generate insecure code in controlled environments, raising critical concerns about their reliability and security in real-world applications. This paper uses predefined security parameters to evaluate the security compliance of LLM-generated code across multiple models, such as ChatGPT, DeepSeek, Claude, Gemini and Grok. The analysis reveals critical vulnerabilities in authentication mechanisms, session management, input validation and HTTP security headers. Although some models implement security measures to a limited extent, none fully align with industry best practices, highlighting the associated risks in automated software development. Our findings underscore that human expertise is crucial to ensure secure software deployment or review of LLM-generated code. Also, there is a need for robust security assessment frameworks to enhance the reliability of LLM-generated code in real-world applications.

[Arxiv](https://arxiv.org/abs/2504.20612)