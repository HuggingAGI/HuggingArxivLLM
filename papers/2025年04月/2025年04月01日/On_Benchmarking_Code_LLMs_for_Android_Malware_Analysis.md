# # 论代码大型语言模型在安卓恶意软件分析中的基准测试

发布时间：2025年04月01日

`LLM应用` `网络安全` `移动应用`

> On Benchmarking Code LLMs for Android Malware Analysis

# 摘要

> 大型语言模型（LLMs）在代码智能任务中表现优异，但在 Android 恶意软件分析领域仍有待深入探索。反编译的 Android 代码因庞大的函数数量和缺失有意义的函数名称而带来独特挑战。本文提出 Cama，一个系统性评估代码 LLM 在 Android 恶意软件分析任务中表现的基准框架。Cama 通过定义结构化的模型输出（函数摘要、优化函数名称及恶意性评分），支持恶意函数识别和恶意软件目的总结等关键任务。基于此，Cama 集成了一致性、保真度和语义相关性三个领域特定评估指标，实现模型稳定性和有效性的严格评估及跨模型对比。我们构建了一个包含 118 个 Android 恶意软件样本（涵盖 750 万个不同函数）的基准数据集，并利用 Cama 对四个流行开源模型进行了评估。实验结果揭示了代码 LLM 解释反编译代码的方式，并量化了函数重命名的敏感度，突显了代码 LLM 在恶意软件分析中的潜力与局限性。

> Large Language Models (LLMs) have demonstrated strong capabilities in various code intelligence tasks. However, their effectiveness for Android malware analysis remains underexplored. Decompiled Android code poses unique challenges for analysis, primarily due to its large volume of functions and the frequent absence of meaningful function names. This paper presents Cama, a benchmarking framework designed to systematically evaluate the effectiveness of Code LLMs in Android malware analysis tasks. Cama specifies structured model outputs (comprising function summaries, refined function names, and maliciousness scores) to support key malware analysis tasks, including malicious function identification and malware purpose summarization. Built on these, it integrates three domain-specific evaluation metrics, consistency, fidelity, and semantic relevance, enabling rigorous stability and effectiveness assessment and cross-model comparison. We construct a benchmark dataset consisting of 118 Android malware samples, encompassing over 7.5 million distinct functions, and use Cama to evaluate four popular open-source models. Our experiments provide insights into how Code LLMs interpret decompiled code and quantify the sensitivity to function renaming, highlighting both the potential and current limitations of Code LLMs in malware analysis tasks.

[Arxiv](https://arxiv.org/abs/2504.00694)