# DeepSeek-R1 思维之道：聊聊 LLM 推理那些事儿

发布时间：2025年04月01日

`LLM理论` `推理模型` `认知科学`

> DeepSeek-R1 Thoughtology: Let's <think> about LLM Reasoning

# 摘要

> 大型推理模型（Large Reasoning Models）如 DeepSeek-R1 标志着 LLM 在处理复杂问题方式上的重大转变。与传统模型直接输出答案不同，DeepSeek-R1 会生成详细的多步骤推理链，仿佛在“思考”问题后再给出答案。这一公开的推理过程为研究模型的推理行为提供了无限可能，并开拓了“思维学”这一新领域。我们从 DeepSeek-R1 推理的基本构建块分类法入手，分析了推理链长度的影响与可控性、长篇或复杂上下文的管理、文化与安全问题，以及 DeepSeek-R1 在认知现象中的地位，如类人语言处理和世界建模。研究发现揭示了复杂的推理图景。值得注意的是，我们发现 DeepSeek-R1 存在推理的“最佳区间”，额外的推理时间可能损害模型性能。此外，我们发现 DeepSeek-R1 存在持续沉溺于先前探索的问题表述的倾向，阻碍进一步探索。与非推理版本相比，我们还发现 DeepSeek-R1 存在显著的安全漏洞，这也可能危及与安全对齐的 LLM。

> Large Reasoning Models like DeepSeek-R1 mark a fundamental shift in how LLMs approach complex problems. Instead of directly producing an answer for a given input, DeepSeek-R1 creates detailed multi-step reasoning chains, seemingly "thinking" about a problem before providing an answer. This reasoning process is publicly available to the user, creating endless opportunities for studying the reasoning behaviour of the model and opening up the field of Thoughtology. Starting from a taxonomy of DeepSeek-R1's basic building blocks of reasoning, our analyses on DeepSeek-R1 investigate the impact and controllability of thought length, management of long or confusing contexts, cultural and safety concerns, and the status of DeepSeek-R1 vis-à-vis cognitive phenomena, such as human-like language processing and world modelling. Our findings paint a nuanced picture. Notably, we show DeepSeek-R1 has a 'sweet spot' of reasoning, where extra inference time can impair model performance. Furthermore, we find a tendency for DeepSeek-R1 to persistently ruminate on previously explored problem formulations, obstructing further exploration. We also note strong safety vulnerabilities of DeepSeek-R1 compared to its non-reasoning counterpart, which can also compromise safety-aligned LLMs.

[Arxiv](https://arxiv.org/abs/2504.07128)