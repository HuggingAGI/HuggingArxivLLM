# 迈向更智能的招聘：零样本和少样本预训练LLMs是否已准备好应对HR口语面试记录分析？

发布时间：2025年04月08日

`LLM应用` `人力资源` `评估系统`

> Towards Smarter Hiring: Are Zero-Shot and Few-Shot Pre-trained LLMs Ready for HR Spoken Interview Transcript Analysis?

# 摘要

> 本文对GPT-4 Turbo、GPT-3.5 Turbo等知名预训练大型语言模型（LLMs）在模拟人力资源（HR）面试中的表现进行了全面分析，对比了这些模型与专家级人工评估员在提供评分、识别错误、以及向候选人提供反馈和改进建议方面的能力。我们引入了包含3,890份真实人力资源面试记录的HURIT数据集。研究发现，GPT-4 Turbo和GPT-3.5 Turbo等预训练LLMs表现优异，能够生成与专家级人工评估员相当的评估结果。然而，尽管这些模型在提供评分方面表现出色，但它们在识别错误并提供具体改进建议方面仍有不足。研究表明，目前最先进的预训练LLMs尚未完全适合在HR面试评估中实现自动化部署。我们建议采用"人在回路"方法，通过人工检查和优化反馈质量来提升评估效果。


> This research paper presents a comprehensive analysis of the performance of prominent pre-trained large language models (LLMs), including GPT-4 Turbo, GPT-3.5 Turbo, text-davinci-003, text-babbage-001, text-curie-001, text-ada-001, llama-2-7b-chat, llama-2-13b-chat, and llama-2-70b-chat, in comparison to expert human evaluators in providing scores, identifying errors, and offering feedback and improvement suggestions to candidates during mock HR (Human Resources) interviews. We introduce a dataset called HURIT (Human Resource Interview Transcripts), which comprises 3,890 HR interview transcripts sourced from real-world HR interview scenarios. Our findings reveal that pre-trained LLMs, particularly GPT-4 Turbo and GPT-3.5 Turbo, exhibit commendable performance and are capable of producing evaluations comparable to those of expert human evaluators. Although these LLMs demonstrate proficiency in providing scores comparable to human experts in terms of human evaluation metrics, they frequently fail to identify errors and offer specific actionable advice for candidate performance improvement in HR interviews. Our research suggests that the current state-of-the-art pre-trained LLMs are not fully conducive for automatic deployment in an HR interview assessment. Instead, our findings advocate for a human-in-the-loop approach, to incorporate manual checks for inconsistencies and provisions for improving feedback quality as a more suitable strategy.

[Arxiv](https://arxiv.org/abs/2504.05683)