# 深入探索兔子洞：LLM生成的攻击性叙述中针对心理健康群体的浮现偏见

发布时间：2025年04月08日

`LLM应用` `心理健康` `社会学`

> Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups

# 摘要

> 大型语言模型（LLMs）对特定群体表现出明显的偏见问题。然而，关于LLMs对高风险群体发起的无端攻击研究仍较为匮乏。本文带来三项创新性贡献：(1)针对高危心理健康群体的LLMs攻击性言论进行深入评估；(2)构建网络框架研究偏见传播机制；(3)量化攻击引发的污名化程度。通过对最新大型偏见审核数据集的分析发现，心理健康议题在攻击性叙事网络中占据核心位置，表现为显著更高的接近中心性均值（p值 = 4.06e-10）和高度聚集的特性（基尼系数 = 0.7）。基于污名化理论的社会学视角，我们的分析表明，心理健康障碍相关目标在生成链中相较于初始目标增加了更多标签成分。这些发现揭示了大型语言模型在放大有害言论方面的结构性倾向，强调了开发有效缓解策略的迫切需求。

> Large Language Models (LLMs) have been shown to demonstrate imbalanced biases against certain groups. However, the study of unprovoked targeted attacks by LLMs towards at-risk populations remains underexplored. Our paper presents three novel contributions: (1) the explicit evaluation of LLM-generated attacks on highly vulnerable mental health groups; (2) a network-based framework to study the propagation of relative biases; and (3) an assessment of the relative degree of stigmatization that emerges from these attacks. Our analysis of a recently released large-scale bias audit dataset reveals that mental health entities occupy central positions within attack narrative networks, as revealed by a significantly higher mean centrality of closeness (p-value = 4.06e-10) and dense clustering (Gini coefficient = 0.7). Drawing from sociological foundations of stigmatization theory, our stigmatization analysis indicates increased labeling components for mental health disorder-related targets relative to initial targets in generation chains. Taken together, these insights shed light on the structural predilections of large language models to heighten harmful discourse and highlight the need for suitable approaches for mitigation.

[Arxiv](https://arxiv.org/abs/2504.06160)