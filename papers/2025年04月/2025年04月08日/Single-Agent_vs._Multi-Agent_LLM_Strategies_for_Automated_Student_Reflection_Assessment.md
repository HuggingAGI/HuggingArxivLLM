# 单智能体 vs. 多智能体：LLM 在自动化学生反思评估中的策略对比

发布时间：2025年04月08日

`LLM应用`

> Single-Agent vs. Multi-Agent LLM Strategies for Automated Student Reflection Assessment

# 摘要

> 我们探索了利用大型语言模型（LLMs）自动评估学生的开放文本反思，并预测其学术表现。传统评估方法耗时且难以有效扩展，因此我们采用LLMs结合两种评估策略（单agent和多agent）和两种提示技术（零-shot和few-shot），将学生的反思转化为定量分数。实验基于包含377名学生、跨越三个学年的5,278份反思数据集，结果显示，单agent结合few-shot策略的评估结果最接近人工评价。此外，采用LLM评估的反思分数在识别有风险学生和预测学生成绩方面均优于传统方法。这些发现表明，LLMs不仅能有效实现反思评估的自动化，还能帮助教育工作者及时为需要额外支持的学生提供帮助，从而减轻工作负担。我们的研究强调了将先进生成式AI技术融入教育实践的潜力，有望提升学生参与度和学业成就。

> We explore the use of Large Language Models (LLMs) for automated assessment of open-text student reflections and prediction of academic performance. Traditional methods for evaluating reflections are time-consuming and may not scale effectively in educational settings. In this work, we employ LLMs to transform student reflections into quantitative scores using two assessment strategies (single-agent and multi-agent) and two prompting techniques (zero-shot and few-shot). Our experiments, conducted on a dataset of 5,278 reflections from 377 students over three academic terms, demonstrate that the single-agent with few-shot strategy achieves the highest match rate with human evaluations. Furthermore, models utilizing LLM-assessed reflection scores outperform baselines in both at-risk student identification and grade prediction tasks. These findings suggest that LLMs can effectively automate reflection assessment, reduce educators' workload, and enable timely support for students who may need additional assistance. Our work emphasizes the potential of integrating advanced generative AI technologies into educational practices to enhance student engagement and academic success.

[Arxiv](https://arxiv.org/abs/2504.05716)