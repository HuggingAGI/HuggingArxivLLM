# # 能否调整你的双筒望远镜？在大型语言模型的权重中嵌入文本水印

发布时间：2025年04月08日

`LLM应用

摘要讨论了如何通过微调模型来嵌入水印，以提高AI生成内容的透明度和问责，属于模型的应用层面。` `版权保护` `内容安全`

> Can you Finetune your Binoculars? Embedding Text Watermarks into the Weights of Large Language Models

# 摘要

> AI生成内容与人类文本难以分辨的特点带来了透明度和问责方面的挑战。尽管已有多种方法可用于为API背后的模型添加水印，但直接将水印策略嵌入到模型权重中并在模型输出中体现仍然具有挑战性。本研究提出了一种通过微调模型的一对低秩适配器来解决这一问题的策略：其中一个适配器作为文本生成模型，另一个作为检测器。这样，第一模型生成的文本中会嵌入微妙的水印，同时由第二模型进行可检测性优化。这样一来，水印策略就实现了完整的端到端学习。这一过程带来了优化上的挑战，因为要在水印的鲁棒性、自然性和任务性能之间找到平衡需要权衡取舍。我们探讨了优化这一最小化目标的策略，并展示了这种修改对指令微调效果的影响。

> The indistinguishability of AI-generated content from human text raises challenges in transparency and accountability. While several methods exist to watermark models behind APIs, embedding watermark strategies directly into model weights that are later reflected in the outputs of the model is challenging. In this study we propose a strategy to finetune a pair of low-rank adapters of a model, one serving as the text-generating model, and the other as the detector, so that a subtle watermark is embedded into the text generated by the first model and simultaneously optimized for detectability by the second. In this way, the watermarking strategy is fully learned end-to-end. This process imposes an optimization challenge, as balancing watermark robustness, naturalness, and task performance requires trade-offs. We discuss strategies on how to optimize this min-max objective and present results showing the effect of this modification to instruction finetuning.

[Arxiv](https://arxiv.org/abs/2504.06446)