# # SEA-LION：东南亚语言一站式网络平台

发布时间：2025年04月08日

`LLM应用` `人工智能` `东南亚语言`

> SEA-LION: Southeast Asian Languages in One Network

# 摘要

> 大型语言模型（LLMs）凭借其卓越的自然语言处理能力，在人工智能领域占据主导地位。然而，当前LLM的研究和开发主要集中在英语，导致东南亚（SEA）等低资源语言的代表性不足。为了解决这一问题，我们推出了两款专为SEA语言设计的前沿多语言LLMs：Llama-SEA-LION-v3-8B-IT和Gemma-SEA-LION-v3-9B-IT。SEA-LION系列的LLMs支持包括英语、中文、印度尼西亚语、越南语、马来语、泰语、缅甸语、老挝语、菲律宾语、泰米尔语和高棉语在内的11种SEA语言。我们的研究采用大规模多语言持续预训练，并结合全面的后训练策略，包括多阶段的指令微调、对齐和模型合并。在多语言基准测试中，我们的模型在支持SEA语言的LLMs中表现最优。我们开源了这些模型，以惠及更广泛的SEA社区。

> Recently, Large Language Models (LLMs) have dominated much of the artificial intelligence scene with their ability to process and generate natural languages. However, the majority of LLM research and development remains English-centric, leaving low-resource languages such as those in the Southeast Asian (SEA) region under-represented. To address this representation gap, we introduce Llama-SEA-LION-v3-8B-IT and Gemma-SEA-LION-v3-9B-IT, two cutting-edge multilingual LLMs designed for SEA languages. The SEA-LION family of LLMs supports 11 SEA languages, namely English, Chinese, Indonesian, Vietnamese, Malay, Thai, Burmese, Lao, Filipino, Tamil, and Khmer. Our work leverages large-scale multilingual continued pre-training with a comprehensive post-training regime involving multiple stages of instruction fine-tuning, alignment, and model merging. Evaluation results on multilingual benchmarks indicate that our models achieve state-of-the-art performance across LLMs supporting SEA languages. We open-source the models to benefit the wider SEA community.

[Arxiv](https://arxiv.org/abs/2504.05747)