# # GPT 采用与披露政策的影响  
GPT 的采用及其披露政策的影响

发布时间：2025年04月02日

`LLM应用`

> GPT Adoption and the Impact of Disclosure Policies

# 摘要

> 生成式预训练变换器（GPTs），特别是像ChatGPT这样的大型语言模型（LLMs），在内容生成和生产力提升方面表现卓越。然而，这些工具的法律风险导致了采用差异，并促使组织隐藏AI的使用。本研究通过代理理论的视角，探讨了披露对咨询公司中法律、审计和咨询角色采用ChatGPT的影响。我们进行了一项调查实验，以评估在未受监管的企业使用ChatGPT背景下代理成本，重点关注强制性披露如何影响信息不对称和利益不一致。研究发现，在缺乏企业法规（如AI政策）的情况下，企业可能会产生代理成本，这可能阻碍GPT采用的全部效益。尽管披露政策减少了信息不对称，但由于管理者低估了分析师在GPT使用中的贡献，总体代理成本并未显著降低。最后，我们考察了欧洲和美国现有法规中关于披露要求的范围，探讨了企业内部风险和责任的分担，并分析了激励机制如何促进负责任的AI采用。

> Generative Pre-trained Transformers (GPTs), particularly Large Language Models (LLMs) like ChatGPT, have proven effective in content generation and productivity enhancement. However, legal risks associated with these tools lead to adoption variance and concealment of AI use within organizations. This study examines the impact of disclosure on ChatGPT adoption in legal, audit and advisory roles in consulting firms through the lens of agency theory. We conducted a survey experiment to evaluate agency costs in the context of unregulated corporate use of ChatGPT, with a particular focus on how mandatory disclosure influences information asymmetry and misaligned interests. Our findings indicate that in the absence of corporate regulations, such as an AI policy, firms may incur agency costs, which can hinder the full benefits of GPT adoption. While disclosure policies reduce information asymmetry, they do not significantly lower overall agency costs due to managers undervaluing analysts' contributions with GPT use. Finally, we examine the scope of existing regulations in Europe and the United States regarding disclosure requirements, explore the sharing of risk and responsibility within firms, and analyze how incentive mechanisms promote responsible AI adoption.

[Arxiv](https://arxiv.org/abs/2504.01566)