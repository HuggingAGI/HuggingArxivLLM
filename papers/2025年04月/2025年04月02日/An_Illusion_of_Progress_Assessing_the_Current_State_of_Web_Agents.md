# # 网络代理的发展现状：一场进步的幻觉？

发布时间：2025年04月02日

`Agent

理由：这篇论文主要关注的是基于大型语言模型（LLMs）的网络代理的能力评估和基准测试。研究的重点在于开发新的评估基准和自动评估方法，以更准确地衡量这些代理的表现。因此，它属于Agent类别，因为它专注于网络代理的评估和比较，而不是LLMs本身的应用或理论。` `自动化` `网络自动化`

> An Illusion of Progress? Assessing the Current State of Web Agents

# 摘要

> 随着数字化和云技术的飞速发展，网络在现代社会中扮演着越来越重要的角色。基于大型语言模型（LLMs）的自主网络代理在工作自动化领域展现出巨大的潜力。因此，准确衡量和监控这些代理能力的进展显得尤为重要。在本研究中，我们对当前网络代理的能力进行了全面而严谨的评估。我们的研究结果揭示了现有代理能力与之前报告结果之间存在显著差异，表明先前的结果可能过于乐观。这种差距主要源于现有基准的不足。我们推出了Online-Mind2Web，这是一个包含300个多样且现实任务的在线评估基准，覆盖136个网站。它使我们能够在类似于真实用户使用这些代理的环境中进行评估。为了促进更具扩展性的评估和开发，我们还开发了一种创新的基于LLM的自动评估方法，并证明其与人类判断的一致性高达85%，远超现有方法。最后，我们首次对当前网络代理进行了全面的比较分析，既突出了它们的优势，也指出了它们的局限性，旨在为未来的研究提供方向和灵感。

> As digitalization and cloud technologies evolve, the web is becoming increasingly important in the modern society. Autonomous web agents based on large language models (LLMs) hold a great potential in work automation. It is therefore important to accurately measure and monitor the progression of their capabilities. In this work, we conduct a comprehensive and rigorous assessment of the current state of web agents. Our results depict a very different picture of the competency of current agents, suggesting over-optimism in previously reported results. This gap can be attributed to shortcomings in existing benchmarks. We introduce Online-Mind2Web, an online evaluation benchmark consisting of 300 diverse and realistic tasks spanning 136 websites. It enables us to evaluate web agents under a setting that approximates how real users use these agents. To facilitate more scalable evaluation and development, we also develop a novel LLM-as-a-Judge automatic evaluation method and show that it can achieve around 85% agreement with human judgment, substantially higher than existing methods. Finally, we present the first comprehensive comparative analysis of current web agents, highlighting both their strengths and limitations to inspire future research.

[Arxiv](https://arxiv.org/abs/2504.01382)