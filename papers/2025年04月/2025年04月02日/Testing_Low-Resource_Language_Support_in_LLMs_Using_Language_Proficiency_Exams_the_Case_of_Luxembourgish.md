# 利用语言熟练度考试评估大型语言模型对低资源语言的支持能力——以卢森堡语为例

发布时间：2025年04月02日

`LLM应用` `评估工具`

> Testing Low-Resource Language Support in LLMs Using Language Proficiency Exams: the Case of Luxembourgish

# 摘要

> 大型语言模型（LLMs）正变得越来越重要，不仅是研究领域的重要工具，在整个社会中也发挥着越来越重要的作用。尽管LLMs被专家和普通用户在全球范围内广泛使用，但它们主要以英语使用者为目标进行开发，在英语和其他广泛应用的语言中表现出色，而像卢森堡语这样资源较少的语言则被视为优先级较低。这种忽视也体现在现有评估工具和数据集的稀缺性上。在这项研究中，我们探讨了语言能力考试作为卢森堡语评估工具的可行性。我们发现，像ChatGPT、Claude和DeepSeek-R1这样的大型模型通常能够获得高分，而较小的模型则表现较弱。我们还发现，这些语言考试中的表现可以用来预测其他自然语言处理任务中的表现。

> Large Language Models (LLMs) have become an increasingly important tool in research and society at large. While LLMs are regularly used all over the world by experts and lay-people alike, they are predominantly developed with English-speaking users in mind, performing well in English and other wide-spread languages while less-resourced languages such as Luxembourgish are seen as a lower priority. This lack of attention is also reflected in the sparsity of available evaluation tools and datasets. In this study, we investigate the viability of language proficiency exams as such evaluation tools for the Luxembourgish language. We find that large models such as ChatGPT, Claude and DeepSeek-R1 typically achieve high scores, while smaller models show weak performances. We also find that the performances in such language exams can be used to predict performances in other NLP tasks.

[Arxiv](https://arxiv.org/abs/2504.01667)