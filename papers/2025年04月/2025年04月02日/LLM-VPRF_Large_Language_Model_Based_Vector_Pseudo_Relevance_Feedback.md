# LLM-VPRF：基于大型语言模型的向量伪相关反馈机制

发布时间：2025年04月02日

`LLM应用

摘要讨论了向量伪相关反馈（VPRF）在基于大型语言模型（LLM）的密集检索系统中的应用，提出了一种新的方法LLM-VPRF，并验证了其有效性。这属于将VPRF技术应用到LLM的具体任务中，以提升检索性能，因此归类为LLM应用。` `信息检索`

> LLM-VPRF: Large Language Model Based Vector Pseudo Relevance Feedback

# 摘要

> 向量伪相关反馈（VPRF）在提升基于BERT的密集检索系统方面表现突出，通过迭代优化查询表示实现了显著效果。本文研究了VPRF在基于大型语言模型（LLM）的密集检索器中的应用潜力。我们提出了LLM-VPRF，并通过多个基准数据集验证其有效性，深入分析了不同LLM对反馈机制的影响。研究结果表明，VPRF的优势成功扩展到了LLM架构，证明了它作为提升密集检索性能的稳健技术，无论底层模型如何。这项工作不仅架起了VPRF与传统基于BERT的密集检索器和现代LLM之间的桥梁，更为未来研究提供了重要方向。

> Vector Pseudo Relevance Feedback (VPRF) has shown promising results in improving BERT-based dense retrieval systems through iterative refinement of query representations. This paper investigates the generalizability of VPRF to Large Language Model (LLM) based dense retrievers. We introduce LLM-VPRF and evaluate its effectiveness across multiple benchmark datasets, analyzing how different LLMs impact the feedback mechanism. Our results demonstrate that VPRF's benefits successfully extend to LLM architectures, establishing it as a robust technique for enhancing dense retrieval performance regardless of the underlying models. This work bridges the gap between VPRF with traditional BERT-based dense retrievers and modern LLMs, while providing insights into their future directions.

[Arxiv](https://arxiv.org/abs/2504.01448)