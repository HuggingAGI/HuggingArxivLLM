# 情节渐趋复杂：多模态大语言模型可视化素养的分层定量探索

发布时间：2025年04月02日

`LLM应用` `数据可视化` `人工智能`

> The Plot Thickens: Quantitative Part-by-Part Exploration of MLLM Visualization Literacy

# 摘要

> 多模态大型语言模型（MLLMs）能够解读数据可视化，但什么因素使这些模型能够理解可视化呢？颜色、形状和文字等因素是否会影响可读性？这些因素对模型的影响与人类感知有何异同？在本文中，我们基于先前的研究，系统性地评估了哪些可视化特征会影响MLLM的可解释性。我们通过改变图表类型、颜色和标题，将可视化素养评估测试（VLAT）的测试集从12个扩展到了380个可视化样本。这使我们能够统计分析这些特征对模型性能的影响。我们的研究发现，虽然颜色方案对准确率没有显著影响，但图表类型和标题类型对MLLM的性能有显著影响。我们还观察到类似的趋势存在于模型遗漏的情况中。基于这些见解，我们探讨了在不同任务中哪些图表类型对MLLMs有益，并提出了增强MLLM可读性的可视化设计原则。此外，我们还将扩展后的VLAT测试集VLAT ex公开发布在https://osf.io/ermwx/，同时提供了补充材料，以供未来对模型进行测试和评估使用。

> Multimodal Large Language Models (MLLMs) can interpret data visualizations, but what makes a visualization understandable to these models? Do factors like color, shape, and text influence legibility, and how does this compare to human perception? In this paper, we build on prior work to systematically assess which visualization characteristics impact MLLM interpretability. We expanded the Visualization Literacy Assessment Test (VLAT) test set from 12 to 380 visualizations by varying plot types, colors, and titles. This allowed us to statistically analyze how these features affect model performance. Our findings suggest that while color palettes have no significant impact on accuracy, plot types and the type of title significantly affect MLLM performance. We observe similar trends for model omissions. Based on these insights, we look into which plot types are beneficial for MLLMs in different tasks and propose visualization design principles that enhance MLLM readability. Additionally, we make the extended VLAT test set, VLAT ex, publicly available on https://osf.io/ermwx/ together with our supplemental material for future model testing and evaluation.

[Arxiv](https://arxiv.org/abs/2504.02217)