# 增进AI与科学家的理解：用可解释推理让LLM像物理学家般思考

发布时间：2025年04月02日

`LLM应用`

> Advancing AI-Scientist Understanding: Making LLM Think Like a Physicist with Interpretable Reasoning

# 摘要

> 大型语言模型 (LLMs) 正在通过增强推理、符号操作和数值计算，在物理研究中发挥越来越重要的作用。然而，确保其输出的可靠性和可解释性仍然是一个重大挑战。在我们的框架中，AI 与人类科学家的合作分为三个模块：推理模块、解释模块和交互模块。为了实现有效的物理推理，我们需要严格的逻辑、精准的计算以及与现有理论的紧密结合。因此，我们引入了独特的解释模块，帮助更深入地理解 AI 的输出，这一创新在以往研究中尚未被充分探索。该模块由多个专门代理组成，包括摘要器、模型构建者、界面构建者和测试器，它们共同协作，将 LLM 的输出整合到物理框架中，构建更易理解的科学模型。案例研究证明，我们的方法不仅提升了透明度，还加强了 AI 辅助推理能力，为科学发现提供了有力支持。

> Large Language Models (LLMs) are playing an expanding role in physics research by enhancing reasoning, symbolic manipulation, and numerical computation. However, ensuring the reliability and interpretability of their outputs remains a significant challenge. In our framework, we conceptualize the collaboration between AI and human scientists as a dynamic interplay among three modules: the reasoning module, the interpretation module, and the AI-scientist interaction module. Recognizing that effective physics reasoning demands rigorous logical consistency, quantitative precision, and deep integration with established theoretical models, we introduce the interpretation module to improve the understanding of AI-generated outputs, which is not previously explored in the literature. This module comprises multiple specialized agents, including summarizers, model builders, UI builders, and testers, which collaboratively structure LLM outputs within a physically grounded framework, by constructing a more interpretable science model. A case study demonstrates that our approach enhances transparency, facilitates validation, and strengthens AI-augmented reasoning in scientific discovery.

[Arxiv](https://arxiv.org/abs/2504.01911)