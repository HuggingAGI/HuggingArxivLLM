# # 标题
与大型语言模型协作，实现多样化的人类-like团队合作与沟通

发布时间：2025年04月04日

`Agent` `人工智能` `协作系统`

> Algorithmic Prompt Generation for Diverse Human-like Teaming and Communication with Large Language Models

# 摘要

> 理解人类在团队中的协作与沟通方式对优化人机协作和AI辅助决策至关重要。然而，受限于实际操作中的种种挑战，单纯依赖大规模用户研究数据并不现实，因此我们需要构建能够模拟多种多样化人类行为的合成模型。最近，基于大型语言模型（LLMs）的智能体在社交场景中展现出模拟人类行为的潜力。然而，获取多样化的大量行为集合需要通过手动设计提示词来实现。另一方面，质量多样性（QD）优化已被证明能够生成多样化的强化学习（RL）智能体行为。在本研究中，我们将QD优化与基于LLMs的智能体相结合，通过迭代搜索生成在长周期、多步骤协作环境中多样化团队行为的提示词。首先，我们通过一项针对54名参与者的实验表明，人类在该领域展现出多样化的协调与沟通行为。然后，我们证明了我们的方法不仅能够有效复制人类协作数据的趋势，还能够捕捉到在不收集大量数据的情况下难以观察到的行为。我们的研究发现表明，将QD与基于LLMs的智能体相结合是一种研究多智能体协作中团队协作和沟通策略的有效工具。

> Understanding how humans collaborate and communicate in teams is essential for improving human-agent teaming and AI-assisted decision-making. However, relying solely on data from large-scale user studies is impractical due to logistical, ethical, and practical constraints, necessitating synthetic models of multiple diverse human behaviors. Recently, agents powered by Large Language Models (LLMs) have been shown to emulate human-like behavior in social settings. But, obtaining a large set of diverse behaviors requires manual effort in the form of designing prompts. On the other hand, Quality Diversity (QD) optimization has been shown to be capable of generating diverse Reinforcement Learning (RL) agent behavior. In this work, we combine QD optimization with LLM-powered agents to iteratively search for prompts that generate diverse team behavior in a long-horizon, multi-step collaborative environment. We first show, through a human-subjects experiment (n=54 participants), that humans exhibit diverse coordination and communication behavior in this domain. We then show that our approach can effectively replicate trends from human teaming data and also capture behaviors that are not easily observed without collecting large amounts of data. Our findings highlight the combination of QD and LLM-powered agents as an effective tool for studying teaming and communication strategies in multi-agent collaboration.

[Arxiv](https://arxiv.org/abs/2504.03991)