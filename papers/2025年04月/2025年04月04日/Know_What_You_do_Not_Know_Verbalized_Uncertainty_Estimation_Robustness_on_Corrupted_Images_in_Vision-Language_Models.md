# 知其所不知：视觉-语言模型中不确定性表达估计的受损图像鲁棒性

发布时间：2025年04月04日

`LLM应用` `计算机视觉` `人工智能`

> Know What You do Not Know: Verbalized Uncertainty Estimation Robustness on Corrupted Images in Vision-Language Models

# 摘要

> 要充分发挥大型语言模型（LLMs）的潜力，了解其答案的不确定性至关重要。这意味着模型必须能够量化其对给定回答正确性的信心程度。糟糕的不确定性估计会导致模型过于自信地给出错误答案，从而削弱人们对这些模型的信任。尽管在处理文本输入并生成文本输出的语言模型方面已经做了很多研究，但由于视觉能力是最近才被引入到这些模型中，因此在视觉语言模型（VLMs）的不确定性方面还没有取得太多进展。我们测试了三个最先进的VLM在受损图像数据上的表现。我们发现，图像损坏的严重程度对模型估计其不确定性的能力产生了负面影响，而且模型在大多数实验中也表现出过度自信。

> To leverage the full potential of Large Language Models (LLMs) it is crucial to have some information on their answers' uncertainty. This means that the model has to be able to quantify how certain it is in the correctness of a given response. Bad uncertainty estimates can lead to overconfident wrong answers undermining trust in these models. Quite a lot of research has been done on language models that work with text inputs and provide text outputs. Still, since the visual capabilities have been added to these models recently, there has not been much progress on the uncertainty of Visual Language Models (VLMs). We tested three state-of-the-art VLMs on corrupted image data. We found that the severity of the corruption negatively impacted the models' ability to estimate their uncertainty and the models also showed overconfidence in most of the experiments.

[Arxiv](https://arxiv.org/abs/2504.03440)