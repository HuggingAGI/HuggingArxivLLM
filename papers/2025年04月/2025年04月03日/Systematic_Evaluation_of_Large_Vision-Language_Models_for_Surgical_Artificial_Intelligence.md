# # 系统性评估：大型视觉-语言模型在外科人工智能中的应用
# 系统性评估：大型视觉-语言模型在外科人工智能中的应用

发布时间：2025年04月03日

`LLM应用

理由：这篇论文探讨了大型视觉语言模型（VLMs）在医学图像理解中的实际应用，特别是在外科手术领域。它分析了VLMs在不同任务中的表现，展示了它们在临床环境中的潜力和挑战。这属于将LLM应用于特定领域的实际研究，因此归类为LLM应用。`

> Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence

# 摘要

> 大型视觉语言模型为AI驱动的图像理解开辟了新范式，无需特定任务训练即可执行任务。这一灵活性在医学领域尤其具有前景，因为该领域中专家标注的数据稀缺。然而，VLMs在以干预为导向的领域--特别是外科手术，其中决策具有主观性且临床场景多变--的实际效用仍不明朗。我们对11种最先进的VLMs进行了全面分析，涵盖外科AI中的17个关键视觉理解任务，从解剖识别到技能评估，使用了13个涵盖腹腔镜、机器人和开放手术的数据集。实验中，VLMs展示了令人鼓舞的泛化能力，有时在部署到训练环境之外时甚至超越了监督模型的性能。通过在测试中纳入示例的上下文学习，性能提升了三倍，表明适应性是其关键优势。然而，需要空间或时间推理的任务仍然具有挑战性。除了手术领域，我们的发现为VLMs在临床乃至更广泛现实世界应用中应对复杂动态场景的潜力提供了见解。

> Large Vision-Language Models offer a new paradigm for AI-driven image understanding, enabling models to perform tasks without task-specific training. This flexibility holds particular promise across medicine, where expert-annotated data is scarce. Yet, VLMs' practical utility in intervention-focused domains--especially surgery, where decision-making is subjective and clinical scenarios are variable--remains uncertain. Here, we present a comprehensive analysis of 11 state-of-the-art VLMs across 17 key visual understanding tasks in surgical AI--from anatomy recognition to skill assessment--using 13 datasets spanning laparoscopic, robotic, and open procedures. In our experiments, VLMs demonstrate promising generalizability, at times outperforming supervised models when deployed outside their training setting. In-context learning, incorporating examples during testing, boosted performance up to three-fold, suggesting adaptability as a key strength. Still, tasks requiring spatial or temporal reasoning remained difficult. Beyond surgery, our findings offer insights into VLMs' potential for tackling complex and dynamic scenarios in clinical and broader real-world applications.

[Arxiv](https://arxiv.org/abs/2504.02799)