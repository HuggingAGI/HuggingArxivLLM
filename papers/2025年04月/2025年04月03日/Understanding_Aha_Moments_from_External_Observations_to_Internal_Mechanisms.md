# 洞察顿悟时刻：从外在观察到内在机制

发布时间：2025年04月03日

`LLM理论` `人工智能` `认知科学`

> Understanding Aha Moments: from External Observations to Internal Mechanisms

# 摘要

> 大型推理模型（LRMs）在处理复杂问题方面的能力使其在编程、数学和常识推理等领域中发挥着关键作用。然而，理解这些模型如何获取推理能力，并在重新组织推理方法时展现出“顿悟时刻”，仍然是一个核心挑战。本研究从语言模式、不确定性描述、“推理崩溃”到潜在空间分析，系统性地探讨了LRMs中的“顿悟时刻”。我们发现，“顿悟时刻”在外部表现为更频繁地使用拟人化语气进行自我反思，以及根据问题难度自适应地调整不确定性。这一过程帮助模型完成推理而不陷入“推理崩溃”。在内部，这对应着拟人化特征与纯推理之间的分离，且面对更困难的问题时，拟人化语气会增加。此外，我们发现“顿悟时刻”通过改变模型对问题难度的感知，帮助其解决复杂问题。随着模型层数的增加，简单问题往往被感知为更复杂，而困难问题则显得更简单。

> Large Reasoning Models (LRMs), capable of reasoning through complex problems, have become crucial for tasks like programming, mathematics, and commonsense reasoning. However, a key challenge lies in understanding how these models acquire reasoning capabilities and exhibit "aha moments" when they reorganize their methods to allocate more thinking time to problems. In this work, we systematically study "aha moments" in LRMs, from linguistic patterns, description of uncertainty, "Reasoning Collapse" to analysis in latent space. We demonstrate that the "aha moment" is externally manifested in a more frequent use of anthropomorphic tones for self-reflection and an adaptive adjustment of uncertainty based on problem difficulty. This process helps the model complete reasoning without succumbing to "Reasoning Collapse". Internally, it corresponds to a separation between anthropomorphic characteristics and pure reasoning, with an increased anthropomorphic tone for more difficult problems. Furthermore, we find that the "aha moment" helps models solve complex problems by altering their perception of problem difficulty. As the layer of the model increases, simpler problems tend to be perceived as more complex, while more difficult problems appear simpler.

[Arxiv](https://arxiv.org/abs/2504.02956)