# 从单向获取到携手共创：通过测量互动模式，提升人类在开放任务中的认知能力

发布时间：2025年04月03日

`LLM应用` `知识工作` `人机交互`

> From Consumption to Collaboration: Measuring Interaction Patterns to Augment Human Cognition in Open-Ended Tasks

# 摘要

> 生成式AI，特别是大型语言模型（LLMs），正在深刻改变知识工作中的人类思维和决策过程，引发了关于其对人类推理与问题解决能力影响的深入讨论。随着这些AI系统逐步融入工作流程，它们不仅为增强人类思维提供了前所未有的机遇，同时也带来了通过被动接受生成答案而引发认知能力退化的风险。这种矛盾在开放性任务中尤为突出，因为这类任务的有效解决方案需要深度的上下文理解和专业知识的整合。与有明确评估标准的结构化任务不同，在开放性任务中衡量人与LLM互动的质量面临重大挑战，原因在于缺乏真实基准以及解决方案开发的迭代特性。为应对这一挑战，我们提出了一种框架，从两个维度分析交互模式：认知活动模式（探索 vs. 开发）和认知参与模式（建设性 vs. 消极性）。该框架提供了一套系统化的测量方法，以评估LLMs在何种情况下能够成为有效的思维工具，而非人类认知的替代品。这不仅深化了我们对AI系统的理论理解，也为开发既能保护又能增强人类认知能力的AI系统提供了实践指导。

> The rise of Generative AI, and Large Language Models (LLMs) in particular, is fundamentally changing cognitive processes in knowledge work, raising critical questions about their impact on human reasoning and problem-solving capabilities. As these AI systems become increasingly integrated into workflows, they offer unprecedented opportunities for augmenting human thinking while simultaneously risking cognitive erosion through passive consumption of generated answers. This tension is particularly pronounced in open-ended tasks, where effective solutions require deep contextualization and integration of domain knowledge. Unlike structured tasks with established metrics, measuring the quality of human-LLM interaction in such open-ended tasks poses significant challenges due to the absence of ground truth and the iterative nature of solution development. To address this, we present a framework that analyzes interaction patterns along two dimensions: cognitive activity mode (exploration vs. exploitation) and cognitive engagement mode (constructive vs. detrimental). This framework provides systematic measurements to evaluate when LLMs are effective tools for thought rather than substitutes for human cognition, advancing theoretical understanding and practical guidance for developing AI systems that protect and augment human cognitive capabilities.

[Arxiv](https://arxiv.org/abs/2504.02780)