# 联合检索与外部知识：提升有害文本检测效果

发布时间：2025年04月03日

`LLM应用

理由：这篇论文探讨了大型语言模型在有害文本检测中的应用，提出了一种结合预训练模型与知识图谱的框架，属于LLM的应用层面研究。` `AI安全` `知识图谱`

> Improving Harmful Text Detection with Joint Retrieval and External Knowledge

# 摘要

> 有害文本检测已成为大型语言模型开发和部署中的关键任务，特别是在AI生成内容持续扩展的背景下。本研究提出了一种结合预训练语言模型与知识图谱的联合检索框架，以提升有害文本检测的准确性和鲁棒性。实验结果表明，与单一模型基线相比，联合检索方法在资源有限的训练场景和多语言环境中表现尤为突出。通过利用外部上下文信息，该方法能够有效捕捉细微的有害内容，弥补了传统检测模型的局限性。未来研究应着重优化计算效率、提升模型可解释性以及扩展多模态检测能力，以更好地应对不断演变的有害内容模式。本研究为AI安全领域的发展做出了贡献，有助于构建更加可信可靠的内容审核系统。

> Harmful text detection has become a crucial task in the development and deployment of large language models, especially as AI-generated content continues to expand across digital platforms. This study proposes a joint retrieval framework that integrates pre-trained language models with knowledge graphs to improve the accuracy and robustness of harmful text detection. Experimental results demonstrate that the joint retrieval approach significantly outperforms single-model baselines, particularly in low-resource training scenarios and multilingual environments. The proposed method effectively captures nuanced harmful content by leveraging external contextual information, addressing the limitations of traditional detection models. Future research should focus on optimizing computational efficiency, enhancing model interpretability, and expanding multimodal detection capabilities to better tackle evolving harmful content patterns. This work contributes to the advancement of AI safety, ensuring more trustworthy and reliable content moderation systems.

[Arxiv](https://arxiv.org/abs/2504.02310)