# 图通：一个全面且可扩展的图论任务大语言模型基准框架

发布时间：2025年04月17日

`LLM应用` `人工智能` `图推理`

> GraphOmni: A Comprehensive and Extendable Benchmark Framework for Large Language Models on Graph-theoretic Tasks

# 摘要

> 本文提出了一项名为 GraphOmni 的全面基准框架，旨在系统性评估大型语言模型 (LLMs) 的图推理能力。通过深入分析图类型、序列化格式和提示方案等关键维度，我们全面揭示了当前 LLMs 的优势与局限。实证研究表明，不存在单一序列化或提示策略能够持续领先。基于此，我们提出了一种基于强化学习的解决方案，通过动态选择最优序列化-提示组合，显著提升了模型性能。GraphOmni 的模块化和可扩展设计为未来研究提供了坚实基础，推动了通用图推理模型的发展。

> In this paper, we presented GraphOmni, a comprehensive benchmark framework for systematically evaluating the graph reasoning capabilities of LLMs. By analyzing critical dimensions, including graph types, serialization formats, and prompt schemes, we provided extensive insights into the strengths and limitations of current LLMs. Our empirical findings emphasize that no single serialization or prompting strategy consistently outperforms others. Motivated by these insights, we propose a reinforcement learning-based approach that dynamically selects the best serialization-prompt pairings, resulting in significant accuracy improvements. GraphOmni's modular and extensible design establishes a robust foundation for future research, facilitating advancements toward general-purpose graph reasoning models.

[Arxiv](https://arxiv.org/abs/2504.12764)