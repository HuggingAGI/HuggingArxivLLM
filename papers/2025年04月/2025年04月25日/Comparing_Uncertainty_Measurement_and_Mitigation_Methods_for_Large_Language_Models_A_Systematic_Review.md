# 大型语言模型不确定性测量与缓解方法的比较研究：系统综述

发布时间：2025年04月25日

`LLM理论` `模型评估` `可靠性工程`

> Comparing Uncertainty Measurement and Mitigation Methods for Large Language Models: A Systematic Review

# 摘要

> 大型语言模型（LLMs）在众多领域带来了革命性变革。然而，幻觉问题——即模型自信地输出错误信息——仍然是LLMs面临的主要挑战之一。这促使我们思考如何准确评估和量化LLMs的不确定性。传统模型的相关文献已深入探讨了不确定性量化（Uncertainty Quantification, UQ）以衡量不确定性，并采用校准技术来解决不确定性与准确性之间的不匹配问题。尽管部分方法已尝试应用于LLMs，但现有研究仍存在明显不足：缺乏对这些方法有效性的深入分析，且未能提供一个全面的基准框架来支持现有解决方案的对比分析。本研究通过系统性梳理LLMs领域中具有代表性的UQ和校准方法，填补了这一研究空白，并引入了严格的评估基准。基于两个广为采用的可靠性数据集，我们对六种相关方法进行了实证评估，结果充分验证了我们综述中的关键发现。最后，我们展望了未来研究的重点方向，并指出了当前仍待解决的开放性挑战。据我们所知，本综述是首个专门针对LLMs校准方法及其相关指标的研究。


> Large Language Models (LLMs) have been transformative across many domains. However, hallucination -- confidently outputting incorrect information -- remains one of the leading challenges for LLMs. This raises the question of how to accurately assess and quantify the uncertainty of LLMs. Extensive literature on traditional models has explored Uncertainty Quantification (UQ) to measure uncertainty and employed calibration techniques to address the misalignment between uncertainty and accuracy. While some of these methods have been adapted for LLMs, the literature lacks an in-depth analysis of their effectiveness and does not offer a comprehensive benchmark to enable insightful comparison among existing solutions. In this work, we fill this gap via a systematic survey of representative prior works on UQ and calibration for LLMs and introduce a rigorous benchmark. Using two widely used reliability datasets, we empirically evaluate six related methods, which justify the significant findings of our review. Finally, we provide outlooks for key future directions and outline open challenges. To the best of our knowledge, this survey is the first dedicated study to review the calibration methods and relevant metrics for LLMs.

[Arxiv](https://arxiv.org/abs/2504.18346)