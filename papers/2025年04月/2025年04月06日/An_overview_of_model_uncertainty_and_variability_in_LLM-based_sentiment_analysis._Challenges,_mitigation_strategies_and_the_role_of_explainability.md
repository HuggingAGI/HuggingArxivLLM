# # 摘要
全面解析基于大型语言模型（LLMs）的情感分析中的模型不确定性和变异性。探讨其中的挑战、应对策略以及可解释性的重要作用。

发布时间：2025年04月06日

`LLM应用`

> An overview of model uncertainty and variability in LLM-based sentiment analysis. Challenges, mitigation strategies and the role of explainability

# 摘要

> 大型语言模型（LLMs）推动了情感分析的显著进步，但其固有的不确定性和变异性对实现可靠且一致的结果提出了严峻挑战。本文系统性地探讨了基于LLM的情感分析中的模型变异性问题（MVP），该问题由随机推理机制、提示敏感性和训练数据偏见引发，表现为情感分类不一致、两极分化和不确定性。我们深入分析了MVP的核心成因，并通过具体案例和研究实例展示了其影响。此外，我们还深入研究了关键挑战与缓解策略，特别关注温度参数对输出随机性的影响，并强调可解释性在提升透明度和用户信任中的关键作用。通过提供一个结构化的视角，聚焦于稳定性、可重复性和可信度，本研究助力开发更可靠、可解释且稳健的情感分析模型，为其在金融、医疗和政策制定等高风险领域的广泛应用铺平道路。

> Large Language Models (LLMs) have significantly advanced sentiment analysis, yet their inherent uncertainty and variability pose critical challenges to achieving reliable and consistent outcomes. This paper systematically explores the Model Variability Problem (MVP) in LLM-based sentiment analysis, characterized by inconsistent sentiment classification, polarization, and uncertainty arising from stochastic inference mechanisms, prompt sensitivity, and biases in training data. We analyze the core causes of MVP, presenting illustrative examples and a case study to highlight its impact. In addition, we investigate key challenges and mitigation strategies, paying particular attention to the role of temperature as a driver of output randomness and emphasizing the crucial role of explainability in improving transparency and user trust. By providing a structured perspective on stability, reproducibility, and trustworthiness, this study helps develop more reliable, explainable, and robust sentiment analysis models, facilitating their deployment in high-stakes domains such as finance, healthcare, and policymaking, among others.

[Arxiv](https://arxiv.org/abs/2504.04462)