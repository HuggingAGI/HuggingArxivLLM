# # 摘要  
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年04月10日

`其他` `数据合规` `版权法律`

> The KL3M Data Project: Copyright-Clean Training Resources for Large Language Models

# 摘要

> 几乎所有大型语言模型的预训练数据都涉及版权侵权和合同违约的全球性法律不确定性，这为用户和开发者带来了潜在风险。KL3M 数据项目直面这一关键挑战，推出了目前规模最大、最全面的训练数据管道，旨在最大限度地降低版权或合同违约相关风险。该项目建立在一个包含 1.32 亿份文档和万亿个令牌的多源语料库基础上，所有数据均经过严格验证，确保符合详述的版权和许可协议。我们正公开分享完整的数据管道，包括：1) 文档获取与处理的源代码，2) 带有出处和元数据的原始文档格式，3) 标准化提取内容，4) 预分词文档表示，以及 5) 问答、摘要、转换、起草、分类、预测和对话等多种中期及后期训练资源。所有资源均在 S3、Hugging Face 和 GitHub 上以 CC-BY 协议免费开放。我们承诺持续推动此项目，以促进 AI 模型开发和使用的道德性、合法性和可持续性。


> Practically all large language models have been pre-trained on data that is subject to global uncertainty related to copyright infringement and breach of contract. This creates potential risk for users and developers due to this uncertain legal status. The KL3M Data Project directly confronts this critical issue by introducing the largest comprehensive training data pipeline that minimizes risks related to copyright or breach of contract. The foundation of this project is a corpus of over 132 million documents and trillions of tokens spanning 16 different sources that have been verified to meet the strict copyright and licensing protocol detailed herein. We are releasing the entire pipeline, including 1) the source code to acquire and process these documents, 2) the original document formats with associated provenance and metadata, 3) extracted content in a standardized format, 4) pre-tokenized representations of the documents, and 5) various mid- and post-train resources such as question-answer, summarization, conversion, drafting, classification, prediction, and conversational data. All of these resources are freely available to the public on S3, Hugging Face, and GitHub under CC-BY terms. We are committed to continuing this project in furtherance of a more ethical, legal, and sustainable approach to the development and use of AI models.

[Arxiv](https://arxiv.org/abs/2504.07854)