# 通过利用推理模型的解答来提升不具备推理能力的模型效能

发布时间：2025年04月13日

`LLM应用

理由：这篇论文探讨了如何利用推理密集型大型语言模型生成的高质量输出来改进非推理型模型，属于模型优化和实际应用层面的改进。` `人工智能` `模型优化`

> Leveraging Reasoning Model Answers to Enhance Non-Reasoning Model Capability

# 摘要

> 近期，大型语言模型（如DeepSeek-R1和OpenAI-o1）在测试时扩展方面取得了显著成效，展现出在各类基准测试中性能的大幅提升。这些先进模型通过刻意设计的“思考”步骤，系统性地提升了答案质量。本文提出，利用这些推理密集型模型生成的高质量输出，来改进计算需求较低的非推理型模型。我们探索并比较了利用推理模型生成的答案来训练和提升非推理模型的方法。通过在 established benchmarks 上进行简单的 Supervised Fine-Tuning (SFT) 实验，我们展示了在各类基准测试中的一致性改进，突显了这一方法在提升模型直接回答问题能力方面的潜力。

> Recent advancements in large language models (LLMs), such as DeepSeek-R1 and OpenAI-o1, have demonstrated the significant effectiveness of test-time scaling, achieving substantial performance gains across various benchmarks. These advanced models utilize deliberate "thinking" steps to systematically enhance answer quality. In this paper, we propose leveraging these high-quality outputs generated by reasoning-intensive models to improve less computationally demanding, non-reasoning models. We explore and compare methodologies for utilizing the answers produced by reasoning models to train and improve non-reasoning models. Through straightforward Supervised Fine-Tuning (SFT) experiments on established benchmarks, we demonstrate consistent improvements across various benchmarks, underscoring the potential of this approach for advancing the ability of models to answer questions directly.

[Arxiv](https://arxiv.org/abs/2504.09639)