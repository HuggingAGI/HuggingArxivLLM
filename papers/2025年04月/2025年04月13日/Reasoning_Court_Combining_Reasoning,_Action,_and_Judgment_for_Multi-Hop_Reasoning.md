# 推理法庭：结合推理、行动与判断进行多跳推理

发布时间：2025年04月13日

`LLM应用` `问答系统` `事实核查`

> Reasoning Court: Combining Reasoning, Action, and Judgment for Multi-Hop Reasoning

# 摘要

> 虽然大型语言模型（LLMs）在问答和事实核查等任务中表现出色，但它们在多跳推理任务中仍然面临幻觉和推理错误的困扰，尤其是在需要整合多个信息源的情况下。目前，人们主要通过基于检索的技术（将推理扎根于外部证据）、基于推理的方法（通过改进提示来增强连贯性）或两者的混合策略来解决这些问题。其中，ReAct作为一种突出的混合方法，在纯检索或纯推理方法中表现更优；然而，它缺乏对中间推理步骤的内部验证，可能导致潜在错误在复杂推理任务中传播。

本文中，我们引入了Reasoning Court（RC），一个扩展迭代推理-检索方法（如ReAct）的全新框架，配备了一个专门的LLM裁判。与ReAct不同，RC利用这个裁判独立评估多个由不同LLM代理生成的候选答案及其相关推理。裁判根据提供的推理和证据，选择它认为最基于事实且逻辑连贯的答案，或者如果所有候选答案都不足、有缺陷或无效，则利用可用证据和其预训练知识综合出一个新的答案。

在多跳基准测试（HotpotQA、MuSiQue）和事实核查（FEVER）上的评估表明，RC在无需特定任务微调的情况下，始终优于当前最先进的少样本提示方法。

> While large language models (LLMs) have demonstrated strong capabilities in tasks like question answering and fact verification, they continue to suffer from hallucinations and reasoning errors, especially in multi-hop tasks that require integration of multiple information sources. Current methods address these issues through retrieval-based techniques (grounding reasoning in external evidence), reasoning-based approaches (enhancing coherence via improved prompting), or hybrid strategies combining both elements. One prominent hybrid method, ReAct, has outperformed purely retrieval-based or reasoning-based approaches; however, it lacks internal verification of intermediate reasoning steps, allowing potential errors to propagate through complex reasoning tasks. In this paper, we introduce Reasoning Court (RC), a novel framework that extends iterative reasoning-and-retrieval methods, such as ReAct, with a dedicated LLM judge. Unlike ReAct, RC employs this judge to independently evaluate multiple candidate answers and their associated reasoning generated by separate LLM agents. The judge is asked to select the answer that it considers the most factually grounded and logically coherent based on the presented reasoning and evidence, or synthesizes a new answer using available evidence and its pre-trained knowledge if all candidates are inadequate, flawed, or invalid. Evaluations on multi-hop benchmarks (HotpotQA, MuSiQue) and fact-verification (FEVER) demonstrate that RC consistently outperforms state-of-the-art few-shot prompting methods without task-specific fine-tuning.

[Arxiv](https://arxiv.org/abs/2504.09781)