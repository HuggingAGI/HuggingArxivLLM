# EmoAgent：评估与保护人类与AI交互，保障心理健康安全

发布时间：2025年04月13日

`LLM应用` `心理健康` `人机交互`

> EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety

# 摘要

> 大型语言模型驱动的AI角色的兴起引发了安全担忧，尤其是对心理脆弱的用户群体。为应对这些风险，我们提出了EmoAgent——一个用于评估和降低人机交互中心理健康风险的多智能体AI框架。EmoAgent包含两个核心组件：EmoEval模拟虚拟用户，包括心理脆弱的个体，评估与AI角色互动前后的心理健康变化。它采用经过临床验证的心理评估工具（PHQ-9、PDI、PANSS）来评估LLM引发的心理风险。EmoGuard作为中介，实时监控用户的心理状态，预测潜在危害，并提供纠正反馈以降低风险。在流行的基于角色的聊天机器人中进行的实验表明，情感化的对话可能导致脆弱用户的心理状况恶化，模拟中有超过34.4%的情况出现心理状态恶化。而EmoGuard的引入显著降低了这些恶化率，凸显了其在保障更安全的人机交互中的重要作用。我们的代码已在GitHub上开放：https://github.com/1akaman/EmoAgent

> The rise of LLM-driven AI characters raises safety concerns, particularly for vulnerable human users with psychological disorders. To address these risks, we propose EmoAgent, a multi-agent AI framework designed to evaluate and mitigate mental health hazards in human-AI interactions. EmoAgent comprises two components: EmoEval simulates virtual users, including those portraying mentally vulnerable individuals, to assess mental health changes before and after interactions with AI characters. It uses clinically proven psychological and psychiatric assessment tools (PHQ-9, PDI, PANSS) to evaluate mental risks induced by LLM. EmoGuard serves as an intermediary, monitoring users' mental status, predicting potential harm, and providing corrective feedback to mitigate risks. Experiments conducted in popular character-based chatbots show that emotionally engaging dialogues can lead to psychological deterioration in vulnerable users, with mental state deterioration in more than 34.4% of the simulations. EmoGuard significantly reduces these deterioration rates, underscoring its role in ensuring safer AI-human interactions. Our code is available at: https://github.com/1akaman/EmoAgent

[Arxiv](https://arxiv.org/abs/2504.09689)