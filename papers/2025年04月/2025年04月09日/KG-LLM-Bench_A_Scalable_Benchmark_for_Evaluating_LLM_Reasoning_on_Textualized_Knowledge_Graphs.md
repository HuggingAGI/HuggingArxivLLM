# KG-LLM-Bench: 一个用于评估 LLM 在文本化知识图谱上推理能力的可扩展基准测试

发布时间：2025年04月09日

`LLM应用` `知识图谱`

> KG-LLM-Bench: A Scalable Benchmark for Evaluating LLM Reasoning on Textualized Knowledge Graphs

# 摘要

> 知识图谱作为一种流行的方法，用于将最新的事实知识注入大型语言模型（LLMs）中。这通常是通过将知识图谱转换为LLM可以处理的上下文文本实现的。尽管提出了多种知识图谱编码方法，但这一文本化过程对LLM性能的影响仍未被充分探索。我们引入了KG-LLM-Bench，这是一个全面且可扩展的基准，涵盖了五个知识图谱理解任务，并评估了不同编码策略对各种基础模型性能的影响。我们使用七种语言模型和五种文本化策略进行了广泛实验，为优化LLM在KG推理任务上的性能提供了见解。

> Knowledge graphs have emerged as a popular method for injecting up-to-date, factual knowledge into large language models (LLMs). This is typically achieved by converting the knowledge graph into text that the LLM can process in context. While multiple methods of encoding knowledge graphs have been proposed, the impact of this textualization process on LLM performance remains under-explored. We introduce KG-LLM-Bench, a comprehensive and extensible benchmark spanning five knowledge graph understanding tasks, and evaluate how different encoding strategies affect performance across various base models. Our extensive experiments with seven language models and five textualization strategies provide insights for optimizing LLM performance on KG reasoning tasks.

[Arxiv](https://arxiv.org/abs/2504.07087)