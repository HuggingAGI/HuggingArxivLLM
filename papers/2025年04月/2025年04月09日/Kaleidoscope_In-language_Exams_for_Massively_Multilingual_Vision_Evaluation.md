# Kaleidoscope：面向大规模多语言视觉评估的本族语考试工具

发布时间：2025年04月09日

`LLM应用

论文摘要：视觉语言模型 (VLMs) 的评估主要依赖于英语基准测试，这在多语言和多文化覆盖方面存在显著空白。尽管多语言基准测试在规模和语言数量上有所扩展，但许多测试依赖于对英语数据集的翻译，未能捕捉文化细微差别。在此工作中，我们提出了 Kaleidoscope，作为迄今为止最全面的多语言视觉语言模型评估基准测试。Kaleidoscope 是一个大规模、原语言的多模态基准测试，旨在评估视觉语言模型在多种语言和视觉输入下的表现。Kaleidoscope 覆盖了 18 种语言和 14 个不同科目，总计 20,911 个多项选择题。通过与全球多样化研究团队的开放科学合作构建，Kaleidoscope 确保了语言和文化的真实性。我们评估了顶级多语言视觉语言模型，发现它们在低资源语言和复杂多模态场景下的表现不佳。我们的结果强调了在文化包容性多模态评估框架方面取得进展的必要性。` `视觉语言模型` `跨文化评估`

> Kaleidoscope: In-language Exams for Massively Multilingual Vision Evaluation

# 摘要

> 视觉语言模型 (VLMs) 的评估主要依赖于英语基准测试，这在多语言和多文化覆盖方面存在显著空白。尽管多语言基准测试在规模和语言数量上有所扩展，但许多测试依赖于对英语数据集的翻译，未能捕捉文化细微差别。在此工作中，我们提出了 Kaleidoscope，作为迄今为止最全面的多语言视觉语言模型评估基准测试。Kaleidoscope 是一个大规模、原语言的多模态基准测试，旨在评估视觉语言模型在多种语言和视觉输入下的表现。Kaleidoscope 覆盖了 18 种语言和 14 个不同科目，总计 20,911 个多项选择题。通过与全球多样化研究团队的开放科学合作构建，Kaleidoscope 确保了语言和文化的真实性。我们评估了顶级多语言视觉语言模型，发现它们在低资源语言和复杂多模态场景下的表现不佳。我们的结果强调了在文化包容性多模态评估框架方面取得进展的必要性。

> The evaluation of vision-language models (VLMs) has mainly relied on English-language benchmarks, leaving significant gaps in both multilingual and multicultural coverage. While multilingual benchmarks have expanded, both in size and languages, many rely on translations of English datasets, failing to capture cultural nuances. In this work, we propose Kaleidoscope, as the most comprehensive exam benchmark to date for the multilingual evaluation of vision-language models. Kaleidoscope is a large-scale, in-language multimodal benchmark designed to evaluate VLMs across diverse languages and visual inputs. Kaleidoscope covers 18 languages and 14 different subjects, amounting to a total of 20,911 multiple-choice questions. Built through an open science collaboration with a diverse group of researchers worldwide, Kaleidoscope ensures linguistic and cultural authenticity. We evaluate top-performing multilingual vision-language models and find that they perform poorly on low-resource languages and in complex multimodal scenarios. Our results highlight the need for progress on culturally inclusive multimodal evaluation frameworks.

[Arxiv](https://arxiv.org/abs/2504.07072)