# # 高效人机协作货架拣选的多模态交互框架

发布时间：2025年04月09日

`Agent`

> A Multi-Modal Interaction Framework for Efficient Human-Robot Collaborative Shelf Picking

# 摘要

> 服务机器人在以人为中心的环境中（如仓库）日益普及，这要求实现无缝且直观的人机协作。本文提出了一种结合多模态交互、基于物理的推理和任务分配的协作式货架拣选框架，以增强人机团队合作。该框架使机器人能够识别人类的手势，理解口头提示和语音指令，并通过视觉和听觉反馈进行沟通。此外，该框架基于大语言模型（LLM），利用链式思维（CoT）和基于物理的模拟引擎，安全地从货架上提取杂乱堆放的箱子，通过关系图生成子任务、提取序列规划和决策。最后，我们通过实际货架拣选实验验证了该框架，包括1）基于手势的抽屉提取，2）协作式货架清理，3）协作式稳定性辅助。

> The growing presence of service robots in human-centric environments, such as warehouses, demands seamless and intuitive human-robot collaboration. In this paper, we propose a collaborative shelf-picking framework that combines multimodal interaction, physics-based reasoning, and task division for enhanced human-robot teamwork.
  The framework enables the robot to recognize human pointing gestures, interpret verbal cues and voice commands, and communicate through visual and auditory feedback. Moreover, it is powered by a Large Language Model (LLM) which utilizes Chain of Thought (CoT) and a physics-based simulation engine for safely retrieving cluttered stacks of boxes on shelves, relationship graph for sub-task generation, extraction sequence planning and decision making. Furthermore, we validate the framework through real-world shelf picking experiments such as 1) Gesture-Guided Box Extraction, 2) Collaborative Shelf Clearing and 3) Collaborative Stability Assistance.

[Arxiv](https://arxiv.org/abs/2504.06593)