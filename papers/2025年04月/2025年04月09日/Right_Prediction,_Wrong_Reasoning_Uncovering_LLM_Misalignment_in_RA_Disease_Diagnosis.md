# 预测正确，推理出错：揭开 LLM 在类风湿性关节炎诊断中的偏差

发布时间：2025年04月09日

`LLM应用

摘要中详细探讨了大型语言模型在医疗诊断中的实际应用，特别是在类风湿性关节炎诊断中的表现和挑战。研究不仅评估了LLMs的预测准确性，还分析了其推理过程的可靠性，属于实际应用场景的研究，因此归类为LLM应用。`

> Right Prediction, Wrong Reasoning: Uncovering LLM Misalignment in RA Disease Diagnosis

# 摘要

> 大型语言模型（LLMs）为医疗领域带来了一种革命性的预筛查工具，不仅提升了早期疾病检测的效率，还为医疗资源匮乏的社区提供了更优质的医疗服务。在医疗实践中，多种疾病的早期诊断仍然面临巨大挑战，原因在于早期症状往往缺乏特异性、专业医疗人员数量有限以及需要较长的临床评估周期，这些因素可能导致治疗延误并影响患者的最终治疗效果。凭借在多种疾病预测中展现的高准确性，LLMs有望彻底革新临床预筛查和医疗决策流程。本研究利用真实世界患者的医疗数据，深入探讨了LLMs在类风湿性关节炎（RA）诊断中的应用潜力。我们对比了LLMs与医疗专家的诊断结果，评估其在RA预测中的表现。研究过程中，我们发现了一个引人注目的诊断模式，同时也揭示了一个令人意外的现象：**预测结果与推理解释之间存在显著不一致**。通过不同LLM代理进行的多轮分析表明，表现最佳的模型在95%的情况下能够准确预测类风湿性关节炎（RA）疾病。然而，医疗专家对模型生成的推理过程进行评估后发现，其中近68%的推理存在错误。这一研究结果凸显了LLMs高预测准确性与其推理缺陷之间的明显不匹配，引发了在临床环境中依赖LLM解释的深刻思考。**LLMs在类风湿性关节炎诊断中，常常通过错误的推理得出正确的答案。**这一发现对临床实践具有重要启示意义。

> Large language models (LLMs) offer a promising pre-screening tool, improving early disease detection and providing enhanced healthcare access for underprivileged communities. The early diagnosis of various diseases continues to be a significant challenge in healthcare, primarily due to the nonspecific nature of early symptoms, the shortage of expert medical practitioners, and the need for prolonged clinical evaluations, all of which can delay treatment and adversely affect patient outcomes. With impressive accuracy in prediction across a range of diseases, LLMs have the potential to revolutionize clinical pre-screening and decision-making for various medical conditions. In this work, we study the diagnostic capability of LLMs for Rheumatoid Arthritis (RA) with real world patients data. Patient data was collected alongside diagnoses from medical experts, and the performance of LLMs was evaluated in comparison to expert diagnoses for RA disease prediction. We notice an interesting pattern in disease diagnosis and find an unexpected \textit{misalignment between prediction and explanation}. We conduct a series of multi-round analyses using different LLM agents. The best-performing model accurately predicts rheumatoid arthritis (RA) diseases approximately 95\% of the time. However, when medical experts evaluated the reasoning generated by the model, they found that nearly 68\% of the reasoning was incorrect. This study highlights a clear misalignment between LLMs high prediction accuracy and its flawed reasoning, raising important questions about relying on LLM explanations in clinical settings. \textbf{LLMs provide incorrect reasoning to arrive at the correct answer for RA disease diagnosis.}

[Arxiv](https://arxiv.org/abs/2504.06581)