# # 摘要
大型语言模型时代的检索增强生成评估：综述

发布时间：2025年04月21日

`RAG`

> Retrieval Augmented Generation Evaluation in the Era of Large Language Models: A Comprehensive Survey

# 摘要

> # 摘要
检索增强生成（RAG）的最新进展彻底改变了自然语言处理领域。通过将大型语言模型（LLMs）与外部信息检索相结合，RAG在各种应用场景中实现了准确、最新且可验证的文本生成。然而，由于RAG系统结合了检索和生成组件的混合架构，以及对动态知识来源的依赖，在LLM时代评估RAG系统面临独特挑战。

本文对RAG的评估方法和框架进行了全面综述，系统性地回顾了传统和新兴的评估方法，针对LLM时代的系统性能、事实准确性、安全性和计算效率进行了深入分析。我们整理并分类了特定于RAG的数据集和评估框架，并对高影响力RAG研究中的评估实践进行了元分析。据我们所知，这项工作是RAG评估领域最全面的综述，连接了传统方法和由LLM驱动的方法，并为推进RAG的发展提供了关键资源。


> Recent advancements in Retrieval-Augmented Generation (RAG) have revolutionized natural language processing by integrating Large Language Models (LLMs) with external information retrieval, enabling accurate, up-to-date, and verifiable text generation across diverse applications. However, evaluating RAG systems presents unique challenges due to their hybrid architecture that combines retrieval and generation components, as well as their dependence on dynamic knowledge sources in the LLM era. In response, this paper provides a comprehensive survey of RAG evaluation methods and frameworks, systematically reviewing traditional and emerging evaluation approaches, for system performance, factual accuracy, safety, and computational efficiency in the LLM era. We also compile and categorize the RAG-specific datasets and evaluation frameworks, conducting a meta-analysis of evaluation practices in high-impact RAG research. To the best of our knowledge, this work represents the most comprehensive survey for RAG evaluation, bridging traditional and LLM-driven methods, and serves as a critical resource for advancing RAG development.

[Arxiv](https://arxiv.org/abs/2504.14891)