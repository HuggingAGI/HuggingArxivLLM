# # Seed-Thinking-v1.5: 强化学习助力卓越推理模型的演进

发布时间：2025年04月21日

`LLM应用` `STEM` `编程教育`

> Seed-Thinking-v1.5: Advancing Superb Reasoning Models with Reinforcement Learning

# 摘要

> 我们很高兴推出 Seed-Thinking-v1.5，它通过思考推理后再作答，显著提升了在各类基准测试中的表现。在 AIME 2024、Codeforces 和 GPQA 上分别取得了 86.7、55.0 和 77.3 的优异成绩，充分证明了其在 STEM 和编程领域的卓越推理能力。Seed-Thinking-v1.5 不仅在推理任务中表现出色，在其他领域也展现了强大的泛化能力。例如，在非推理任务中，其胜率较 DeepSeek R1 提升了 8%，凸显了其更广泛的应用潜力。与其它先进推理模型不同，Seed-Thinking-v1.5 是一种专家混合模型（MoE），尽管总参数量达 200B，但活跃参数仅为 20B，规模相对较小。为了更好地评估通用推理能力，我们开发了 BeyondAIME 和 Codeforces 两个内部基准测试，未来将公开发布，以助力更多研究。

> We introduce Seed-Thinking-v1.5, capable of reasoning through thinking before responding, resulting in improved performance on a wide range of benchmarks. Seed-Thinking-v1.5 achieves 86.7 on AIME 2024, 55.0 on Codeforces and 77.3 on GPQA, demonstrating excellent reasoning abilities in STEM and coding. Beyond reasoning tasks, the method demonstrates notable generalization across diverse domains. For instance, it surpasses DeepSeek R1 by 8% in win rate on non-reasoning tasks, indicating its broader applicability. Compared to other state-of-the-art reasoning models, Seed-Thinking-v1.5 is a Mixture-of-Experts (MoE) model with a relatively small size, featuring 20B activated and 200B total parameters. As part of our effort to assess generalized reasoning, we develop two internal benchmarks, BeyondAIME and Codeforces, both of which will be publicly released to support future research.

[Arxiv](https://arxiv.org/abs/2504.13914)