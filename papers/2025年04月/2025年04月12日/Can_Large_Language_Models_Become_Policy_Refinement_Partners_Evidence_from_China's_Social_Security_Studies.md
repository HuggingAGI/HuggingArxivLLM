# # 摘要  
大型语言模型 (LLMs) 的最新进展推动了从机器人流程自动化 (RPA) 到智能体流程自动化 (Agentic Process Automation) 的革命性范式转变，这一转变基于 LLMs 自动化了工作流编排过程。

发布时间：2025年04月12日

`LLM应用

理由：这篇论文探讨了大型语言模型在政策建议生成中的实际应用，分析了其能力边界和性能特征，属于LLM的实际应用研究。` `政策建议` `决策支持`

> Can Large Language Models Become Policy Refinement Partners? Evidence from China's Social Security Studies

# 摘要

> 大型语言模型（LLMs）的快速发展正在重塑多学科领域的运营范式。它们在跨学科边界综合政策相关见解的能力，使其有望成为决策支持工具。然而，作为政策完善伙伴的实际表现和适用性，仍需通过严格系统的评估来验证。

本研究采用上下文嵌入生成-适应框架，对比分析了美国的GPT-4o、中国的DeepSeek-R1与人类研究人员，探讨LLMs在为中国社会保障问题生成政策建议方面的能力边界与性能特征。

研究发现，大型LLMs在系统性政策设计上优势明显，但在处理复杂社会动态、平衡利益相关者利益以及控制社会保障领域的财政风险方面存在显著局限。此外，DeepSeek-R1在政策建议生成的所有评估维度上均优于GPT-4o，凸显了本地化训练在提升上下文契合度方面的潜力。

这些发现表明，地区适应型LLMs可作为补充工具，利用特定领域社会见解生成多样化政策选择。然而，政策完善的制定仍需与人类研究人员的专业知识相结合，这对于解读制度框架、文化规范和价值体系至关重要。

> The rapid development of large language models (LLMs) is reshaping operational paradigms across multidisciplinary domains. LLMs' emergent capability to synthesize policy-relevant insights across disciplinary boundaries suggests potential as decision-support tools. However, their actual performance and suitability as policy refinement partners still require verification through rigorous and systematic evaluations. Our study employs the context-embedded generation-adaptation framework to conduct a tripartite comparison among the American GPT-4o, the Chinese DeepSeek-R1 and human researchers, investigating the capability boundaries and performance characteristics of LLMs in generating policy recommendations for China's social security issues. This study demonstrates that while large LLMs exhibit distinct advantages in systematic policy design, they face significant limitations in addressing complex social dynamics, balancing stakeholder interests, and controlling fiscal risks within the social security domain. Furthermore, DeepSeek-R1 demonstrates superior performance to GPT-4o across all evaluation dimensions in policy recommendation generation, illustrating the potential of localized training to improve contextual alignment. These findings suggest that regionally-adapted LLMs can function as supplementary tools for generating diverse policy alternatives informed by domain-specific social insights. Nevertheless, the formulation of policy refinement requires integration with human researchers' expertise, which remains critical for interpreting institutional frameworks, cultural norms, and value systems.

[Arxiv](https://arxiv.org/abs/2504.09137)