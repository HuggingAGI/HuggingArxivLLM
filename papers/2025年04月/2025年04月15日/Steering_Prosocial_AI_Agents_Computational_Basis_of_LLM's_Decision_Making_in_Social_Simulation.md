# # 引导亲社会型AI代理：揭示大型语言模型在社会模拟中决策的计算基础

发布时间：2025年04月15日

`LLM应用` `社会科学` `社会模拟`

> Steering Prosocial AI Agents: Computational Basis of LLM's Decision Making in Social Simulation

# 摘要

> 大型语言模型（LLMs）如今常被用作社会科学和实际应用中的类人决策代理。这些LLM代理通常被赋予类人性格，并置于现实情境中。然而，这些性格和情境如何影响LLM的行为仍是一个未充分研究的领域。本研究提出并测试了在“独裁者博弈”这一经典公平与亲社会行为实验中，探究、量化和调整LLM内部表征的方法。我们从LLM的内部状态中提取了“变量变化向量”（例如，“男性”到“女性”）。在模型推理过程中对这些向量进行调整，能够显著改变这些变量与模型决策之间的关系。这种方法提供了一种系统化的方式，用于研究和调控社会概念在基于变压器的模型中的编码与设计，对齐、去偏见以及为学术和商业应用设计用于社会模拟的AI代理具有重要意义。

> Large language models (LLMs) increasingly serve as human-like decision-making agents in social science and applied settings. These LLM-agents are typically assigned human-like characters and placed in real-life contexts. However, how these characters and contexts shape an LLM's behavior remains underexplored. This study proposes and tests methods for probing, quantifying, and modifying an LLM's internal representations in a Dictator Game -- a classic behavioral experiment on fairness and prosocial behavior. We extract ``vectors of variable variations'' (e.g., ``male'' to ``female'') from the LLM's internal state. Manipulating these vectors during the model's inference can substantially alter how those variables relate to the model's decision-making. This approach offers a principled way to study and regulate how social concepts can be encoded and engineered within transformer-based models, with implications for alignment, debiasing, and designing AI agents for social simulations in both academic and commercial applications.

[Arxiv](https://arxiv.org/abs/2504.11671)