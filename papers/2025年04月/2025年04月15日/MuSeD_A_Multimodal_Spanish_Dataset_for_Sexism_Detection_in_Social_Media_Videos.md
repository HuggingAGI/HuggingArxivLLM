# MuSeD：一个多模态西班牙语数据集，面向社交媒体视频中的性别歧视检测

发布时间：2025年04月15日

`LLM应用` `性别研究` `社交媒体`

> MuSeD: A Multimodal Spanish Dataset for Sexism Detection in Social Media Videos

# 摘要

> 性别歧视通常指基于性别或性别的偏见和歧视，影响社会的方方面面，从社会制度到人际关系和个人行为。社交媒体平台不仅通过文本，还通过多种模态传播歧视内容，凸显了采用多模态方法分析在线性别歧视的迫切需求。随着用户分享短视频的社交媒体平台的兴起，性别歧视正越来越多地通过视频内容传播。自动检测视频中的性别歧视是一项具有挑战性的任务，因为它需要分析语言、音频和视觉元素的结合来识别性别歧视内容。

这一研究有三大贡献：（1）我们推出了MuSeD，一个全新的多模态西班牙语性别歧视检测数据集，包含从TikTok和BitChute提取的约11小时的视频；（2）我们提出了一种创新的标注框架，用于分析文本和多模态标签在分类性别歧视和非性别歧视内容中的作用；（3）我们评估了多种大型语言模型（LLMs）和多模态LLMs在性别歧视检测任务上的性能。

研究发现，视觉信息在标注性别歧视内容时对人类和模型都起到了关键作用。模型能够有效检测显性性别歧视；然而，它们在隐性案例（如刻板印象）上表现挣扎，这些案例中注释者也显示出较低的一致性。这凸显了任务本身的难度，因为识别隐性性别歧视取决于社会和文化背景。

> Sexism is generally defined as prejudice and discrimination based on sex or gender, affecting every sector of society, from social institutions to relationships and individual behavior. Social media platforms amplify the impact of sexism by conveying discriminatory content not only through text but also across multiple modalities, highlighting the critical need for a multimodal approach to the analysis of sexism online. With the rise of social media platforms where users share short videos, sexism is increasingly spreading through video content. Automatically detecting sexism in videos is a challenging task, as it requires analyzing the combination of verbal, audio, and visual elements to identify sexist content. In this study, (1) we introduce MuSeD, a new Multimodal Spanish dataset for Sexism Detection consisting of $\approx$ 11 hours of videos extracted from TikTok and BitChute; (2) we propose an innovative annotation framework for analyzing the contribution of textual and multimodal labels in the classification of sexist and non-sexist content; and (3) we evaluate a range of large language models (LLMs) and multimodal LLMs on the task of sexism detection. We find that visual information plays a key role in labeling sexist content for both humans and models. Models effectively detect explicit sexism; however, they struggle with implicit cases, such as stereotypes, instances where annotators also show low agreement. This highlights the inherent difficulty of the task, as identifying implicit sexism depends on the social and cultural context.

[Arxiv](https://arxiv.org/abs/2504.11169)