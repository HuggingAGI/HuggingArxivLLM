# 评估一种视觉问答策略在静止图像中的零样本面部表情识别效果

发布时间：2025年04月30日

`LLM应用` `计算机视觉` `人机交互`

> An Evaluation of a Visual Question Answering Strategy for Zero-shot Facial Expression Recognition in Still Images

# 摘要

> 面部表情识别（FER）是计算机视觉与人机交互领域的重要研究方向。尽管深度学习领域不断进步，但在推广至新场景时仍面临诸多挑战。特别值得注意的是，零样本FER显著降低了现有模型的性能。为解决这一难题，研究界开始探索将大型语言模型的知识整合到视觉任务中。本研究对本地执行的视觉语言模型（VLMs）进行了广泛评估，通过视觉问答策略弥补了任务特定知识的不足。我们对比了集成与未集成VLMs的最新FER模型，并在AffectNet、FERPlus和RAF-DB等知名基准上进行了测试。结果显示，部分VLMs在零样本FER场景中表现优异，这表明进一步研究以提升FER模型的泛化能力具有重要意义。

> Facial expression recognition (FER) is a key research area in computer vision and human-computer interaction. Despite recent advances in deep learning, challenges persist, especially in generalizing to new scenarios. In fact, zero-shot FER significantly reduces the performance of state-of-the-art FER models. To address this problem, the community has recently started to explore the integration of knowledge from Large Language Models for visual tasks. In this work, we evaluate a broad collection of locally executed Visual Language Models (VLMs), avoiding the lack of task-specific knowledge by adopting a Visual Question Answering strategy. We compare the proposed pipeline with state-of-the-art FER models, both integrating and excluding VLMs, evaluating well-known FER benchmarks: AffectNet, FERPlus, and RAF-DB. The results show excellent performance for some VLMs in zero-shot FER scenarios, indicating the need for further exploration to improve FER generalization.

[Arxiv](https://arxiv.org/abs/2504.21309)