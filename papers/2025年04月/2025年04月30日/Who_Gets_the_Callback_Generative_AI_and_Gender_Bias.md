# 谁会被回电？生成式 AI 中的性别偏见

发布时间：2025年04月30日

`LLM应用` `性别偏见`

> Who Gets the Callback? Generative AI and Gender Bias

# 摘要

> 生成式人工智能（AI），尤其是大型语言模型（LLMs），正迅速应用于招聘和候选人筛选。我们利用332,044份真实在线招聘信息的数据集，对多个中型开源LLMs进行了性别偏见审计。针对每份招聘信息，我们要求模型推荐同等资质的男性或女性候选人是否应获得面试机会。研究发现，大多数模型倾向于推荐男性，尤其在薪资较高的职位中更为明显。通过将职位描述与标准职业分类系统匹配，我们发现女性在男性主导的职业中获得面试邀请的可能性较低，而在与女性相关的职业中可能性较高，这表明了职业隔离现象。进一步分析招聘广告的语言特征，发现模型推荐结果与传统性别刻板印象高度吻合。为了探讨招聘者身份的影响，我们通过注入大五人格特质并模拟历史人物的观点来引导模型行为。研究发现，更不随和的人格特质减少了刻板印象，这与LLMs中的随和性偏见一致。我们的研究结果揭示了AI驱动招聘可能如何延续劳动力市场的偏见，并对企业的公平性和多样性具有重要启示。

> Generative artificial intelligence (AI), particularly large language models (LLMs), is being rapidly deployed in recruitment and for candidate shortlisting. We audit several mid-sized open-source LLMs for gender bias using a dataset of 332,044 real-world online job postings. For each posting, we prompt the model to recommend whether an equally qualified male or female candidate should receive an interview callback. We find that most models tend to favor men, especially for higher-wage roles. Mapping job descriptions to the Standard Occupational Classification system, we find lower callback rates for women in male-dominated occupations and higher rates in female-associated ones, indicating occupational segregation. A comprehensive analysis of linguistic features in job ads reveals strong alignment of model recommendations with traditional gender stereotypes. To examine the role of recruiter identity, we steer model behavior by infusing Big Five personality traits and simulating the perspectives of historical figures. We find that less agreeable personas reduce stereotyping, consistent with an agreeableness bias in LLMs. Our findings highlight how AI-driven hiring may perpetuate biases in the labor market and have implications for fairness and diversity within firms.

[Arxiv](https://arxiv.org/abs/2504.21400)