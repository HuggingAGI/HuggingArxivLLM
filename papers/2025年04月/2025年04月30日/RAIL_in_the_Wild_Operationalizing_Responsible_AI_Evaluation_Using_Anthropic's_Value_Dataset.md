# RAIL在实际应用中的探索：基于Anthropic价值数据集的负责任AI评估实践

发布时间：2025年04月30日

`LLM应用

摘要讨论了如何评估大型语言模型（LLMs）在实际应用中的伦理行为，提出了基于RAIL框架的评估方法，并应用于具体数据集，属于LLM的应用层面。` `AI伦理` `价值观评估`

> RAIL in the Wild: Operationalizing Responsible AI Evaluation Using Anthropic's Value Dataset

# 摘要

> 随着AI系统逐渐融入实际应用，确保它们符合伦理标准变得尤为重要。现有的AI伦理框架虽然强调了公平性、透明性和问责制，但往往缺乏具体可行的评估方法。本文提出了一种基于“负责任的AI实验室”（RAIL）框架的系统性方法，该框架通过八个可衡量的维度，全面评估大型语言模型（LLMs）的行为规范性。我们运用这一框架对Anthropic的“价值观在现实中”数据集进行了深入分析，该数据集包含了308,000多条匿名对话（与Claude的互动）以及3,000多个标注的价值观表达。通过将这些价值观与RAIL维度进行映射，计算合成分数，我们揭示了LLMs在实际应用中的伦理行为模式，为理解其伦理表现提供了有价值的洞见。

> As AI systems become embedded in real-world applications, ensuring they meet ethical standards is crucial. While existing AI ethics frameworks emphasize fairness, transparency, and accountability, they often lack actionable evaluation methods. This paper introduces a systematic approach using the Responsible AI Labs (RAIL) framework, which includes eight measurable dimensions to assess the normative behavior of large language models (LLMs). We apply this framework to Anthropic's "Values in the Wild" dataset, containing over 308,000 anonymized conversations with Claude and more than 3,000 annotated value expressions. Our study maps these values to RAIL dimensions, computes synthetic scores, and provides insights into the ethical behavior of LLMs in real-world use.

[Arxiv](https://arxiv.org/abs/2505.00204)