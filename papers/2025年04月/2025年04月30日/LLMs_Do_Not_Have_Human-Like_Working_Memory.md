# 大型语言模型不具备人类式的工作记忆能力.

发布时间：2025年04月30日

`LLM理论` `人工智能` `认知科学`

> LLMs Do Not Have Human-Like Working Memory

# 摘要

> 人类的工作记忆是一个积极的认知系统，不仅能够临时存储信息，还能对其进行处理和利用。缺乏工作记忆，人们可能会说出不切实际的话语，出现自我矛盾，甚至在需要推理的任务中举步维艰。本文指出，大型语言模型 (LLMs) 缺乏这种类似人类的认知能力，这对实现人工通用智能构成了重大挑战。我们通过三个实验验证了这一观点：(1) 数字猜谜游戏，(2) 是或否游戏，以及 (3) 数学魔术。实验结果表明，当前的 LLMs 在这些场景中未能展现出类似人类的认知行为。我们希望通过揭示这一局限性，激发更多研究，推动开发具有更强大工作记忆能力的 LLMs。

> Human working memory is an active cognitive system that enables not only the temporary storage of information but also its processing and utilization. Without working memory, individuals may produce unreal conversations, exhibit self-contradiction, and struggle with tasks requiring mental reasoning. In this paper, we demonstrate that Large Language Models (LLMs) lack this human-like cognitive ability, posing a significant challenge to achieving artificial general intelligence. We validate this claim through three experiments: (1) Number Guessing Game, (2) Yes or No Game, and (3) Math Magic. Experimental results on several model families indicate that current LLMs fail to exhibit human-like cognitive behaviors in these scenarios. By highlighting this limitation, we aim to encourage further research in developing LLMs with improved working memory capabilities.

[Arxiv](https://arxiv.org/abs/2505.10571)