# 让LLMs更人性：心理测量工具、数据集与人机交互应用综述

发布时间：2025年04月30日

`LLM应用` `心理评估` `人工智能`

> Humanizing LLMs: A Survey of Psychological Measurements with Tools, Datasets, and Human-Agent Applications

# 摘要

> 随着大型语言模型 (LLMs) 在人类任务中的广泛应用，评估其心理特质对于理解社会影响和实现可信的 AI 对齐至关重要。尽管现有综述涉及部分相关研究，但仍有关键领域尚未得到系统探讨，包括多样化心理测试、特定于 LLM 的心理数据集，以及 LLM 的心理特质应用。为此，我们系统回顾了将心理理论应用于 LLMs 的六个核心维度：评估工具、LLM 特定数据集、评估指标（一致性和稳定性）、经验发现、人格模拟方法，以及基于 LLM 的行为模拟。分析显示，当前方法虽具优势，但也存在局限。某些 LLM 在特定提示方案下展现可重复人格模式，但跨任务和设置的差异显著。本研究通过识别心理工具与 LLM 能力不匹配及评估实践不一致等方法学挑战，旨在为开发更可解释、健壮和通用的 LLM 心理评估框架提出未来方向。

> As large language models (LLMs) are increasingly used in human-centered tasks, assessing their psychological traits is crucial for understanding their social impact and ensuring trustworthy AI alignment. While existing reviews have covered some aspects of related research, several important areas have not been systematically discussed, including detailed discussions of diverse psychological tests, LLM-specific psychological datasets, and the applications of LLMs with psychological traits. To address this gap, we systematically review six key dimensions of applying psychological theories to LLMs: (1) assessment tools; (2) LLM-specific datasets; (3) evaluation metrics (consistency and stability); (4) empirical findings; (5) personality simulation methods; and (6) LLM-based behavior simulation. Our analysis highlights both the strengths and limitations of current methods. While some LLMs exhibit reproducible personality patterns under specific prompting schemes, significant variability remains across tasks and settings. Recognizing methodological challenges such as mismatches between psychological tools and LLMs' capabilities, as well as inconsistencies in evaluation practices, this study aims to propose future directions for developing more interpretable, robust, and generalizable psychological assessment frameworks for LLMs.

[Arxiv](https://arxiv.org/abs/2505.00049)