# Audo-Sight：为视障人士赋能环境互动

发布时间：2025年04月30日

`LLM应用` `无障碍技术` `人工智能`

> Audo-Sight: Enabling Ambient Interaction For Blind And Visually Impaired Individuals

# 摘要

> 视障人士在与复杂环境互动和理解时面临巨大挑战，传统辅助技术往往难以快速提供必要的上下文理解和交互智能。本论文介绍了Audo-Sight，一个集成多模态大型语言模型（MLLMs）的先进辅助系统，旨在为盲人和视障人士（BVI）提供快速、上下文感知的交互体验。该系统运行于两种模式：通过用户识别实现个性化交互，以及在公共场所（如博物馆和购物中心）提供公共访问。在定制环境中，系统根据用户的个人偏好调整输出，通过用户感知的交互形式提升无障碍性。在共享环境中，Audo-Sight采用一种无需手动重新配置即可适应当前用户的共享架构。为了促进与大型语言模型的适当交互，公共版Audo-Sight解决方案包含年龄范围判别器和安全查询过滤器。此外，该系统通过NeMo护栏确保对BVI用户的回答尊重。通过利用多模态推理、BVI认知响应编辑和安全防护功能，这项研究代表了人工智能驱动的无障碍技术的重大飞跃，能够增强视障人士在社交环境中的自主性、安全性和互动性。最后，我们展示了Audo-Sight与SmartSight的整合，为视障人士提供了增强的情境感知能力。这一整合利用了SmartSight的实时视觉分析功能，结合Audo-Sight的广泛推理和交互能力，超越了简单的物体识别，能够在动态环境中提供基于上下文、语音控制的辅助支持。

> Visually impaired people face significant challenges when attempting to interact with and understand complex environments, and traditional assistive technologies often struggle to quickly provide necessary contextual understanding and interactive intelligence. This thesis presents Audo-Sight, a state-of-the-art assistive system that seamlessly integrates Multimodal Large Language Models (MLLMs) to provide expedient, context-aware interactions for Blind and Visually Impaired (BVI) individuals. The system operates in two different modalities: personalized interaction through user identification and public access in common spaces like museums and shopping malls. In tailored environments, the system adjusts its output to conform to the preferences of individual users, thus enhancing accessibility through a user-aware form of interaction. In shared environments, Audo-Sight employs a shared architecture that adapts to its current user with no manual reconfiguration required. To facilitate appropriate interactions with the LLM, the public Audo-Sight solution includes an Age-Range Determiner and Safe Query Filter. Additionally, the system ensures that responses are respectful to BVI users through NeMo Guardrails. By utilizing multimodal reasoning, BVI-cognizant response editing, and safeguarding features, this work represents a major leap in AI-driven accessibility technology capable of increasing autonomy, safety, and interaction for people with visual impairments in social settings. Finally, we present the integration of Audo-Sight and SmartSight, which enables enhanced situational awareness for BVI individuals. This integration takes advantage of the real-time visual analysis of SmartSight, combined with the extensive reasoning and interactive capabilities of Audo-Sight, and goes beyond object identification to provide context-driven, voice-controlled assistance in dynamic environments.

[Arxiv](https://arxiv.org/abs/2505.00153)