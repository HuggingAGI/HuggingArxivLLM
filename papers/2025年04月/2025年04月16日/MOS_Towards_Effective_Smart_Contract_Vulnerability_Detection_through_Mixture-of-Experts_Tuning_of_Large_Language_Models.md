# MOS：通过专家混合微调大型语言模型，实现智能合约漏洞的有效检测

发布时间：2025年04月16日

`LLM应用

理由：这篇论文探讨了如何利用大型语言模型（LLM）来改进智能合约漏洞检测。具体来说，他们提出了一种基于LLM的混合专家调优框架（MOS），用于提高检测的准确性和解释性。论文的重点在于将LLM应用于实际的安全检测任务，并展示了其在智能合约漏洞检测中的有效性。因此，这篇论文属于LLM应用类别。` `区块链` `网络安全`

> MOS: Towards Effective Smart Contract Vulnerability Detection through Mixture-of-Experts Tuning of Large Language Models

# 摘要

> 智能合约漏洞对区块链系统构成重大安全威胁，可能导致严重的财务损失。现有方法存在以下局限性：

1. 基于程序分析的方法依赖预定义模式，缺乏对新漏洞类型的灵活性；
2. 基于深度学习的方法缺乏解释性；
3. 基于大型语言模型的方法误报率较高。

我们提出了一种名为MOS的智能合约漏洞检测框架，基于大型语言模型的专家混合调优（MOE-Tuning）。框架具有以下创新点：

- 在大规模智能合约数据集上进行持续预训练，提供领域增强的初始化；
- 通过结合LLM生成和专家验证的多阶段管道，构建高质量MOE-Tuning数据集，实现可靠解释；
- 设计漏洞感知路由机制，分析代码特征及其与专家匹配程度，激活最相关专家网络；
- 将前馈层扩展为多个并行专家网络，每个网络专门处理特定漏洞模式。

我们采用双目标损失函数：
1. 优化检测和解释性能；
2. 通过计算熵值确保漏洞类型在专家间的合理分布。

实验结果表明，MOS显著优于现有方法：
- F1分数平均提升6.32%；
- 准确率平均提升4.80%；
- 漏洞解释在正确性、完整性和简洁性方面分别获得82.96%、85.21%和94.58%的正面评分（4分制，人工和LLM评估）。


> Smart contract vulnerabilities pose significant security risks to blockchain systems, potentially leading to severe financial losses. Existing methods face several limitations: (1) Program analysis-based approaches rely on predefined patterns, lacking flexibility for new vulnerability types; (2) Deep learning-based methods lack explanations; (3) Large language model-based approaches suffer from high false positives. We propose MOS, a smart contract vulnerability detection framework based on mixture-of-experts tuning (MOE-Tuning) of large language models. First, we conduct continual pre-training on a large-scale smart contract dataset to provide domain-enhanced initialization. Second, we construct a high-quality MOE-Tuning dataset through a multi-stage pipeline combining LLM generation and expert verification for reliable explanations. Third, we design a vulnerability-aware routing mechanism that activates the most relevant expert networks by analyzing code features and their matching degree with experts. Finally, we extend the feed-forward layers into multiple parallel expert networks, each specializing in specific vulnerability patterns. We employ a dual-objective loss function: one for optimizing detection and explanation performance, and another for ensuring reasonable distribution of vulnerability types to experts through entropy calculation. Experiments show that MOS significantly outperforms existing methods with average improvements of 6.32% in F1 score and 4.80% in accuracy. The vulnerability explanations achieve positive ratings (scores of 3-4 on a 4-point scale) of 82.96%, 85.21% and 94.58% for correctness, completeness, and conciseness through human and LLM evaluation.

[Arxiv](https://arxiv.org/abs/2504.12234)