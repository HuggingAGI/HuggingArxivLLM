# # 评估大型语言模型的目标导向能力

发布时间：2025年04月16日

`LLM理论` `人工智能`

> Evaluating the Goal-Directedness of Large Language Models

# 摘要

> 大型语言模型（LLMs）在实现目标时，多大程度上发挥了自身能力？我们将其定义为目标定向性的衡量标准。在需要信息收集、认知投入和计划执行的任务中，我们通过分解子任务来评估各模型的能力。对 Google DeepMind、OpenAI 和 Anthropic 的 LLMs 的评估显示，目标定向性在不同任务中表现一致，与任务完成度不同，且仅对激励提示有适度反应。值得注意的是，多数模型尚未完全具备目标定向性。我们希望这项评估能更好地追踪 LLM 的发展，并为智能体特性在 LLM 中的设计提供更明智的参考。

> To what extent do LLMs use their capabilities towards their given goal? We take this as a measure of their goal-directedness. We evaluate goal-directedness on tasks that require information gathering, cognitive effort, and plan execution, where we use subtasks to infer each model's relevant capabilities. Our evaluations of LLMs from Google DeepMind, OpenAI, and Anthropic show that goal-directedness is relatively consistent across tasks, differs from task performance, and is only moderately sensitive to motivational prompts. Notably, most models are not fully goal-directed. We hope our goal-directedness evaluations will enable better monitoring of LLM progress, and enable more deliberate design choices of agentic properties in LLMs.

[Arxiv](https://arxiv.org/abs/2504.11844)