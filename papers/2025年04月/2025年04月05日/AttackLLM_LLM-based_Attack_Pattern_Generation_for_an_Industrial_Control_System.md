# AttackLLM: 基于LLM的工业控制系统攻击模式生成方法研究

发布时间：2025年04月05日

`LLM应用` `工业控制系统`

> AttackLLM: LLM-based Attack Pattern Generation for an Industrial Control System

# 摘要

> 恶意示例对于评估机器学习算法在攻击下的鲁棒性至关重要，特别是在工业控制系统 (ICS) 中。然而，由于测试床的稀缺和专业人才的高成本，收集 ICS 环境中的正常和攻击数据颇具挑战性。现有数据集往往受限于从业者的领域专业知识，导致过程成本高昂且效率低下。缺乏全面的攻击模式数据对开发稳健的异常检测方法构成了重大问题。本文中，我们提出了一种结合数据驱动和设计驱动方法的新颖方法，利用大型语言模型 (LLMs) 生成攻击模式。我们的结果表明，LLMs 生成的攻击模式不仅在质量和数量上超越了人类专家创建的模式，还提供了一种可扩展的解决方案，无需依赖昂贵的测试床或预先存在的攻击示例。这一基于多智能体的方法为增强 ICS 环境的安全性和弹性提供了一个有前景的途径。

> Malicious examples are crucial for evaluating the robustness of machine learning algorithms under attack, particularly in Industrial Control Systems (ICS). However, collecting normal and attack data in ICS environments is challenging due to the scarcity of testbeds and the high cost of human expertise. Existing datasets are often limited by the domain expertise of practitioners, making the process costly and inefficient. The lack of comprehensive attack pattern data poses a significant problem for developing robust anomaly detection methods. In this paper, we propose a novel approach that combines data-centric and design-centric methodologies to generate attack patterns using large language models (LLMs). Our results demonstrate that the attack patterns generated by LLMs not only surpass the quality and quantity of those created by human experts but also offer a scalable solution that does not rely on expensive testbeds or pre-existing attack examples. This multi-agent based approach presents a promising avenue for enhancing the security and resilience of ICS environments.

[Arxiv](https://arxiv.org/abs/2504.04187)