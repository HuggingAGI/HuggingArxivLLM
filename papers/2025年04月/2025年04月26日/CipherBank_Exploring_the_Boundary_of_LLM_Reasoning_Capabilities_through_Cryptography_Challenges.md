# CipherBank: 探索 LLM 推理能力边界的新密码学挑战

发布时间：2025年04月26日

`LLM应用` `密码学` `人工智能`

> CipherBank: Exploring the Boundary of LLM Reasoning Capabilities through Cryptography Challenges

# 摘要

> 大型语言模型 (LLMs) 展现出了卓越的能力，尤其是在最近的推理能力突破，如 o1 和 o3，推动了 AI 的边界。尽管在数学和编程方面取得了令人瞩目的成就，但 LLMs 在需要密码学专业知识的领域中的推理能力仍未得到充分探索。本文中，我们介绍了 CipherBank，一个全面的基准测试，旨在评估 LLMs 在密码解密任务中的推理能力。CipherBank 包含 2,358 个精心设计的问题，涵盖 5 个领域和 14 个子领域中的 262 个独特的明文，重点放在需要加密的隐私敏感和现实场景中。从密码学角度来看，CipherBank 包含了 3 大类加密方法，涉及 9 种不同的算法，从古典密码到定制的密码技术。我们对 CipherBank 上的先进 LLMs 进行了评估，例如 GPT-4o、DeepSeek-V3，以及专注于推理的先进模型，如 o1 和 DeepSeek-R1。结果显示，通用聊天 LLMs 与推理 LLMs 之间存在显著差距，且当前推理模型在古典密码解密任务上的表现也不尽如人意。通过详细分析和错误调查，我们揭示了 LLMs 在密码推理方面的局限性，并指出了潜在的改进方向。这些发现强调了提升 LLM 推理能力的必要性。
    

> Large language models (LLMs) have demonstrated remarkable capabilities, especially the recent advancements in reasoning, such as o1 and o3, pushing the boundaries of AI. Despite these impressive achievements in mathematics and coding, the reasoning abilities of LLMs in domains requiring cryptographic expertise remain underexplored. In this paper, we introduce CipherBank, a comprehensive benchmark designed to evaluate the reasoning capabilities of LLMs in cryptographic decryption tasks. CipherBank comprises 2,358 meticulously crafted problems, covering 262 unique plaintexts across 5 domains and 14 subdomains, with a focus on privacy-sensitive and real-world scenarios that necessitate encryption. From a cryptographic perspective, CipherBank incorporates 3 major categories of encryption methods, spanning 9 distinct algorithms, ranging from classical ciphers to custom cryptographic techniques. We evaluate state-of-the-art LLMs on CipherBank, e.g., GPT-4o, DeepSeek-V3, and cutting-edge reasoning-focused models such as o1 and DeepSeek-R1. Our results reveal significant gaps in reasoning abilities not only between general-purpose chat LLMs and reasoning-focused LLMs but also in the performance of current reasoning-focused models when applied to classical cryptographic decryption tasks, highlighting the challenges these models face in understanding and manipulating encrypted data. Through detailed analysis and error investigations, we provide several key observations that shed light on the limitations and potential improvement areas for LLMs in cryptographic reasoning. These findings underscore the need for continuous advancements in LLM reasoning capabilities.

[Arxiv](https://arxiv.org/abs/2504.19093)