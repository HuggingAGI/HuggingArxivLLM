# LLaVul：面向源代码可解释漏洞推理的多模态大型语言模型

发布时间：2025年09月21日

`LLM应用` `基础理论`

> LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code

# 摘要

> 软件系统的复杂性不断提升，对能够揭示源代码漏洞的推理工具需求日益迫切。当前许多方法将漏洞分析当作分类任务，过度简化了现实场景中细微且依赖上下文的复杂情况；尽管现有的代码大型语言模型（LLMs）在代码理解上表现卓越，但它们对安全特定推理的关注度往往不足。为此我们提出LLaVul——一种多模态LLM，专为通过问答（QA）提供代码细粒度推理而设计。该模型通过训练将成对的代码与自然语言查询整合到统一空间，从而增强对代码漏洞的推理能力及依赖上下文的洞察。为评估模型性能我们构建了精心整理的数据集，其中包含现实世界漏洞及与之配对的安全相关问答。在问答和检测任务中，我们的模型性能超过了最先进通用及代码LLM；我们还通过定性分析解释其决策过程以阐明模型的优势与局限；通过整合代码与问答，LLaVul实现了更具可解释性且聚焦安全需求的代码理解。

> Increasing complexity in software systems places a growing demand on reasoning tools that unlock vulnerabilities manifest in source code. Many current approaches focus on vulnerability analysis as a classifying task, oversimplifying the nuanced and context-dependent real-world scenarios. Even though current code large language models (LLMs) excel in code understanding, they often pay little attention to security-specific reasoning. We propose LLaVul, a multimodal LLM tailored to provide fine-grained reasoning about code through question-answering (QA). Our model is trained to integrate paired code and natural queries into a unified space, enhancing reasoning and context-dependent insights about code vulnerability. To evaluate our model performance, we construct a curated dataset of real-world vulnerabilities paired with security-focused questions and answers. Our model outperforms state-of-the-art general-purpose and code LLMs in the QA and detection tasks. We further explain decision-making by conducting qualitative analysis to highlight capabilities and limitations. By integrating code and QA, LLaVul enables more interpretable and security-focused code understanding.

[Arxiv](https://arxiv.org/abs/2509.17337)