# 流畅却冷漠：语言模型的情感盲点

发布时间：2025年09月11日

`LLM应用` `医疗健康`

> Fluent but Unfeeling: The Emotional Blind Spots of Language Models

# 摘要

> 大型语言模型（LLMs）凭借其在自然语言理解上的多功能性，在心理健康研究领域日益受到青睐。尽管众多研究已探索LLMs的情感识别能力，但在细粒度层面评估其是否与人类情感一致仍存在关键空白。现有研究往往将情感归类为预定义的有限类别，却忽略了更细腻的情感表达。为填补这一空白，我们构建了EXPRESS基准数据集——该数据集源自Reddit社区，包含251个细粒度的自我披露情感标签。我们的综合评估框架会分析预测的情感术语，并基于成熟的情感理论将其分解为八种基本情感，从而实现细粒度比较。通过在不同提示设置下对主流LLMs进行系统测试，我们发现准确预测与人类自我披露情感一致的情感仍颇具挑战。定性分析进一步表明，尽管部分LLMs生成的情感术语符合成熟的情感理论与定义，但它们有时无法像人类自我披露那样有效捕捉上下文线索。这些发现揭示了LLMs在细粒度情感对齐上的局限性，并为未来旨在提升其上下文理解能力的研究提供了启示。

> The versatility of Large Language Models (LLMs) in natural language understanding has made them increasingly popular in mental health research. While many studies explore LLMs' capabilities in emotion recognition, a critical gap remains in evaluating whether LLMs align with human emotions at a fine-grained level. Existing research typically focuses on classifying emotions into predefined, limited categories, overlooking more nuanced expressions. To address this gap, we introduce EXPRESS, a benchmark dataset curated from Reddit communities featuring 251 fine-grained, self-disclosed emotion labels. Our comprehensive evaluation framework examines predicted emotion terms and decomposes them into eight basic emotions using established emotion theories, enabling a fine-grained comparison. Systematic testing of prevalent LLMs under various prompt settings reveals that accurately predicting emotions that align with human self-disclosed emotions remains challenging. Qualitative analysis further shows that while certain LLMs generate emotion terms consistent with established emotion theories and definitions, they sometimes fail to capture contextual cues as effectively as human self-disclosures. These findings highlight the limitations of LLMs in fine-grained emotion alignment and offer insights for future research aimed at enhancing their contextual understanding.

[Arxiv](https://arxiv.org/abs/2509.09593)