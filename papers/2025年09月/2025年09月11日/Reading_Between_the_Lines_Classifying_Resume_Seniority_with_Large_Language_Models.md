# 字里行间：借助大型语言模型分类简历资历

发布时间：2025年09月11日

`LLM应用` `基础理论`

> Reading Between the Lines: Classifying Resume Seniority with Large Language Models

# 摘要

> 从简历中准确评估候选人资历，是一项关键却颇具挑战的任务——夸大其词的经验描述与模糊不清的自我呈现屡见不鲜，更添难度。本研究探讨了大型语言模型（LLMs）——包括微调的BERT架构——在简历资历自动分类任务中的有效性。为严格评估模型性能，我们构建了混合数据集：既包含真实简历，也涵盖合成生成的“硬案例”，专门模拟夸大资历与低估资历的场景。基于此数据集，我们评估了LLMs检测资历夸大与隐性专业知识相关的细微语言线索的能力。研究结果为优化AI驱动的候选人评估系统、减少自我宣传语言带来的偏见提供了可行方向。该数据集已开放至https://bit.ly/4mcTovt，供研究社区使用。

> Accurately assessing candidate seniority from resumes is a critical yet challenging task, complicated by the prevalence of overstated experience and ambiguous self-presentation. In this study, we investigate the effectiveness of large language models (LLMs), including fine-tuned BERT architectures, for automating seniority classification in resumes. To rigorously evaluate model performance, we introduce a hybrid dataset comprising both real-world resumes and synthetically generated hard examples designed to simulate exaggerated qualifications and understated seniority. Using the dataset, we evaluate the performance of Large Language Models in detecting subtle linguistic cues associated with seniority inflation and implicit expertise. Our findings highlight promising directions for enhancing AI-driven candidate evaluation systems and mitigating bias introduced by self-promotional language. The dataset is available for the research community at https://bit.ly/4mcTovt

[Arxiv](https://arxiv.org/abs/2509.09229)