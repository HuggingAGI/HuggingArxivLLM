# 像素中的幽默：大型多模态模型网络漫画理解能力的基准测试

发布时间：2025年09月11日

`LLM应用` `媒体与娱乐`

> Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics

# 摘要

> 理解幽默是社交智能的核心要素，然而这对大型多模态模型（LMMs）而言仍是一大难题。为此，我们推出了PixelHumor——一个包含2800个带注释的多格漫画的基准数据集，专门用于评估LMMs解读多模态幽默和识别叙事顺序的能力。对最先进的LMMs进行测试后发现，它们存在显著不足：比如，顶尖模型在漫画格排序任务中的准确率仅为61%，远不及人类水平。这凸显出当前模型在整合视觉与文本线索、实现连贯叙事和幽默理解方面存在严重局限。PixelHumor提供了一个评估多模态语境与叙事推理的严谨框架，旨在推动LMMs的发展，让它们能更好地参与自然且具备社交感知的互动。

> Understanding humor is a core aspect of social intelligence, yet it remains a significant challenge for Large Multimodal Models (LMMs). We introduce PixelHumor, a benchmark dataset of 2,800 annotated multi-panel comics designed to evaluate LMMs' ability to interpret multimodal humor and recognize narrative sequences. Experiments with state-of-the-art LMMs reveal substantial gaps: for instance, top models achieve only 61% accuracy in panel sequencing, far below human performance. This underscores critical limitations in current models' integration of visual and textual cues for coherent narrative and humor understanding. By providing a rigorous framework for evaluating multimodal contextual and narrative reasoning, PixelHumor aims to drive the development of LMMs that better engage in natural, socially aware interactions.

[Arxiv](https://arxiv.org/abs/2509.12248)