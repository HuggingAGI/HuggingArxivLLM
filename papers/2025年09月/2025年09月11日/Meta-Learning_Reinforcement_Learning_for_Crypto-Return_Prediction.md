# 基于元学习强化学习的加密货币收益预测

发布时间：2025年09月11日

`强化学习` `金融科技`

> Meta-Learning Reinforcement Learning for Crypto-Return Prediction

# 摘要

> 预测加密货币收益向来困难重重：其价格波动由链上活动、新闻动态与社会情绪的快速变化共同驱动，而标记训练数据稀缺且成本高昂。为此，本文提出Meta-RL-Crypto——一种基于Transformer的统一架构，它融合元学习与强化学习（RL），构建出可完全自我进化的交易智能体。该智能体以基础指令微调大型语言模型（LLM）为起点，在闭环架构中迭代切换执行者、评判者与元评判者三种角色。整个学习过程无需人工干预，还能利用多模态市场输入与内部偏好反馈，持续优化交易策略与评估标准。在不同市场状态下的实验表明，Meta-RL-Crypto在真实市场技术指标上表现优异，且性能超过其他基于LLM的基准模型。

> Predicting cryptocurrency returns is notoriously difficult: price movements are driven by a fast-shifting blend of on-chain activity, news flow, and social sentiment, while labeled training data are scarce and expensive. In this paper, we present Meta-RL-Crypto, a unified transformer-based architecture that unifies meta-learning and reinforcement learning (RL) to create a fully self-improving trading agent. Starting from a vanilla instruction-tuned LLM, the agent iteratively alternates between three roles-actor, judge, and meta-judge-in a closed-loop architecture. This learning process requires no additional human supervision. It can leverage multimodal market inputs and internal preference feedback. The agent in the system continuously refines both the trading policy and evaluation criteria. Experiments across diverse market regimes demonstrate that Meta-RL-Crypto shows good performance on the technical indicators of the real market and outperforming other LLM-based baselines.

[Arxiv](https://arxiv.org/abs/2509.09751)