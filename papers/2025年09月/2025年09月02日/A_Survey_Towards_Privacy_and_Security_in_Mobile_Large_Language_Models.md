# 综述：移动大型语言模型的隐私与安全研究

发布时间：2025年09月02日

`LLM应用` `基础理论`

> A Survey: Towards Privacy and Security in Mobile Large Language Models

# 摘要

> 移动大型语言模型（LLMs）凭借能随时随地执行高级自然语言处理任务的特性，正给医疗、金融、教育等众多领域带来革命性变革。但在移动和边缘环境部署这类模型时，因其资源密集的特性及处理数据的敏感性，隐私与安全方面的挑战尤为突出。本综述围绕移动LLMs的隐私安全问题展开全面梳理，系统归纳了差分隐私、联邦学习、提示加密等现有解决方案。此外，本文还剖析了移动LLMs的特有漏洞，如对抗性攻击、成员推理、侧信道攻击等，并深入对比了这些漏洞的影响与应对局限。尽管近年来成果斐然，移动LLMs在资源受限环境下仍面临一个棘手问题：如何在保障高安全性的同时兼顾运行效率。为此，本文提出潜在应用场景，探讨当前未解难题，并指明未来研究方向，旨在为构建可信、合规、可扩展的移动LLM系统奠定基础。

> Mobile Large Language Models (LLMs) are revolutionizing diverse fields such as healthcare, finance, and education with their ability to perform advanced natural language processing tasks on-the-go. However, the deployment of these models in mobile and edge environments introduces significant challenges related to privacy and security due to their resource-intensive nature and the sensitivity of the data they process. This survey provides a comprehensive overview of privacy and security issues associated with mobile LLMs, systematically categorizing existing solutions such as differential privacy, federated learning, and prompt encryption. Furthermore, we analyze vulnerabilities unique to mobile LLMs, including adversarial attacks, membership inference, and side-channel attacks, offering an in-depth comparison of their effectiveness and limitations. Despite recent advancements, mobile LLMs face unique hurdles in achieving robust security while maintaining efficiency in resource-constrained environments. To bridge this gap, we propose potential applications, discuss open challenges, and suggest future research directions, paving the way for the development of trustworthy, privacy-compliant, and scalable mobile LLM systems.

[Arxiv](https://arxiv.org/abs/2509.02411)