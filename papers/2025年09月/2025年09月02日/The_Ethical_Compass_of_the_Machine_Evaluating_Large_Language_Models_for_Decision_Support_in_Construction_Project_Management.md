# # 机器的道德指南针：大型语言模型在建设项目管理决策支持中的评估

发布时间：2025年09月02日

`LLM应用` `工业与制造`

> The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management

# 摘要

> 人工智能（AI）与建筑项目管理（CPM）的融合正加速推进，大型语言模型（LLMs）逐渐成为易用的决策支持工具。本研究旨在深入评估LLMs在CPM这类伦理敏感、高风险决策场景中的伦理可行性与可靠性。研究采用混合方法设计：一方面，通过新的伦理决策支持评估清单（EDSAC），对两款主流LLM在12个真实伦理场景中的表现开展定量测试；另一方面，对12位行业专家进行半结构化访谈，通过定性分析了解专业人士的看法。结果显示，LLMs在法律合规等结构化领域表现尚可，但在处理语境细节、落实问责机制及提供透明推理过程方面存在明显短板。利益相关者对AI自主进行伦理判断普遍持保留态度，强烈建议实施严格的“人在回路”监督机制。据悉，本研究是首批通过实证检验建筑领域LLMs伦理推理能力的研究之一，不仅提出了可复用的EDSAC框架，还给出了切实可行的建议，强调当前LLMs更适合作为决策辅助工具，而非独立的伦理决策主体。

> The integration of Artificial Intelligence (AI) into construction project management (CPM) is accelerating, with Large Language Models (LLMs) emerging as accessible decision-support tools. This study aims to critically evaluate the ethical viability and reliability of LLMs when applied to the ethically sensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods research design was employed, involving the quantitative performance testing of two leading LLMs against twelve real-world ethical scenarios using a novel Ethical Decision Support Assessment Checklist (EDSAC), and qualitative analysis of semi-structured interviews with 12 industry experts to capture professional perceptions. The findings reveal that while LLMs demonstrate adequate performance in structured domains such as legal compliance, they exhibit significant deficiencies in handling contextual nuance, ensuring accountability, and providing transparent reasoning. Stakeholders expressed considerable reservations regarding the autonomous use of AI for ethical judgments, strongly advocating for robust human-in-the-loop oversight. To our knowledge, this is one of the first studies to empirically test the ethical reasoning of LLMs within the construction domain. It introduces the EDSAC framework as a replicable methodology and provides actionable recommendations, emphasising that LLMs are currently best positioned as decision-support aids rather than autonomous ethical agents.

[Arxiv](https://arxiv.org/abs/2509.04505)