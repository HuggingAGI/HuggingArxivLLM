# # 大型语言模型（LLMs）智能体强化学习全景：综述

发布时间：2025年09月02日

`Agent` `基础理论`

> The Landscape of Agentic Reinforcement Learning for LLMs: A Survey

# 摘要

> 智能体强化学习（Agentic RL）的兴起，标志着传统强化学习在大型语言模型（LLM RL）应用上的范式转变——LLM不再是被动的序列生成器，而是演变为嵌入复杂动态环境中的自主决策智能体。本综述通过对比LLM-RL的退化单步马尔可夫决策过程（MDPs）与Agentic RL所基于的时间扩展、部分可观测马尔可夫决策过程（POMDPs），正式确立了这一概念转变。在此基础上，我们提出了一个全面的双重分类体系：一类聚焦智能体的核心能力，涵盖规划、工具使用、记忆、推理、自我提升与感知；另一类则围绕这些能力在不同任务领域的应用展开。本文的核心观点是，强化学习是将这些能力从静态启发式模块转化为自适应、稳健智能体行为的核心机制。为助力并加速未来研究，我们整合了开源环境、基准与框架的全景，形成一份实用纲要。通过综述五百多篇最新研究，本文勾勒出这一快速演进领域的全貌，同时点明了塑造可扩展、通用人工智能智能体发展的机遇与挑战。

> The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm shift from conventional reinforcement learning applied to large language models (LLM RL), reframing LLMs from passive sequence generators into autonomous, decision-making agents embedded in complex, dynamic worlds. This survey formalizes this conceptual shift by contrasting the degenerate single-step Markov Decision Processes (MDPs) of LLM-RL with the temporally extended, partially observable Markov decision processes (POMDPs) that define Agentic RL. Building on this foundation, we propose a comprehensive twofold taxonomy: one organized around core agentic capabilities, including planning, tool use, memory, reasoning, self-improvement, and perception, and the other around their applications across diverse task domains. Central to our thesis is that reinforcement learning serves as the critical mechanism for transforming these capabilities from static, heuristic modules into adaptive, robust agentic behavior. To support and accelerate future research, we consolidate the landscape of open-source environments, benchmarks, and frameworks into a practical compendium. By synthesizing over five hundred recent works, this survey charts the contours of this rapidly evolving field and highlights the opportunities and challenges that will shape the development of scalable, general-purpose AI agents.

[Arxiv](https://arxiv.org/abs/2509.02547)