# FActBench：医学领域大型语言模型生成文本细粒度自动评估基准

发布时间：2025年09月02日

`LLM应用` `医疗健康`

> FActBench: A Benchmark for Fine-grained Automatic Evaluation of LLM-Generated Text in the Medical Domain

# 摘要

> 大型语言模型在专业领域常常力不从心。尽管评估的各个方面都不容忽视，但事实性是重中之重。同样，可靠的事实核查工具和数据源是缓解幻觉的关键。为解决这些问题，我们构建了医学领域的全面事实核查基准FActBench，涵盖四个生成任务和六个最先进的大型语言模型（LLMs）。我们采用两种前沿事实核查技术：思维链（CoT）提示与自然语言推理（NLI）。实验结果显示，两种技术通过一致投票得出的事实核查分数与领域专家评估的相关性最高。

> Large Language Models tend to struggle when dealing with specialized domains. While all aspects of evaluation hold importance, factuality is the most critical one. Similarly, reliable fact-checking tools and data sources are essential for hallucination mitigation. We address these issues by providing a comprehensive Fact-checking Benchmark FActBench covering four generation tasks and six state-of-the-art Large Language Models (LLMs) for the Medical domain. We use two state-of-the-art Fact-checking techniques: Chain-of-Thought (CoT) Prompting and Natural Language Inference (NLI). Our experiments show that the fact-checking scores acquired through the Unanimous Voting of both techniques correlate best with Domain Expert Evaluation.

[Arxiv](https://arxiv.org/abs/2509.02198)