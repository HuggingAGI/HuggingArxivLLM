# 基于多层大型语言模型框架的疾病预测集成分类方法

发布时间：2025年09月02日

`LLM应用` `医疗健康`

> An Ensemble Classification Approach in A Multi-Layered Large Language Model Framework for Disease Prediction

# 摘要

> 社交远程医疗让患者能够发布症状并远程参与医疗咨询，从而在医疗保健领域取得了显著进展。用户常在社交媒体和在线健康平台分享症状，形成了海量可用于疾病分类的医疗数据。LLAMA3、GPT-3.5等大型语言模型（LLMs）以及BERT等基于Transformer的模型，在处理复杂医疗文本上展现出强大能力。本研究在应用微调的阿拉伯语Transformer模型（CAMeLBERT、AraBERT和AsafayaBERT）之前，先评估了摘要、优化和命名实体识别（NER）这三种阿拉伯语医疗文本预处理方法。为提升稳健性，我们采用多数投票集成方法，融合原始文本与预处理文本表示的预测结果。该方法的最佳分类准确率达80.56%，证明了其通过利用多种文本表示和模型预测来提升医疗文本理解的有效性。据我们所知，这是首次将基于LLM的预处理、微调的阿拉伯语Transformer模型与集成学习相结合，应用于阿拉伯语社交远程医疗数据的疾病分类研究。

> Social telehealth has made remarkable progress in healthcare by allowing patients to post symptoms and participate in medical consultations remotely. Users frequently post symptoms on social media and online health platforms, creating a huge repository of medical data that can be leveraged for disease classification. Large language models (LLMs) such as LLAMA3 and GPT-3.5, along with transformer-based models like BERT, have demonstrated strong capabilities in processing complex medical text. In this study, we evaluate three Arabic medical text preprocessing methods such as summarization, refinement, and Named Entity Recognition (NER) before applying fine-tuned Arabic transformer models (CAMeLBERT, AraBERT, and AsafayaBERT). To enhance robustness, we adopt a majority voting ensemble that combines predictions from original and preprocessed text representations. This approach achieved the best classification accuracy of 80.56%, thus showing its effectiveness in leveraging various text representations and model predictions to improve the understanding of medical texts. To the best of our knowledge, this is the first work that integrates LLM-based preprocessing with fine-tuned Arabic transformer models and ensemble learning for disease classification in Arabic social telehealth data.

[Arxiv](https://arxiv.org/abs/2509.02446)