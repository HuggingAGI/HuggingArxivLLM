# 理性检验！大型语言模型的理性基准评估

发布时间：2025年09月17日

`LLM理论` `基础理论`

> Rationality Check! Benchmarking the Rationality of Large Language Models

# 摘要

> 大型语言模型（LLMs）作为深度学习与机器智能领域的最新突破，展现出令人惊叹的能力，如今已成为实现通用人工智能最具潜力的方向之一。凭借类人智能，LLMs不仅能模拟人类行为，还在各类应用中胜任AI助手的角色。这引发了人们的高度关注：LLMs是否会、又在何种情境下能像真正的人类智能体那样思考与行动？理性是评估人类行为的核心概念，涵盖思考（即理论理性）与行动（即实践理性）两大层面。为此，本研究首次提出评估LLMs综合理性的基准，覆盖多领域与多种LLMs。该基准包含易用工具包、丰富实验数据及深度分析，揭示LLMs与理想化人类理性的异同之处。我们相信，这一基准将成为LLMs开发者与用户的重要基础工具。

> Large language models (LLMs), a recent advance in deep learning and machine intelligence, have manifested astonishing capacities, now considered among the most promising for artificial general intelligence. With human-like capabilities, LLMs have been used to simulate humans and serve as AI assistants across many applications. As a result, great concern has arisen about whether and under what circumstances LLMs think and behave like real human agents. Rationality is among the most important concepts in assessing human behavior, both in thinking (i.e., theoretical rationality) and in taking action (i.e., practical rationality). In this work, we propose the first benchmark for evaluating the omnibus rationality of LLMs, covering a wide range of domains and LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental results, and analysis that illuminates where LLMs converge and diverge from idealized human rationality. We believe the benchmark can serve as a foundational tool for both developers and users of LLMs.

[Arxiv](https://arxiv.org/abs/2509.14546)