# MIRA：基于MLLM的指令推荐赋能智能手机一键式AI服务

发布时间：2025年09月17日

`LLM应用` `媒体与娱乐`

> MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation

# 摘要

> 生成式AI技术的飞速发展正推动各类AI服务融入智能手机，彻底改变了用户与设备的交互方式。为简化预定义AI服务的使用流程，本文提出了MIRA——一个开创性的任务指令推荐框架，让用户能在智能手机上直观地一键调用AI任务。通过MIRA，用户长按图像或文本对象，即可获得与上下文相关的AI任务指令推荐。我们的研究创新点主要有三：1）基于多模态大型语言模型（MLLM）的推荐 pipeline，通过结构化推理提取关键实体、推断用户意图并生成精准指令；2）模板增强推理机制：整合高级推理模板，提升任务推理精度；3）基于前缀树的约束解码策略：将输出限定为预定义指令候选，确保建议连贯且与用户意图一致。通过真实世界标注数据集和用户研究验证，MIRA的指令推荐准确率显著提升。这些振奋人心的结果表明，MIRA有望彻底革新用户在智能手机上使用AI服务的方式，带来更流畅、高效的体验。

> The rapid advancement of generative AI technologies is driving the integration of diverse AI-powered services into smartphones, transforming how users interact with their devices. To simplify access to predefined AI services, this paper introduces MIRA, a pioneering framework for task instruction recommendation that enables intuitive one-touch AI tasking on smartphones. With MIRA, users can long-press on images or text objects to receive contextually relevant instruction recommendations for executing AI tasks. Our work introduces three key innovations: 1) A multimodal large language model (MLLM)-based recommendation pipeline with structured reasoning to extract key entities, infer user intent, and generate precise instructions; 2) A template-augmented reasoning mechanism that integrates high-level reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based constrained decoding strategy that restricts outputs to predefined instruction candidates, ensuring coherent and intent-aligned suggestions. Through evaluation using a real-world annotated datasets and a user study, MIRA has demonstrated substantial improvements in the accuracy of instruction recommendation. The encouraging results highlight MIRA's potential to revolutionize the way users engage with AI services on their smartphones, offering a more seamless and efficient experience.

[Arxiv](https://arxiv.org/abs/2509.13773)