# AgentArch：评估企业智能体架构的全面基准

发布时间：2025年09月12日

`Agent` `基础理论`

> AgentArch: A Comprehensive Benchmark to Evaluate Agent Architectures in Enterprise

# 摘要

> 尽管智能体架构的各个组件已得到单独研究，但对于不同设计维度在复杂多智能体系统中的相互作用，实证理解仍较为有限。本研究旨在填补这些空白，为此提供了一个全面的企业特定基准，在最先进的大型语言模型中评估18种不同的智能体配置。我们研究了四个关键的智能体系统维度：编排策略、智能体提示实现方式（ReAct与函数调用）、记忆架构和思考工具集成。我们的基准揭示了显著的模型特定架构偏好，这对智能体AI系统中普遍存在的“一刀切”范式提出了挑战。该基准还揭示了智能体在企业任务上整体性能的显著不足：得分最高的模型在较复杂任务上的成功率仅为35.3%，在较简单任务上为70.8%。我们希望这些发现能为未来智能体系统的设计提供参考，促成更多基于实证的架构组件和模型选择决策。

> While individual components of agentic architectures have been studied in isolation, there remains limited empirical understanding of how different design dimensions interact within complex multi-agent systems. This study aims to address these gaps by providing a comprehensive enterprise-specific benchmark evaluating 18 distinct agentic configurations across state-of-the-art large language models. We examine four critical agentic system dimensions: orchestration strategy, agent prompt implementation (ReAct versus function calling), memory architecture, and thinking tool integration. Our benchmark reveals significant model-specific architectural preferences that challenge the prevalent one-size-fits-all paradigm in agentic AI systems. It also reveals significant weaknesses in overall agentic performance on enterprise tasks with the highest scoring models achieving a maximum of only 35.3\% success on the more complex task and 70.8\% on the simpler task. We hope these findings inform the design of future agentic systems by enabling more empirically backed decisions regarding architectural components and model selection.

[Arxiv](https://arxiv.org/abs/2509.10769)