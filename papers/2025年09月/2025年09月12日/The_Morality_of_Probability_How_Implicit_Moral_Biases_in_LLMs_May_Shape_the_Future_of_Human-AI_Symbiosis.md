# 概率的道德：大型语言模型的隐性道德偏见如何塑造人机共生的未来

发布时间：2025年09月12日

`LLM理论` `基础理论`

> The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis

# 摘要

> 人工智能（AI）的飞速发展，引发了如何让机器决策与人类道德价值观相契合这一紧迫议题。本工作论文探究了领先AI系统对道德结果的优先排序方式，及其所揭示的人机共生可能性。我们聚焦两个核心问题：（1）最先进的大型语言模型（LLMs）在面对道德困境时，会隐含地倾向于哪些道德价值观？（2）模型架构、文化起源及可解释性的差异，会如何影响这些道德偏好？为探究这些问题，我们对六个LLM开展定量实验，在18个分别代表五种道德框架的困境中，对结果进行排序与评分。研究结果显示，所有模型都存在显著一致的价值偏向：关怀与美德价值观的结果始终被评为最具道德性，而自由意志主义选择则持续受到负面评价。具备推理能力的模型对语境更为敏感，能提供更丰富的解释；而非推理模型的判断则更统一，但也更不透明。本研究贡献有三：（i）实证层面，首次对文化背景各异的LLM的道德推理进行了大规模比较；（ii）理论层面，将概率模型行为与潜在的价值编码建立了关联；（iii）实践层面，强调可解释性与文化意识作为关键设计原则，以引导AI迈向透明、契合且共生的未来。

> Artificial intelligence (AI) is advancing at a pace that raises urgent questions about how to align machine decision-making with human moral values. This working paper investigates how leading AI systems prioritize moral outcomes and what this reveals about the prospects for human-AI symbiosis. We address two central questions: (1) What moral values do state-of-the-art large language models (LLMs) implicitly favour when confronted with dilemmas? (2) How do differences in model architecture, cultural origin, and explainability affect these moral preferences? To explore these questions, we conduct a quantitative experiment with six LLMs, ranking and scoring outcomes across 18 dilemmas representing five moral frameworks. Our findings uncover strikingly consistent value biases. Across all models, Care and Virtue values outcomes were rated most moral, while libertarian choices were consistently penalized. Reasoning-enabled models exhibited greater sensitivity to context and provided richer explanations, whereas non-reasoning models produced more uniform but opaque judgments. This research makes three contributions: (i) Empirically, it delivers a large-scale comparison of moral reasoning across culturally distinct LLMs; (ii) Theoretically, it links probabilistic model behaviour with underlying value encodings; (iii) Practically, it highlights the need for explainability and cultural awareness as critical design principles to guide AI toward a transparent, aligned, and symbiotic future.

[Arxiv](https://arxiv.org/abs/2509.10297)