# 传统心理测量学与生态效度问卷之辩：对大型语言模型中心理评估的再思考

发布时间：2025年09月12日

`其他` `基础理论`

> Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models

# 摘要

> 研究人员借助BFI、PVQ等成熟心理测量问卷，旨在捕捉大型语言模型（LLMs）回答中折射出的人格特质与价值观。然而，将这类人类设计的问卷直接套用于LLMs的做法引发了争议。争议点之一在于其生态效度不足：这些问卷题目能否充分反映LLMs在响应用户查询时生成文本的真实场景，仍有待商榷。但现有问卷与具备生态效度的问卷在结果上有何差异，这些差异又能带来何种启示，目前仍不明确。为此，本文对这两类问卷展开了全面的对比分析。分析结果显示，现有问卷存在四大问题：（1）得出的LLMs画像与生态效度问卷结果差异显著，且偏离了用户查询情境中LLMs展现的心理特征；（2）测量题目数量不足，难以实现稳定测量；（3）易让人误以为LLMs具备稳定的心理结构；（4）对人格提示型LLMs的画像存在夸大倾向。综上，本研究警示：不宜将现有心理问卷直接用于LLMs研究。相关代码将在论文发表后公开。

> Researchers have applied established psychometric questionnaires (e.g., BFI, PVQ) to measure the personality traits and values reflected in the responses of Large Language Models (LLMs). However, concerns have been raised about applying these human-designed questionnaires to LLMs. One such concern is their lack of ecological validity--the extent to which survey questions adequately reflect and resemble real-world contexts in which LLMs generate texts in response to user queries. However, it remains unclear how established questionnaires and ecologically valid questionnaires differ in their outcomes, and what insights these differences may provide. In this paper, we conduct a comprehensive comparative analysis of the two types of questionnaires. Our analysis reveals that established questionnaires (1) yield substantially different profiles of LLMs from ecologically valid ones, deviating from the psychological characteristics expressed in the context of user queries, (2) suffer from insufficient items for stable measurement, (3) create misleading impressions that LLMs possess stable constructs, and (4) yield exaggerated profiles for persona-prompted LLMs. Overall, our work cautions against the use of established psychological questionnaires for LLMs. Our code will be released upon publication.

[Arxiv](https://arxiv.org/abs/2509.10078)