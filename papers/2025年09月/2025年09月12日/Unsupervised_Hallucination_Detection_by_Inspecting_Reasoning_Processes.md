# 无监督幻觉检测：基于推理过程的审视

发布时间：2025年09月12日

`LLM应用` `基础理论`

> Unsupervised Hallucination Detection by Inspecting Reasoning Processes

# 摘要

> 无监督幻觉检测旨在识别大型语言模型（LLMs）生成的幻觉内容，且无需依赖标记数据。尽管无监督方法因省去了劳动密集型的人工标注而日益流行，但它们却常依赖与事实正确性无关的代理信号。这种错位导致检测探针偏向表面特征或非真实性相关方面，从而限制了其在不同数据集和场景中的泛化能力。为克服这些局限，我们提出无监督幻觉检测框架IRIS，借助与事实正确性内在关联的内部表征。IRIS引导LLM仔细验证给定陈述的真实性，并将其上下文嵌入作为训练的信息特征。同时，将每个响应的不确定性用作真实性的软伪标签。实验结果表明，IRIS始终优于现有的无监督方法。我们的方法完全无监督、计算成本低廉，即便训练数据有限也表现优异，因此适用于实时检测。

> Unsupervised hallucination detection aims to identify hallucinated content generated by large language models (LLMs) without relying on labeled data. While unsupervised methods have gained popularity by eliminating labor-intensive human annotations, they frequently rely on proxy signals unrelated to factual correctness. This misalignment biases detection probes toward superficial or non-truth-related aspects, limiting generalizability across datasets and scenarios. To overcome these limitations, we propose IRIS, an unsupervised hallucination detection framework, leveraging internal representations intrinsic to factual correctness. IRIS prompts the LLM to carefully verify the truthfulness of a given statement, and obtain its contextualized embedding as informative features for training. Meanwhile, the uncertainty of each response is considered a soft pseudolabel for truthfulness. Experimental results demonstrate that IRIS consistently outperforms existing unsupervised methods. Our approach is fully unsupervised, computationally low cost, and works well even with few training data, making it suitable for real-time detection.

[Arxiv](https://arxiv.org/abs/2509.10004)