# ZLATTE：几何感知、无需学习的框架——人机交互中语言驱动的轨迹重塑

发布时间：2025年09月07日

`LLM应用` `工业与制造`

> ZLATTE: A Geometry-Aware, Learning-Free Framework for Language-Driven Trajectory Reshaping in Human-Robot Interaction

# 摘要

> 我们提出ZLATTE——一个用于人机交互中语言驱动轨迹重塑的几何感知、无学习框架。与以往基于学习的方法不同，ZLATTE借助视觉语言模型将物体注册为几何基元，并利用大语言模型把自然语言指令转化为明确的几何和运动学约束。这些约束被整合到势场优化中，在保持轨迹可行性和安全性的同时调整初始轨迹。多智能体策略进一步提升了复杂或冲突命令下的鲁棒性。仿真与真实世界实验表明，相比最先进的基线方法，ZLATTE能实现更平滑、更安全且更具可解释性的轨迹修改。

> We present ZLATTE, a geometry-aware, learning-free framework for language-driven trajectory reshaping in human-robot interaction. Unlike prior learning-based methods, ZLATTE leverages Vision-Language Models to register objects as geometric primitives and employs a Large Language Model to translate natural language instructions into explicit geometric and kinematic constraints. These constraints are integrated into a potential field optimization to adapt initial trajectories while preserving feasibility and safety. A multi-agent strategy further enhances robustness under complex or conflicting commands. Simulation and real-world experiments demonstrate that ZLATTE achieves smoother, safer, and more interpretable trajectory modifications compared to state-of-the-art baselines.

[Arxiv](https://arxiv.org/abs/2509.06031)