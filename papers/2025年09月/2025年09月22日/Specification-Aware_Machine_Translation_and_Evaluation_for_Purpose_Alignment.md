# 规范感知的机器翻译及目的对齐评估

发布时间：2025年09月22日

`LLM应用` `金融科技`

> Specification-Aware Machine Translation and Evaluation for Purpose Alignment

# 摘要

> 在专业场景下，翻译工作以沟通目标和客户需求为导向，而这些目标与需求往往会被正式化为具体规范。尽管现有评估框架认可此类规范的重要性，但在机器翻译（MT）研究中，这些规范却常常只被隐含处理。借鉴翻译研究成果，我们不仅阐释了规范在专业翻译中至关重要的理论依据，还提供了实施规范感知型机器翻译与评估的实用指南。基于这一基础，我们将该框架应用于33家上市公司投资者关系文本的翻译实践中。在实验中，我们对比了五种翻译类型，包括官方人工翻译和大型语言模型（LLMs）的提示型输出，并采用专家错误分析、用户偏好排序及自动指标进行评估。结果显示，在人工评估中，遵循规范的大型语言模型翻译表现持续优于官方人工翻译，这凸显了感知质量与预期质量之间的差距。这些发现表明，将规范整合到机器翻译工作流中并辅以人工监督，能够显著提升翻译质量，且与专业实践要求高度契合。

> In professional settings, translation is guided by communicative goals and client needs, often formalized as specifications. While existing evaluation frameworks acknowledge the importance of such specifications, these specifications are often treated only implicitly in machine translation (MT) research. Drawing on translation studies, we provide a theoretical rationale for why specifications matter in professional translation, as well as a practical guide to implementing specification-aware MT and evaluation. Building on this foundation, we apply our framework to the translation of investor relations texts from 33 publicly listed companies. In our experiment, we compare five translation types, including official human translations and prompt-based outputs from large language models (LLMs), using expert error analysis, user preference rankings, and an automatic metric. The results show that LLM translations guided by specifications consistently outperformed official human translations in human evaluations, highlighting a gap between perceived and expected quality. These findings demonstrate that integrating specifications into MT workflows, with human oversight, can improve translation quality in ways aligned with professional practice.

[Arxiv](https://arxiv.org/abs/2509.17559)