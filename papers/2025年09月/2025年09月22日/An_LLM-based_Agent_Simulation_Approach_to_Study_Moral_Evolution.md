# 基于大型语言模型（LLM）的智能体模拟：道德演化研究方法

发布时间：2025年09月22日

`Agent` `基础理论`

> An LLM-based Agent Simulation Approach to Study Moral Evolution

# 摘要

> 道德进化始终是个谜题：自然选择本应青睐自利，人类却演化出倡导利他的道德体系。为解开这一谜题，我们构建了全新的基于大型语言模型（LLM）的智能体模拟框架，专门模拟史前狩猎采集社会。该平台旨在探索社会进化的多元问题，涵盖生存优势与群体互动等领域。为研究道德进化，我们依据扩展圈理论\citep{singer1981expanding}设计了不同道德倾向的智能体，通过系列模拟评估其进化成效，并在定制的道德困境中分析决策过程。实验结果表明，智能体的道德框架与其认知约束共同作用，直接塑造行为并决定进化结局。尤为重要的是，模拟中涌现的模式与社会科学相关领域的开创性理论高度吻合，为模拟提供了外部验证。这项研究确立了基于LLM的模拟作为强大新范式，可补充进化生物学与人类学的传统研究，为探索道德及社会进化的复杂机制开辟了新路径。

> The evolution of morality presents a puzzle: natural selection should favor self-interest, yet humans developed moral systems promoting altruism. We address this question by introducing a novel Large Language Model (LLM)-based agent simulation framework modeling prehistoric hunter-gatherer societies. This platform is designed to probe diverse questions in social evolution, from survival advantages to inter-group dynamics. To investigate moral evolution, we designed agents with varying moral dispositions based on the Expanding Circle Theory \citep{singer1981expanding}. We evaluated their evolutionary success across a series of simulations and analyzed their decision-making in specially designed moral dilemmas. These experiments reveal how an agent's moral framework, in combination with its cognitive constraints, directly shapes its behavior and determines its evolutionary outcome. Crucially, the emergent patterns echo seminal theories from related domains of social science, providing external validation for the simulations. This work establishes LLM-based simulation as a powerful new paradigm to complement traditional research in evolutionary biology and anthropology, opening new avenues for investigating the complexities of moral and social evolution.

[Arxiv](https://arxiv.org/abs/2509.17703)