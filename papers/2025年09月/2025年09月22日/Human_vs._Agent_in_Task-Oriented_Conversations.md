# 任务型对话中的人类与智能体

发布时间：2025年09月22日

`Agent` `基础理论`

> Human vs. Agent in Task-Oriented Conversations

# 摘要

> 面向任务的对话系统能高效满足多样化用户需求，但其开发离不开海量高质量对话数据，而获取这类数据不仅难度大，成本也很高。尽管大型语言模型（LLMs）已展现出生成合成对话的潜力，但这类智能体生成的交互能否有效替代真实人类对话，其程度尚不明确。本研究首次针对个性化面向任务对话，对LLM模拟用户与人类用户展开了系统性对比。我们构建了一个全面的分析框架，涵盖对话策略、交互风格、对话评估三个关键方面及十个维度，用于评估用户行为；同时在相同条件下，从四个代表性场景中采集了人类用户与LLM智能体用户的平行对话数据集。分析结果显示，两类用户在问题解决方式、提问广度、用户参与度、上下文依赖性、反馈极性与承诺、语言风格及幻觉感知等方面，行为差异显著。不过，在深度优先/广度优先维度及有用性维度上，智能体用户与人类用户的表现则具有一致性。这些发现为改进基于LLM的用户模拟提供了重要启示。我们构建的多维度分类体系，形成了一个可推广的用户行为模式分析框架，同时也为理解LLM智能体用户与人类用户提供了洞见。这项研究也为未来对话系统中用户模拟的应用方式提供了新的思考视角。

> Task-oriented conversational systems are essential for efficiently addressing diverse user needs, yet their development requires substantial amounts of high-quality conversational data that is challenging and costly to obtain. While large language models (LLMs) have demonstrated potential in generating synthetic conversations, the extent to which these agent-generated interactions can effectively substitute real human conversations remains unclear. This work presents the first systematic comparison between LLM-simulated users and human users in personalized task-oriented conversations. We propose a comprehensive analytical framework encompassing three key aspects (conversation strategy, interaction style, and conversation evaluation) and ten distinct dimensions for evaluating user behaviors, and collect parallel conversational datasets from both human users and LLM agent users across four representative scenarios under identical conditions. Our analysis reveals significant behavioral differences between the two user types in problem-solving approaches, question broadness, user engagement, context dependency, feedback polarity and promise, language style, and hallucination awareness. We found consistency in the agent users and human users across the depth-first or breadth-first dimensions, as well as the usefulness dimensions. These findings provide critical insights for advancing LLM-based user simulation. Our multi-dimensional taxonomy constructed a generalizable framework for analyzing user behavior patterns, offering insights from LLM agent users and human users. By this work, we provide perspectives on rethinking how to use user simulation in conversational systems in the future.

[Arxiv](https://arxiv.org/abs/2509.17619)