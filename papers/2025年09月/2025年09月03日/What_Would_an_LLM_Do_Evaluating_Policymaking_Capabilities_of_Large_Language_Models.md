# LLM将如何决策？评估大型语言模型的政策制定能力

发布时间：2025年09月03日

`LLM应用` `基础理论`

> What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models

# 摘要

> 大型语言模型（LLMs）正日益应用于高风险领域。凭借处理海量非结构化数据、探索多元场景及应对复杂情境因素的能力，LLMs为复杂的社会政策制定提供了独特的新见解。本文以缓解全球超1.5亿人面临的无家可归问题为研究对象，评估LLMs是否与领域专家（及模型间）观点一致，从而为相关社会政策制定提供参考。我们构建了一个全新基准，涵盖美国南本德、西班牙巴塞罗那、南非约翰内斯堡及中国澳门特别行政区四个地区的政策选择决策场景，这些政策均基于人类发展的“能力方法”概念框架。我们还设计了自动化流程，将基准政策与智能体模型对接，通过模拟社会场景探究推荐政策的社会影响。研究表明，LLMs在社会政策制定中具有巨大应用潜力。若与当地专家合作建立负责任的保障机制并进行情境校准，LLMs便能以规模化替代政策方案的形式，为人类提供极具价值的洞见。

> Large language models (LLMs) are increasingly being adopted in high-stakes domains. Their capacity to process vast amounts of unstructured data, explore flexible scenarios, and handle a diversity of contextual factors can make them uniquely suited to provide new insights for the complexity of social policymaking. This article evaluates whether LLMs' are aligned with domain experts (and among themselves) to inform social policymaking on the subject of homelessness alleviation - a challenge affecting over 150 million people worldwide. We develop a novel benchmark comprised of decision scenarios with policy choices across four geographies (South Bend, USA; Barcelona, Spain; Johannesburg, South Africa; Macau SAR, China). The policies in scope are grounded in the conceptual framework of the Capability Approach for human development. We also present an automated pipeline that connects the benchmarked policies to an agent-based model, and we explore the social impact of the recommended policies through simulated social scenarios. The paper results reveal promising potential to leverage LLMs for social policy making. If responsible guardrails and contextual calibrations are introduced in collaboration with local domain experts, LLMs can provide humans with valuable insights, in the form of alternative policies at scale.

[Arxiv](https://arxiv.org/abs/2509.03827)