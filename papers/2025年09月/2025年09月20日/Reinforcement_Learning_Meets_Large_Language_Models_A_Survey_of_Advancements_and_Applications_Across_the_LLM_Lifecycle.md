# 强化学习邂逅大型语言模型：LLM生命周期中的进展与应用综述

发布时间：2025年09月20日

`强化学习` `基础理论`

> Reinforcement Learning Meets Large Language Models: A Survey of Advancements and Applications Across the LLM Lifecycle

# 摘要

> 近年来，以强化学习（RL）为核心的训练方法显著提升了大型语言模型（LLMs）的推理与对齐性能，尤其在理解人类意图、遵循用户指令以及增强推理能力等方面表现突出。尽管现有综述已对RL增强LLMs进行了概述，但其范围往往有限，未能全面总结RL在LLMs整个生命周期中的运作机制。我们系统综述了RL赋能LLMs的理论与实践进展，重点关注可验证奖励强化学习（RLVR）。首先，简要介绍RL的基本理论；其次，详细阐述RL在LLM生命周期各阶段的应用策略，包括预训练、对齐微调和强化推理——特别值得强调的是，强化推理阶段的RL方法是推动模型推理能力迈向极限的关键动力。接下来，整理了当前用于RL微调的现有数据集和评估基准，涵盖人工标注数据集、AI辅助偏好数据及程序验证风格语料库。随后，综述了现有的主流开源工具与训练框架，为后续研究提供了明确的实践参考。最后，分析了RL增强LLMs领域的未来挑战与趋势。本综述旨在向研究人员与从业者呈现RL与LLMs交叉领域的最新进展和前沿趋势，以期促进更智能、更具通用性且更安全的LLMs的发展。

> In recent years, training methods centered on Reinforcement Learning (RL) have markedly enhanced the reasoning and alignment performance of Large Language Models (LLMs), particularly in understanding human intents, following user instructions, and bolstering inferential strength. Although existing surveys offer overviews of RL augmented LLMs, their scope is often limited, failing to provide a comprehensive summary of how RL operates across the full lifecycle of LLMs. We systematically review the theoretical and practical advancements whereby RL empowers LLMs, especially Reinforcement Learning with Verifiable Rewards (RLVR). First, we briefly introduce the basic theory of RL. Second, we thoroughly detail application strategies for RL across various phases of the LLM lifecycle, including pre-training, alignment fine-tuning, and reinforced reasoning. In particular, we emphasize that RL methods in the reinforced reasoning phase serve as a pivotal driving force for advancing model reasoning to its limits. Next, we collate existing datasets and evaluation benchmarks currently used for RL fine-tuning, spanning human-annotated datasets, AI-assisted preference data, and program-verification-style corpora. Subsequently, we review the mainstream open-source tools and training frameworks available, providing clear practical references for subsequent research. Finally, we analyse the future challenges and trends in the field of RL-enhanced LLMs. This survey aims to present researchers and practitioners with the latest developments and frontier trends at the intersection of RL and LLMs, with the goal of fostering the evolution of LLMs that are more intelligent, generalizable, and secure.

[Arxiv](https://arxiv.org/abs/2509.16679)