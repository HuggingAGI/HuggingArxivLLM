# 大型语言模型（LLMs）：布局设计师的空间推理视角

发布时间：2025年09月20日

`Agent` `媒体与娱乐`

> LLMs as Layout Designers: A Spatial Reasoning Perspective

# 摘要

> 大型语言模型（LLMs）虽在文本领域展现出卓越的推理与规划能力，且能高效执行复杂任务指令，但其空间理解与推理能力仍显不足。然而，这些能力对于内容感知图形布局设计等应用却至关重要——这类应用要求在有限的视觉空间内，对多个元素进行精准放置、对齐与结构化组织。为弥合这一差距，我们提出LaySPA——一个基于强化学习的框架，可为LLM智能体赋予显式空间推理能力。LaySPA借助融合几何有效性、结构保真度与视觉质量的混合奖励信号，让智能体能够建模元素间关系、在画布上灵活导航并优化空间布局。通过迭代自我探索与自适应策略优化，LaySPA能生成可解释的推理轨迹与结构化布局。实验结果显示，LaySPA生成的布局不仅结构合理、视觉吸引力强，还超越了更大规模的通用LLM，性能与最先进的专用布局模型不相上下。

> While Large Language Models (LLMs) have demonstrated impressive reasoning and planning abilities in textual domains and can effectively follow instructions for complex tasks, their capacity for spatial understanding and reasoning remains limited. Such capabilities, however, are critical for applications like content-aware graphic layout design, which demands precise placement, alignment, and structural organization of multiple elements within constrained visual spaces. To address this gap, we propose LaySPA, a reinforcement learning-based framework that augments LLM agents with explicit spatial reasoning capabilities. LaySPA leverages hybrid reward signals that capture geometric validity, structural fidelity, and visual quality, enabling agents to model inter-element relationships, navigate the canvas, and optimize spatial arrangements. Through iterative self-exploration and adaptive policy optimization, LaySPA produces both interpretable reasoning traces and structured layouts. Experimental results demonstrate that LaySPA generates structurally sound and visually appealing layouts, outperforming larger general-purpose LLMs and achieving results on par with state-of-the-art specialized layout models.

[Arxiv](https://arxiv.org/abs/2509.16891)