# 圆桌策略：基于大型语言模型（LLMs）的置信加权共识改进科学推理与叙事

发布时间：2025年09月20日

`Agent` `基础理论`

> Roundtable Policy: Improving Scientific Reasoning and Narratives through Confidence-Weighted Consensus of LLMs

# 摘要

> 大型语言模型（LLMs）不仅在语言生成领域表现卓越，更在推动科学发现方面展现出非凡潜力。越来越多的研究探索了提升其推理能力的方法，涵盖自一致性、思维链乃至多智能体辩论等。受科学委员会运作机制与“心智社会”理论的启发，我们提出了“圆桌策略”（Roundtable Policy）——一种互补性的推理时推理框架，通过多个LLM的加权共识实现推理。研究结果表明，该方法显著提升了复杂异构科学任务的推理能力，在科学叙事的创造力、严谨性和逻辑连贯性上均有改进，同时减少了单一模型易出现的幻觉问题。我们的方法注重结构化、可解释的共识达成，而非不透明的收敛过程，且仅需黑盒访问与统一流程，因此广泛适用于多LLM推理场景。

> Large language models (LLMs) have demonstrated remarkable capabilities not only in language generation but also in advancing scientific discovery. A growing body of work has explored ways to improve their reasoning, from self-consistency and chain-of-thought to multi-agent debate. Inspired by the dynamics of scientific committees and the "Society of Mind," we introduce Roundtable Policy, a complementary inference-time reasoning framework that performs inference through the weighted consensus of multiple LLMs. Our findings indicate that this approach significantly enhances reasoning in complex heterogeneous scientific tasks and improves scientific narratives in terms of creativity, rigor, and logical coherence, while reducing hallucinations that single models are prone to. Our approach emphasizes structured and interpretable consensus rather than opaque convergence, while requiring only black-box access and uniform procedures, making it broadly applicable to multi-LLM reasoning.

[Arxiv](https://arxiv.org/abs/2509.16839)