# # 网络安全中的大型语言模型（LLMs）：人类决策循环中的友与敌？

发布时间：2025年09月08日

`LLM应用` `基础理论`

> LLMs in Cybersecurity: Friend or Foe in the Human Decision Loop?

# 摘要

> 大型语言模型（LLMs）正以认知协作者的身份改变人类决策。但这一变革背后藏着矛盾：它们在提升决策准确性的同时，也可能削弱独立思考能力、助长过度依赖，甚至导致决策趋同。本文探讨了LLMs在安全关键场景中对人类判断的影响。我们通过两个探索性焦点小组（分别为无辅助组和LLM辅助组），对决策准确性、行为韧性及依赖动态展开评估。研究发现，尽管LLMs能提升常规决策的准确性与一致性，却可能无意中减少认知多样性，甚至加剧自动化偏见——这种情况在低韧性用户中尤为突出。与之相反，高韧性个体则能更高效地利用LLMs，这意味着认知特质在AI益处的发挥中起到了调节作用。

> Large Language Models (LLMs) are transforming human decision-making by acting as cognitive collaborators. Yet, this promise comes with a paradox: while LLMs can improve accuracy, they may also erode independent reasoning, promote over-reliance and homogenize decisions. In this paper, we investigate how LLMs shape human judgment in security-critical contexts. Through two exploratory focus groups (unaided and LLM-supported), we assess decision accuracy, behavioral resilience and reliance dynamics. Our findings reveal that while LLMs enhance accuracy and consistency in routine decisions, they can inadvertently reduce cognitive diversity and improve automation bias, which is especially the case among users with lower resilience. In contrast, high-resilience individuals leverage LLMs more effectively, suggesting that cognitive traits mediate AI benefit.

[Arxiv](https://arxiv.org/abs/2509.06595)