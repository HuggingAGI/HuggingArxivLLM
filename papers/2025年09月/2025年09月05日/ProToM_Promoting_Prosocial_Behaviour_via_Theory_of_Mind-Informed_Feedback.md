# ProToM：通过基于心理理论的反馈促进亲社会行为

发布时间：2025年09月05日

`Agent` `基础理论`

> ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback

# 摘要

> 人类天生是社会性生物，但确定何时以及如何协助他人、开展合作——尤其是在追求各自目标时——这一难题往往会阻碍协作。为解决这一挑战，我们旨在开发一种人工智能系统，通过提供有用反馈来促进亲社会行为——即那些即便与自身目标不完全一致，也能造福他人的行为。为此，我们提出了ProToM——一种基于心理理论的促进器，它通过向个体智能体提供针对性强、且能适应上下文的反馈，来推动多智能体系统中的亲社会行为。ProToM首先利用贝叶斯逆规划推断智能体的目标，然后在推断出的目标分布基础上，通过最大化期望效用选择要传达的反馈。我们在两个多智能体环境（Doors, Keys, and Gems与Overcooked）中，将该方法与基线模型进行了对比评估。结果显示，当前最先进的大型语言与推理模型在传达“既贴合上下文又时机恰当”的反馈方面表现欠佳——这会导致通信开销增加，任务效率降低。相比之下，ProToM能提供针对性强、实用性高的反馈，不仅实现了更高的成功率和更短的任务完成时间，还始终受到人类用户的青睐。

> While humans are inherently social creatures, the challenge of identifying when and how to assist and collaborate with others - particularly when pursuing independent goals - can hinder cooperation. To address this challenge, we aim to develop an AI system that provides useful feedback to promote prosocial behaviour - actions that benefit others, even when not directly aligned with one's own goals. We introduce ProToM, a Theory of Mind-informed facilitator that promotes prosocial actions in multi-agent systems by providing targeted, context-sensitive feedback to individual agents. ProToM first infers agents' goals using Bayesian inverse planning, then selects feedback to communicate by maximising expected utility, conditioned on the inferred goal distribution. We evaluate our approach against baselines in two multi-agent environments: Doors, Keys, and Gems, as well as Overcooked. Our results suggest that state-of-the-art large language and reasoning models fall short of communicating feedback that is both contextually grounded and well-timed - leading to higher communication overhead and task speedup. In contrast, ProToM provides targeted and helpful feedback, achieving a higher success rate, shorter task completion times, and is consistently preferred by human users.

[Arxiv](https://arxiv.org/abs/2509.05091)