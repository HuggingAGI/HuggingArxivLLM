# # 认知、功能与因果维度的三元融合：面向可解释大型语言模型（LLMs）的TAXAL框架

发布时间：2025年09月05日

`Agent` `医疗健康` `法律科技`

> Triadic Fusion of Cognitive, Functional, and Causal Dimensions for Explainable LLMs: The TAXAL Framework

# 摘要

> 大型语言模型（LLMs）正日益应用于高风险领域，但其不透明性、偏见与不稳定性严重削弱了信任与问责。传统可解释性方法仅关注表面输出，难以捕捉智能体LLM的推理路径、规划逻辑及系统性影响。
  为此，我们提出TAXAL（智能体LLM可解释性的三元对齐）——一个融合认知（用户理解）、功能（实际效用）与因果（忠实推理）三个互补维度的三元框架。TAXAL为在各类社会技术场景中设计、评估和部署解释奠定了统一且角色敏感的基础。
  我们的分析整合了现有方法（从后验归因、对话界面到解释感知提示），并将其纳入TAXAL三元框架中。通过法律、教育、医疗及公共服务领域的案例研究，我们验证了TAXAL的适用性，同时展示了解释策略如何适配制度约束与利益相关者角色。
  TAXAL通过整合概念清晰度、设计模式与部署路径，推动可解释性成为技术与社会技术实践的核心，助力在智能体AI时代落地可信且情境敏感的LLM应用。

> Large Language Models (LLMs) are increasingly being deployed in high-risk domains where opacity, bias, and instability undermine trust and accountability. Traditional explainability methods, focused on surface outputs, do not capture the reasoning pathways, planning logic, and systemic impacts of agentic LLMs.
  We introduce TAXAL (Triadic Alignment for eXplainability in Agentic LLMs), a triadic fusion framework that unites three complementary dimensions: cognitive (user understanding), functional (practical utility), and causal (faithful reasoning). TAXAL provides a unified, role-sensitive foundation for designing, evaluating, and deploying explanations in diverse sociotechnical settings.
  Our analysis synthesizes existing methods, ranging from post-hoc attribution and dialogic interfaces to explanation-aware prompting, and situates them within the TAXAL triadic fusion model. We further demonstrate its applicability through case studies in law, education, healthcare, and public services, showing how explanation strategies adapt to institutional constraints and stakeholder roles.
  By combining conceptual clarity with design patterns and deployment pathways, TAXAL advances explainability as a technical and sociotechnical practice, supporting trustworthy and context-sensitive LLM applications in the era of agentic AI.

[Arxiv](https://arxiv.org/abs/2509.05199)