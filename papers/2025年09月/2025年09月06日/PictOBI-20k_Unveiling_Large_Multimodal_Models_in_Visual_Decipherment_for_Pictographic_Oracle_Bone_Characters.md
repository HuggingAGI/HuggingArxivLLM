# PictOBI-20k：揭秘大型多模态模型在象形甲骨文视觉破译中的应用

发布时间：2025年09月06日

`LLM应用` `基础理论`

> PictOBI-20k: Unveiling Large Multimodal Models in Visual Decipherment for Pictographic Oracle Bone Characters

# 摘要

> 甲骨文（OBCs）作为中国现存最古老的成熟文字形式，其破译始终是学者们不懈追求的终极目标，也是理解人类早期生产方式不可替代的钥匙。当前甲骨文破译方法主要受制于考古发掘的零散性及铭文语料库的稀缺性。借助大型多模态模型（LMMs）强大的视觉感知能力，其在甲骨文视觉破译任务中的应用潜力愈发显著。本文中，我们提出PictOBI-20k数据集，专门用于评估LMMs在象形甲骨文视觉破译任务中的性能。该数据集包含2万张精心采集的甲骨文与实物图像，构建了逾1.5万个选择题。我们还开展了主观标注工作，旨在探究人类与LMMs在视觉推理过程中参考基准的一致性。实验结果显示，通用LMMs已具备初步的视觉破译能力，但其未能有效利用视觉信息，反而在多数情况下受限于语言先验。我们期望该数据集能够助力未来面向甲骨文的LMMs在视觉注意力机制上的评估与优化。相关代码与数据集将在https://github.com/OBI-Future/PictOBI-20k开源发布。

> Deciphering oracle bone characters (OBCs), the oldest attested form of written Chinese, has remained the ultimate, unwavering goal of scholars, offering an irreplaceable key to understanding humanity's early modes of production. Current decipherment methodologies of OBC are primarily constrained by the sporadic nature of archaeological excavations and the limited corpus of inscriptions. With the powerful visual perception capability of large multimodal models (LMMs), the potential of using LMMs for visually deciphering OBCs has increased. In this paper, we introduce PictOBI-20k, a dataset designed to evaluate LMMs on the visual decipherment tasks of pictographic OBCs. It includes 20k meticulously collected OBC and real object images, forming over 15k multi-choice questions. We also conduct subjective annotations to investigate the consistency of the reference point between humans and LMMs in visual reasoning. Experiments indicate that general LMMs possess preliminary visual decipherment skills, and LMMs are not effectively using visual information, while most of the time they are limited by language priors. We hope that our dataset can facilitate the evaluation and optimization of visual attention in future OBC-oriented LMMs. The code and dataset will be available at https://github.com/OBI-Future/PictOBI-20k.

[Arxiv](https://arxiv.org/abs/2509.05773)