# 情感计算与情感数据：隐私法规、《人工智能法案》及大型语言模型伦理面临的挑战与启示

发布时间：2025年09月24日

`LLM应用` `医疗健康` `教育科技`

> Affective Computing and Emotional Data: Challenges and Implications in Privacy Regulations, The AI Act, and Ethics in Large Language Models

# 摘要

> 本文探讨情感智能与人工智能系统的融合，重点关注情感计算以及大型语言模型（LLMs）——如ChatGPT和Claude——在识别与响应人类情感方面日益强大的能力。依托计算机科学、心理学与神经科学的跨学科研究，本研究深入分析了支撑情感识别的基础神经架构：用于处理面部表情的卷积神经网络（CNNs），以及用于处理语音、文本等序列数据的循环神经网络（RNNs）。文章还探讨人类情感体验如何转化为结构化情感数据，同时区分两类数据：研究场景中经知情同意收集的显式情感数据，以及日常数字交互中被动获取的隐式数据。这一区分引发了数字环境下情感表达相关的关键议题，包括合法处理、AI透明度及个人自主权。此外，本文探讨了情感智能在医疗、教育、客服等多领域的应用启示，同时直面情感表达的文化差异及不同人群情感识别系统中的潜在偏见问题。从监管层面，本文结合《通用数据保护条例》（GDPR）与《欧盟人工智能法案》框架，指出情感数据或被视为敏感个人数据，需构建强有力的保障机制，涵盖目的限制、数据最小化及有意义的同意流程。

> This paper examines the integration of emotional intelligence into artificial intelligence systems, with a focus on affective computing and the growing capabilities of Large Language Models (LLMs), such as ChatGPT and Claude, to recognize and respond to human emotions. Drawing on interdisciplinary research that combines computer science, psychology, and neuroscience, the study analyzes foundational neural architectures - CNNs for processing facial expressions and RNNs for sequential data, such as speech and text - that enable emotion recognition. It examines the transformation of human emotional experiences into structured emotional data, addressing the distinction between explicit emotional data collected with informed consent in research settings and implicit data gathered passively through everyday digital interactions. That raises critical concerns about lawful processing, AI transparency, and individual autonomy over emotional expressions in digital environments. The paper explores implications across various domains, including healthcare, education, and customer service, while addressing challenges of cultural variations in emotional expression and potential biases in emotion recognition systems across different demographic groups. From a regulatory perspective, the paper examines emotional data in the context of the GDPR and the EU AI Act frameworks, highlighting how emotional data may be considered sensitive personal data that requires robust safeguards, including purpose limitation, data minimization, and meaningful consent mechanisms.

[Arxiv](https://arxiv.org/abs/2509.20153)