# # 多语言大型语言模型（LLMs）性别偏见探查：波斯语刻板印象案例研究

发布时间：2025年09月24日

`LLM应用` `基础理论`

> Probing Gender Bias in Multilingual LLMs: A Case Study of Stereotypes in Persian

# 摘要

> 多语言大型语言模型（LLMs）的全球应用日益广泛，确保其无性别偏见以避免代表性伤害因此至关重要。尽管已有研究探讨了高资源语言中的此类偏见，但低资源语言的相关研究仍显不足。本文提出一种基于模板的探测方法，经真实数据验证，可用于揭示LLMs中的性别刻板印象。作为该框架的一部分，我们还引入特定领域性别偏差指数（DS-GSI）——一种量化性别平等偏离程度的指标。我们在四个语义领域对GPT-4o mini、DeepSeek R1、Gemini 2.0 Flash和Qwen QwQ 32B这四个主流模型进行了评估，重点关注波斯语——一种具有独特语言特征的低资源语言。结果显示，所有模型均存在性别刻板印象，且在所有领域中，波斯语的偏见差异均大于英语；其中，体育领域的性别偏见最为顽固。本研究强调了包容性NLP实践的必要性，并为评估其他低资源语言的偏见提供了框架。

> Multilingual Large Language Models (LLMs) are increasingly used worldwide, making it essential to ensure they are free from gender bias to prevent representational harm. While prior studies have examined such biases in high-resource languages, low-resource languages remain understudied. In this paper, we propose a template-based probing methodology, validated against real-world data, to uncover gender stereotypes in LLMs. As part of this framework, we introduce the Domain-Specific Gender Skew Index (DS-GSI), a metric that quantifies deviations from gender parity. We evaluate four prominent models, GPT-4o mini, DeepSeek R1, Gemini 2.0 Flash, and Qwen QwQ 32B, across four semantic domains, focusing on Persian, a low-resource language with distinct linguistic features. Our results show that all models exhibit gender stereotypes, with greater disparities in Persian than in English across all domains. Among these, sports reflect the most rigid gender biases. This study underscores the need for inclusive NLP practices and provides a framework for assessing bias in other low-resource languages.

[Arxiv](https://arxiv.org/abs/2509.20168)