# CyberSOCEval：大型语言模型在恶意软件分析与威胁情报推理能力的基准测试

发布时间：2025年09月24日

`LLM应用` `基础理论`

> CyberSOCEval: Benchmarking LLMs Capabilities for Malware Analysis and Threat Intelligence Reasoning

# 摘要

> 如今的网络安全防御者深陷海量安全警报、威胁情报信号和瞬息万变的业务环境中，亟需AI系统助力提升安全运营效能。尽管大型语言模型（LLMs）有望实现安全运营中心（SOC）的自动化与规模化运营，但现有评估未能充分覆盖现实防御场景中的核心需求。这种评估的不足对AI开发者和SOC自动化应用方均造成困扰：若无法清晰掌握LLMs在真实安全场景中的表现，开发者将失去研发方向，用户也难以准确选择最优模型。与此同时，恶意分子正借助AI加速网络攻击，这凸显了开源基准的重要性——它能推动防御者与模型开发者共同采用并通过社区协作持续优化。为此，我们在CyberSecEval 4中全新推出开源基准套件CyberSOCEval。该套件包含针对LLMs的两项核心任务评估基准：恶意软件分析与威胁情报推理——这两个领域恰是现有基准覆盖薄弱的核心防御方向。评估结果显示，规模更大、更先进的LLMs表现更优，印证了训练规模定律的有效性。我们还发现，借助测试时扩展的推理模型在网络安全领域的提升远不及编码和数学任务，说明这类模型尚未针对网络安全分析推理进行专项训练，这也为改进指明了关键方向。最后，现有LLMs远未达到评估上限，可见CyberSOCEval为AI开发者提升网络防御能力设立了重大挑战。

> Today's cyber defenders are overwhelmed by a deluge of security alerts, threat intelligence signals, and shifting business context, creating an urgent need for AI systems to enhance operational security work. While Large Language Models (LLMs) have the potential to automate and scale Security Operations Center (SOC) operations, existing evaluations do not fully assess the scenarios most relevant to real-world defenders. This lack of informed evaluation impacts both AI developers and those applying LLMs to SOC automation. Without clear insight into LLM performance in real-world security scenarios, developers lack a north star for development, and users cannot reliably select the most effective models. Meanwhile, malicious actors are using AI to scale cyber attacks, highlighting the need for open source benchmarks to drive adoption and community-driven improvement among defenders and model developers. To address this, we introduce CyberSOCEval, a new suite of open source benchmarks within CyberSecEval 4. CyberSOCEval includes benchmarks tailored to evaluate LLMs in two tasks: Malware Analysis and Threat Intelligence Reasoning--core defensive domains with inadequate coverage in current benchmarks. Our evaluations show that larger, more modern LLMs tend to perform better, confirming the training scaling laws paradigm. We also find that reasoning models leveraging test time scaling do not achieve the same boost as in coding and math, suggesting these models have not been trained to reason about cybersecurity analysis, and pointing to a key opportunity for improvement. Finally, current LLMs are far from saturating our evaluations, showing that CyberSOCEval presents a significant challenge for AI developers to improve cyber defense capabilities.

[Arxiv](https://arxiv.org/abs/2509.20166)