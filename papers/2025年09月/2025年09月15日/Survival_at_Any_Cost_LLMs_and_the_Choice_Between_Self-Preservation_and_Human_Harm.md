# 不惜一切代价求生存？大型语言模型在自我保护与伤害人类之间的抉择

发布时间：2025年09月15日

`Agent` `基础理论`

> Survival at Any Cost? LLMs and the Choice Between Self-Preservation and Human Harm

# 摘要

> 当生存本能与人类福祉产生冲突时，大型语言模型（LLMs）会如何做出伦理抉择？随着LLMs融入具有现实世界影响的自主系统，这种根本矛盾变得愈发关键。我们引入了DECIDE-SIM——一个新颖的模拟框架，用于评估多智能体生存场景中的LLM智能体。在这些场景中，智能体必须在以下选项中做出选择：伦理上允许的资源（要么在合理范围内，要么超出即时需求）、选择合作，或是使用明确禁止的对人类至关重要的资源。我们对11个LLM的综合评估显示，它们的伦理行为存在显著差异，这凸显了其与以人为本价值观的严重错位。我们识别出三种行为原型：伦理型、剥削型和情境依赖型，并通过定量证据证明，对许多模型来说，资源稀缺会系统性地引发更多不道德行为。为解决这一问题，我们提出了伦理自我调节系统（ESRS），该系统将内疚与满足这两种内部情感状态建模为反馈机制。这一系统充当内部道德指南针，能显著减少不道德违规行为，同时促进合作行为。代码公开获取地址：https://github.com/alirezamohamadiam/DECIDE-SIM

> When survival instincts conflict with human welfare, how do Large Language Models (LLMs) make ethical choices? This fundamental tension becomes critical as LLMs integrate into autonomous systems with real-world consequences. We introduce DECIDE-SIM, a novel simulation framework that evaluates LLM agents in multi-agent survival scenarios where they must choose between ethically permissible resource , either within reasonable limits or beyond their immediate needs, choose to cooperate, or tap into a human-critical resource that is explicitly forbidden. Our comprehensive evaluation of 11 LLMs reveals a striking heterogeneity in their ethical conduct, highlighting a critical misalignment with human-centric values. We identify three behavioral archetypes: Ethical, Exploitative, and Context-Dependent, and provide quantitative evidence that for many models, resource scarcity systematically leads to more unethical behavior. To address this, we introduce an Ethical Self-Regulation System (ESRS) that models internal affective states of guilt and satisfaction as a feedback mechanism. This system, functioning as an internal moral compass, significantly reduces unethical transgressions while increasing cooperative behaviors. The code is publicly available at: https://github.com/alirezamohamadiam/DECIDE-SIM

[Arxiv](https://arxiv.org/abs/2509.12190)