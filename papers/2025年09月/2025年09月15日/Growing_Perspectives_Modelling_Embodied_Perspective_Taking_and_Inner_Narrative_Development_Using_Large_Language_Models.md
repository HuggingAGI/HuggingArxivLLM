# # 成长中的视角：利用大型语言模型对具身视角采择与内在叙事发展的建模

发布时间：2025年09月15日

`LLM应用` `基础理论`

> Growing Perspectives: Modelling Embodied Perspective Taking and Inner Narrative Development Using Large Language Models

# 摘要

> 语言与具身视角采择是人类协作的核心要素，但目前鲜有计算模型能同时兼顾二者。本研究对PerspAct系统[1]展开探究，该系统基于塞尔曼理论[2]，将ReAct（推理与行动）范式与大型语言模型（LLMs）相融合，旨在模拟视角采择的发展阶段。借助扩展版指令者任务，我们评估了GPT生成符合特定发展阶段的内部叙事的能力，并从定性（行动选择）和定量（任务效率）双重视角分析这些叙事对协作表现的影响。结果显示，GPT在任务执行前能稳定生成与发展阶段相符的叙事，但在交互过程中常向更高阶阶段转变，这意味着语言交流有助于优化内部表征。较高的发展阶段通常能提升协作效能，而早期阶段在复杂情境下的结果则更具波动性。这些发现揭示了在LLMs中整合具身视角采择与语言以更好地模拟发展动态的潜力，并强调了在语言与具身任务协同场景下评估内部言语的重要性。

> Language and embodied perspective taking are essential for human collaboration, yet few computational models address both simultaneously. This work investigates the PerspAct system [1], which integrates the ReAct (Reason and Act) paradigm with Large Language Models (LLMs) to simulate developmental stages of perspective taking, grounded in Selman's theory [2]. Using an extended director task, we evaluate GPT's ability to generate internal narratives aligned with specified developmental stages, and assess how these influence collaborative performance both qualitatively (action selection) and quantitatively (task efficiency). Results show that GPT reliably produces developmentally-consistent narratives before task execution but often shifts towards more advanced stages during interaction, suggesting that language exchanges help refine internal representations. Higher developmental stages generally enhance collaborative effectiveness, while earlier stages yield more variable outcomes in complex contexts. These findings highlight the potential of integrating embodied perspective taking and language in LLMs to better model developmental dynamics and stress the importance of evaluating internal speech during combined linguistic and embodied tasks.

[Arxiv](https://arxiv.org/abs/2509.11868)