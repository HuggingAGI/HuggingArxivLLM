# DoubleAgents：探索主动式AI信任建立机制

发布时间：2025年09月15日

`Agent` `基础理论`

> DoubleAgents: Exploring Mechanisms of Building Trust with Proactive AI

# 摘要

> 智能体工作流虽有望提升效率，但其普及的关键在于人们是否真正信任这些代其行事的系统。我们研发了DoubleAgents——一款智能体规划工具，它通过用户干预、价值导向策略、丰富的状态可视化及人类协作任务的不确定性标记，将透明度与控制力深度融入设计。其内置的响应者模拟功能可生成真实场景，让用户在实际应用前进行演练、优化策略并调整依赖度。我们通过为期两天的实验室研究（n=10）、两次实际部署（n=2）及一次技术评估，对DoubleAgents展开了全面评估。结果显示，参与者起初对委托任务心存犹豫，但在模拟场景中体验到透明度、可控性与自适应学习后，依赖度逐渐提升。部署结果验证了DoubleAgents在现实场景中的实用性与适用性，同时表明所需投入会随任务复杂度及上下文数据的增加而合理调整。我们提出了主动式AI的“信任设计”模式与核心机制——一致性、可控性和可解释性，并将模拟作为一种安全路径，助力用户逐步建立和校准信任。

> Agentic workflows promise efficiency, but adoption hinges on whether people actually trust systems that act on their behalf. We present DoubleAgents, an agentic planning tool that embeds transparency and control through user intervention, value-reflecting policies, rich state visualizations, and uncertainty flagging for human coordination tasks. A built-in respondent simulation generates realistic scenarios, allowing users to rehearse, refine policies, and calibrate their reliance before live use. We evaluate DoubleAgents in a two-day lab study (n=10), two deployments (n=2), and a technical evaluation. Results show that participants initially hesitated to delegate but grew more reliant as they experienced transparency, control, and adaptive learning during simulated cases. Deployment results demonstrate DoubleAgents' real-world relevance and usefulness, showing that the effort required scaled appropriately with task complexity and contextual data. We contribute trust-by-design patterns and mechanisms for proactive AI -- consistency, controllability, and explainability -- along with simulation as a safe path to build and calibrate trust over time.

[Arxiv](https://arxiv.org/abs/2509.12626)