# 为高能物理中的中微子事件分类适配视觉-语言模型

发布时间：2025年09月10日

`LLM应用` `基础理论`

> Adapting Vision-Language Models for Neutrino Event Classification in High-Energy Physics

# 摘要

> 大型语言模型（LLMs）的最新进展，展现出其在处理和推理自然语言之外的结构化与非结构化数据模态上的卓越能力。本研究探索了视觉语言模型（VLMs）的应用，具体为LLaMa 3.2的一个微调变体，旨在解决高能物理（HEP）实验中像素探测器数据的中微子相互作用识别任务。我们将该模型与最先进的卷积神经网络（CNN）架构进行了性能对比——这类架构与NOvA和DUNE实验中所采用的类似，已在电子中微子与μ子中微子事件分类中实现了高效率与高纯度。评估不仅关注模型的分类性能，还兼顾了预测结果的可解释性。结果表明，VLMs不仅性能超越CNN，还在整合辅助文本或语义信息时具备更高灵活性，并能生成更具可解释性的推理式预测。本研究凸显了VLMs作为物理事件分类通用主干的潜力——凭借其高性能、可解释性与泛化性，为实验中微子物理领域整合多模态推理打开了全新局面。

> Recent advances in Large Language Models (LLMs) have demonstrated their remarkable capacity to process and reason over structured and unstructured data modalities beyond natural language. In this work, we explore the applications of Vision Language Models (VLMs), specifically a fine-tuned variant of LLaMa 3.2, to the task of identifying neutrino interactions in pixelated detector data from high-energy physics (HEP) experiments. We benchmark this model against a state-of-the-art convolutional neural network (CNN) architecture, similar to those used in the NOvA and DUNE experiments, which have achieved high efficiency and purity in classifying electron and muon neutrino events. Our evaluation considers both the classification performance and interpretability of the model predictions. We find that VLMs can outperform CNNs, while also providing greater flexibility in integrating auxiliary textual or semantic information and offering more interpretable, reasoning-based predictions. This work highlights the potential of VLMs as a general-purpose backbone for physics event classification, due to their high performance, interpretability, and generalizability, which opens new avenues for integrating multimodal reasoning in experimental neutrino physics.

[Arxiv](https://arxiv.org/abs/2509.08461)