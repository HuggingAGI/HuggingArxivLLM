# 大型语言模型在进化优化中的系统性综述：从建模到求解

发布时间：2025年09月10日

`LLM应用` `基础理论`

> A Systematic Survey on Large Language Models for Evolutionary Optimization: From Modeling to Solving

# 摘要

> 大型语言模型（LLMs）凭借强大的理解与推理能力，在优化问题求解领域的应用探索日益深入，尤其在与进化计算的协同方面。然而，尽管发展迅速，该领域仍缺乏统一的综述与系统分类。本综述通过全面梳理最新进展并构建结构化框架，填补了这一空白。我们将现有研究划分为两大阶段：LLMs用于优化建模，以及LLMs用于优化求解。后者根据LLMs在优化流程中的角色进一步细分为三种范式：LLMs作为独立优化器、嵌入优化算法的底层LLMs，以及负责算法选择与生成的高层LLMs。针对每个类别，我们剖析代表性方法、提炼技术挑战，并探讨其与传统方法的互动关系。我们还综述了横跨自然科学、工程学及机器学习领域的跨学科应用。通过对比LLM驱动方法与传统方法，我们揭示了核心局限性与研究空白，并指明未来方向——构建用于优化的自进化智能体生态系统。相关文献的最新合集可访问https://github.com/ishmael233/LLM4OPT获取。

> Large Language Models (LLMs), with their strong understanding and reasoning capabilities, are increasingly being explored for tackling optimization problems, especially in synergy with evolutionary computation. Despite rapid progress, however, the field still lacks a unified synthesis and a systematic taxonomy. This survey addresses this gap by providing a comprehensive review of recent developments and organizing them within a structured framework. We classify existing research into two main stages: LLMs for optimization modeling and LLMs for optimization solving. The latter is further divided into three paradigms according to the role of LLMs in the optimization workflow: LLMs as stand-alone optimizers, low-level LLMs embedded within optimization algorithms, and high-level LLMs for algorithm selection and generation. For each category, we analyze representative methods, distill technical challenges, and examine their interplay with traditional approaches. We also review interdisciplinary applications spanning the natural sciences, engineering, and machine learning. By contrasting LLM-driven and conventional methods, we highlight key limitations and research gaps, and point toward future directions for developing self-evolving agentic ecosystems for optimization. An up-to-date collection of related literature is maintained at https://github.com/ishmael233/LLM4OPT.

[Arxiv](https://arxiv.org/abs/2509.08269)