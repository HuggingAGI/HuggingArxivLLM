# 与大型语言模型立约——基于代理理论的大型语言模型对齐探析

发布时间：2025年09月09日

`LLM应用` `基础理论`

> Getting In Contract with Large Language Models -- An Agency Theory Perspective On Large Language Model Alignment

# 摘要

> 在组织中应用大型语言模型（LLMs）有望彻底改变我们的生活与工作方式。但这些模型也可能生成跑题、歧视性或有害内容。这种AI对齐问题往往源于LLM部署过程中的规范偏差，而LLM的黑箱特性使得委托人难以察觉此类问题。尽管多个研究领域已对AI对齐展开探讨，但均未解决组织采用者与黑箱LLM智能体之间的信息不对称，也未考虑组织AI的实际部署流程。为此，我们提出LLM ATLAS（LLM代理理论引导的对齐策略）——一个基于代理（合同）理论的概念框架，旨在缓解组织部署LLM时的对齐难题。我们以组织LLM部署阶段和代理理论为核心概念，开展了概念性文献分析。该方法的成果包括：（1）构建了针对组织LLM部署场景下AI对齐方法的扩展文献分析流程；（2）提出了首个LLM对齐问题-解决方案空间。

> Adopting Large language models (LLMs) in organizations potentially revolutionizes our lives and work. However, they can generate off-topic, discriminating, or harmful content. This AI alignment problem often stems from misspecifications during the LLM adoption, unnoticed by the principal due to the LLM's black-box nature. While various research disciplines investigated AI alignment, they neither address the information asymmetries between organizational adopters and black-box LLM agents nor consider organizational AI adoption processes. Therefore, we propose LLM ATLAS (LLM Agency Theory-Led Alignment Strategy) a conceptual framework grounded in agency (contract) theory, to mitigate alignment problems during organizational LLM adoption. We conduct a conceptual literature analysis using the organizational LLM adoption phases and the agency theory as concepts. Our approach results in (1) providing an extended literature analysis process specific to AI alignment methods during organizational LLM adoption and (2) providing a first LLM alignment problem-solution space.

[Arxiv](https://arxiv.org/abs/2509.07642)