# 与奥姆帕-卢姆帕斯人对话：一种评估LLM智能体语言习得的新框架

发布时间：2025年09月09日

`Agent` `基础理论`

> Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents

# 摘要

> 目前对大型语言模型（LLM智能体）语言能力的评估研究主要聚焦于词汇学习、形态规则归纳、句法泛化、语用推理及跨语言迁移。然而，这些研究均未评估LLM智能体能否通过模式识别与交互式反馈习得语言——这正是人类语言习得的核心特征。为此，我们提出了一个全新的实验框架：让LLM智能体与仅懂Tinkatongue的机器人对话，以此评估其习得并使用这种新构建语言（Tinkatongue）的能力。研究发现，LLM智能体虽无法在100次回应内开展对话，却会采用独特策略，这些策略与人类语言学习方法颇为相似。这些结果不仅为评估基准指明了新方向，也为设计能更高效利用交互式反馈学习的模型开辟了路径。

> Existing evaluation studies on linguistic competence of large language models (LLM agents) have focused primarily on vocabulary learning, morphological rule induction, syntactic generalization, pragmatic inference, and cross-linguistic transfer. However, none assess whether LLM agents can acquire a language through pattern recognition and interactive feedback, a central feature of human language acquisition. We propose a novel experimental framework in which an LLM agent is evaluated on its ability to acquire and use a newly constructed language (Tinkatongue) in conversation with a bot that understands only Tinkatongue. Our findings show that LLM agents fail to establish a conversation within 100 responses, yet they adopt distinct strategies that mirror human approaches to language learning. The results suggest a new direction for evaluation benchmarks and open pathways to model designs that learn more effectively from interactive feedback.

[Arxiv](https://arxiv.org/abs/2509.07389)