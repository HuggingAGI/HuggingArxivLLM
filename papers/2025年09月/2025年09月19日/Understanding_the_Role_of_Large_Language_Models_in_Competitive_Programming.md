# 探析大型语言模型在竞技编程中的作用

发布时间：2025年09月19日

`LLM应用` `教育科技`

> Understanding the Role of Large Language Models in Competitive Programming

# 摘要

> 本文探讨大型语言模型（LLMs）如何重塑竞技编程领域。作为计算机科学教育中的智力竞技领域，它以快速迭代、实时反馈、透明解题方案及严格诚信准则为显著特征。以往研究虽已评估LLMs在竞赛题上的表现，但对于LLMs带来的变革如何影响人类利益相关者——包括参赛者、出题人、教练与平台管理者——调整其工作流程及竞赛规范，我们仍缺乏深入了解。与此同时，AI辅助滥用行为的增多及治理措施的不统一，凸显了在维护公平与公信力方面亟待弥补的漏洞。通过对上述四类角色的37次访谈及针对207名参赛者的全球调研，我们的研究贡献包括：（i）对工作流程演变的实证阐述；（ii）对公平规范争议的分析；（iii）一种受国际象棋启发的治理方案，其中包含可落地措施——如在线竞赛实时LLMs检测、同行协同监督与报告，以及与线下表现的交叉验证——旨在遏制LLMs辅助滥用，同时保障公平、透明与公信力。

> This paper investigates how large language models (LLMs) are reshaping competitive programming. The field functions as an intellectual contest within computer science education and is marked by rapid iteration, real-time feedback, transparent solutions, and strict integrity norms. Prior work has evaluated LLMs performance on contest problems, but little is known about how human stakeholders -- contestants, problem setters, coaches, and platform stewards -- are adapting their workflows and contest norms under LLMs-induced shifts. At the same time, rising AI-assisted misuse and inconsistent governance expose urgent gaps in sustaining fairness and credibility. Drawing on 37 interviews spanning all four roles and a global survey of 207 contestants, we contribute: (i) an empirical account of evolving workflows, (ii) an analysis of contested fairness norms, and (iii) a chess-inspired governance approach with actionable measures -- real-time LLMs checks in online contests, peer co-monitoring and reporting, and cross-validation against offline performance -- to curb LLMs-assisted misuse while preserving fairness, transparency, and credibility.

[Arxiv](https://arxiv.org/abs/2509.15867)