# 智能体驱动的空中电影摄影：从对话线索到电影化轨迹

发布时间：2025年09月19日

`Agent` `媒体与娱乐`

> Agentic Aerial Cinematography: From Dialogue Cues to Cinematic Trajectories

# 摘要

> 我们提出智能体空中摄影：从对话线索到电影轨迹（ACDC）——这是一套由人类导演与无人机通过自然语言交流驱动的自主无人机摄影系统。以往无人机摄影流程的主要瓶颈在于，需基于预设意图手动选择航点与视角，不仅耗时费力，效果也不稳定。为此，本文提出借助大型语言模型（LLMs）与视觉基础模型（VFMs），将自由形式的自然语言指令直接转化为可执行的室内无人机视频巡拍任务。具体来说，该方法包含三大模块：用于初始航点选择的视觉-语言检索管道、基于偏好的贝叶斯优化框架（利用美学反馈优化姿态），以及生成安全四旋翼轨迹的运动规划器。我们通过仿真与硬件在环实验验证了ACDC，结果表明它能在各类室内场景中稳定产出专业级画质影像，且无需用户具备机器人学或摄影专业背景。这些成果彰显了具身AI智能体的潜力——有望实现从开放词汇对话到现实世界自主空中摄影的闭环。

> We present Agentic Aerial Cinematography: From Dialogue Cues to Cinematic Trajectories (ACDC), an autonomous drone cinematography system driven by natural language communication between human directors and drones. The main limitation of previous drone cinematography workflows is that they require manual selection of waypoints and view angles based on predefined human intent, which is labor-intensive and yields inconsistent performance. In this paper, we propose employing large language models (LLMs) and vision foundation models (VFMs) to convert free-form natural language prompts directly into executable indoor UAV video tours. Specifically, our method comprises a vision-language retrieval pipeline for initial waypoint selection, a preference-based Bayesian optimization framework that refines poses using aesthetic feedback, and a motion planner that generates safe quadrotor trajectories. We validate ACDC through both simulation and hardware-in-the-loop experiments, demonstrating that it robustly produces professional-quality footage across diverse indoor scenes without requiring expertise in robotics or cinematography. These results highlight the potential of embodied AI agents to close the loop from open-vocabulary dialogue to real-world autonomous aerial cinematography.

[Arxiv](https://arxiv.org/abs/2509.16176)