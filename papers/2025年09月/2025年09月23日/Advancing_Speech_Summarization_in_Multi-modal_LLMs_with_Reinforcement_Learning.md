# 基于强化学习提升多模态LLMs的语音摘要能力

发布时间：2025年09月23日

`强化学习` `媒体与娱乐`

> Advancing Speech Summarization in Multi-modal LLMs with Reinforcement Learning

# 摘要

> 语音摘要是口语内容理解的核心环节，尤其在口语及视听数据爆炸式增长的当下。多模态大型语言模型（MLLMs）的最新进展凭借LLMs的强大能力，实现了无需中间转录、直接从语音生成文本摘要，还支持可控的风格与零样本泛化。但开源MLLMs仍落后于最先进的文本基LLMs，这制约了其在语音摘要场景的实际落地。为此，我们提出了一种新颖的多阶段强化学习训练框架，用于提升MLLMs的语音摘要能力。该模型在强基线基础上实现了显著提升，不仅性能超越了规模大得多的MLLMs，还大幅缩小了与最先进文本基LLMs的差距。

> Speech summarization is a critical component of spoken content understanding, particularly in the era of rapidly growing spoken and audiovisual data. Recent advances in multi-modal large language models (MLLMs), leveraging the power of LLMs, enable generating textual summaries directly from speech without intermediate transcriptions, while supporting controllable styles and zero-shot generalization. However, open-source MLLMs continue to lag behind the state-of-the-art text-based LLMs, limiting their practical deployment for speech summarization. In this work, we present a novel multi-stage reinforcement learning training framework to enhance the speech summarization capabilities in MLLMs. Our model delivers substantial improvements over strong baselines, outperforms much larger MLLMs, and significantly narrows the gap with state-of-the-art text-based LLMs.

[Arxiv](https://arxiv.org/abs/2509.19631)