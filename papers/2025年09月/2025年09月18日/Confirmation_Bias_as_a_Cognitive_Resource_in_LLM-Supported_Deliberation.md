# 确认偏误：LLM支持审议中的认知资源

发布时间：2025年09月18日

`LLM应用` `基础理论`

> Confirmation Bias as a Cognitive Resource in LLM-Supported Deliberation

# 摘要

> 大型语言模型（LLMs）在群体决策中的应用日益广泛，但其影响却潜藏着助长从众、削弱认知警惕性的风险。借鉴推理论证理论，我们提出：通常被视作弊端的确认偏误，若与批判性评估相结合，便能转化为一种可用资源。我们设计了三步流程：首先，个体独立构思想法；接着，借助LLMs对想法进行打磨与阐述；最后，将LLMs当作“认知挑衅者”，提前预判可能面临的群体质疑。这种定位将LLMs打造成激发分歧的脚手架工具，助力个体为更高效的群体讨论做好准备。

> Large language models (LLMs) are increasingly used in group decision-making, but their influence risks fostering conformity and reducing epistemic vigilance. Drawing on the Argumentative Theory of Reasoning, we argue that confirmation bias, often seen as detrimental, can be harnessed as a resource when paired with critical evaluation. We propose a three-step process in which individuals first generate ideas independently, then use LLMs to refine and articulate them, and finally engage with LLMs as epistemic provocateurs to anticipate group critique. This framing positions LLMs as tools for scaffolding disagreement, helping individuals prepare for more productive group discussions.

[Arxiv](https://arxiv.org/abs/2509.14824)