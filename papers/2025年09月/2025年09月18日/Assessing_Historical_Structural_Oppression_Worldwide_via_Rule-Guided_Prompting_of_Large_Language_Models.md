# 基于大型语言模型的规则引导提示评估全球历史性结构性压迫

发布时间：2025年09月18日

`LLM应用` `医疗健康`

> Assessing Historical Structural Oppression Worldwide via Rule-Guided Prompting of Large Language Models

# 摘要

> 传统上，衡量历史结构性压迫的研究在跨国适用性上一直面临挑战——每个国家都有独特的、植根于本土的排斥史、殖民史和社会地位演变，而现有方法常依赖结构化指数，这类指数偏重物质资源，却忽略了基于身份的真实排斥体验。为此，我们提出一种全新的压迫测量框架：借助大型语言模型（LLMs），在不同地缘政治场景下生成对实际历史劣势的情境敏感评分。我们利用多语言COVID-19全球研究中收集的非结构化自我认同种族表述，设计了规则引导的提示策略，促使模型生成可解释、有理论支撑的压迫估计值。我们在多个最先进的LLM上对这些策略进行了系统评估，结果显示：在明确规则的引导下，LLM能够捕捉到国家内部基于身份的历史压迫的细微表现形式。这种方法提供了一种补充性测量工具，可突出系统性排斥的多个维度，为理解压迫在数据驱动研究和公共卫生领域的表现提供了可扩展的跨文化视角。为支持可重复评估，我们发布了一个开源基准数据集，用于评估LLM在压迫测量任务上的表现（https://github.com/chattergpt/llm-oppression-benchmark）。

> Traditional efforts to measure historical structural oppression struggle with cross-national validity due to the unique, locally specified histories of exclusion, colonization, and social status in each country, and often have relied on structured indices that privilege material resources while overlooking lived, identity-based exclusion. We introduce a novel framework for oppression measurement that leverages Large Language Models (LLMs) to generate context-sensitive scores of lived historical disadvantage across diverse geopolitical settings. Using unstructured self-identified ethnicity utterances from a multilingual COVID-19 global study, we design rule-guided prompting strategies that encourage models to produce interpretable, theoretically grounded estimations of oppression. We systematically evaluate these strategies across multiple state-of-the-art LLMs. Our results demonstrate that LLMs, when guided by explicit rules, can capture nuanced forms of identity-based historical oppression within nations. This approach provides a complementary measurement tool that highlights dimensions of systemic exclusion, offering a scalable, cross-cultural lens for understanding how oppression manifests in data-driven research and public health contexts. To support reproducible evaluation, we release an open-sourced benchmark dataset for assessing LLMs on oppression measurement (https://github.com/chattergpt/llm-oppression-benchmark).

[Arxiv](https://arxiv.org/abs/2509.15216)