# Sentinel智能体：多智能体系统中保障安全可信智能体AI的哨兵智能体

发布时间：2025年09月18日

`Agent` `基础理论`

> Sentinel Agents for Secure and Trustworthy Agentic AI in Multi-Agent Systems

# 摘要

> 本文提出一种新颖的架构框架，旨在提升多智能体系统（MAS）的安全性与可靠性。该框架的核心组件是哨兵智能体网络，它作为分布式安全层，集成了多项技术，如基于大型语言模型（LLMs）的语义分析、行为分析、检索增强验证及跨智能体异常检测。这类智能体能够监督智能体间通信、识别潜在威胁、执行隐私与访问控制，并维护完整的审计记录。与哨兵智能体相辅相成的是协调智能体的引入。协调智能体负责监督策略执行、管理智能体参与，同时接收哨兵智能体发出的警报。基于这些警报，它能够调整策略、隔离行为异常的智能体、遏制威胁，从而维护MAS生态系统的完整性。这种双层安全机制结合了哨兵智能体的持续监控与协调智能体的治理功能，可支持针对多种威胁的动态自适应防御，包括提示注入、智能体合谋行为、LLMs幻觉、隐私泄露及协同多智能体攻击。除架构设计外，我们还开展了模拟研究：在多智能体对话环境中注入了162次不同类型的合成攻击（包括提示注入、幻觉和数据泄露）。哨兵智能体成功检测到所有攻击尝试，验证了所提监控方法的实际可行性。该框架还具备增强的系统可观测性，支持法规合规，并能实现策略的动态演进。

> This paper proposes a novel architectural framework aimed at enhancing security and reliability in multi-agent systems (MAS). A central component of this framework is a network of Sentinel Agents, functioning as a distributed security layer that integrates techniques such as semantic analysis via large language models (LLMs), behavioral analytics, retrieval-augmented verification, and cross-agent anomaly detection. Such agents can potentially oversee inter-agent communications, identify potential threats, enforce privacy and access controls, and maintain comprehensive audit records. Complementary to the idea of Sentinel Agents is the use of a Coordinator Agent. The Coordinator Agent supervises policy implementation, and manages agent participation. In addition, the Coordinator also ingests alerts from Sentinel Agents. Based on these alerts, it can adapt policies, isolate or quarantine misbehaving agents, and contain threats to maintain the integrity of the MAS ecosystem. This dual-layered security approach, combining the continuous monitoring of Sentinel Agents with the governance functions of Coordinator Agents, supports dynamic and adaptive defense mechanisms against a range of threats, including prompt injection, collusive agent behavior, hallucinations generated by LLMs, privacy breaches, and coordinated multi-agent attacks. In addition to the architectural design, we present a simulation study where 162 synthetic attacks of different families (prompt injection, hallucination, and data exfiltration) were injected into a multi-agent conversational environment. The Sentinel Agents successfully detected the attack attempts, confirming the practical feasibility of the proposed monitoring approach. The framework also offers enhanced system observability, supports regulatory compliance, and enables policy evolution over time.

[Arxiv](https://arxiv.org/abs/2509.14956)