# 中间语言至关重要：形式语言与大型语言模型对神经符号推理的影响

发布时间：2025年09月04日

`LLM理论` `基础理论`

> Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning

# 摘要

> 大型语言模型（LLMs）在各类任务中表现惊艳，但在形式推理方面仍显不足。神经符号LLM推理是一种颇具潜力的解决方案，其原理是利用LLMs将自然语言转换为形式语言，再通过符号求解器推导出正确结果。尽管如此，神经符号LLM推理成功的关键影响因素仍不明确。本文研究表明，此前被忽略的一个关键因素是形式语言的选择。我们提出了“中间语言挑战”：即为神经符号推理选择适宜的形式语言。我们在三个数据集和七个LLM上对四种形式语言进行了比较，结果显示形式语言的选择会同时影响句法和语义推理能力。我们还探讨了不同LLM之间的效果差异。

> Large language models (LLMs) achieve astonishing results on a wide range of tasks. However, their formal reasoning ability still lags behind. A promising approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators from natural to formal languages and symbolic solvers for deriving correct results. Still, the contributing factors to the success of Neurosymbolic LLM reasoning remain unclear. This paper demonstrates that one previously overlooked factor is the choice of the formal language. We introduce the intermediate language challenge: selecting a suitable formal language for neurosymbolic reasoning. By comparing four formal languages across three datasets and seven LLMs, we show that the choice of formal language affects both syntactic and semantic reasoning capabilities. We also discuss the varying effects across different LLMs.

[Arxiv](https://arxiv.org/abs/2509.04083)