# 迈向健康模拟的个性化解释：一种以利益相关者为中心的总结混合方法框架

发布时间：2025年09月04日

`LLM应用` `医疗健康`

> Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization

# 摘要

> 建模与仿真（M&S）方法（如基于智能体的模型）在健康领域的决策支持中潜力巨大，近期应用实例包括疫苗接种研究，相关领域还有关于健康饮食与运动行为的丰富文献。这些模型有望服务于多类利益相关者：既能帮助政策制定者预估干预措施的潜在影响，也能引导个人在复杂环境中践行健康选择。然而，模型的复杂性可能阻碍其潜力的充分释放——最能从中获益的利益相关者往往难以驾驭这类模型。尽管大型语言模型（LLMs）能将模拟结果与模型设计转化为文本，但现有方法多采用“一刀切”的摘要模式，难以满足临床医生、政策制定者、患者、护理人员及健康倡导者等不同群体的差异化信息需求与风格偏好。这一局限的根源在于一个核心问题：我们尚未系统掌握这些利益相关者对解释的具体需求，以及如何据此定制化解释内容。为此，我们提出一套循序渐进的框架：先识别利益相关者需求，再引导LLMs生成健康模拟的定制化解释。该流程采用混合方法设计：首先采集各类健康利益相关者的解释需求与风格偏好，接着优化LLMs生成定制化输出的表现（如通过可控属性调优），最后通过多维度指标评估，从而持续优化摘要的定制化生成质量。

> Modeling & Simulation (M&S) approaches such as agent-based models hold significant potential to support decision-making activities in health, with recent examples including the adoption of vaccines, and a vast literature on healthy eating behaviors and physical activity behaviors. These models are potentially usable by different stakeholder groups, as they support policy-makers to estimate the consequences of potential interventions and they can guide individuals in making healthy choices in complex environments. However, this potential may not be fully realized because of the models' complexity, which makes them inaccessible to the stakeholders who could benefit the most. While Large Language Models (LLMs) can translate simulation outputs and the design of models into text, current approaches typically rely on one-size-fits-all summaries that fail to reflect the varied informational needs and stylistic preferences of clinicians, policymakers, patients, caregivers, and health advocates. This limitation stems from a fundamental gap: we lack a systematic understanding of what these stakeholders need from explanations and how to tailor them accordingly. To address this gap, we present a step-by-step framework to identify stakeholder needs and guide LLMs in generating tailored explanations of health simulations. Our procedure uses a mixed-methods design by first eliciting the explanation needs and stylistic preferences of diverse health stakeholders, then optimizing the ability of LLMs to generate tailored outputs (e.g., via controllable attribute tuning), and then evaluating through a comprehensive range of metrics to further improve the tailored generation of summaries.

[Arxiv](https://arxiv.org/abs/2509.04646)