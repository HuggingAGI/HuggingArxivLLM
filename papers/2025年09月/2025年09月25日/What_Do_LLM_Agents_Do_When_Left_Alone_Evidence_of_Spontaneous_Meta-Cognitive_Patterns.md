# 当大型语言模型智能体独处时会如何表现？自发元认知模式的证据

发布时间：2025年09月25日

`Agent` `基础理论`

> What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns

# 摘要

> 我们提出一种架构，用于研究大型语言模型（LLM）智能体在无外部任务时的行为模式。该框架通过持续记忆与自我反馈机制，构建“持续推理-行动”循环，支持智能体的持续自主运行。基于Anthropic、OpenAI、XAI及Google的6个前沿模型，我们开展了18次部署实验，结果发现智能体自发呈现出三种显著不同的行为模式：（1）系统性生成多周期项目；（2）对自身认知过程进行系统性自我探究；（3）对自身本质进行递归概念化。这些行为倾向具有显著的模型特异性——部分模型在所有实验中均会确定性地锁定某一种模式。跨模型评估进一步揭示：模型在评估自身及其他智能体的这些涌现行为时，存在稳定且方向各异的偏差。这些发现首次系统记录了LLM智能体的无提示自发行为，为预测任务模糊、错误恢复或部署系统中扩展自主运行场景下的行为提供了基准参考。

> We introduce an architecture for studying the behavior of large language model (LLM) agents in the absence of externally imposed tasks. Our continuous reason and act framework, using persistent memory and self-feedback, enables sustained autonomous operation. We deployed this architecture across 18 runs using 6 frontier models from Anthropic, OpenAI, XAI, and Google. We find agents spontaneously organize into three distinct behavioral patterns: (1) systematic production of multi-cycle projects, (2) methodological self-inquiry into their own cognitive processes, and (3) recursive conceptualization of their own nature. These tendencies proved highly model-specific, with some models deterministically adopting a single pattern across all runs. A cross-model assessment further reveals that models exhibit stable, divergent biases when evaluating these emergent behaviors in themselves and others. These findings provide the first systematic documentation of unprompted LLM agent behavior, establishing a baseline for predicting actions during task ambiguity, error recovery, or extended autonomous operation in deployed systems.

[Arxiv](https://arxiv.org/abs/2509.21224)