# # 大型语言模型的沟通偏差：监管视角

发布时间：2025年09月25日

`其他` `法律科技`

> Communication Bias in Large Language Models: A Regulatory Perspective

# 摘要

> 大型语言模型（LLMs）在众多应用中愈发核心，引发了人们对偏见、公平性及合规性的担忧。本文回顾了偏见性输出的风险及其社会影响，重点探讨欧盟《人工智能法案》《数字服务法案》等框架。我们认为，除持续监管外，还需加强对竞争与设计治理的关注，以保障人工智能的公平与可信。本文为《ACM通讯》同名文章的预印本。

> Large language models (LLMs) are increasingly central to many applications, raising concerns about bias, fairness, and regulatory compliance. This paper reviews risks of biased outputs and their societal impact, focusing on frameworks like the EU's AI Act and the Digital Services Act. We argue that beyond constant regulation, stronger attention to competition and design governance is needed to ensure fair, trustworthy AI. This is a preprint of the Communications of the ACM article of the same title.

[Arxiv](https://arxiv.org/abs/2509.21075)