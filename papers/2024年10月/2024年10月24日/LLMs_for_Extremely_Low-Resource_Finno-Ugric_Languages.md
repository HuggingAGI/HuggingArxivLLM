# 面向极低资源芬兰-乌戈尔语系的LLMs

发布时间：2024年10月24日

`LLM应用

理由：这篇论文主要关注的是如何将大型语言模型（LLMs）应用于低资源语言的处理，包括数据收集、指令微调和评估等步骤。论文的目标是推动语言多样性，使资源较少的语言也能从NLP的进步中受益。因此，这篇论文属于LLM应用的范畴。` `多语言`

> LLMs for Extremely Low-Resource Finno-Ugric Languages

# 摘要

> 大型语言模型（LLMs）的进展主要聚焦于高资源语言，而低资源语言，如芬兰-乌戈尔语系的语言，则鲜有涉及。本文以沃罗语、利沃尼亚语和科米语为研究对象，填补了这一空白。我们几乎涵盖了LLM创建的整个生命周期，从数据收集到指令微调和评估。我们的贡献包括开发多语言基础和指令微调模型、创建smugri-MT-bench多轮对话评估基准，以及进行人类评估。我们希望通过这项工作推动语言多样性，让资源较少的语言也能从NLP的进步中受益。

> The advancement of large language models (LLMs) has predominantly focused on high-resource languages, leaving low-resource languages, such as those in the Finno-Ugric family, significantly underrepresented. This paper addresses this gap by focusing on Võro, Livonian, and Komi. We cover almost the entire cycle of LLM creation, from data collection to instruction tuning and evaluation. Our contributions include developing multilingual base and instruction-tuned models; creating evaluation benchmarks, including the smugri-MT-bench multi-turn conversational benchmark; and conducting human evaluation. We intend for this work to promote linguistic diversity, ensuring that lesser-resourced languages can benefit from advancements in NLP.

[Arxiv](https://arxiv.org/abs/2410.18902)