# AI助力选举谣言预防：提升美国选举信心

发布时间：2024年10月24日

`LLM应用`

> Prebunking Elections Rumors: Artificial Intelligence Assisted Interventions Increase Confidence in American Elections

# 摘要

> 大型语言模型（LLMs）在预防选举错误信息方面大有可为。基于2024年8月对4,293名美国注册选民的两波实验研究，我们发现LLM辅助的预防措施显著降低了对特定选举谣言的信任，且效果至少持续一周。治疗后，选民对选举完整性的信心也有所提升。值得注意的是，即使在控制人口统计和态度因素（如阴谋论思维）的情况下，这种效果在党派之间依然一致。LLM辅助的预防措施是快速应对选举错误信息变化的利器。

> Large Language Models (LLMs) can assist in the prebunking of election misinformation. Using results from a preregistered two-wave experimental study of 4,293 U.S. registered voters conducted in August 2024, we show that LLM-assisted prebunking significantly reduced belief in specific election myths,with these effects persisting for at least one week. Confidence in election integrity was also increased post-treatment. Notably, the effect was consistent across partisan lines, even when controlling for demographic and attitudinal factors like conspiratorial thinking. LLM-assisted prebunking is a promising tool for rapidly responding to changing election misinformation narratives.

[Arxiv](https://arxiv.org/abs/2410.19202)