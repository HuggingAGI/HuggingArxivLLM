# LLM安全评估的阿拉伯语数据集

发布时间：2024年10月22日

`LLM应用` `安全评估`

> Arabic Dataset for LLM Safeguard Evaluation

# 摘要

> 随着大型语言模型（LLMs）的广泛应用，其安全性问题备受关注。尽管英语领域的研究众多，但阿拉伯语因其语言和文化的复杂性，LLMs的安全性仍未被充分探讨。为此，我们致力于填补这一空白。我们特别推出了一个针对阿拉伯地区的安全评估数据集，包含5,799个问题，涵盖直接攻击、间接攻击和带有敏感词汇的无害请求，这些问题经过调整以反映阿拉伯世界的社会文化背景。为了揭示处理敏感和有争议话题时不同立场的影响，我们提出了一个双视角评估框架，从政府和反对派两个角度评估LLMs的响应。通过对五个领先的阿拉伯语和多语言LLMs的实验，我们发现它们在安全性表现上存在显著差异。这凸显了需要特定文化的数据集来确保LLMs的负责任部署。

> The growing use of large language models (LLMs) has raised concerns regarding their safety. While many studies have focused on English, the safety of LLMs in Arabic, with its linguistic and cultural complexities, remains under-explored. Here, we aim to bridge this gap. In particular, we present an Arab-region-specific safety evaluation dataset consisting of 5,799 questions, including direct attacks, indirect attacks, and harmless requests with sensitive words, adapted to reflect the socio-cultural context of the Arab world. To uncover the impact of different stances in handling sensitive and controversial topics, we propose a dual-perspective evaluation framework. It assesses the LLM responses from both governmental and opposition viewpoints. Experiments over five leading Arabic-centric and multilingual LLMs reveal substantial disparities in their safety performance. This reinforces the need for culturally specific datasets to ensure the responsible deployment of LLMs.

[Arxiv](https://arxiv.org/abs/2410.17040)