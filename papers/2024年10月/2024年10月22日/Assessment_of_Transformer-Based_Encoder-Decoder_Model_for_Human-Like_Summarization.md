# # 基于Transformer的编码器-解码器模型的人类化摘要评估

发布时间：2024年10月22日

`LLM应用

**解释**：这篇论文主要讨论了使用基于Transformer的BART模型进行自动文本摘要生成，并对其性能进行了评估和改进。这属于大型语言模型（LLM）在实际应用中的使用，因此分类为LLM应用。` `社交媒体`

> Assessment of Transformer-Based Encoder-Decoder Model for Human-Like Summarization

# 摘要

> 近年来，从海量文本中提取有价值信息的进展显著。尤其在社交媒体时代，人们渴望快速获取信息。自动文本摘要通过将冗长文本压缩为简洁摘要，解决了这一需求。这一研究领域通过挖掘文本中的关键内容，助力决策制定。随着深度学习模型的进步，语言模型领域涌现出大量重要成果。其中，编码器-解码器框架已成为自动文本摘要的核心方法。本研究采用基于Transformer的BART模型进行类人摘要生成，这一开放性问题充满挑战。在对编码器-解码器模型进行训练和微调后，我们使用多样化样本文章进行测试，并基于人工评估参数评估摘要质量。此外，我们基于ROUGE分数和BERTScore等评估指标，将微调模型与基线预训练模型进行性能对比。为提高对话者间对话的抽象摘要性能，模型还需进行领域适应。研究发现，现有评估指标对事实错误不敏感。为此，我们进一步使用WeCheck和SummaC等当代事实一致性评估指标，对微调模型生成的摘要进行了深入分析。在BBC新闻文章上的实验结果表明，人类编写的黄金标准摘要比微调模型生成的摘要事实一致性高出17%。

> In recent times, extracting valuable information from large text is making significant progress. Especially in the current era of social media, people expect quick bites of information. Automatic text summarization seeks to tackle this by slimming large texts down into more manageable summaries. This important research area can aid in decision-making by digging out salient content from large text. With the progress in deep learning models, significant work in language models has emerged. The encoder-decoder framework in deep learning has become the central approach for automatic text summarization. This work leverages transformer-based BART model for human-like summarization which is an open-ended problem with many challenges. On training and fine-tuning the encoder-decoder model, it is tested with diverse sample articles and the quality of summaries of diverse samples is assessed based on human evaluation parameters. Further, the finetuned model performance is compared with the baseline pretrained model based on evaluation metrics like ROUGE score and BERTScore. Additionally, domain adaptation of the model is required for improved performance of abstractive summarization of dialogues between interlocutors. On investigating, the above popular evaluation metrics are found to be insensitive to factual errors. Further investigation of the summaries generated by finetuned model is done using the contemporary evaluation metrics of factual consistency like WeCheck and SummaC. Empirical results on BBC News articles highlight that the gold standard summaries written by humans are more factually consistent by 17% than the abstractive summaries generated by finetuned model.

[Arxiv](https://arxiv.org/abs/2410.16842)