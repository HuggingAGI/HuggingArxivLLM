# 基于GRE分析性写作评估的AI生成文章评价

发布时间：2024年10月22日

`LLM应用

理由：这篇论文主要关注的是大型语言模型（LLMs）在生成文本质量评估中的应用，特别是针对GRE分析性写作评估的表现。研究通过人类评分员和自动评分引擎对LLMs生成的文本进行评估，并分析了检测器的准确性。这些内容属于LLM在实际应用中的表现和评估，因此归类为“LLM应用”。`

> Evaluating AI-Generated Essays with GRE Analytical Writing Assessment

# 摘要

> 生成式AI的最新突破让大型语言模型（LLMs）能够生成逼真且连贯的文本。尽管已有多种评估生成文本质量的指标，但对LLMs在复杂且高要求的写作评估中的表现仍缺乏严格评估。本研究分析了十个领先LLMs为GRE分析性写作评估生成的文章，并采用GRE评分流程中的人类评分员和e-rater自动评分引擎进行评估。表现最佳的GPT-4o平均得分为4.67，介于“分析深入、表达清晰”和“分析合格、表达尚可”之间。我们还评估了这些文章的检测准确性，检测器基于相同和不同LLMs生成的文章进行训练。

> The recent revolutionary advance in generative AI enables the generation of realistic and coherent texts by large language models (LLMs). Despite many existing evaluation metrics on the quality of the generated texts, there is still a lack of rigorous assessment of how well LLMs perform in complex and demanding writing assessments. This study examines essays generated by ten leading LLMs for the analytical writing assessment of the Graduate Record Exam (GRE). We assessed these essays using both human raters and the e-rater automated scoring engine as used in the GRE scoring pipeline. Notably, the top-performing GPT-4o received an average score of 4.67, falling between "generally thoughtful, well-developed analysis of the issue and conveys meaning clearly" and "presents a competent analysis of the issue and conveys meaning with acceptable clarity" according to the GRE scoring guideline. We also evaluated the detection accuracy of these essays, with detectors trained on essays generated by the same and different LLMs.

[Arxiv](https://arxiv.org/abs/2410.17439)