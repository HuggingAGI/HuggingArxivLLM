# # 摘要  
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2024年10月03日

`LLM理论` `人工智能`

> Bias Amplification in Language Model Evolution: An Iterated Learning Perspective

# 摘要

> 大型语言模型（LLMs）的广泛应用使得模型间的迭代互动更加普遍。近期，多轮自我改进方法的突破让LLMs能够为后续模型生成新训练样本，同时多智能体LLM系统也逐渐兴起，推动了智能体间的自动化交互。因此，无论是短期还是长期，LLMs都可能主动参与一种进化过程。我们发现，LLMs的行为与人类文化进化有相似之处，后者已被认知科学家长期研究。我们借助迭代学习（IL）这一贝叶斯框架，揭示人类文化进化中微妙偏见被放大的机制，以此解释LLMs的部分行为。本文通过实验验证，探讨了贝叶斯-IL框架下智能体行为的关键特征，这些预测得到了多种LLMs的支持。这一理论框架有望为预测和引导LLMs向理想方向进化提供有效工具。

> With the widespread adoption of Large Language Models (LLMs), the prevalence of iterative interactions among these models is anticipated to increase. Notably, recent advancements in multi-round self-improving methods allow LLMs to generate new examples for training subsequent models. At the same time, multi-agent LLM systems, involving automated interactions among agents, are also increasing in prominence. Thus, in both short and long terms, LLMs may actively engage in an evolutionary process. We draw parallels between the behavior of LLMs and the evolution of human culture, as the latter has been extensively studied by cognitive scientists for decades. Our approach involves leveraging Iterated Learning (IL), a Bayesian framework that elucidates how subtle biases are magnified during human cultural evolution, to explain some behaviors of LLMs. This paper outlines key characteristics of agents' behavior in the Bayesian-IL framework, including predictions that are supported by experimental verification with various LLMs. This theoretical framework could help to more effectively predict and guide the evolution of LLMs in desired directions.

[Arxiv](https://arxiv.org/abs/2404.04286)