# AgentSense：借助交互式场景为语言智能体的社会智能设立基准

发布时间：2024年10月25日

`Agent` `行为研究` `社会智能`

> AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios

# 摘要

> 大型语言模型（LLMs）愈发被用于助力自主代理在行为研究的众多领域模拟人类。然而，评估它们应对复杂社会互动的能力仍是难题。过往研究因场景多样性与复杂性不足，以及视角单一而受限。为此，我们推出了 AgentSense：通过交互式场景为语言代理的社会智能设立基准。依托戏剧理论，AgentSense 采用自下而上的方式，从众多脚本中构建出 1225 个多样的社会场景。我们通过多轮交互来评估 LLM 驱动的代理，着重于目标达成和隐性推理。我们运用 ERG 理论分析目标，并开展全面实验。我们的发现表明，LLMs 在复杂社会场景中实现目标存在困难，特别是高级的成长需求方面，就连 GPT-4o 在私人信息推理上也有待提升。

> Large language models (LLMs) are increasingly leveraged to empower autonomous agents to simulate human beings in various fields of behavioral research. However, evaluating their capacity to navigate complex social interactions remains a challenge. Previous studies face limitations due to insufficient scenario diversity, complexity, and a single-perspective focus. To this end, we introduce AgentSense: Benchmarking Social Intelligence of Language Agents through Interactive Scenarios. Drawing on Dramaturgical Theory, AgentSense employs a bottom-up approach to create 1,225 diverse social scenarios constructed from extensive scripts. We evaluate LLM-driven agents through multi-turn interactions, emphasizing both goal completion and implicit reasoning. We analyze goals using ERG theory and conduct comprehensive experiments. Our findings highlight that LLMs struggle with goals in complex social scenarios, especially high-level growth needs, and even GPT-4o requires improvement in private information reasoning.

[Arxiv](https://arxiv.org/abs/2410.19346)