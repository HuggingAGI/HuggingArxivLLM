# CoPS: 让LLM代理具备可验证的跨任务经验共享能力

发布时间：2024年10月21日

`Agent

理由：这篇论文主要讨论了如何通过跨任务经验共享和选择来增强智能体系统中的顺序推理能力。论文提出的CoPS算法旨在利用智能体在先前任务中的经验，通过一种可证明的悲观主义策略选择分布匹配的经验，从而提升智能体在不同任务中的泛化能力和适应性。虽然论文中提到了大型语言模型（LLMs）的作用，但核心内容集中在智能体的推理和决策过程上，因此更适合归类为Agent。` `智能体系统` `顺序推理`

> CoPS: Empowering LLM Agents with Provable Cross-Task Experience Sharing

# 摘要

> # 摘要
大型语言模型（LLMs）显著推动了智能体系统中的顺序推理，但现有方法仍有局限。反思驱动的推理仅依赖预训练模型的知识，限制了新场景中的表现；而经验辅助的推理则依赖外部经验，缺乏选择代表性经验的明确原则。为此，我们提出了CoPS（跨任务经验共享），一种通过跨任务经验共享和选择来增强顺序推理的通用算法。CoPS利用智能体在先前任务中的经验，通过一种可证明的悲观主义策略选择分布匹配的经验，最大化效用并最小化分布变化的风险。在Alfworld、Webshop和HotPotQA等基准上的实验表明，CoPS始终优于最先进的基线方法，且样本效率高，适用于资源受限场景。理论上，我们证明了算法的性能取决于预训练LLM的质量以及智能体任务依赖的试验分布与LLM生成分布之间的匹配。我们的工作填补了现有顺序推理范式的空白，验证了跨任务经验的有效性，为提升智能体在不同任务中的泛化能力和适应性提供了新思路。代码已开源：$\href{https://github.com/uclaml/COPS}{	ext{https://github.com/uclaml/COPS}}$。

> Sequential reasoning in agent systems has been significantly advanced by large language models (LLMs), yet existing approaches face limitations. Reflection-driven reasoning relies solely on knowledge in pretrained models, limiting performance in novel scenarios, while experience-assisted reasoning often depends on external experiences and lacks clear principles for selecting representative experiences. We address these limitations by proposing CoPS (Cross-Task Experience Sharing), a generalizable algorithm that enhances sequential reasoning by cross-task experience sharing and selection. In detail, CoPS leverages agents' experiences on previous tasks, selecting distribution-matched experiences via a provable pessimism-based strategy to maximize utility while minimizing risks from distribution shifts. Extensive experimental results on benchmarks like Alfworld, Webshop, and HotPotQA demonstrate that CoPS consistently outperforms state-of-the-art baselines, with superior sample efficiency suitable for resource-constrained scenarios. Theoretically, we show that the performance of our algorithm depends on both the quality of the pretrained LLM and the matching between the agent's task-dependent trial distribution and that generated by the LLM. Our work bridges the gap between existing sequential reasoning paradigms and validates the effectiveness of leveraging cross-task experiences, shedding light on the potential to improve agents' generalization and adaptability across diverse tasks. Our codes are available at $\href{https://github.com/uclaml/COPS}{\text{https://github.com/uclaml/COPS}}$.

[Arxiv](https://arxiv.org/abs/2410.16670)