# 大型语言模型在借助外部知识进行多跳推理时依旧面临诸多挑战。

发布时间：2024年12月11日

`LLM应用` `语言模型`

> Large Language Models Still Face Challenges in Multi-Hop Reasoning with External Knowledge

# 摘要

> 我们从三个方面开展了一系列实验，以测试大型语言模型的多跳推理能力，即：选择与组合外部知识、处理非顺序推理任务以及在更多跳数的数据样本上进行泛化。我们用思维链提示（及其变体）在四个推理基准上对 GPT-3.5 模型进行了测试。结果显示，尽管大型语言模型在各类推理任务中表现出色，但仍存在严重缺陷，与人类有很大差距。

> We carry out a series of experiments to test large language models' multi-hop reasoning ability from three aspects: selecting and combining external knowledge, dealing with non-sequential reasoning tasks and generalising to data samples with larger numbers of hops. We test the GPT-3.5 model on four reasoning benchmarks with Chain-of-Thought prompting (and its variations). Our results reveal that despite the amazing performance achieved by large language models on various reasoning tasks, models still suffer from severe drawbacks which shows a large gap with humans.

[Arxiv](https://arxiv.org/abs/2412.08317)