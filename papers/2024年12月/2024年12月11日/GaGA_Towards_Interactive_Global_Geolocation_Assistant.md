# GaGA：走向交互式全球地理定位助手

发布时间：2024年12月11日

`LLM应用` `计算机视觉` `地理定位`

> GaGA: Towards Interactive Global Geolocation Assistant

# 摘要

> 全球地理定位，即预测在全球任何地方拍摄的图像的地理位置，是计算机视觉领域极具挑战性的任务之一。在本文中，我们推出了一款创新的交互式全球地理定位助手——GaGA，它基于蓬勃发展的大型视觉语言模型（LVLMs）构建。GaGA 能挖掘图像中的地理线索，并结合 LVLMs 中蕴含的丰富世界知识来确定地理位置，同时为预测结果提供依据和解释。我们还设计了一种新颖的交互式地理定位方法，超越了传统的静态推理方式。它允许用户干预、修正或为预测提供线索，让模型更灵活实用。GaGA 的开发依托新提出的多模态全球地理定位（MG-Geo）数据集，这是一个涵盖 500 万高质量图像 - 文本对的综合集合。GaGA 在 GWS15k 数据集上表现出色，在国家层面准确率提高了 4.57％，在城市层面提高了 2.92％，创下新标杆。这些进展意味着在开发具有全球适用性的高精度、交互式地理定位系统方面实现了重大突破。

> Global geolocation, which seeks to predict the geographical location of images captured anywhere in the world, is one of the most challenging tasks in the field of computer vision. In this paper, we introduce an innovative interactive global geolocation assistant named GaGA, built upon the flourishing large vision-language models (LVLMs). GaGA uncovers geographical clues within images and combines them with the extensive world knowledge embedded in LVLMs to determine the geolocations while also providing justifications and explanations for the prediction results. We further designed a novel interactive geolocation method that surpasses traditional static inference approaches. It allows users to intervene, correct, or provide clues for the predictions, making the model more flexible and practical. The development of GaGA relies on the newly proposed Multi-modal Global Geolocation (MG-Geo) dataset, a comprehensive collection of 5 million high-quality image-text pairs. GaGA achieves state-of-the-art performance on the GWS15k dataset, improving accuracy by 4.57% at the country level and 2.92% at the city level, setting a new benchmark. These advancements represent a significant leap forward in developing highly accurate, interactive geolocation systems with global applicability.

[Arxiv](https://arxiv.org/abs/2412.08907)