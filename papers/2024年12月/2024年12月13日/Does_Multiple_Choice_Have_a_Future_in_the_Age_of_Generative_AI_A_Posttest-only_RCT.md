# 在生成式人工智能的时代，多项选择题是否还有未来？一项仅进行后测的随机对照试验

发布时间：2024年12月13日

`LLM应用` `教学评估`

> Does Multiple Choice Have a Future in the Age of Generative AI? A Posttest-only RCT

# 摘要

> 多项选择题（MCQs）作为有效学习工具的作用在过往研究中饱受争议。虽说因其评分简便而被广泛运用，不过随着大型语言模型（LLMs）在自动评分上的进步，开放式回答问题在教学中也愈发常用。本研究对多项选择题相对于开放式回答问题在学习方面的成效进行了评估，包括单独使用及组合使用的情况。这些活动被嵌入到关于倡导的六个辅导课程里。通过仅后测的随机对照设计，我们对比了 234 名辅导教师（790 次课程完成情况）在以下三种情形中的表现：仅多项选择题、仅开放式回答、以及两者结合。我们发现后测中不同情形之间的学习差异并不显著，但处于多项选择题情形的辅导教师完成教学所花费的时间明显更少。这些结果表明，在练习时间有限时，多项选择题在学习上与开放式回答任务同样有效，且效率更高。为进一步提升效率，我们使用 GPT-4o 和 GPT-4-turbo 对开放式回答进行自动评分。GPT 模型在低风险评估中表现良好，但要更广泛应用还需进一步研究。本研究贡献了课程日志数据、人工注释准则和 LLM 提示的数据集，以增进透明度和可重复性。

> The role of multiple-choice questions (MCQs) as effective learning tools has been debated in past research. While MCQs are widely used due to their ease in grading, open response questions are increasingly used for instruction, given advances in large language models (LLMs) for automated grading. This study evaluates MCQs effectiveness relative to open-response questions, both individually and in combination, on learning. These activities are embedded within six tutor lessons on advocacy. Using a posttest-only randomized control design, we compare the performance of 234 tutors (790 lesson completions) across three conditions: MCQ only, open response only, and a combination of both. We find no significant learning differences across conditions at posttest, but tutors in the MCQ condition took significantly less time to complete instruction. These findings suggest that MCQs are as effective, and more efficient, than open response tasks for learning when practice time is limited. To further enhance efficiency, we autograded open responses using GPT-4o and GPT-4-turbo. GPT models demonstrate proficiency for purposes of low-stakes assessment, though further research is needed for broader use. This study contributes a dataset of lesson log data, human annotation rubrics, and LLM prompts to promote transparency and reproducibility.

[Arxiv](https://arxiv.org/abs/2412.10267)