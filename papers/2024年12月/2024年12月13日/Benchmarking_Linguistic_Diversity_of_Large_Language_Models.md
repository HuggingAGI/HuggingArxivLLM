# 对大型语言模型的语言多样性进行基准测试

发布时间：2024年12月13日

`LLM应用` `语言模型`

> Benchmarking Linguistic Diversity of Large Language Models

# 摘要

> 大型语言模型（LLMs）的开发与评估重点多在其任务解决能力上，近来部分模型甚至在某些领域超越了人类表现。但这种侧重往往忽视了机器生成语言在词汇选用、句法结构及意义表达等方面能否达到人类的多样水平，从而引发了语言生成的根本问题是否得到妥善处理的疑问。鉴于由LLMs生成或辅助生成的在线内容大幅增加，本文强调了考察语言模型对人类语言丰富性的保留情况的重要性。我们提出了一个从词汇、句法和语义等多个语言多样性维度评估LLMs的综合框架。运用此框架，我们对若干最先进的LLMs在所有多样性维度上进行了基准测试，并针对句法多样性展开了深入的案例研究。最后，我们剖析了不同的开发和部署选择对LLM输出的语言多样性有何影响。

> The development and evaluation of Large Language Models (LLMs) has primarily focused on their task-solving capabilities, with recent models even surpassing human performance in some areas. However, this focus often neglects whether machine-generated language matches the human level of diversity, in terms of vocabulary choice, syntactic construction, and expression of meaning, raising questions about whether the fundamentals of language generation have been fully addressed. This paper emphasizes the importance of examining the preservation of human linguistic richness by language models, given the concerning surge in online content produced or aided by LLMs. We propose a comprehensive framework for evaluating LLMs from various linguistic diversity perspectives including lexical, syntactic, and semantic dimensions. Using this framework, we benchmark several state-of-the-art LLMs across all diversity dimensions, and conduct an in-depth case study for syntactic diversity. Finally, we analyze how different development and deployment choices impact the linguistic diversity of LLM outputs.

[Arxiv](https://arxiv.org/abs/2412.10271)