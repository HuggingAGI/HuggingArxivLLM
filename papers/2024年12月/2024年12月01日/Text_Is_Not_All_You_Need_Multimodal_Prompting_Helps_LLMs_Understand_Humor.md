# 文本并非您的唯一所需：多模态提示能够助力大型语言模型理解幽默。

发布时间：2024年12月01日

`LLM应用` `幽默研究`

> Text Is Not All You Need: Multimodal Prompting Helps LLMs Understand Humor

# 摘要

> 尽管大型语言模型（LLMs）在各类基于文本的任务里展现出了出色的自然语言理解能力，然而理解幽默却始终是个难题。幽默往往是多模态的，依靠语音的歧义、节奏和时机来传递含义。在本研究中，我们探索了一种用于理解和解释幽默的简单多模态提示方法。我们给一个LLM同时呈现了一个笑话的文本和口语形式，口语形式由现成的文本转语音（TTS）系统生成。在所有测试的数据集中，相比文本提示，使用多模态提示提升了对幽默的解释效果。

> While Large Language Models (LLMs) have demonstrated impressive natural language understanding capabilities across various text-based tasks, understanding humor has remained a persistent challenge. Humor is frequently multimodal, relying on phonetic ambiguity, rhythm and timing to convey meaning. In this study, we explore a simple multimodal prompting approach to humor understanding and explanation. We present an LLM with both the text and the spoken form of a joke, generated using an off-the-shelf text-to-speech (TTS) system. Using multimodal cues improves the explanations of humor compared to textual prompts across all tested datasets.

[Arxiv](https://arxiv.org/abs/2412.05315)