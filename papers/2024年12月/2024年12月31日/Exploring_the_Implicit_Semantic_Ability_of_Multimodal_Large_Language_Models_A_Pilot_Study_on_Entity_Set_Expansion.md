# 探索多模态大语言模型的隐含语义能力：实体集扩展的初步研究

发布时间：2024年12月31日

`LLM应用

**理由**：该论文主要探讨了多模态大型语言模型（MLLMs）在多模态实体集扩展（MESE）任务中的应用，并引入了一种新的列表排序方法 LUSAR 来提升模型在该任务中的表现。这属于将大型语言模型应用于具体任务的范畴，因此分类为 **LLM应用**。` `信息检索`

> Exploring the Implicit Semantic Ability of Multimodal Large Language Models: A Pilot Study on Entity Set Expansion

# 摘要

> 多模态大型语言模型（MLLMs）的迅猛发展，为现实应用中的多种任务带来了显著提升。然而，LLMs 在提取隐含语义信息方面仍有不足。本文中，我们将 MLLMs 应用于多模态实体集扩展（MESE）任务，旨在通过同一语义类的新实体扩展少量种子实体，每个实体均附带多模态信息。通过 MESE 任务，我们探索了 MLLMs 在实体级粒度上理解隐含语义信息的能力，并引入了一种将局部分数映射到全局排名的列表排序方法 LUSAR。LUSAR 显著提升了 MLLM 在 MESE 任务中的表现，标志着生成式 MLLM 首次用于 ESE 任务，并拓宽了列表排序的应用范围。

> The rapid development of multimodal large language models (MLLMs) has brought significant improvements to a wide range of tasks in real-world applications. However, LLMs still exhibit certain limitations in extracting implicit semantic information. In this paper, we apply MLLMs to the Multi-modal Entity Set Expansion (MESE) task, which aims to expand a handful of seed entities with new entities belonging to the same semantic class, and multi-modal information is provided with each entity. We explore the capabilities of MLLMs to understand implicit semantic information at the entity-level granularity through the MESE task, introducing a listwise ranking method LUSAR that maps local scores to global rankings. Our LUSAR demonstrates significant improvements in MLLM's performance on the MESE task, marking the first use of generative MLLM for ESE tasks and extending the applicability of listwise ranking.

[Arxiv](https://arxiv.org/abs/2501.00330)