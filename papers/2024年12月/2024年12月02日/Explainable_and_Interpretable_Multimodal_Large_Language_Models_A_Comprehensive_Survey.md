# 可解释与可理解的多模态大型语言模型：全面综述

发布时间：2024年12月02日

`LLM应用` `人工智能` `多模态`

> Explainable and Interpretable Multimodal Large Language Models: A Comprehensive Survey

# 摘要

> 人工智能（AI）的迅猛发展给众多领域带来了变革，大型语言模型（LLMs）和计算机视觉（CV）系统分别推动了自然语言理解和视觉处理的进步。这些技术的融合促使多模态AI兴起，实现了涵盖文本、视觉、音频和视频模式的更丰富的跨模态理解。尤其是多模态大型语言模型（MLLMs）已成为强大的框架，在图像-文本生成、视觉问答和跨模态检索等任务中表现出色。然而，尽管有这些进步，MLLMs的复杂性和规模在可解释性和可说明性方面带来了显著挑战，这对于在高风险应用中建立透明度、可信度和可靠性至关重要。本文对MLLMs的可解释性和可说明性展开了全面调研，提出了一个新框架，从三个视角对现有研究进行归类：（I）数据，（II）模型，（III）训练与推理。我们系统地分析了从标记层到嵌入层表示的可解释性，评估了与架构分析和设计相关的方法，并探讨了能提高透明度的训练和推理策略。通过对比各种方法，我们明确了它们的优势和局限，并提出了未来的研究方向，以应对多模态可解释性中的未决挑战。此次调研为提升MLLMs的可解释性和透明度提供了基础资源，引领研究人员和从业者开发更负责、更强大的多模态AI系统。

> The rapid development of Artificial Intelligence (AI) has revolutionized numerous fields, with large language models (LLMs) and computer vision (CV) systems driving advancements in natural language understanding and visual processing, respectively. The convergence of these technologies has catalyzed the rise of multimodal AI, enabling richer, cross-modal understanding that spans text, vision, audio, and video modalities. Multimodal large language models (MLLMs), in particular, have emerged as a powerful framework, demonstrating impressive capabilities in tasks like image-text generation, visual question answering, and cross-modal retrieval. Despite these advancements, the complexity and scale of MLLMs introduce significant challenges in interpretability and explainability, essential for establishing transparency, trustworthiness, and reliability in high-stakes applications. This paper provides a comprehensive survey on the interpretability and explainability of MLLMs, proposing a novel framework that categorizes existing research across three perspectives: (I) Data, (II) Model, (III) Training \& Inference. We systematically analyze interpretability from token-level to embedding-level representations, assess approaches related to both architecture analysis and design, and explore training and inference strategies that enhance transparency. By comparing various methodologies, we identify their strengths and limitations and propose future research directions to address unresolved challenges in multimodal explainability. This survey offers a foundational resource for advancing interpretability and transparency in MLLMs, guiding researchers and practitioners toward developing more accountable and robust multimodal AI systems.

[Arxiv](https://arxiv.org/abs/2412.02104)