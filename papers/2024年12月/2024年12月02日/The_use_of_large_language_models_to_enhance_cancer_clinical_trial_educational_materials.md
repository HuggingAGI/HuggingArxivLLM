# 利用大型语言模型来强化癌症临床试验的教育材料

发布时间：2024年12月02日

`LLM应用` `临床试验`

> The use of large language models to enhance cancer clinical trial educational materials

# 摘要

> 癌症临床试验常常因缺乏面向参与者的信息和教育资源，在招募和参与环节遭遇难题。本研究探索了大型语言模型（LLMs），尤其是 GPT4，从临床试验知情同意书生成对患者友好的教育内容的潜力。借助 ClinicalTrials.gov 的数据，我们运用零次学习创建试验总结，运用单次学习开发多项选择题，并通过患者调查和众包标注来评估其效果。结果显示，GPT4 生成的总结既易读又全面，或许能增进患者对临床试验的理解和兴趣。多项选择题展现出高准确率，且与众包标注者的意见相符。对于这两类资源，都存在需要持续人工监管的幻觉问题。这些发现表明，LLMs“开箱即用”有潜力在极少的特定试验工程下支持生成临床试验教育材料，但仍需人工介入以规避错误信息风险。

> Cancer clinical trials often face challenges in recruitment and engagement due to a lack of participant-facing informational and educational resources. This study investigated the potential of Large Language Models (LLMs), specifically GPT4, in generating patient-friendly educational content from clinical trial informed consent forms. Using data from ClinicalTrials.gov, we employed zero-shot learning for creating trial summaries and one-shot learning for developing multiple-choice questions, evaluating their effectiveness through patient surveys and crowdsourced annotation. Results showed that GPT4-generated summaries were both readable and comprehensive, and may improve patients' understanding and interest in clinical trials. The multiple-choice questions demonstrated high accuracy and agreement with crowdsourced annotators. For both resource types, hallucinations were identified that require ongoing human oversight. The findings demonstrate the potential of LLMs "out-of-the-box" to support the generation of clinical trial education materials with minimal trial-specific engineering, but implementation with a human-in-the-loop is still needed to avoid misinformation risks.

[Arxiv](https://arxiv.org/abs/2412.01955)