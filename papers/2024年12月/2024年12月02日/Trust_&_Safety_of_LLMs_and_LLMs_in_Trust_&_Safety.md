# 大型语言模型的信任与安全以及在信任与安全方面的大型语言模型

发布时间：2024年12月02日

`LLM应用` `信任和安全`

> Trust & Safety of LLMs and LLMs in Trust & Safety

# 摘要

> 近年来，大型语言模型（LLMs）在自然语言处理任务方面展现出的非凡能力，使其备受瞩目。然而，其广泛应用也引发了有关信任和安全的忧虑。此次系统综述深入探究了 LLMs 在信任和安全方面的现有研究态势，尤其聚焦于 LLMs 在信任和安全领域自身的全新应用。我们深挖在维护信任和安全至关重要的领域运用 LLMs 的复杂性，为这一新兴趋势提供了综合视角。
通过整合多项研究的成果，我们明确了关键挑战和潜在的解决办法，旨在让致力于了解 LLMs 与信任和安全之间微妙交互关系的研究人员和从业者从中获益。
本综述就信任和安全领域使用 LLMs 的最佳实践给出了见解，并探讨了诸如提示注入和越狱攻击等新兴风险。最终，该研究有助于更深刻地理解如何有效且负责地运用 LLMs 来提升数字领域的信任和安全。

> In recent years, Large Language Models (LLMs) have garnered considerable attention for their remarkable abilities in natural language processing tasks. However, their widespread adoption has raised concerns pertaining to trust and safety. This systematic review investigates the current research landscape on trust and safety in LLMs, with a particular focus on the novel application of LLMs within the field of Trust and Safety itself. We delve into the complexities of utilizing LLMs in domains where maintaining trust and safety is paramount, offering a consolidated perspective on this emerging trend.\
  By synthesizing findings from various studies, we identify key challenges and potential solutions, aiming to benefit researchers and practitioners seeking to understand the nuanced interplay between LLMs and Trust and Safety.
  This review provides insights on best practices for using LLMs in Trust and Safety, and explores emerging risks such as prompt injection and jailbreak attacks. Ultimately, this study contributes to a deeper understanding of how LLMs can be effectively and responsibly utilized to enhance trust and safety in the digital realm.

[Arxiv](https://arxiv.org/abs/2412.02113)