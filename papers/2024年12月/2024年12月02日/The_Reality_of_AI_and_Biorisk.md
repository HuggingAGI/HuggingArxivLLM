# 《AI 与生物风险的现实状况》

发布时间：2024年12月02日

`LLM应用` `生物风险`

> The Reality of AI and Biorisk

# 摘要

> 要准确且笃定地回答“AI 模型或系统会不会增加生物风险”这个问题，既要有关于 AI 模型或系统如何增加生物风险的合理理论威胁模型，也要有检验该威胁模型的可靠办法。本文对围绕两个 AI 与生物风险威胁模型的现有研究进行了分析：一是通过大型语言模型（LLMs）获取信息和规划，二是在合成新型生物制品时使用支持 AI 的生物工具（BTs）。我们发现，有关 AI 相关生物风险的现有研究还处于起步阶段，常常具有推测性，或者在方法的成熟度和透明度上存在局限。现有文献显示，当下的 LLMs 和 BTs 不会立刻带来风险，还需要做更多工作来开发严格的方法，以弄清楚未来的模型怎样增加生物风险。最后，我们给出了关于如何拓展实证工作以更精准地针对生物风险，并保证研究结果的严谨性和有效性的建议。

> To accurately and confidently answer the question 'could an AI model or system increase biorisk', it is necessary to have both a sound theoretical threat model for how AI models or systems could increase biorisk and a robust method for testing that threat model. This paper provides an analysis of existing available research surrounding two AI and biorisk threat models: 1) access to information and planning via large language models (LLMs), and 2) the use of AI-enabled biological tools (BTs) in synthesizing novel biological artifacts. We find that existing studies around AI-related biorisk are nascent, often speculative in nature, or limited in terms of their methodological maturity and transparency. The available literature suggests that current LLMs and BTs do not pose an immediate risk, and more work is needed to develop rigorous approaches to understanding how future models could increase biorisks. We end with recommendations about how empirical work can be expanded to more precisely target biorisk and ensure rigor and validity of findings.

[Arxiv](https://arxiv.org/abs/2412.01946)