# 大型语言模型与形式方法相融合，打造可信的人工智能代理：路线图

发布时间：2024年12月09日

`LLM应用` `软件工程` `人工智能`

> The Fusion of Large Language Models and Formal Methods for Trustworthy AI Agents: A Roadmap

# 摘要

> 大型语言模型（LLMs）已然成为一种具有变革性的人工智能范式，凭借出色的语言理解和上下文生成能力，对日常生活产生了深远影响。尽管LLMs表现出众，但也面临关键挑战：因其基于学习的本质存在固有局限，容易产出不可靠的结果。另一方面，形式方法（FMs）是一种成熟的计算范式，为系统建模、指定及验证正确性提供了数学上严谨的技术，已在关键任务软件工程、嵌入式系统和网络安全领域广泛应用。然而，FMs在实际场景中部署的主要阻碍在于学习曲线陡峭、缺乏友好的用户界面以及效率和适应性问题。
  本立场文件勾勒出借助LLMs和FMs相互促进来推进下一代可信人工智能系统的路线图。首先，阐述了包括推理和认证技术在内的FMs如何助力LLMs生成更可靠且经过正式认证的输出。接着，强调了LLMs的先进学习能力和适应性能够极大提升现有FM工具的可用性、效率和可扩展性。最后，表明统一这两种计算范式——将LLMs的灵活性与智能和FMs的严谨推理能力相融合——对可信人工智能软件系统的发展具有变革潜力。我们承认，这种整合有望提高软件工程实践的可信度和效率，同时推动能够应对复杂现实挑战的智能FM工具的发展。

> Large Language Models (LLMs) have emerged as a transformative AI paradigm, profoundly influencing daily life through their exceptional language understanding and contextual generation capabilities. Despite their remarkable performance, LLMs face a critical challenge: the propensity to produce unreliable outputs due to the inherent limitations of their learning-based nature. Formal methods (FMs), on the other hand, are a well-established computation paradigm that provides mathematically rigorous techniques for modeling, specifying, and verifying the correctness of systems. FMs have been extensively applied in mission-critical software engineering, embedded systems, and cybersecurity. However, the primary challenge impeding the deployment of FMs in real-world settings lies in their steep learning curves, the absence of user-friendly interfaces, and issues with efficiency and adaptability.
  This position paper outlines a roadmap for advancing the next generation of trustworthy AI systems by leveraging the mutual enhancement of LLMs and FMs. First, we illustrate how FMs, including reasoning and certification techniques, can help LLMs generate more reliable and formally certified outputs. Subsequently, we highlight how the advanced learning capabilities and adaptability of LLMs can significantly enhance the usability, efficiency, and scalability of existing FM tools. Finally, we show that unifying these two computation paradigms -- integrating the flexibility and intelligence of LLMs with the rigorous reasoning abilities of FMs -- has transformative potential for the development of trustworthy AI software systems. We acknowledge that this integration has the potential to enhance both the trustworthiness and efficiency of software engineering practices while fostering the development of intelligent FM tools capable of addressing complex yet real-world challenges.

[Arxiv](https://arxiv.org/abs/2412.06512)