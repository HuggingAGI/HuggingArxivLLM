# 在学校课程中使用聊天机器人：我们对用于自动评估家庭作业的 Fobizz 工具进行测试

发布时间：2024年12月09日

`LLM应用` `人工智能`

> Chatbots im Schulunterricht: Wir testen das Fobizz-Tool zur automatischen Bewertung von Hausaufgaben

# 摘要

> 本研究对德国 Fobizz 公司的人工智能评分工具“AI 评分助手”进行了考察，其旨在辅助教师评估学生作业并给予反馈。在教育系统压力过大，且对人工智能解决此类挑战期望渐高的社会背景下，通过两个测试系列对该工具的功能适用性进行了评估。结果暴露出诸多显著缺陷：该工具的数字评分和定性反馈常常是随机的，即便采纳其建议也毫无改进。只有 ChatGPT 生成的文本才能拿到最高分。错误主张和无意义的提交常未被察觉，部分评分标准的执行既不可靠又不透明。鉴于这些不足源于大型语言模型（LLMs）的固有局限，此类或类似工具的根本改进短期内难以实现。该研究对将人工智能作为教育系统问题快速解决办法的广泛趋势予以批评，认为 Fobizz 把该工具作为客观且省时的解决方案来营销，是具有误导性且不负责任的。最后，研究呼吁对教育情境中人工智能工具的使用进行系统评估和学科特定的教学审查。

> This study examines the AI-powered grading tool "AI Grading Assistant" by the German company Fobizz, designed to support teachers in evaluating and providing feedback on student assignments. Against the societal backdrop of an overburdened education system and rising expectations for artificial intelligence as a solution to these challenges, the investigation evaluates the tool's functional suitability through two test series. The results reveal significant shortcomings: The tool's numerical grades and qualitative feedback are often random and do not improve even when its suggestions are incorporated. The highest ratings are achievable only with texts generated by ChatGPT. False claims and nonsensical submissions frequently go undetected, while the implementation of some grading criteria is unreliable and opaque. Since these deficiencies stem from the inherent limitations of large language models (LLMs), fundamental improvements to this or similar tools are not immediately foreseeable. The study critiques the broader trend of adopting AI as a quick fix for systemic problems in education, concluding that Fobizz's marketing of the tool as an objective and time-saving solution is misleading and irresponsible. Finally, the study calls for systematic evaluation and subject-specific pedagogical scrutiny of the use of AI tools in educational contexts.

[Arxiv](https://arxiv.org/abs/2412.06651)