# WiS 平台：借助基于游戏的分析提升对基于 LLM 的多智能体系统的评估

发布时间：2024年12月04日

`Agent` `多智能体系统`

> WiS Platform: Enhancing Evaluation of LLM-Based Multi-Agent Systems Through Game-Based Analysis

# 摘要

> 近期，基于大型语言模型（LLMs）的自主多智能体系统（MAS）取得了进步，这不仅拓展了应用场景，还提升了 LLMs 处理复杂任务的能力。尽管成效显著，但现有研究在基于 LLM 的 MAS 的评估、分析及可重复性方面，仍面临明显困境。在本文中，为推动基于 LLM 的 MAS 的研究，我们基于“谁是间谍？”（WiS）游戏，引入了一个开放、可扩展且实时更新的平台，用于访问和分析基于 LLM 的 MAS。我们的平台有三大主要价值：（1）支持 Hugging Face 上可用模型的统一模型评估接口；（2）实时更新的模型评估排行榜；（3）涵盖游戏获胜率、攻击、防御策略及 LLMs 推理的综合评估。为严格测试 WiS，我们开展了广泛的实验，涵盖了各类开源和闭源的 LLMs，发现不同的智能体在游戏中呈现出各异且有趣的行为。实验结果表明，我们的平台在评估基于 LLM 的 MAS 方面既有效又高效。我们的平台及其文档可在 url{https://whoisspy.ai/} 公开获取。

> Recent advancements in autonomous multi-agent systems (MAS) based on large language models (LLMs) have enhanced the application scenarios and improved the capability of LLMs to handle complex tasks. Despite demonstrating effectiveness, existing studies still evidently struggle to evaluate, analysis, and reproducibility of LLM-based MAS. In this paper, to facilitate the research on LLM-based MAS, we introduce an open, scalable, and real-time updated platform for accessing and analyzing the LLM-based MAS based on the games Who is Spy?" (WiS). Our platform is featured with three main worths: (1) a unified model evaluate interface that supports models available on Hugging Face; (2) real-time updated leaderboard for model evaluation; (3) a comprehensive evaluation covering game-winning rates, attacking, defense strategies, and reasoning of LLMs. To rigorously test WiS, we conduct extensive experiments coverage of various open- and closed-source LLMs, we find that different agents exhibit distinct and intriguing behaviors in the game. The experimental results demonstrate the effectiveness and efficiency of our platform in evaluating LLM-based MAS. Our platform and its documentation are publicly available at url{https://whoisspy.ai/}

[Arxiv](https://arxiv.org/abs/2412.03359)