# KKLIP：借助 K 均值聚类实现知识蒸馏以用于语言 - 图像预训练

发布时间：2024年12月04日

`LLM应用` `多模态` `知识蒸馏`

> KKLIP: Knowledge Distillation Exploiting K-means Clustering for Language-Image Pre-Training

# 摘要

> 最近，CLIP 在多模态场景中成为了对齐图像和文本信息的宝贵模型。然而，研究人员发现，CLIP 的文本和图像编码器在从字幕 - 图像对中提取详细知识方面能力有限。为此，本文引入了 KKLIP，这是一种通过融入源自 Llama 2 的新知识蒸馏（KD）方法来提升 CLIP 质量的新途径。我们的方法包含三个目标：文本嵌入蒸馏、概念学习和对比学习。其一，文本嵌入蒸馏是训练 KKLIP 文本编码器来模仿教师模型 Llama 2。其二，概念学习通过对来自 Llama 2 的文本信息进行离线 k 均值聚类，为每个字幕 - 图像对赋予一个软概念标签，让 KKLIP 能从这些软概念标签中学习。其三，对比学习协调文本和图像嵌入。我们的实验结果表明，KKLIP 提升了文本和图像编码器的质量。

> Recently, CLIP has emerged as a valuable model for aligning image and text information in multi-modal scenarios. However, researchers have observed limitations in the ability of CLIP's text and image encoders to extract detailed knowledge from caption-image pairs. In response, this paper introduces KKLIP, a novel approach designed to enhance the quality of CLIP by incorporating a new knowledge distillation (KD) method derived from Llama 2. Our method comprises three objectives: Text Embedding Distillation, Concept Learning, and Contrastive Learning. Firstly, Text Embedding Distillation involves training the KKLIP text encoder to emulate the teacher model, Llama 2. Secondly, Concept Learning assigns a soft concept label to each caption-image pair through offline k-means clustering of text information from Llama 2, allowing KKLIP to learn from these soft concept labels. Finally, Contrastive Learning harmonizes text and image embeddings. Our experimental results demonstrate that KKLIP enhances the quality of both text and image encoders.

[Arxiv](https://arxiv.org/abs/2412.03513)