# 关于不同大型语言模型架构的调研：趋势、基准及挑战

发布时间：2024年12月04日

`LLM应用`

> Survey of different Large Language Model Architectures: Trends, Benchmarks, and Challenges

# 摘要

> 大型语言模型（LLMs）属于一类深度学习模型，善于理解自然语言，能针对各种提示或询问给出连贯回应。这类模型的复杂程度远超传统神经网络，往往涵盖数十个神经网络层，包含数十亿乃至数万亿个参数。它们通常基于庞大的数据集训练，采用基于转换器块的架构。当下的LLMs具备多种功能，能够完成从文本生成、语言翻译到问答，以及代码生成与分析等一系列任务。其中的高级子集，即多模态大型语言模型（MLLMs），将LLM的能力拓展到处理和解读包括图像、音频、视频在内的多种数据模态。这一提升赋予了MLLMs诸如视频编辑、图像理解和视觉内容配字幕等能力。本次调研对LLMs的最新进展进行了全面综述。我们先追溯LLMs的发展历程，接着深入探讨MLLMs的出现及细微之处。我们对新兴的先进MLLMs进行分析，探究其技术特点、优势和局限性。此外，我们对这些模型展开比较分析，并论述它们所面临的挑战、潜在的局限以及未来发展的前景。

> Large Language Models (LLMs) represent a class of deep learning models adept at understanding natural language and generating coherent responses to various prompts or queries. These models far exceed the complexity of conventional neural networks, often encompassing dozens of neural network layers and containing billions to trillions of parameters. They are typically trained on vast datasets, utilizing architectures based on transformer blocks. Present-day LLMs are multi-functional, capable of performing a range of tasks from text generation and language translation to question answering, as well as code generation and analysis. An advanced subset of these models, known as Multimodal Large Language Models (MLLMs), extends LLM capabilities to process and interpret multiple data modalities, including images, audio, and video. This enhancement empowers MLLMs with capabilities like video editing, image comprehension, and captioning for visual content. This survey provides a comprehensive overview of the recent advancements in LLMs. We begin by tracing the evolution of LLMs and subsequently delve into the advent and nuances of MLLMs. We analyze emerging state-of-the-art MLLMs, exploring their technical features, strengths, and limitations. Additionally, we present a comparative analysis of these models and discuss their challenges, potential limitations, and prospects for future development.

[Arxiv](https://arxiv.org/abs/2412.03220)