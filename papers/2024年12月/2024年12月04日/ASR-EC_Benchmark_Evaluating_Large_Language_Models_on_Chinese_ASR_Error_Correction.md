# ASR-EC 基准：评估大型语言模型在中文 ASR 纠错上的表现

发布时间：2024年12月04日

`LLM应用` `语音处理`

> ASR-EC Benchmark: Evaluating Large Language Models on Chinese ASR Error Correction

# 摘要

> 自动语音识别（ASR）乃是语音和自然语言处理领域的一项基础且关键的任务，也是众多应用（如语音助手、语音翻译等）中不可或缺的一部分。尽管近年来 ASR 技术不断进步，但由于环境噪声、语义模糊等因素，现代 ASR 系统仍难免出现大量错误识别。故而，ASR 中的错误纠正极为重要。

正因如此，本文着眼于汉语中的 ASR 错误纠正，汉语作为世界上最流行的语言之一，拥有众多使用者。我们率先创建了一个名为\emph{ASR-EC}的基准数据集，其中涵盖了由工业级 ASR 系统产生的各类 ASR 错误。据了解，这是首个中文 ASR 错误纠正基准。接着，受\emph{大型语言模型（LLMs）}最新进展的启发，我们探索如何借助 LLMs 的力量来矫正 ASR 错误。我们在三个范式中把 LLMs 应用于 ASR 错误纠正。第一个范式是提示，可进一步细分为零样本、少样本和多步骤。第二个范式是微调，用 ASR 错误纠正数据对 LLMs 进行微调。第三个范式是多模态增强，综合利用音频和 ASR 转录本来进行错误纠正。大量实验表明，提示对 ASR 错误纠正效果不佳。微调仅对部分 LLMs 有效。多模态增强是错误纠正最有效的方式，并取得了最先进的性能。

> Automatic speech Recognition (ASR) is a fundamental and important task in the field of speech and natural language processing. It is an inherent building block in many applications such as voice assistant, speech translation, etc. Despite the advancement of ASR technologies in recent years, it is still inevitable for modern ASR systems to have a substantial number of erroneous recognition due to environmental noise, ambiguity, etc. Therefore, the error correction in ASR is crucial.
  Motivated by this, this paper studies ASR error correction in the Chinese language, which is one of the most popular languages and enjoys a large number of users in the world. We first create a benchmark dataset named \emph{ASR-EC} that contains a wide spectrum of ASR errors generated by industry-grade ASR systems. To the best of our knowledge, it is the first Chinese ASR error correction benchmark. Then, inspired by the recent advances in \emph{large language models (LLMs)}, we investigate how to harness the power of LLMs to correct ASR errors. We apply LLMs to ASR error correction in three paradigms. The first paradigm is prompting, which is further categorized as zero-shot, few-shot, and multi-step. The second paradigm is finetuning, which finetunes LLMs with ASR error correction data. The third paradigm is multi-modal augmentation, which collectively utilizes the audio and ASR transcripts for error correction. Extensive experiments reveal that prompting is not effective for ASR error correction. Finetuning is effective only for a portion of LLMs. Multi-modal augmentation is the most effective method for error correction and achieves state-of-the-art performance.

[Arxiv](https://arxiv.org/abs/2412.03075)