# 花岗石卫士

发布时间：2024年12月10日

`LLM应用` `人工智能` `风险检测`

> Granite Guardian

# 摘要

> 我们推出了 Granite Guardian 模型，这是一组用于提示和响应的风险检测保障措施，能与任何大型语言模型（LLM）配合使用，确保安全且负责。该模型在多个风险维度实现全面覆盖，涵盖社会偏见、亵渎、暴力、性相关内容、不道德行为、越狱以及与幻觉相关的风险，比如检索增强生成（RAG）的上下文相关性、基础可靠性和答案相关性。基于融合了来自不同来源的人工标注和合成数据的独特数据集进行训练，Granite Guardian 模型解决了传统风险检测模型常忽视的风险，像越狱和 RAG 特有的问题。在有害内容和与 RAG 幻觉相关的基准测试中，AUC 得分分别达 0.871 和 0.854，Granite Guardian 是此领域中通用性最强、竞争力最大的模型。作为开源项目发布，Granite Guardian 旨在推动整个社区负责任的人工智能发展。
  https://github.com/ibm-granite/granite-guardian

> We introduce the Granite Guardian models, a suite of safeguards designed to provide risk detection for prompts and responses, enabling safe and responsible use in combination with any large language model (LLM). These models offer comprehensive coverage across multiple risk dimensions, including social bias, profanity, violence, sexual content, unethical behavior, jailbreaking, and hallucination-related risks such as context relevance, groundedness, and answer relevance for retrieval-augmented generation (RAG). Trained on a unique dataset combining human annotations from diverse sources and synthetic data, Granite Guardian models address risks typically overlooked by traditional risk detection models, such as jailbreaks and RAG-specific issues. With AUC scores of 0.871 and 0.854 on harmful content and RAG-hallucination-related benchmarks respectively, Granite Guardian is the most generalizable and competitive model available in the space. Released as open-source, Granite Guardian aims to promote responsible AI development across the community.
  https://github.com/ibm-granite/granite-guardian

[Arxiv](https://arxiv.org/abs/2412.07724)