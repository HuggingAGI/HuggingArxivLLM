# 探寻结构：借助大型语言模型探究新兴通信

发布时间：2024年12月10日

`LLM应用` `语言进化` `语言模型`

> Searching for Structure: Investigating Emergent Communication with Large Language Models

# 摘要

> 人类语言在反复的学习与使用中逐渐形成了结构。这一过程引入了一些偏差，它们在语言习得期间发挥作用，促使语言系统朝着交际高效的方向发展。在本文中，我们探究了若为大型语言模型（LLMs）的隐性偏差优化人工语言，是否会出现同样的情况。为此，我们模拟了一个经典的指称游戏，在其中LLMs学习并使用人工语言。我们的研究结果显示，起初无结构的整体语言确实被塑造出了一些结构特性，使得两个LLM代理能够成功交流。和人类实验中的观察相似，代际传递提高了语言的可学习性，但同时可能导致非人类式的退化词汇。总的来说，这项工作拓展了实验发现，表明LLMs能够作为语言进化模拟的工具，并为该领域未来的人机实验创造了可能。

> Human languages have evolved to be structured through repeated language learning and use. These processes introduce biases that operate during language acquisition and shape linguistic systems toward communicative efficiency. In this paper, we investigate whether the same happens if artificial languages are optimised for implicit biases of Large Language Models (LLMs). To this end, we simulate a classical referential game in which LLMs learn and use artificial languages. Our results show that initially unstructured holistic languages are indeed shaped to have some structural properties that allow two LLM agents to communicate successfully. Similar to observations in human experiments, generational transmission increases the learnability of languages, but can at the same time result in non-humanlike degenerate vocabularies. Taken together, this work extends experimental findings, shows that LLMs can be used as tools in simulations of language evolution, and opens possibilities for future human-machine experiments in this field.

[Arxiv](https://arxiv.org/abs/2412.07646)