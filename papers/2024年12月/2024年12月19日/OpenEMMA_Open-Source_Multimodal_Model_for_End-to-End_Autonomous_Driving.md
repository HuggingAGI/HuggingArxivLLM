# OpenEMMA：端到端自动驾驶的开源多模态模型

发布时间：2024年12月19日

`LLM应用` `自动驾驶` `人工智能`

> OpenEMMA: Open-Source Multimodal Model for End-to-End Autonomous Driving

# 摘要

> 自多模态大型语言模型（MLLMs）问世以来，其在众多现实应用中产生了重大影响，尤其是在自动驾驶（AD）方面。它们处理复杂视觉数据及推理复杂驾驶场景的能力，为端到端AD系统开创了新范式。然而，AD端到端模型的开发进展缓慢，现有的微调方法需要大量资源，如强大的计算能力、大规模数据集和充足的资金。受推理计算最新进展的启发，我们推出了OpenEMMA，这是一个基于MLLMs的开源端到端框架。融入思维链推理过程后，OpenEMMA在运用各类MLLMs时较基线有显著提升。此外，OpenEMMA在多种富有挑战性的驾驶场景中展现出有效性、通用性和稳健性，为自动驾驶提供了更高效、更有效的途径。我们在https://github.com/taco-group/OpenEMMA 上公布了所有代码。

> Since the advent of Multimodal Large Language Models (MLLMs), they have made a significant impact across a wide range of real-world applications, particularly in Autonomous Driving (AD). Their ability to process complex visual data and reason about intricate driving scenarios has paved the way for a new paradigm in end-to-end AD systems. However, the progress of developing end-to-end models for AD has been slow, as existing fine-tuning methods demand substantial resources, including extensive computational power, large-scale datasets, and significant funding. Drawing inspiration from recent advancements in inference computing, we propose OpenEMMA, an open-source end-to-end framework based on MLLMs. By incorporating the Chain-of-Thought reasoning process, OpenEMMA achieves significant improvements compared to the baseline when leveraging a diverse range of MLLMs. Furthermore, OpenEMMA demonstrates effectiveness, generalizability, and robustness across a variety of challenging driving scenarios, offering a more efficient and effective approach to autonomous driving. We release all the codes in https://github.com/taco-group/OpenEMMA.

[Arxiv](https://arxiv.org/abs/2412.15208)