# HarmonicEval：借助视觉语言模型实现的多模态、多任务、多标准自动评估

发布时间：2024年12月19日

`LLM应用` `视觉语言` `评估指标`

> HarmonicEval: Multi-modal, Multi-task, Multi-criteria Automatic Evaluation Using a Vision Language Model

# 摘要

> 视觉语言模型（VLMs）在文本和图像理解上表现出色。但现有的评估 VLMs 生成文本的指标只关注整体质量，存在两个局限：一是难以从整体得分中看出文本哪些方面需改进；二是预测整体得分时可能忽略特定评估标准。为解决这些问题，我们提出了 HarmonicEval，这一无参考评估指标以自下而上的方式聚合各标准得分来得出整体得分。此外，我们构建了多任务多标准人类评估（MMHE）数据集，涵盖四个视觉语言任务的 18000 个专家人工判断。实验表明，HarmonicEval 与人类判断的相关性高于传统指标，且能为每个标准给出数值分数。

> Vision-language models (VLMs) have shown impressive abilities in text and image understanding. However, existing metrics for evaluating the text generated by VLMs focus exclusively on overall quality, leading to two limitations: 1) it is challenging to identify which aspects of the text need improvement from the overall score; 2) metrics may overlook specific evaluation criteria when predicting an overall score. To address these limitations, we propose HarmonicEval, a reference-free evaluation metric that aggregates criterion-wise scores to produce the overall score in a bottom-up manner. Furthermore, we construct the Multi-task Multi-criteria Human Evaluation (MMHE) dataset, which comprises 18,000 expert human judgments across four vision-language tasks. Our experiments demonstrate that HarmonicEval achieves higher correlations with human judgments than conventional metrics while providing numerical scores for each criterion.

[Arxiv](https://arxiv.org/abs/2412.14613)