# 通用AI模型部署中的核心风险：网络安全给我们带来了哪些启示？

发布时间：2024年12月19日

`LLM应用

理由：这篇论文摘要讨论了大型语言模型（LLMs）在多种应用场景中的普及和演变，包括工具使用、微软Copilot/Office集成以及OpenAI的Altera等案例。这些内容主要涉及LLMs在实际应用中的使用和集成，因此应归类为“LLM应用”。` `人工智能` `网络安全`

> Fundamental Risks in the Current Deployment of General-Purpose AI Models: What Have We (Not) Learnt From Cybersecurity?

# 摘要

> 通用人工智能（如大型语言模型，LLMs）已在众多应用场景中迅速普及。令人惊叹的是，它们从最初的语言模型演变为聊天机器人，甚至具备了类似“操作系统”的功能，能够掌控应用程序的决策逻辑。工具使用、微软Copilot/Office集成以及OpenAI的Altera等案例，展现了其日益增强的自主性、数据访问和执行能力。然而，这些技术也伴随着一系列网络安全挑战。我们分享了一些评估工作的成果，并展望了未来的机遇与挑战。

> General Purpose AI - such as Large Language Models (LLMs) - have seen rapid deployment in a wide range of use cases. Most surprisingly, they have have made their way from plain language models, to chat-bots, all the way to an almost ``operating system''-like status that can control decisions and logic of an application. Tool-use, Microsoft co-pilot/office integration, and OpenAIs Altera are just a few examples of increased autonomy, data access, and execution capabilities. These methods come with a range of cybersecurity challenges. We highlight some of the work we have done in terms of evaluation as well as outline future opportunities and challenges.

[Arxiv](https://arxiv.org/abs/2501.01435)