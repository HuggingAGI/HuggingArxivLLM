# 向着强大的超详细图像描述迈进：采用一种多智能体方法以及针对真实性和覆盖范围的双重评估指标

发布时间：2024年12月19日

`Agent` `图像字幕` `多模态语言模型`

> Toward Robust Hyper-Detailed Image Captioning: A Multiagent Approach and Dual Evaluation Metrics for Factuality and Coverage

# 摘要

> 多模态大型语言模型（MLLMs）在生成高度详尽的字幕方面表现出色，但常常出现幻觉。我们的分析显示，现有的幻觉检测手段应对详细字幕时颇为吃力。这是因为随着序列长度的增长，MLLMs 愈发依赖其生成的文本，而非输入图像。为解决此问题，我们提出了一种多智能体方法，借助 LLM-MLLM 协作来校正给定的字幕。另外，我们引入了一个评估框架和一个基准数据集，以助力对详细字幕的系统分析。我们的实验表明，我们所提出的评估方法比现有的指标更贴合人类对真实性的判断，而且现有的提升 MLLM 真实性的方法在超详细图像字幕任务中或许成效不彰。相较而言，我们提出的方法大幅提升了字幕的事实准确性，甚至让 GPT-4V 生成的字幕也更准确。最后，我们通过证明 MLLM 在 VQA 基准测试中的表现可能与生成详细图像字幕的能力无关，凸显了以 VQA 为中心的基准测试存在的局限性。

> Multimodal large language models (MLLMs) excel at generating highly detailed captions but often produce hallucinations. Our analysis reveals that existing hallucination detection methods struggle with detailed captions. We attribute this to the increasing reliance of MLLMs on their generated text, rather than the input image, as the sequence length grows. To address this issue, we propose a multiagent approach that leverages LLM-MLLM collaboration to correct given captions. Additionally, we introduce an evaluation framework and a benchmark dataset to facilitate the systematic analysis of detailed captions. Our experiments demonstrate that our proposed evaluation method better aligns with human judgments of factuality than existing metrics and that existing approaches to improve the MLLM factuality may fall short in hyper-detailed image captioning tasks. In contrast, our proposed method significantly enhances the factual accuracy of captions, even improving those generated by GPT-4V. Finally, we highlight a limitation of VQA-centric benchmarking by demonstrating that an MLLM's performance on VQA benchmarks may not correlate with its ability to generate detailed image captions.

[Arxiv](https://arxiv.org/abs/2412.15484)