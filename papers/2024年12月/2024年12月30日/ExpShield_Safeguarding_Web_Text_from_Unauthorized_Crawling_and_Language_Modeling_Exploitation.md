# ExpShield：守护网络文本，使其免受未经授权的爬取以及语言模型的利用

发布时间：2024年12月30日

`LLM应用` `版权保护` `数据安全`

> ExpShield: Safeguarding Web Text from Unauthorized Crawling and Language Modeling Exploitation

# 摘要

> 随着大型语言模型（LLMs）对网络抓取数据集的依赖程度日益加深，人们对于未经授权使用受版权保护或个人内容进行训练的担忧愈发强烈。尽管有像《通用数据保护条例》（GDPR）这样的法规，但数据所有者对其内容在模型训练中的使用仍缺乏有效控制。为应对此问题，我们提出了 ExpShield 这一主动的自我保护机制，它能让内容所有者将不可见的扰动嵌入文本，在不影响可读性的前提下限制 LLMs 训练中的数据滥用。这种未雨绸缪的方法使数据所有者无需依赖第三方就能直接保护敏感内容。从随机扰动入手，我们阐明了利用扰动来隐藏受保护内容的原理。我们还通过识别记忆触发因素并创建陷阱，以更集中的方式分散模型记忆，进一步提高了效率。为验证我们防御措施的有效性，我们提出了一种新的实例利用度量标准，它能够捕捉模型训练所引发的个体风险。实验结果证明了我们方法的有效性，MIA AUC 从 0.95 降至 0.55，实例利用近乎为零。这表明训练后个体风险未增加，凸显了主动防御在保护版权数据方面的重要意义。

> As large language models (LLMs) increasingly depend on web-scraped datasets, concerns over unauthorized use of copyrighted or personal content for training have intensified. Despite regulations such as the General Data Protection Regulation (GDPR), data owners still have limited control over the use of their content in model training. To address this, we propose ExpShield, a proactive self-guard mechanism that empowers content owners to embed invisible perturbations into their text, limiting data misuse in LLMs training without affecting readability. This preemptive approach enables data owners to protect sensitive content directly, without relying on a third-party to perform defense. Starting from the random perturbation, we demonstrate the rationale for using perturbation to conceal protected content. We further enhance the efficiency by identifying memorization triggers and creating pitfalls to diverge the model memorization in a more focused way. To validate our defense's effectiveness, we propose a novel metric of instance exploitation which captures the individual risk raised by model training. The experimental results validate the effectiveness of our approach as the MIA AUC decreases from 0.95 to 0.55, and instance exploitation approaches zero. This suggests that the individual risk does not increase after training, underscoring the significance of proactive defenses in protecting copyrighted data.

[Arxiv](https://arxiv.org/abs/2412.21123)