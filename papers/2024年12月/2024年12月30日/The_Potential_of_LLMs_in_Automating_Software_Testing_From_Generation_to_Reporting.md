# LLMs 在软件测试自动化中的潜力：从生成到报告

发布时间：2024年12月30日

`Agent

理由：这篇论文提出了一种基于大型语言模型（LLMs）的代理导向自动化测试方法，旨在减少人为干预并提升测试效率。该方法通过LLMs生成单元测试、可视化调用图，并自动化测试执行与报告。这表明论文的核心是开发一个基于LLM的代理系统，用于自动化软件测试。因此，将其分类为Agent是合适的。` `软件工程` `自动化测试`

> The Potential of LLMs in Automating Software Testing: From Generation to Reporting

# 摘要

> 在软件工程中，高质量的软件离不开稳健的测试验证。手动测试虽有效，但耗时且昂贵，因此自动化测试需求日益增长。近年来，大型语言模型（LLMs）的突破性进展深刻影响了软件工程，尤其在需求分析、测试自动化和调试等领域。本文提出了一种基于LLMs的代理导向自动化测试方法，旨在减少人为干预并提升测试效率。该框架通过LLMs生成单元测试、可视化调用图，并自动化测试执行与报告。在Python和Java的多项应用评估中，系统展现了高测试覆盖率和高效运行能力。研究表明，LLM驱动的代理在简化测试流程、提升可扩展性和准确性方面具有巨大潜力。

> Having a high quality software is essential in software engineering, which requires robust validation and verification processes during testing activities. Manual testing, while effective, can be time consuming and costly, leading to an increased demand for automated methods. Recent advancements in Large Language Models (LLMs) have significantly influenced software engineering, particularly in areas like requirements analysis, test automation, and debugging. This paper explores an agent-oriented approach to automated software testing, using LLMs to reduce human intervention and enhance testing efficiency. The proposed framework integrates LLMs to generate unit tests, visualize call graphs, and automate test execution and reporting. Evaluations across multiple applications in Python and Java demonstrate the system's high test coverage and efficient operation. This research underscores the potential of LLM-powered agents to streamline software testing workflows while addressing challenges in scalability and accuracy.

[Arxiv](https://arxiv.org/abs/2501.00217)