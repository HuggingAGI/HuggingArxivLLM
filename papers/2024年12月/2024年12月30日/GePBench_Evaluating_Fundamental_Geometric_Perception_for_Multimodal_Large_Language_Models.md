# GePBench：用于评估多模态大型语言模型的基本几何感知

发布时间：2024年12月30日

`LLM应用` `多模态` `几何感知`

> GePBench: Evaluating Fundamental Geometric Perception for Multimodal Large Language Models

# 摘要

> 多模态大型语言模型（MLLMs）在融合视觉与语言理解方面成果斐然。现有的基准虽在丰富的现实场景中对这些模型予以评估，却常常忽视了在偏离日常现实的环境中那些关键的基本感知技能。尤其是几何感知，也就是解读空间关系和抽象视觉模式的能力，尚未得到充分探究。为突破这一局限，我们推出了 GePBench，这是一个专门用于评估 MLLMs 几何感知能力的新基准。大量评估的结果显示，当下最先进的 MLLMs 在这类任务中存在明显不足。另外，我们证实，用来自 GePBench 的数据训练的模型在众多下游任务中都有显著提升，凸显了几何感知作为高级多模态应用之基础的重要性。我们的代码和数据集将会公开。

> Multimodal large language models (MLLMs) have achieved significant advancements in integrating visual and linguistic understanding. While existing benchmarks evaluate these models in context-rich, real-life scenarios, they often overlook fundamental perceptual skills essential for environments deviating from everyday realism. In particular, geometric perception, the ability to interpret spatial relationships and abstract visual patterns, remains underexplored. To address this limitation, we introduce GePBench, a novel benchmark designed to assess the geometric perception capabilities of MLLMs. Results from extensive evaluations reveal that current state-of-the-art MLLMs exhibit significant deficiencies in such tasks. Additionally, we demonstrate that models trained with data sourced from GePBench show notable improvements on a wide range of downstream tasks, underscoring the importance of geometric perception as a foundation for advanced multimodal applications. Our code and datasets will be publicly available.

[Arxiv](https://arxiv.org/abs/2412.21036)