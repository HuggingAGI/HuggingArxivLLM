# Quo Vadis，异常检测何去何从？LLMs 和 VLMs 备受瞩目

发布时间：2024年12月24日

`LLM应用` `视频检测` `人工智能`

> Quo Vadis, Anomaly Detection? LLMs and VLMs in the Spotlight

# 摘要

> 视频异常检测（VAD）借助大型语言模型（LLMs）与视觉语言模型（VLMs）的融合实现了重大突破，成功应对了动态开放世界场景中的可解释性、时间推理和泛化等关键难题。本文深入审视了 2024 年基于 LLM 和 VLM 的前沿手段，着重于四个核心要点：（一）凭借语义洞察和文本阐释提升可解释性，让视觉异常更易理解；（二）捕捉繁杂的时间关联，从而检测并定位视频帧中的动态异常；（三）达成少样本和零样本检测，最大程度降低对大型标注数据集的依赖；（四）运用语义理解和运动特征处理开放世界和类别不明的异常，以保障时空连贯性。我们凸显了其重塑 VAD 格局的潜力。另外，我们探究了 LLMs 和 VLMs 所提供的视觉与文本模态之间的协同效应，突出了它们的综合优势，并给出了充分挖掘提升视频异常检测潜力的未来走向。

> Video anomaly detection (VAD) has witnessed significant advancements through the integration of large language models (LLMs) and vision-language models (VLMs), addressing critical challenges such as interpretability, temporal reasoning, and generalization in dynamic, open-world scenarios. This paper presents an in-depth review of cutting-edge LLM-/VLM-based methods in 2024, focusing on four key aspects: (i) enhancing interpretability through semantic insights and textual explanations, making visual anomalies more understandable; (ii) capturing intricate temporal relationships to detect and localize dynamic anomalies across video frames; (iii) enabling few-shot and zero-shot detection to minimize reliance on large, annotated datasets; and (iv) addressing open-world and class-agnostic anomalies by using semantic understanding and motion features for spatiotemporal coherence. We highlight their potential to redefine the landscape of VAD. Additionally, we explore the synergy between visual and textual modalities offered by LLMs and VLMs, highlighting their combined strengths and proposing future directions to fully exploit the potential in enhancing video anomaly detection.

[Arxiv](https://arxiv.org/abs/2412.18298)