# SocialMind：基于 LLM 的具备类人感知能力的主动式增强现实社交辅助系统，用于现场实时互动

发布时间：2024年12月05日

`LLM应用` `增强现实`

> SocialMind: LLM-based Proactive AR Social Assistive System with Human-like Perception for In-situ Live Interactions

# 摘要

> 社会互动是人类生活的基础。基于大型语言模型（LLMs）的虚拟助手近来崭露头角，展现出革新人类互动和生活方式的巨大潜力。然而，现有的辅助系统主要为个体用户提供被动服务，而非在与对话伙伴的实时社交互动中提供现场协助。在本研究中，我们推出了 SocialMind，这是首个基于 LLM 的主动式增强现实（AR）社交辅助系统，可为用户提供现场社交帮助。SocialMind 借助多模态传感器，运用类人的感知能力提取言语和非言语线索、社会因素以及隐含的角色特征，并将这些社交线索融入 LLM 推理以生成社交建议。此外，SocialMind 采用多层协作生成策略和主动更新机制，在增强现实（AR）眼镜上展示社交建议，确保在不干扰自然对话流程的情况下及时为用户提供建议。对三个公共数据集的评估以及对 20 名参与者的用户研究显示，与基线相比，SocialMind 的参与度高出 38.3％，且 95％的参与者愿意在其实时社交互动中使用 SocialMind。

> Social interactions are fundamental to human life. The recent emergence of large language models (LLMs)-based virtual assistants has demonstrated their potential to revolutionize human interactions and lifestyles. However, existing assistive systems mainly provide reactive services to individual users, rather than offering in-situ assistance during live social interactions with conversational partners. In this study, we introduce SocialMind, the first LLM-based proactive AR social assistive system that provides users with in-situ social assistance. SocialMind employs human-like perception leveraging multi-modal sensors to extract both verbal and nonverbal cues, social factors, and implicit personas, incorporating these social cues into LLM reasoning for social suggestion generation. Additionally, SocialMind employs a multi-tier collaborative generation strategy and proactive update mechanism to display social suggestions on Augmented Reality (AR) glasses, ensuring that suggestions are timely provided to users without disrupting the natural flow of conversation. Evaluations on three public datasets and a user study with 20 participants show that SocialMind achieves 38.3% higher engagement compared to baselines, and 95% of participants are willing to use SocialMind in their live social interactions.

[Arxiv](https://arxiv.org/abs/2412.04036)