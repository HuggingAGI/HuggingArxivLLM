# herakoi：一项针对天文数据的声音化实验

发布时间：2024年12月12日

`LLM应用`

> herakoi: a sonification experiment for astronomical data

# 摘要

> 近期研究显示，数据可听化是一种前景可观的视觉补充手段，有助于数据的感知与解读。我们推出了 herakoi 这款新颖的开源软件，它借助机器学习实现实时图像可听化，尤其聚焦于天文数据。通过网络摄像头追踪手部动作并将其映射至图像坐标，herakoi 能把视觉特性转化为声音，让用户能够“听见”图像。其响应迅速，用户经过短期培训就能获取天文图像中的信息，展现出高可靠性与有效性。该软件在教育和推广领域颇具潜力，能让复杂的天文概念对包括盲人和视障人士在内的各类受众更具吸引力和可及性。我们还探讨了未来的发展方向，比如整合大型语言和视觉模型，在解读天文数据时创造更具互动性的体验。

> Recent research is revealing data-sonification as a promising complementary approach to vision, benefiting both data perception and interpretation. We present herakoi, a novel open-source software that uses machine learning to allow real-time image sonification, with a focus on astronomical data. By tracking hand movements via a webcam and mapping them to image coordinates, herakoi translates visual properties into sound, enabling users to "hear" images. Its swift responsiveness allows users to access information in astronomical images with short training, demonstrating high reliability and effectiveness. The software has shown promise in educational and outreach settings, making complex astronomical concepts more engaging and accessible to diverse audiences, including blind and visually impaired individuals. We also discuss future developments, such as the integration of large language and vision models to create a more interactive experience in interpreting astronomical data.

[Arxiv](https://arxiv.org/abs/2412.09152)