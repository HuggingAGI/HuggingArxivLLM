# C$^2$LEVA：致力于实现全面且无污染的语言模型评估

发布时间：2024年12月06日

`LLM应用` `语言模型` `评估基准`

> C$^2$LEVA: Toward Comprehensive and Contamination-Free Language Model Evaluation

# 摘要

> 近期大型语言模型（LLMs）的进展前景可观，但评估时存在一些问题，尤其是因无法获取专有训练数据而产生的数据污染。为解决此问题，我们推出了 C$^2$LEVA，这是一个具备系统防污染功能的综合双语基准。C$^2$LEVA 一方面提供了涵盖 22 个任务的全面评估，每个任务均针对 LLMs 的特定应用或能力；另一方面，凭借无污染任务，通过系统的防污染策略（完全实现测试数据更新，并在基准数据发布时强制数据保护），提供了可靠评估。我们对 15 个开源和专有模型的大规模评估，证实了 C$^2$LEVA 的有效性。

> Recent advances in large language models (LLMs) have shown significant promise, yet their evaluation raises concerns, particularly regarding data contamination due to the lack of access to proprietary training data. To address this issue, we present C$^2$LEVA, a comprehensive bilingual benchmark featuring systematic contamination prevention. C$^2$LEVA firstly offers a holistic evaluation encompassing 22 tasks, each targeting a specific application or ability of LLMs, and secondly a trustworthy assessment due to our contamination-free tasks, ensured by a systematic contamination prevention strategy that fully automates test data renewal and enforces data protection during benchmark data release. Our large-scale evaluation of 15 open-source and proprietary models demonstrates the effectiveness of C$^2$LEVA.

[Arxiv](https://arxiv.org/abs/2412.04947)