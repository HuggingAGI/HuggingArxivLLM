# AIR-Bench：自动化的异构信息检索基准

发布时间：2024年12月17日

`LLM应用` `信息检索` `评估基准`

> AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark

# 摘要

> 评估在信息检索（IR）模型的进步中扮演着关键角色。然而，当前基于预定义领域和人工标注数据的基准，在经济高效地满足新兴领域的评估需求方面存在局限。为应对此挑战，我们提出了自动异构信息检索基准（AIR-Bench）。AIR-Bench 有三大关键特性：1. 自动化。AIR-Bench 中的测试数据由大型语言模型（LLMs）自动生成，无需人工介入。2. 异构性。AIR-Bench 中的测试数据是针对不同任务、领域和语言生成的。3. 动态性。AIR-Bench 涵盖的领域和语言持续扩充，为社区开发者提供了更全面的评估基准。我们开发了可靠且强大的数据生成管道，基于真实世界的语料库自动创建多样且高质量的评估数据集。我们的发现表明，AIR-Bench 中生成的测试数据与人工标注的测试数据高度一致，使 AIR-Bench 成为评估 IR 模型的可靠基准。AIR-Bench 的资源在 https://github.com/AIR-Bench/AIR-Bench 公开可用。

> Evaluation plays a crucial role in the advancement of information retrieval (IR) models. However, current benchmarks, which are based on predefined domains and human-labeled data, face limitations in addressing evaluation needs for emerging domains both cost-effectively and efficiently. To address this challenge, we propose the Automated Heterogeneous Information Retrieval Benchmark (AIR-Bench). AIR-Bench is distinguished by three key features: 1) Automated. The testing data in AIR-Bench is automatically generated by large language models (LLMs) without human intervention. 2) Heterogeneous. The testing data in AIR-Bench is generated with respect to diverse tasks, domains and languages. 3) Dynamic. The domains and languages covered by AIR-Bench are constantly augmented to provide an increasingly comprehensive evaluation benchmark for community developers. We develop a reliable and robust data generation pipeline to automatically create diverse and high-quality evaluation datasets based on real-world corpora. Our findings demonstrate that the generated testing data in AIR-Bench aligns well with human-labeled testing data, making AIR-Bench a dependable benchmark for evaluating IR models. The resources in AIR-Bench are publicly available at https://github.com/AIR-Bench/AIR-Bench.

[Arxiv](https://arxiv.org/abs/2412.13102)