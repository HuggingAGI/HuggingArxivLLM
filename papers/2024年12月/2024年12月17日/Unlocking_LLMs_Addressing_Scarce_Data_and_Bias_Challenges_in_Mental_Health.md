# 解锁 LLMs：化解心理健康领域的稀缺数据与偏差难题

发布时间：2024年12月17日

`LLM应用` `心理健康`

> Unlocking LLMs: Addressing Scarce Data and Bias Challenges in Mental Health

# 摘要

> 大型语言模型（LLMs）在医疗保健分析领域展现出良好的能力，但也面临着诸如幻觉、鹦鹉学舌和偏见呈现等诸多挑战。在复杂、敏感和资源稀缺的领域，这些挑战更为严峻。为此，在本研究中，我们推出了 IC-AnnoMI，这是一个基于 AnnoMI 并借助 LLMs（尤其是 ChatGPT）生成上下文对话而构建的专家标注的动机性访谈（MI）数据集。IC-AnnoMI 运用通过线索和定制信息精心设计的针对性提示，充分考虑治疗风格（同理心、反思）、上下文相关性和错误语义变化。随后，对话由专家依据动机性访谈技能代码（MISC）进行标注，重点关注 MI 对话的心理和语言维度。我们运用多种经典机器学习和当下最先进的变压器方法构建新的分类任务，对 IC-AnnoMI 数据集和 ChatGPT 的情感推理能力以及对领域复杂性的理解进行全面评估。最后，我们探讨了渐进式提示策略的效果以及扩充数据在减轻 IC-AnnoM 中所呈现偏差方面的作用。我们的贡献不仅为 MI 社区提供了一个全面的数据集，还为在监督环境下将 LLMs 用于会话治疗的共情文本生成提供了宝贵的见解。

> Large language models (LLMs) have shown promising capabilities in healthcare analysis but face several challenges like hallucinations, parroting, and bias manifestation. These challenges are exacerbated in complex, sensitive, and low-resource domains. Therefore, in this work we introduce IC-AnnoMI, an expert-annotated motivational interviewing (MI) dataset built upon AnnoMI by generating in-context conversational dialogues leveraging LLMs, particularly ChatGPT. IC-AnnoMI employs targeted prompts accurately engineered through cues and tailored information, taking into account therapy style (empathy, reflection), contextual relevance, and false semantic change. Subsequently, the dialogues are annotated by experts, strictly adhering to the Motivational Interviewing Skills Code (MISC), focusing on both the psychological and linguistic dimensions of MI dialogues. We comprehensively evaluate the IC-AnnoMI dataset and ChatGPT's emotional reasoning ability and understanding of domain intricacies by modeling novel classification tasks employing several classical machine learning and current state-of-the-art transformer approaches. Finally, we discuss the effects of progressive prompting strategies and the impact of augmented data in mitigating the biases manifested in IC-AnnoM. Our contributions provide the MI community with not only a comprehensive dataset but also valuable insights for using LLMs in empathetic text generation for conversational therapy in supervised settings.

[Arxiv](https://arxiv.org/abs/2412.12981)