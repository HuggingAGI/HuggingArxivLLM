# 大型语言模型生成合成德国公众意见的算法保真度：一项案例研究

发布时间：2024年12月17日

`LLM应用` `公众意见`

> Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study

# 摘要

> 在近期的研究里，大型语言模型（LLMs）被愈发频繁地用于探究公众意见。本研究对LLMs的算法保真度展开了调研，也就是其重现社会文化背景以及人类参与者细微意见的能力。借助来自德国纵向选举研究（GLES）的开放式调查数据，我们促使不同的LLMs通过将人口特征融入角色提示来生成能反映德国亚人群的综合公众意见。我们的成果显示，Llama在代表亚人群方面比其他LLMs表现更出色，尤其是在这些群体内意见多样性较低时。我们的发现还表明，与其他政党相比，LLM在代表诸如绿党和左翼党这类左翼政党的支持者时表现更佳，而与右翼政党AfD的匹配度最差。另外，提示中特定变量的纳入或排除会对模型的预测产生显著影响。这些发现凸显了调整LLMs以更有效地模拟各类公众意见，同时最大程度减少政治偏见并增强代表性稳健性的重要性。

> In recent research, large language models (LLMs) have been increasingly used to investigate public opinions. This study investigates the algorithmic fidelity of LLMs, i.e., the ability to replicate the socio-cultural context and nuanced opinions of human participants. Using open-ended survey data from the German Longitudinal Election Studies (GLES), we prompt different LLMs to generate synthetic public opinions reflective of German subpopulations by incorporating demographic features into the persona prompts. Our results show that Llama performs better than other LLMs at representing subpopulations, particularly when there is lower opinion diversity within those groups. Our findings further reveal that the LLM performs better for supporters of left-leaning parties like The Greens and The Left compared to other parties, and matches the least with the right-party AfD. Additionally, the inclusion or exclusion of specific variables in the prompts can significantly impact the models' predictions. These findings underscore the importance of aligning LLMs to more effectively model diverse public opinions while minimizing political biases and enhancing robustness in representativeness.

[Arxiv](https://arxiv.org/abs/2412.13169)