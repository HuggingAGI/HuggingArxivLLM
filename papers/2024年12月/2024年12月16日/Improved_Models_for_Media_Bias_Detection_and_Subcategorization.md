# 媒体偏见检测与子分类模型的优化

发布时间：2024年12月16日

`LLM应用

解释：这篇论文主要讨论了如何利用大型预训练神经Transformer语言模型（LLM）来改进新闻媒体偏见的检测和分类。论文中提到了零-shot与微调的对比，以及如何利用合成数据提升模型性能，这些都是LLM在实际应用中的具体应用场景。因此，这篇论文应被分类为LLM应用。` `新闻媒体`

> Improved Models for Media Bias Detection and Subcategorization

# 摘要

> 我们开发了改进的模型，用于在英文新闻文章中细粒度检测和子分类新闻媒体偏见。我们对比了零-shot与微调的大型预训练神经Transformer语言模型的性能，研究了类别细节对27种新闻偏见类型新分类法的影响，并展示了如何利用合成生成的示例数据提升质量。

> We present improved models for the granular detection and sub-classification news media bias in English news articles. We compare the performance of zero-shot versus fine-tuned large pre-trained neural transformer language models, explore how the level of detail of the classes affects performance on a novel taxonomy of 27 news bias-types, and demonstrate how using synthetically generated example data can be used to improve quality

[Arxiv](https://arxiv.org/abs/2412.11835)