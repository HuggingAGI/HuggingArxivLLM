# 分析法律文件的图像：朝着用于实现司法获取的多模态大型语言模型迈进

发布时间：2024年12月16日

`LLM应用` `多模态`

> Analyzing Images of Legal Documents: Toward Multi-Modal LLMs for Access to Justice

# 摘要

> 在与法律系统和政府打交道时，需要整合和分析散落在不同（纸质）文件（如表格、证书、合同，比如租约）中的各类信息。这些信息对于了解自身合法权益、填写法院索赔表格或获取政府福利至关重要。然而，对于普通人而言，找到正确的信息、合适的表格并填写好并非易事。大型语言模型（LLM）虽已成为颇具潜力的强大技术，有望弥补这一差距，但仍依赖用户提供准确信息，若信息仅存于复杂的纸质文件中，这可能既困难又易出错。我们开展了一项利用多模态LLM分析手写纸质表格图像的研究，旨在以结构化形式自动提取相关信息。我们的初步成果令人期待，但也暴露出一些局限性（比如图像质量差时）。我们的工作展现了融合多模态LLM以助力普通人及自我代理诉讼者查找和整合相关信息的潜力。

> Interacting with the legal system and the government requires the assembly and analysis of various pieces of information that can be spread across different (paper) documents, such as forms, certificates and contracts (e.g. leases). This information is required in order to understand one's legal rights, as well as to fill out forms to file claims in court or obtain government benefits. However, finding the right information, locating the correct forms and filling them out can be challenging for laypeople. Large language models (LLMs) have emerged as a powerful technology that has the potential to address this gap, but still rely on the user to provide the correct information, which may be challenging and error-prone if the information is only available in complex paper documents. We present an investigation into utilizing multi-modal LLMs to analyze images of handwritten paper forms, in order to automatically extract relevant information in a structured format. Our initial results are promising, but reveal some limitations (e.g., when the image quality is low). Our work demonstrates the potential of integrating multi-modal LLMs to support laypeople and self-represented litigants in finding and assembling relevant information.

[Arxiv](https://arxiv.org/abs/2412.15260)