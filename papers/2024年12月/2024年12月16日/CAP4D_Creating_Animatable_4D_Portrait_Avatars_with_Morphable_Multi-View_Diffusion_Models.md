# CAP4D：借助可变形多视图扩散模型打造可动画的 4D 肖像化身

发布时间：2024年12月16日

`其他` `虚拟现实`

> CAP4D: Creating Animatable 4D Portrait Avatars with Morphable Multi-View Diffusion Models

# 摘要

> 摘要：从图像中重建逼真且动态的肖像化身，对广告、视觉效果和虚拟现实等众多应用而言至关重要。不同应用场景下，化身重建所涉及的捕获设置和约束各不相同——比如，视觉效果工作室会用相机阵列采集数百张参考图像，而内容创作者可能只想给从网上下载的单张肖像图片制作动画。正因如此，存在着一个庞大且多元的化身重建方法生态系统。基于多视图立体或神经渲染的技术能达成最高质量的成果，但需要数百张参考图像。近期的生成模型能从单个参考图像生成令人信服的化身，不过其视觉保真度仍不及多视图技术。在此，我们推出 CAP4D：一种运用可变形多视图扩散模型，能从任意数量的参考图像（即 1 至 100 张）重建逼真的 4D（动态 3D）肖像化身，并对其进行实时动画和渲染的方法。我们的方法在单张、少量及多张图像的 4D 肖像化身重建上展现出了前沿性能，并在缩小单张图像和多视图重建技术的视觉保真度差距方面有所作为。

> 
Abstract:Reconstructing photorealistic and dynamic portrait avatars from images is essential to many applications including advertising, visual effects, and virtual reality. Depending on the application, avatar reconstruction involves different capture setups and constraints $-$ for example, visual effects studios use camera arrays to capture hundreds of reference images, while content creators may seek to animate a single portrait image downloaded from the internet. As such, there is a large and heterogeneous ecosystem of methods for avatar reconstruction. Techniques based on multi-view stereo or neural rendering achieve the highest quality results, but require hundreds of reference images. Recent generative models produce convincing avatars from a single reference image, but visual fidelity yet lags behind multi-view techniques. Here, we present CAP4D: an approach that uses a morphable multi-view diffusion model to reconstruct photoreal 4D (dynamic 3D) portrait avatars from any number of reference images (i.e., one to 100) and animate and render them in real time. Our approach demonstrates state-of-the-art performance for single-, few-, and multi-image 4D portrait avatar reconstruction, and takes steps to bridge the gap in visual fidelity between single-image and multi-view reconstruction techniques.
    

[Arxiv](https://arxiv.org/pdf/2412.12093)