# 利用指令调优的大型语言模型识别警察事件叙述中的脆弱性指标

发布时间：2024年12月16日

`LLM应用

理由：这篇论文主要探讨了指令调优的大型语言模型（IT-LLMs）在分类警察与公众互动描述的非结构化文本中的应用。研究比较了IT-LLMs与人类编码员在定性编码中的表现，并评估了IT-LLM编码中的潜在偏见。论文的重点在于如何利用LLM来增强人类定性编码的效率和质量，这属于LLM在实际应用中的使用场景，因此归类为“LLM应用”。` `公共安全`

> Using Instruction-Tuned Large Language Models to Identify Indicators of Vulnerability in Police Incident Narratives

# 摘要

> # 目标
比较指令调优的大型语言模型（IT-LLMs）与人类编码员在分类警察与公众互动描述的非结构化文本中是否存在脆弱性方面的定性编码，并评估IT-LLM编码中的潜在偏见。方法：我们分析了波士顿警察局记录的警察与公众互动的公开文本叙述，为人类和IT-LLMs提供定性标签编码手册，并比较两者生成的标签，旨在识别与精神健康问题、物质滥用、酒精依赖和无家可归相关的情况。我们探索了多种提示策略和模型大小，以及重复提示生成的标签的变异性。此外，为了探索模型偏见，我们利用反事实方法评估了种族和性别对IT-LLM分类的影响。结果：结果表明，IT-LLMs可以有效支持人类对警察事件叙述的定性编码。尽管LLM和人类生成的标签之间存在一些分歧，但IT-LLMs在筛选不存在脆弱性的叙述方面非常有效，可能大大减少人类编码的需求。反事实分析表明，对叙述中描述的个体的性别和种族的操纵对IT-LLM分类的影响非常有限，超出偶然预期的范围。结论：IT-LLMs提供了一种有效的方式来增强人类定性编码，这种方式需要更少的资源来分析大型非结构化数据集。此外，它们鼓励定性编码的特定性，促进透明度，并为分析大型自由文本警察数据源提供了更标准化、可复制的方法的机会。

> Objectives: Compare qualitative coding of instruction tuned large language models (IT-LLMs) against human coders in classifying the presence or absence of vulnerability in routinely collected unstructured text that describes police-public interactions. Evaluate potential bias in IT-LLM codings. Methods: Analyzing publicly available text narratives of police-public interactions recorded by Boston Police Department, we provide humans and IT-LLMs with qualitative labelling codebooks and compare labels generated by both, seeking to identify situations associated with (i) mental ill health; (ii) substance misuse; (iii) alcohol dependence; and (iv) homelessness. We explore multiple prompting strategies and model sizes, and the variability of labels generated by repeated prompts. Additionally, to explore model bias, we utilize counterfactual methods to assess the impact of two protected characteristics - race and gender - on IT-LLM classification. Results: Results demonstrate that IT-LLMs can effectively support human qualitative coding of police incident narratives. While there is some disagreement between LLM and human generated labels, IT-LLMs are highly effective at screening narratives where no vulnerabilities are present, potentially vastly reducing the requirement for human coding. Counterfactual analyses demonstrate that manipulations to both gender and race of individuals described in narratives have very limited effects on IT-LLM classifications beyond those expected by chance. Conclusions: IT-LLMs offer effective means to augment human qualitative coding in a way that requires much lower levels of resource to analyze large unstructured datasets. Moreover, they encourage specificity in qualitative coding, promote transparency, and provide the opportunity for more standardized, replicable approaches to analyzing large free-text police data sources.

[Arxiv](https://arxiv.org/abs/2412.11878)