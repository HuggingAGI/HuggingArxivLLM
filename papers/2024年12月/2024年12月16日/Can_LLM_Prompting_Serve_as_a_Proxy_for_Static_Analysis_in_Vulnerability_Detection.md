# LLM 提示在漏洞检测中能否充当静态分析的替代品？

发布时间：2024年12月16日

`LLM应用` `漏洞检测` `软件开发`

> Can LLM Prompting Serve as a Proxy for Static Analysis in Vulnerability Detection

# 摘要

> 尽管大型语言模型（LLMs）成就斐然，但在漏洞检测这类应用任务上能力有限。我们对漏洞检测的多种提示策略展开研究，并在探索中提出一种将漏洞的自然语言描述与对比思维链推理方法相融合的提示策略，借助来自合成数据集的对比样本来增强效果。我们的研究凸显了将自然语言描述、对比推理和合成示例整合进综合提示框架，LLMs 在检测漏洞方面的潜力。我们的结果显示，此方法能增强 LLM 对漏洞的理解。在诸如 SVEN 这样的高质量漏洞检测数据集中，我们的提示策略能分别将准确率、F1 分数和成对准确率提高 23%、11%和 14%。

> Despite their remarkable success, large language models (LLMs) have shown limited ability on applied tasks such as vulnerability detection. We investigate various prompting strategies for vulnerability detection and, as part of this exploration, propose a prompting strategy that integrates natural language descriptions of vulnerabilities with a contrastive chain-of-thought reasoning approach, augmented using contrastive samples from a synthetic dataset. Our study highlights the potential of LLMs to detect vulnerabilities by integrating natural language descriptions, contrastive reasoning, and synthetic examples into a comprehensive prompting framework. Our results show that this approach can enhance LLM understanding of vulnerabilities. On a high-quality vulnerability detection dataset such as SVEN, our prompting strategies can improve accuracies, F1-scores, and pairwise accuracies by 23%, 11%, and 14%, respectively.

[Arxiv](https://arxiv.org/abs/2412.12039)