# 理解并评估电子表格中生成式人工智能与大型语言模型的可信度

发布时间：2024年12月18日

`LLM应用` `电子表格` `人工智能`

> Understanding and Evaluating Trust in Generative AI and Large Language Models for Spreadsheets

# 摘要

> 生成式人工智能和大型语言模型（LLMs）有望实现电子表格公式创建的自动化。但由于存在幻觉、偏差以及用户技能参差不齐，生成式人工智能的输出不能视作准确可信。为应对这些挑战，基于评估公式的透明度和可靠性，提出了一个可信度框架。通过可解释性（理解公式的推理）和可见性（检查底层算法）来探究公式的透明度，从可靠性（一致性和准确性）以及伦理考量（偏差和公平性）方面评估生成公式的可靠性。本文还从幻觉、训练数据偏差和不当提示等方面研究了这些指标的驱动因素。最后，考虑了技术不信任的实例并探讨了其后果。

> Generative AI and Large Language Models (LLMs) hold promise for automating spreadsheet formula creation. However, due to hallucinations, bias and variable user skill, outputs obtained from generative AI cannot be assumed to be accurate or trustworthy. To address these challenges, a trustworthiness framework is proposed based on evaluating the transparency and dependability of the formula. The transparency of the formula is explored through explainability (understanding the formula's reasoning) and visibility (inspecting the underlying algorithms). The dependability of the generated formula is evaluated in terms of reliability (consistency and accuracy) and ethical considerations (bias and fairness). The paper also examines the drivers to these metrics in the form of hallucinations, training data bias and poorly constructed prompts. Finally, examples of mistrust in technology are considered and the consequences explored.

[Arxiv](https://arxiv.org/abs/2412.14062)