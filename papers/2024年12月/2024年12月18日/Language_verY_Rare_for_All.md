# 语言对于所有人来说都极为罕见

发布时间：2024年12月18日

`RAG` `语言翻译` `稀有语言`

> Language verY Rare for All

# 摘要

> 在克服语言障碍的征程中，诸如 NLLB 这类编码器 - 解码器模型将机器翻译拓展到了稀有语言领域，部分模型（如 NLLB 1.3B）甚至能在单个 GPU 上训练。通用的大型语言模型在翻译中表现出色，而开放的大型语言模型在针对涉及未知语料库的特定任务进行微调时极具竞争力。我们推出了 LYRA（适用于所有极稀有语言），这一创新方法融合了开放大型语言模型的微调、检索增强生成（RAG）以及从相关高资源语言的迁移学习。本研究专注于单 GPU 训练，以利于推广应用。我们的研究聚焦于法语和摩纳哥语之间的双向翻译，由于语料有限，摩纳哥语是现有翻译工具未支持的稀有语言。我们的成果彰显了 LYRA 的有效性，在稀有语言翻译中屡屡超越并持续比肩最先进的编码器 - 解码器模型。

> In the quest to overcome language barriers, encoder-decoder models like NLLB have expanded machine translation to rare languages, with some models (e.g., NLLB 1.3B) even trainable on a single GPU. While general-purpose LLMs perform well in translation, open LLMs prove highly competitive when fine-tuned for specific tasks involving unknown corpora. We introduce LYRA (Language verY Rare for All), a novel approach that combines open LLM fine-tuning, retrieval-augmented generation (RAG), and transfer learning from related high-resource languages. This study is exclusively focused on single-GPU training to facilitate ease of adoption. Our study focuses on two-way translation between French and Monégasque, a rare language unsupported by existing translation tools due to limited corpus availability. Our results demonstrate LYRA's effectiveness, frequently surpassing and consistently matching state-of-the-art encoder-decoder models in rare language translation.

[Arxiv](https://arxiv.org/abs/2412.13924)