# 衡量面向儿童的文本中的上下文信息丰富度

发布时间：2024年12月23日

`LLM应用` `儿童故事`

> Measuring Contextual Informativeness in Child-Directed Text

# 摘要

> 为填补创作儿童故事以丰富词汇的重要空缺，我们对故事传递目标词汇语义的效果展开自动评估进行了研究，此任务对生成教育内容意义重大。我们推动了这项被称为“测量儿童故事中的上下文信息量”的任务，并提供了正式的任务定义和数据集。我们还进一步提出了使用大型语言模型（LLM）来实现该任务自动化的方法。我们的实验显示，我们的方法与人类对信息量的判断的斯皮尔曼相关性达到 0.4983，而最强的基线仅为 0.3534。另外的分析表明，基于 LLM 的方法能够推广应用于测量成人导向文本中的上下文信息量，且在这方面也超越了所有基线。

> To address an important gap in creating children's stories for vocabulary enrichment, we investigate the automatic evaluation of how well stories convey the semantics of target vocabulary words, a task with substantial implications for generating educational content. We motivate this task, which we call measuring contextual informativeness in children's stories, and provide a formal task definition as well as a dataset for the task. We further propose a method for automating the task using a large language model (LLM). Our experiments show that our approach reaches a Spearman correlation of 0.4983 with human judgments of informativeness, while the strongest baseline only obtains a correlation of 0.3534. An additional analysis shows that the LLM-based approach is able to generalize to measuring contextual informativeness in adult-directed text, on which it also outperforms all baselines.

[Arxiv](https://arxiv.org/abs/2412.17427)