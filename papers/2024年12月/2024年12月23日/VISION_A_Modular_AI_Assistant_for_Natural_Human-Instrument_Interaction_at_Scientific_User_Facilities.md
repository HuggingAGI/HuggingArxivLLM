# VISION：科学用户设施中实现自然人机交互的模块化人工智能助手

发布时间：2024年12月23日

`LLM应用` `科学实验` `人工智能`

> VISION: A Modular AI Assistant for Natural Human-Instrument Interaction at Scientific User Facilities

# 摘要

> 科学用户设施，比如同步辐射光束线，配备了众多的硬件和软件工具，这需要一个用于人机交互的代码库。通常这就需要开发人员参与进来，在用户/研究人员与复杂仪器之间建立联系。生成式人工智能的出现带来了弥合这一知识鸿沟的契机，能够实现无缝交流和高效的实验工作流程。在此，我们通过组合多个具备人工智能的认知模块，为虚拟科学伴侣（VISION）构建了一个模块化架构，每个模块都为大型语言模型（LLMs）的特定任务提供了支撑。借助 VISION，我们在光束线工作站上进行了基于 LLM 的低延迟操作，并在 X 射线散射光束线上开展了首次语音控制实验。其模块化且可扩展的架构易于适应新的仪器和功能。基于自然语言的科学实验开发是即将到来的未来的一块基石，在这个未来，科学外皮层——科学家认知的合成延展——或许会从根本上变革科学实践与发现。

> Scientific user facilities, such as synchrotron beamlines, are equipped with a wide array of hardware and software tools that require a codebase for human-computer-interaction. This often necessitates developers to be involved to establish connection between users/researchers and the complex instrumentation. The advent of generative AI presents an opportunity to bridge this knowledge gap, enabling seamless communication and efficient experimental workflows. Here we present a modular architecture for the Virtual Scientific Companion (VISION) by assembling multiple AI-enabled cognitive blocks that each scaffolds large language models (LLMs) for a specialized task. With VISION, we performed LLM-based operation on the beamline workstation with low latency and demonstrated the first voice-controlled experiment at an X-ray scattering beamline. The modular and scalable architecture allows for easy adaptation to new instrument and capabilities. Development on natural language-based scientific experimentation is a building block for an impending future where a science exocortex -- a synthetic extension to the cognition of scientists -- may radically transform scientific practice and discovery.

[Arxiv](https://arxiv.org/abs/2412.18161)