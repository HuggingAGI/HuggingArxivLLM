# 《对不纯粹理性的批判：揭开医疗大型语言模型的推理表现》

发布时间：2024年12月20日

`LLM应用` `人工智能`

> Critique of Impure Reason: Unveiling the reasoning behaviour of medical Large Language Models

# 摘要

> 背景：尽管大型语言模型（LLMs）在医疗领域已十分普遍，但针对其推理行为的研究却少之又少，这令人诧异。我们着重强调理解推理行为的重要性，而非高级预测的准确性，因为在此情境下，这等同于可解释的人工智能（XAI）。特别是，在临床领域所使用的医疗LLMs中实现XAI，将对整个医疗保健领域产生重大影响。结果：因此，我们在医疗LLMs的特定情境中定义了推理行为的概念。接着，我们对评估医疗LLMs推理行为的方法的现有水平进行分类和探讨。最后，我们提出了理论框架，能够让医疗专业人员或机器学习工程师深入了解这些以往模糊模型的底层推理操作。结论：随之而来的是，临床医生和患者对医疗机器学习模型透明度和信任度的提升，这将加快整个医疗保健系统中医疗人工智能的整合、应用和进一步发展。

> Background: Despite the current ubiquity of Large Language Models (LLMs) across the medical domain, there is a surprising lack of studies which address their reasoning behaviour. We emphasise the importance of understanding reasoning behaviour as opposed to high-level prediction accuracies, since it is equivalent to explainable AI (XAI) in this context. In particular, achieving XAI in medical LLMs used in the clinical domain will have a significant impact across the healthcare sector. Results: Therefore, we define the concept of reasoning behaviour in the specific context of medical LLMs. We then categorise and discuss the current state of the art of methods which evaluate reasoning behaviour in medical LLMs. Finally, we propose theoretical frameworks which can empower medical professionals or machine learning engineers to gain insight into the low-level reasoning operations of these previously obscure models. Conclusion: The subsequent increased transparency and trust in medical machine learning models by clinicians as well as patients will accelerate the integration, application as well as further development of medical AI for the healthcare system as a whole

[Arxiv](https://arxiv.org/abs/2412.15748)