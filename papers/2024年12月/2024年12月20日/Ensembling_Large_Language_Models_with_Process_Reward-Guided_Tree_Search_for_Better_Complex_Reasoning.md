# 利用过程奖励引导的树搜索来集成大型语言模型，从而实现更出色的复杂推理

发布时间：2024年12月20日

`LLM应用`

> Ensembling Large Language Models with Process Reward-Guided Tree Search for Better Complex Reasoning

# 摘要

> 尽管大型语言模型近来有所进步，可开源模型在复杂推理任务中常常难以持续有出色表现。现有的集成方法，不管是在标记层面还是输出层面应用，都难以应对这些挑战。为此，我们推出了带有蒙特卡罗树搜索的语言模型集成（LE-MCTS），这是一个用于语言模型过程级集成的全新框架。LE-MCTS 把语言模型集成的逐步推理构建成马尔可夫决策过程。在此框架中，状态意味着中间推理路径，而动作涵盖使用从预先设定的池子里选出的某个语言模型生成下一个推理步骤。在基于过程的奖励模型引导下，LE-MCTS 对不同语言模型生成的推理步骤展开树搜索，找出最准确的推理链。在五个数学推理基准上的实验结果显示，我们的方法比单个语言模型解码算法和语言模型集成方法都更出色。特别要指出的是，LE-MCTS 在 MATH 和 MQA 数据集上分别将性能提升了 3.6％和 4.3％，凸显了其在解决复杂推理问题上的有效性。

> Despite recent advances in large language models, open-source models often struggle to consistently perform well on complex reasoning tasks. Existing ensemble methods, whether applied at the token or output levels, fail to address these challenges. In response, we present Language model Ensemble with Monte Carlo Tree Search (LE-MCTS), a novel framework for process-level ensembling of language models. LE-MCTS formulates step-by-step reasoning with an ensemble of language models as a Markov decision process. In this framework, states represent intermediate reasoning paths, while actions consist of generating the next reasoning step using one of the language models selected from a predefined pool. Guided by a process-based reward model, LE-MCTS performs a tree search over the reasoning steps generated by different language models, identifying the most accurate reasoning chain. Experimental results on five mathematical reasoning benchmarks demonstrate that our approach outperforms both single language model decoding algorithms and language model ensemble methods. Notably, LE-MCTS improves performance by 3.6% and 4.3% on the MATH and MQA datasets, respectively, highlighting its effectiveness in solving complex reasoning problems.

[Arxiv](https://arxiv.org/abs/2412.15797)