# 《谎言、可恶的谎言与分布式语言统计：借助大型语言模型进行的说服与欺骗》

发布时间：2024年12月22日

`LLM应用` `人工智能` `语言模型`

> Lies, Damned Lies, and Distributional Language Statistics: Persuasion and Deception with Large Language Models

# 摘要

> 大型语言模型（LLMs）能生成极具说服力、堪比人类创作的内容，还似乎能有选择性地制造出具有欺骗性的输出。这些能力令人担忧，随着这些系统被更广泛地应用，可能会被误用并产生意想不到的后果。本综述整合了近期考察 LLMs 说服力和欺骗倾向的实证研究，剖析了由这些能力可能引发的理论风险，并对所提出的缓解措施进行了评估。尽管当前的说服效果相对较小，但诸如微调、多模态和社会因素等各类机制可能会增强其影响力。我们列出了未来研究的关键开放性问题，比如有说服力的人工智能系统会发展成何种模样，真理相对于谎言是否具有内在优势，以及不同的缓解策略在实际应用中可能的效果如何。

> Large Language Models (LLMs) can generate content that is as persuasive as human-written text and appear capable of selectively producing deceptive outputs. These capabilities raise concerns about potential misuse and unintended consequences as these systems become more widely deployed. This review synthesizes recent empirical work examining LLMs' capacity and proclivity for persuasion and deception, analyzes theoretical risks that could arise from these capabilities, and evaluates proposed mitigations. While current persuasive effects are relatively small, various mechanisms could increase their impact, including fine-tuning, multimodality, and social factors. We outline key open questions for future research, including how persuasive AI systems might become, whether truth enjoys an inherent advantage over falsehoods, and how effective different mitigation strategies may be in practice.

[Arxiv](https://arxiv.org/abs/2412.17128)