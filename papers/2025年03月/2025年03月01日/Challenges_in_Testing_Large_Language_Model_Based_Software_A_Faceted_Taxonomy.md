# # 摘要
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年03月01日

`LLM应用` `软件工程` `人工智能`

> Challenges in Testing Large Language Model Based Software: A Faceted Taxonomy

# 摘要

> 大型语言模型（LLMs）和多智能体大型语言模型（MALLMs）不同于传统软件或机器学习软件，它们引入了非确定性特性。这意味着我们需要采用新的方法来验证程序的正确性，而不仅仅是依赖简单的输出比较或测试数据集上的统计准确性。本文提出了一种LLM测试用例设计分类法，该分类法结合了研究文献、实践经验以及代表当前实践水平的开源工具。我们识别了影响测试正确性的关键变体点，并强调了随着LLMs在软件系统中扮演越来越重要的角色，研究界、产业界和开源社区必须共同应对的开放挑战。我们的分类法定义了LLM测试用例设计的四个关键方面，既解决了输入和输出中的模糊性，又制定了最佳实践标准。它区分了目标、被测系统和输入中的变异性，并引入了两种关键预言类型：原子型和聚合型。我们的分析表明，现有工具在处理这些变异性点时存在不足，这凸显了学术界与实践者之间需要加强合作，以提升LLM测试的可靠性和可重复性。

> Large Language Models (LLMs) and Multi-Agent LLMs (MALLMs) introduce non-determinism unlike traditional or machine learning software, requiring new approaches to verifying correctness beyond simple output comparisons or statistical accuracy over test datasets.
  This paper presents a taxonomy for LLM test case design, informed by both the research literature, our experience, and open-source tools that represent the state of practice. We identify key variation points that impact test correctness and highlight open challenges that the research, industry, and open-source communities must address as LLMs become integral to software systems.
  Our taxonomy defines four facets of LLM test case design, addressing ambiguity in both inputs and outputs while establishing best practices. It distinguishes variability in goals, the system under test, and inputs, and introduces two key oracle types: atomic and aggregated. Our mapping indicates that current tools insufficiently account for these variability points, highlighting the need for closer collaboration between academia and practitioners to improve the reliability and reproducibility of LLM testing.

[Arxiv](https://arxiv.org/abs/2503.00481)