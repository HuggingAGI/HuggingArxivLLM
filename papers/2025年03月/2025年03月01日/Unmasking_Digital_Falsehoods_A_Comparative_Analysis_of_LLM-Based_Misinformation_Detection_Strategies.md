# 揭开数字虚假信息的面纱：基于大语言模型的虚假信息检测策略对比分析

发布时间：2025年03月01日

`LLM应用` `社交媒体` `信息检测`

> Unmasking Digital Falsehoods: A Comparative Analysis of LLM-Based Misinformation Detection Strategies

# 摘要

> 社交媒体上虚假信息的泛滥已引发重大社会关注，亟需 robust 的检测机制。大型语言模型如GPT-4和LLaMA2凭借其卓越的自然语言理解和推理能力，被视为检测虚假信息的潜在工具。本文对比了基于文本、多模态和智能体的LLM检测方法，评估了微调模型、零样本学习和系统化事实核查机制在公共卫生、政治和金融等不同领域中的有效性。我们探讨了模型的可扩展性、通用性和可解释性，并指出了幻觉、对抗攻击和计算资源等关键挑战。研究结果表明，结合结构化验证协议和自适应学习技术的混合方法能显著提升检测准确性和可解释性。最后，本文展望了未来研究方向，包括实时虚假信息追踪、联邦学习和跨平台检测模型。

> The proliferation of misinformation on social media has raised significant societal concerns, necessitating robust detection mechanisms. Large Language Models such as GPT-4 and LLaMA2 have been envisioned as possible tools for detecting misinformation based on their advanced natural language understanding and reasoning capabilities. This paper conducts a comparison of LLM-based approaches to detecting misinformation between text-based, multimodal, and agentic approaches. We evaluate the effectiveness of fine-tuned models, zero-shot learning, and systematic fact-checking mechanisms in detecting misinformation across different topic domains like public health, politics, and finance. We also discuss scalability, generalizability, and explainability of the models and recognize key challenges such as hallucination, adversarial attacks on misinformation, and computational resources. Our findings point towards the importance of hybrid approaches that pair structured verification protocols with adaptive learning techniques to enhance detection accuracy and explainability. The paper closes by suggesting potential avenues of future work, including real-time tracking of misinformation, federated learning, and cross-platform detection models.

[Arxiv](https://arxiv.org/abs/2503.00724)