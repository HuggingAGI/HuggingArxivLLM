# # 谁是间谍？探索大型语言模型在文字游戏中的表现

发布时间：2025年03月19日

`LLM应用

理由：这篇论文探讨了如何将大型语言模型（LLMs）应用于文字游戏，并提出了一种无需训练的框架，展示了LLMs在结构化游戏环境中的应用潜力。因此，它属于LLM应用类别。` `文字游戏` `博弈论`

> Exploring Large Language Models for Word Games:Who is the Spy?

# 摘要

> 文字游戏因规则驱动和情境化的特性，在自然语言处理（NLP）、博弈论及相关领域中具有重要研究价值。本研究探讨了如何有效将大型语言模型（LLMs）应用于文字游戏，并提出了一种无需训练的框架。以中文名为“谁是我家”或英文“Who is the Spy”的经典文字游戏为例，我们引入了一种基于链式思考（CoT）的调度框架，使LLMs能够在推断角色词和伪装身份等任务中实现优秀表现。我们根据游戏成功率和LLM代理分析结果的准确性对框架性能进行了评估。实验结果证实了框架的有效性，展示了LLMs在多个数据集上的显著性能提升。本研究凸显了LLMs在结构化游戏环境中掌握情境推理和社会互动的潜力。我们的代码已公开发布于https://github.com/ct-wei/Who-is-The-Spy。

> Word games hold significant research value for natural language processing (NLP), game theory, and related fields due to their rule-based and situational nature. This study explores how large language models (LLMs) can be effectively involved in word games and proposes a training-free framework. "Shei Shi Wo Di" or "Who is the Spy" in English, is a classic word game. Using this game as an example, we introduce a Chain-of-Thought (CoT)-based scheduling framework to enable LLMs to achieve excellent performance in tasks such as inferring role words and disguising their identities. We evaluate the framework's performance based on game success rates and the accuracy of the LLM agents' analytical results. Experimental results affirm the framework's effectiveness, demonstrating notable improvements in LLM performance across multiple datasets. This work highlights the potential of LLMs in mastering situational reasoning and social interactions within structured game environments. Our code is publicly available at https://github.com/ct-wei/Who-is-The-Spy.

[Arxiv](https://arxiv.org/abs/2503.15235)