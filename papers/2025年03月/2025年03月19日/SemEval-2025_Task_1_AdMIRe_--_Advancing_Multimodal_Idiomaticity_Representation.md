# SemEval-2025 任务 1：AdMIRe——提升多模态惯用法表达能力

发布时间：2025年03月19日

`LLM应用` `多模态`

> SemEval-2025 Task 1: AdMIRe -- Advancing Multimodal Idiomaticity Representation

# 摘要

> 习语表达在自然语言处理中是一个独特挑战，因为其意义往往无法从字面推断。尽管大型语言模型（LLMs）不断进步，但习语性依然是实现稳健语义表示的重要障碍。我们为SemEval-2025任务1：AdMiRe（提升多模态习语表达能力）提供了数据集和任务，旨在挑战研究社区评估和提升模型在多模态上下文和多种语言中解读习语表达的能力。参与者在两个子任务中展开竞争：根据习语或字面意义对图像进行排序，以及预测序列中的下一个图像。最有效的方法通过在专家混合设置中利用预训练的LLMs和视觉语言模型，达到了人类级别的性能，同时使用多个查询来弥补这些模型在习语性表示上的不足。

> Idiomatic expressions present a unique challenge in NLP, as their meanings are often not directly inferable from their constituent words. Despite recent advancements in Large Language Models (LLMs), idiomaticity remains a significant obstacle to robust semantic representation. We present datasets and tasks for SemEval-2025 Task 1: AdMiRe (Advancing Multimodal Idiomaticity Representation), which challenges the community to assess and improve models' ability to interpret idiomatic expressions in multimodal contexts and in multiple languages. Participants competed in two subtasks: ranking images based on their alignment with idiomatic or literal meanings, and predicting the next image in a sequence. The most effective methods achieved human-level performance by leveraging pretrained LLMs and vision-language models in mixture-of-experts settings, with multiple queries used to smooth over the weaknesses in these models' representations of idiomaticity.

[Arxiv](https://arxiv.org/abs/2503.15358)