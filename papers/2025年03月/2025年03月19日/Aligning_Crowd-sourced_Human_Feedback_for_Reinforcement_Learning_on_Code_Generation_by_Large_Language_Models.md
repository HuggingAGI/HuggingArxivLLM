# 对齐众包人类反馈，提升大型语言模型的代码生成能力

发布时间：2025年03月19日

`LLM应用` `AI辅助编程` `软件开发`

> Aligning Crowd-sourced Human Feedback for Reinforcement Learning on Code Generation by Large Language Models

# 摘要

> 本文探讨了AI辅助编程和大型语言模型（LLM）如何通过AI工具（如GitHub Copilot和Amazon CodeWhisperer）等LLM代理提升软件开发者的编程能力。我们结合人类反馈增强强化学习（RLHF），并利用众包计算优化文本到代码的生成。此外，我们的贝叶斯优化框架通过分散反馈收集负担，支持代码生成中的AI对齐，凸显了高质量人类反馈的重要性。实证评估表明，该方法有效提升了LLM代理的文本到代码生成能力。我们的贝叶斯优化框架适用于通用领域特定语言，推动了大型语言模型与AI辅助编程中代码生成的人类反馈对齐。

> This paper studies how AI-assisted programming and large language models (LLM) improve software developers' ability via AI tools (LLM agents) like Github Copilot and Amazon CodeWhisperer, while integrating human feedback to enhance reinforcement learning (RLHF) with crowd-sourced computation to enhance text-to-code generation. Additionally, we demonstrate that our Bayesian optimization framework supports AI alignment in code generation by distributing the feedback collection burden, highlighting the value of collecting human feedback of good quality. Our empirical evaluations demonstrate the efficacy of this approach, showcasing how LLM agents can be effectively trained for improved text-to-code generation. Our Bayesian optimization framework can be designed for general domain-specific languages, promoting the alignment of large language model capabilities with human feedback in AI-assisted programming for code generation.

[Arxiv](https://arxiv.org/abs/2503.15129)