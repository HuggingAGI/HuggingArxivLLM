# Video-VoT-R1：一种高效视频推理模型，融合图像打包与AoE架构

发布时间：2025年03月19日

`LLM应用` `视频处理`

> Video-VoT-R1: An efficient video inference model integrating image packing and AoE architecture

# 摘要

> 视频语言预训练领域目前面临着推理效率和多模态数据处理的诸多挑战。本文提出了一种基于长序列图像编码器的 KunLunBaize-VoT-R1 视频推理模型，并详细介绍了其训练与应用方法。通过整合图像打包技术、Autonomy-of-Experts (AoE) 架构，以及结合视频思维 (VoT)——一种基于大规模强化学习训练的大语言模型 (LLM) 和多种训练技术，我们有效提升了模型在视频推理任务中的效率与准确性。实验结果表明，该模型在多项测试中表现优异，为视频语言理解提供了一种全新的解决方案。
    

> In the field of video-language pretraining, existing models face numerous challenges in terms of inference efficiency and multimodal data processing. This paper proposes a KunLunBaize-VoT-R1 video inference model based on a long-sequence image encoder, along with its training and application methods. By integrating image packing technology, the Autonomy-of-Experts (AoE) architecture, and combining the video of Thought (VoT), a large language model (LLM) trained with large-scale reinforcement learning, and multiple training techniques, the efficiency and accuracy of the model in video inference tasks are effectively improved. Experiments show that this model performs outstandingly in multiple tests, providing a new solution for video-language understanding.

[Arxiv](https://arxiv.org/abs/2503.15807)