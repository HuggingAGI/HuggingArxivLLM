# 为什么LLMs缺乏思维能力，以及如何实现突破

发布时间：2025年03月12日

`LLM理论` `人工智能` `计算机科学`

> Why LLMs Cannot Think and How to Fix It

# 摘要

> 本文指出，当前最先进的大型语言模型（LLMs）由于其架构限制，在特征空间内本质上无法进行决策或发展“思想”。我们重新定义了“思想”这一概念，使其既符合传统理解，又能应用于LLMs。我们证明，现代LLMs的架构设计和语言建模训练方法本质上无法进行真正的思考过程。我们的研究重点在于这一理论突破，而非实验数据的实际应用。最后，我们提出了在特征空间内实现思考过程的解决方案，并探讨了这些架构修改带来的更广泛影响。

> This paper elucidates that current state-of-the-art Large Language Models (LLMs) are fundamentally incapable of making decisions or developing "thoughts" within the feature space due to their architectural constraints. We establish a definition of "thought" that encompasses traditional understandings of that term and adapt it for application to LLMs. We demonstrate that the architectural design and language modeling training methodology of contemporary LLMs inherently preclude them from engaging in genuine thought processes. Our primary focus is on this theoretical realization rather than practical insights derived from experimental data. Finally, we propose solutions to enable thought processes within the feature space and discuss the broader implications of these architectural modifications.

[Arxiv](https://arxiv.org/abs/2503.09211)