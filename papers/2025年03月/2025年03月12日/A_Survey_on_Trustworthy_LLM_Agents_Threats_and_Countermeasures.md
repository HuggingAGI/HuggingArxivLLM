# # 可信LLM智能体的威胁与对策调查
可信LLM智能体的威胁与对策调查

发布时间：2025年03月12日

`Agent` `人工智能` `可信计算`

> A Survey on Trustworthy LLM Agents: Threats and Countermeasures

# 摘要

> 大型语言模型（LLMs）的快速发展推动了基于LLMs的智能体和多智能体系统（MAS）的演进，显著扩展了LLM生态的能力。这种演进源于为LLMs赋予了记忆、工具、环境和其他智能体等额外模块。然而，这种进步也带来了更复杂的可信性问题，这是之前仅关注LLMs的研究无法涵盖的。在本研究中，我们提出了TrustAgent框架，这是一个关于智能体可信性的全面研究，具有模块化分类、多维内涵和技术实现的特征。

通过全面调查和总结针对智能体和MAS新出现的攻击、防御和评估方法，我们将可信LLM的概念扩展到了新兴的可信智能体范式。在TrustAgent框架中，我们首先分解并介绍了智能体和MAS的各种组件。然后，我们将它们的可信性分为内在（大脑、记忆和工具）和外在（用户、智能体和环境）两个方面。接着，我们阐述了可信性的多方面含义，并详细说明了现有研究中与这些内部和外部模块相关的实现技术。最后，我们提出了对我们领域的一些见解和展望，旨在为未来的研究提供指导。


> With the rapid evolution of Large Language Models (LLMs), LLM-based agents and Multi-agent Systems (MAS) have significantly expanded the capabilities of LLM ecosystems. This evolution stems from empowering LLMs with additional modules such as memory, tools, environment, and even other agents. However, this advancement has also introduced more complex issues of trustworthiness, which previous research focused solely on LLMs could not cover. In this survey, we propose the TrustAgent framework, a comprehensive study on the trustworthiness of agents, characterized by modular taxonomy, multi-dimensional connotations, and technical implementation. By thoroughly investigating and summarizing newly emerged attacks, defenses, and evaluation methods for agents and MAS, we extend the concept of Trustworthy LLM to the emerging paradigm of Trustworthy Agent. In TrustAgent, we begin by deconstructing and introducing various components of the Agent and MAS. Then, we categorize their trustworthiness into intrinsic (brain, memory, and tool) and extrinsic (user, agent, and environment) aspects. Subsequently, we delineate the multifaceted meanings of trustworthiness and elaborate on the implementation techniques of existing research related to these internal and external modules. Finally, we present our insights and outlook on this domain, aiming to provide guidance for future endeavors.

[Arxiv](https://arxiv.org/abs/2503.09648)