# # A Survey on Enhancing Causal Reasoning Ability of Large Language Models
大型语言模型因果推理能力提升研究综述

发布时间：2025年03月12日

`LLM理论` `医疗保健` `经济分析`

> A Survey on Enhancing Causal Reasoning Ability of Large Language Models

# 摘要

> 大型语言模型（LLMs）在语言任务及其他领域展现出了卓越的能力。然而，由于其固有的因果推理能力有限，LLMs在医疗保健和经济分析等需要强大因果推理能力的任务中仍面临挑战。因此，大量研究开始关注如何提升LLMs的因果推理能力。尽管研究如火如荼，但目前仍缺乏对此领域的系统性综述。本文旨在填补这一空白，系统性地回顾了增强LLMs因果推理能力的相关研究。首先，我们介绍了这一研究主题的背景和动机，随后总结了该领域的关键挑战。在此基础上，我们提出了一种新的分类法，以系统性地对现有方法进行分类，并对各类方法之间和内部进行了详细比较。此外，我们汇总了现有的基准测试和评估指标，用于评估LLMs的因果推理能力。最后，我们概述了这一新兴领域未来的研究方向，为相关领域的研究者和实践者提供了宝贵的见解和启发。

> Large language models (LLMs) have recently shown remarkable performance in language tasks and beyond. However, due to their limited inherent causal reasoning ability, LLMs still face challenges in handling tasks that require robust causal reasoning ability, such as health-care and economic analysis. As a result, a growing body of research has focused on enhancing the causal reasoning ability of LLMs. Despite the booming research, there lacks a survey to well review the challenges, progress and future directions in this area. To bridge this significant gap, we systematically review literature on how to strengthen LLMs' causal reasoning ability in this paper. We start from the introduction of background and motivations of this topic, followed by the summarisation of key challenges in this area. Thereafter, we propose a novel taxonomy to systematically categorise existing methods, together with detailed comparisons within and between classes of methods. Furthermore, we summarise existing benchmarks and evaluation metrics for assessing LLMs' causal reasoning ability. Finally, we outline future research directions for this emerging field, offering insights and inspiration to researchers and practitioners in the area.

[Arxiv](https://arxiv.org/abs/2503.09326)