# 媒体与负责任的AI治理：基于博弈论视角和LLM的分析研究

发布时间：2025年03月12日

`其他` `AI治理` `媒体与信任`

> Media and responsible AI governance: a game-theoretic and LLM analysis

# 摘要

> 本文深入探讨了AI开发者、监管机构、用户与媒体之间在构建可信AI系统中的复杂互动关系。研究采用进化博弈论和大型语言模型（LLMs）作为工具，模拟分析了不同监管制度下各方的战略互动模式。研究重点关注两大核心机制：通过媒体报道激励有效监管，以及基于专业评论建立用户信任。研究发现，媒体在为用户提供关键信息方面扮演着重要角色，其通过调查开发者或监管机构，可能发挥类似“软性”监管的作用，尤其在许多地区尚未建立完善的机构化AI监管体系时。无论是博弈论分析还是基于LLMs的模拟实验，都揭示了有效监管与可信AI开发形成的条件，强调了从进化博弈论视角分析不同监管制度影响的重要性。研究最终指出，实现有效的AI治理需要在激励高质量评论与控制相关成本之间取得平衡。

> This paper investigates the complex interplay between AI developers, regulators, users, and the media in fostering trustworthy AI systems. Using evolutionary game theory and large language models (LLMs), we model the strategic interactions among these actors under different regulatory regimes. The research explores two key mechanisms for achieving responsible governance, safe AI development and adoption of safe AI: incentivising effective regulation through media reporting, and conditioning user trust on commentariats' recommendation. The findings highlight the crucial role of the media in providing information to users, potentially acting as a form of "soft" regulation by investigating developers or regulators, as a substitute to institutional AI regulation (which is still absent in many regions). Both game-theoretic analysis and LLM-based simulations reveal conditions under which effective regulation and trustworthy AI development emerge, emphasising the importance of considering the influence of different regulatory regimes from an evolutionary game-theoretic perspective. The study concludes that effective governance requires managing incentives and costs for high quality commentaries.

[Arxiv](https://arxiv.org/abs/2503.09858)