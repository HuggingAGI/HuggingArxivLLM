# # SySLLM: 使用大型语言模型为强化学习智能体生成合成策略摘要
# SySLLM: 通过大型语言模型为强化学习智能体生成合成策略摘要

发布时间：2025年03月13日

`LLM应用` `人机交互` `智能体行为解释`

> SySLLM: Generating Synthesized Policy Summaries for Reinforcement Learning Agents Using Large Language Models

# 摘要

> 强化学习 (RL) 生成的策略往往难以向用户解释，因为它们是复杂奖励结构与神经网络表示相互作用的结果。这种复杂性常导致难以预测的行为模式，不仅增加了策略分析的难度，也在实际应用中对建立用户信任提出了挑战。全局策略总结方法通过在部分世界状态下的动作演示来描述智能体行为，但受限于用户只能观看有限演示的现实，这种方法难以全面传达策略信息。更关键的是，这些方法过于依赖用户的主观解读，因为它们无法将观察结果转化为连贯的模式。为了解决这些问题，我们提出了SySLLM（基于LLMs的合成摘要），一种创新方法。它利用大型语言模型 (LLMs) 广博的知识和强大的模式捕捉能力，生成策略的文本摘要。通过专家评估，我们发现SySLLM生成的摘要不仅能够准确反映专家见解，还能有效避免显著的幻觉问题。用户研究进一步表明，与传统的基于演示的方法相比，SySLLM摘要更受用户青睐，并在客观的智能体识别任务中表现优异。

> Policies generated by Reinforcement Learning (RL) algorithms can be difficult to describe to users, as they result from the interplay between complex reward structures and neural network-based representations. This combination often leads to unpredictable behaviors, making policies challenging to analyze and posing significant obstacles to fostering human trust in real-world applications. Global policy summarization methods aim to describe agent behavior through a demonstration of actions in a subset of world-states. However, users can only watch a limited number of demonstrations, restricting their understanding of policies. Moreover, those methods overly rely on user interpretation, as they do not synthesize observations into coherent patterns. In this work, we present SySLLM (Synthesized Summary using LLMs), a novel method that employs synthesis summarization, utilizing large language models' (LLMs) extensive world knowledge and ability to capture patterns, to generate textual summaries of policies. Specifically, an expert evaluation demonstrates that the proposed approach generates summaries that capture the main insights generated by experts while not resulting in significant hallucinations. Additionally, a user study shows that SySLLM summaries are preferred over demonstration-based policy summaries and match or surpass their performance in objective agent identification tasks.

[Arxiv](https://arxiv.org/abs/2503.10509)