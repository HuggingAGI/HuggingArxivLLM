# 揭示 DeepSeek 模型中的数学推理：大型语言模型的比较研究

发布时间：2025年03月13日

`LLM应用` `数学推理` `人工智能`

> Unveiling the Mathematical Reasoning in DeepSeek Models: A Comparative Study of Large Language Models

# 摘要

> 人工智能（AI）的飞速发展推动了大型语言模型（LLMs）在医疗、公共卫生、工程、科学、农业、教育、艺术、人文和数学推理等领域的边界重塑。在这些进展中，DeepSeek模型以其卓越能力脱颖而出，成为引人注目的参与者。尽管此前已有研究对LLMs进行了比较分析，但针对广泛LLMs数学推理能力的全面评估仍较为匮乏。本研究旨在填补这一空白，通过深入比较研究，聚焦于DeepSeek模型与其领先竞争对手的优势与局限性。具体而言，我们系统评估了两个DeepSeek模型与五个著名LLMs在三个独立基准数据集上的数学推理性能。研究发现：1）DeepSeek-R1在三个数据集中的两个数据集上始终保持最高准确率，彰显其强大的数学推理能力。2）LLMs的蒸馏变体表现显著逊色于同侪，凸显蒸馏技术的潜在弊端。3）在响应时间方面，Gemini 2.0 Flash展现最快处理速度，效率领先，这对于实时应用至关重要。除定量评估外，我们深入探讨了架构、训练和优化对LLMs数学推理能力的影响。此外，本研究不仅限于性能比较，还识别了未来LLM驱动数学推理发展的关键领域。这项研究深化了我们对LLMs数学推理能力的理解，为未来的发展奠定了基础。

> With the rapid evolution of Artificial Intelligence (AI), Large Language Models (LLMs) have reshaped the frontiers of various fields, spanning healthcare, public health, engineering, science, agriculture, education, arts, humanities, and mathematical reasoning. Among these advancements, DeepSeek models have emerged as noteworthy contenders, demonstrating promising capabilities that set them apart from their peers. While previous studies have conducted comparative analyses of LLMs, few have delivered a comprehensive evaluation of mathematical reasoning across a broad spectrum of LLMs. In this work, we aim to bridge this gap by conducting an in-depth comparative study, focusing on the strengths and limitations of DeepSeek models in relation to their leading counterparts. In particular, our study systematically evaluates the mathematical reasoning performance of two DeepSeek models alongside five prominent LLMs across three independent benchmark datasets. The findings reveal several key insights: 1). DeepSeek-R1 consistently achieved the highest accuracy on two of the three datasets, demonstrating strong mathematical reasoning capabilities. 2). The distilled variant of LLMs significantly underperformed compared to its peers, highlighting potential drawbacks in using distillation techniques. 3). In terms of response time, Gemini 2.0 Flash demonstrated the fastest processing speed, outperforming other models in efficiency, which is a crucial factor for real-time applications. Beyond these quantitative assessments, we delve into how architecture, training, and optimization impact LLMs' mathematical reasoning. Moreover, our study goes beyond mere performance comparison by identifying key areas for future advancements in LLM-driven mathematical reasoning. This research enhances our understanding of LLMs' mathematical reasoning and lays the groundwork for future advancements

[Arxiv](https://arxiv.org/abs/2503.10573)