# 大型语言模型变身教育分析师：将多模态数据转变为可操作的阅读评估报告

发布时间：2025年03月03日

`LLM应用` `人工智能`

> LLMs as Educational Analysts: Transforming Multimodal Data Traces into Actionable Reading Assessment Reports

# 摘要

> 阅读评估是提升学生理解能力的关键，但许多教育科技应用仅关注基于结果的评估指标，难以深入洞察学生的行为与认知。本研究通过整合多模态数据源——包括眼动追踪数据、学习成果、评估内容及教学标准——来挖掘阅读行为的深层见解。我们利用无监督学习技术识别出独特的阅读模式，再借助大型语言模型（LLM）将这些数据转化为直观的教育报告，帮助教师快速获取洞察。由LLM专家和教育工作者组成的团队对报告进行了全面评估，重点关注其清晰度、准确性、相关性及教学实用性。研究发现，LLM能够有效扮演教育分析师的角色，将多样化的数据转化为教师友好的见解，并且得到了教育工作者的广泛认可。虽然在自动化见解生成方面潜力巨大，但人工监督仍然是确保结果可靠性和公平性的关键。这项研究推动了教育领域中以人为本的人工智能发展，将数据驱动的分析与实际课堂应用紧密结合。

> Reading assessments are essential for enhancing students' comprehension, yet many EdTech applications focus mainly on outcome-based metrics, providing limited insights into student behavior and cognition. This study investigates the use of multimodal data sources -- including eye-tracking data, learning outcomes, assessment content, and teaching standards -- to derive meaningful reading insights. We employ unsupervised learning techniques to identify distinct reading behavior patterns, and then a large language model (LLM) synthesizes the derived information into actionable reports for educators, streamlining the interpretation process. LLM experts and human educators evaluate these reports for clarity, accuracy, relevance, and pedagogical usefulness. Our findings indicate that LLMs can effectively function as educational analysts, turning diverse data into teacher-friendly insights that are well-received by educators. While promising for automating insight generation, human oversight remains crucial to ensure reliability and fairness. This research advances human-centered AI in education, connecting data-driven analytics with practical classroom applications.

[Arxiv](https://arxiv.org/abs/2503.02099)