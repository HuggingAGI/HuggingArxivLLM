# ABFS：基于LLM的NLP软件自然鲁棒性测试方案

发布时间：2025年03月03日

`LLM应用` `金融分析` `内容审核`

> ABFS: Natural Robustness Testing for LLM-based NLP Software

# 摘要

> 大型语言模型（LLMs）在自然语言处理（NLP）任务中的卓越表现使其在金融分析、内容审核等领域迅速获得广泛应用。然而，这些应用常常存在稳健性不足的问题：输入（提示+示例）的轻微扰动可能导致错误输出。当前的稳健性测试方法面临两大挑战：测试效果较低，限制了 LLM 基础软件在安全关键场景中的适用性；测试案例的自然性不足，降低了测试结果的实际价值。

为了解决这些问题，本文提出了一种简单而有效的自动化测试方法 ABFS，首次将输入提示和示例作为一个整体进行稳健性测试。具体来说，ABFS 将测试过程建模为组合优化问题，采用最佳优先搜索在扰动空间中识别成功测试案例，并设计了一种新型自适应控制策略以提升测试案例的自然性。

我们在五个威胁模型下对三个数据集进行了评估。在 Llama2-13b 上，传统 StressTest 的成功率仅为 13.273%，而 ABFS 达到了 98.064% 的成功率，支持在软件部署前进行更全面的稳健性评估。与基线方法相比，ABFS 对原始输入的修改更少，始终生成自然度更优的测试案例。此外，ABFS 生成的测试案例具有更强的迁移性和更高的测试效率，显著降低了测试成本。

> Owing to the exceptional performance of Large Language Models (LLMs) in Natural Language Processing (NLP) tasks, LLM-based NLP software has rapidly gained traction across various domains, such as financial analysis and content moderation. However, these applications frequently exhibit robustness deficiencies, where slight perturbations in input (prompt+example) may lead to erroneous outputs. Current robustness testing methods face two main limitations: (1) low testing effectiveness, limiting the applicability of LLM-based software in safety-critical scenarios, and (2) insufficient naturalness of test cases, reducing the practical value of testing outcomes. To address these issues, this paper proposes ABFS, a straightforward yet effective automated testing method that, for the first time, treats the input prompts and examples as a unified whole for robustness testing. Specifically, ABFS formulates the testing process as a combinatorial optimization problem, employing Best-First Search to identify successful test cases within the perturbation space and designing a novel Adaptive control strategy to enhance test case naturalness. We evaluate the robustness testing performance of ABFS on three datasets across five threat models. On Llama2-13b, the traditional StressTest achieves only a 13.273% success rate, while ABFS attains a success rate of 98.064%, supporting a more comprehensive robustness assessment before software deployment. Compared to baseline methods, ABFS introduces fewer modifications to the original input and consistently generates test cases with superior naturalness. Furthermore, test cases generated by ABFS exhibit stronger transferability and higher testing efficiency, significantly reducing testing costs.

[Arxiv](https://arxiv.org/abs/2503.01319)