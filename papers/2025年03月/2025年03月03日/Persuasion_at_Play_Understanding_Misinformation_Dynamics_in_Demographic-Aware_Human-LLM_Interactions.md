# 劝说在互动中：探索人口统计感知下人与LLM的虚假信息动态

发布时间：2025年03月03日

`LLM应用` `错误信息` `人工智能伦理`

> Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions

# 摘要

> # 摘要
当前的错误信息接触和易感性问题在不同人口群体间存在显著差异，因为某些群体比其他群体更容易受到错误信息的影响。大型语言模型（LLMs）通过其生成具有说服力内容的能力和强化现有偏见的能力，为这些挑战引入了新的维度。本研究探讨了当人类和LLMs接触到错误信息时，两者之间的双向劝说动态。我们使用人类立场数据集来分析人类对LLMs的影响，并通过生成基于LLMs的劝说性论点来评估LLMs对人类的影响。此外，我们采用一个多智能体LLM框架，分析了劝说过程中面向特定人口群体的LLM智能体中错误信息的传播。我们的研究发现，人口因素会影响LLMs对错误信息的易感性，这一现象与人类基于人口特征的易感模式非常相似。我们还发现，与人类人口群体类似，多智能体LLMs也表现出回音室效应。这项研究深入探讨了人类与LLMs之间的相互作用，突显了在错误信息背景下的人口群体差异，并为未来的干预提供了见解。

> Existing challenges in misinformation exposure and susceptibility vary across demographic groups, as some populations are more vulnerable to misinformation than others. Large language models (LLMs) introduce new dimensions to these challenges through their ability to generate persuasive content at scale and reinforcing existing biases. This study investigates the bidirectional persuasion dynamics between LLMs and humans when exposed to misinformative content. We analyze human-to-LLM influence using human-stance datasets and assess LLM-to-human influence by generating LLM-based persuasive arguments. Additionally, we use a multi-agent LLM framework to analyze the spread of misinformation under persuasion among demographic-oriented LLM agents. Our findings show that demographic factors influence susceptibility to misinformation in LLMs, closely reflecting the demographic-based patterns seen in human susceptibility. We also find that, similar to human demographic groups, multi-agent LLMs exhibit echo chamber behavior. This research explores the interplay between humans and LLMs, highlighting demographic differences in the context of misinformation and offering insights for future interventions.

[Arxiv](https://arxiv.org/abs/2503.02038)