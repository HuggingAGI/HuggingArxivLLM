# 多模态组合检索研究综述：方法与应用探索

发布时间：2025年03月03日

`其他` `电子商务` `公共安全`

> Composed Multi-modal Retrieval: A Survey of Approaches and Applications

# 摘要

> 社交媒体、短视频平台和电子商务中多模态数据的快速增长，使得基于内容的检索成为高效挖掘异构信息的必备技术。检索技术的发展历程从单模态检索（UR）逐步演进到跨模态检索（CR），而最近更发展到了组合多模态检索（CMR）。CMR通过结合参考视觉输入与文本修改，赋予用户检索图像或视频的能力，显著提升了搜索的灵活性与精准度。本文对CMR进行了全面梳理，涵盖其核心挑战、技术突破，以及在监督学习、零样本学习和半监督学习范式下的分类。我们深入探讨了关键研究方向，包括监督CMR中的数据增强、模型架构优化和损失函数设计，以及零样本CMR中的转换框架构建和外部知识融合。此外，本文还重点介绍了CMR在组合图像检索、视频检索和人物检索中的应用前景，这些方向在电子商务、在线搜索和公共安全领域具有重要价值。凭借其优化和个性化搜索体验的独特优势，CMR正逐渐成为下一代检索系统中的核心技术。相关研究与资源的精选列表可访问以下链接：https://github.com/kkzhang95/Awesome-Composed-Multi-modal-Retrieval

> With the rapid growth of multi-modal data from social media, short video platforms, and e-commerce, content-based retrieval has become essential for efficiently searching and utilizing heterogeneous information. Over time, retrieval techniques have evolved from Unimodal Retrieval (UR) to Cross-modal Retrieval (CR) and, more recently, to Composed Multi-modal Retrieval (CMR). CMR enables users to retrieve images or videos by integrating a reference visual input with textual modifications, enhancing search flexibility and precision. This paper provides a comprehensive review of CMR, covering its fundamental challenges, technical advancements, and categorization into supervised, zero-shot, and semi-supervised learning paradigms. We discuss key research directions, including data augmentation, model architecture, and loss optimization in supervised CMR, as well as transformation frameworks and external knowledge integration in zero-shot CMR. Additionally, we highlight the application potential of CMR in composed image retrieval, video retrieval, and person retrieval, which have significant implications for e-commerce, online search, and public security. Given its ability to refine and personalize search experiences, CMR is poised to become a pivotal technology in next-generation retrieval systems. A curated list of related works and resources is available at: https://github.com/kkzhang95/Awesome-Composed-Multi-modal-Retrieval

[Arxiv](https://arxiv.org/abs/2503.01334)