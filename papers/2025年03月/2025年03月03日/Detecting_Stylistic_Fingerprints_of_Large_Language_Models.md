# 识别大型语言模型的独特风格特征

发布时间：2025年03月03日

`LLM应用` `内容安全`

> Detecting Stylistic Fingerprints of Large Language Models

# 摘要

> 大型语言模型（LLMs）即使被提示以不同写作风格输出，仍具有独特且一致的风格指纹。识别这些指纹在保护知识产权、确保AI生成内容透明度以及防止AI技术滥用等方面具有重要意义。本文提出了一种基于模型风格指纹对文本进行分类的新方法，并构建了一个由三种架构各异、基于不同训练数据的分类器组成的集成模型。该模型专注于对Claude、Gemini、Llama和OpenAI这四个知名LLM家族生成的文本进行分类。由于任务具有高度成本敏感性且可能产生严重后果，我们致力于最大限度减少误报并提升置信度。仅当集成模型中的所有三个分类器对输出分类达成一致时，我们认为该预测结果有效。在由Claude、Gemini、Llama和OpenAI模型生成的测试集文本上，该集成模型实现了极高的精度（0.9988）和极低的误报率（0.0004）。此外，我们展示了该模型区分已知和未知模型生成文本的能力，揭示了不同模型之间有趣的风格关联。这种风格分析方法为验证AI生成文本的原创性及追踪模型训练技术的来源提供了重要参考。

> Large language models (LLMs) have distinct and consistent stylistic fingerprints, even when prompted to write in different writing styles. Detecting these fingerprints is important for many reasons, among them protecting intellectual property, ensuring transparency regarding AI-generated content, and preventing the misuse of AI technologies. In this paper, we present a novel method to classify texts based on the stylistic fingerprints of the models that generated them. We introduce an LLM-detection ensemble that is composed of three classifiers with varied architectures and training data. This ensemble is trained to classify texts generated by four well-known LLM families: Claude, Gemini, Llama, and OpenAI. As this task is highly cost-sensitive and might have severe implications, we want to minimize false-positives and increase confidence. We consider a prediction as valid when all three classifiers in the ensemble unanimously agree on the output classification. Our ensemble is validated on a test set of texts generated by Claude, Gemini, Llama, and OpenAI models, and achieves extremely high precision (0.9988) and a very low false-positive rate (0.0004). Furthermore, we demonstrate the ensemble's ability to distinguish between texts generated by seen and unseen models. This reveals interesting stylistic relationships between models. This approach to stylistic analysis has implications for verifying the originality of AI-generated texts and tracking the origins of model training techniques.

[Arxiv](https://arxiv.org/abs/2503.01659)