# 研究多模态大型语言模型的知识推理一致性

发布时间：2025年03月03日

`LLM应用` `多模态` `知识推理`

> Exploring and Evaluating Multimodal Knowledge Reasoning Consistency of Multimodal Large Language Models

# 摘要

> 近年来，多模态大型语言模型（MLLMs）在跨文本和视觉的理解方面取得了显著突破。然而，在多模态知识推理过程中，现有MLLMs仍面临有效整合跨模态知识的挑战，导致推理结果存在不一致。为此，我们提出了四个评估任务并构建了一个新的数据集。通过在该数据集上进行的一系列实验，我们系统性地分析和比较了MLLMs在多模态知识推理过程中一致性下降的程度。基于实验结果，我们识别了导致观察到的一致性下降的因素。本研究不仅揭示了多模态知识推理的挑战，更为未来改进MLLMs提供了新的见解和宝贵的指导。

> In recent years, multimodal large language models (MLLMs) have achieved significant breakthroughs, enhancing understanding across text and vision. However, current MLLMs still face challenges in effectively integrating knowledge across these modalities during multimodal knowledge reasoning, leading to inconsistencies in reasoning outcomes. To systematically explore this issue, we propose four evaluation tasks and construct a new dataset. We conduct a series of experiments on this dataset to analyze and compare the extent of consistency degradation in multimodal knowledge reasoning within MLLMs. Based on the experimental results, we identify factors contributing to the observed degradation in consistency. Our research provides new insights into the challenges of multimodal knowledge reasoning and offers valuable guidance for future efforts aimed at improving MLLMs.

[Arxiv](https://arxiv.org/abs/2503.04801)