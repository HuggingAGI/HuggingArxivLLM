# 探索MLLM赋能应用在视障及低视力人群视觉理解中的应用研究

发布时间：2025年03月07日

`LLM应用

理由：这篇论文探讨了多模态大型语言模型（MLLMs）在视觉解释应用中的实际应用，特别是针对盲人和低视力人群。研究评估了这些模型在提高视觉解读质量、用户信任和满意度方面的效果，并通过用户研究验证了其应用价值。因此，它属于LLM应用类别。` `视觉辅助` `人工智能`

> Towards Understanding the Use of MLLM-Enabled Applications for Visual Interpretation by Blind and Low Vision People

# 摘要

> 盲人和低视力（BLV）人群借助AI驱动的视觉解释应用满足日常需求。尽管这些应用提供了一定帮助，但先前研究显示用户对其频繁出错仍感不满。近期，多模态大型语言模型（MLLMs）被引入视觉解释应用，展现出提供更详尽视觉解读的潜力。然而，这一进展如何改变用户行为仍待探讨。为此，我们开展了一项为期两周的日记研究，20名BLV参与者使用我们开发的MLLM增强型视觉解释应用，共收集到553条记录。本文报告了对6名参与者60条日记的初步分析。结果显示，参与者认为该应用的视觉解释值得信赖（平均4.15分，满分5分），并感到满意（平均3.75分，满分5分）。更令人鼓舞的是，在高风险场景如药物剂量建议中，参与者也对我们的应用充满信任。我们正计划完成后续分析，以期为未来MLLM增强型视觉解释系统的开发提供指导。

> Blind and Low Vision (BLV) people have adopted AI-powered visual interpretation applications to address their daily needs. While these applications have been helpful, prior work has found that users remain unsatisfied by their frequent errors. Recently, multimodal large language models (MLLMs) have been integrated into visual interpretation applications, and they show promise for more descriptive visual interpretations. However, it is still unknown how this advancement has changed people's use of these applications. To address this gap, we conducted a two-week diary study in which 20 BLV people used an MLLM-enabled visual interpretation application we developed, and we collected 553 entries. In this paper, we report a preliminary analysis of 60 diary entries from 6 participants. We found that participants considered the application's visual interpretations trustworthy (mean 3.75 out of 5) and satisfying (mean 4.15 out of 5). Moreover, participants trusted our application in high-stakes scenarios, such as receiving medical dosage advice. We discuss our plan to complete our analysis to inform the design of future MLLM-enabled visual interpretation systems.

[Arxiv](https://arxiv.org/abs/2503.05899)