# # 大型机器学习模型的路由机制

发布时间：2025年03月07日

`其他

摘要讨论了在训练大型语言模型（LLMs）和其他大规模机器学习模型时，如何优化数据中心网络中的数据流路由方式。虽然与LLMs的训练有关，但其主要关注点是网络通信和路由优化，而不是直接涉及LLM的应用或理论。因此，归类为其他。` `计算机网络` `机器学习`

> Routing for Large ML Models

# 摘要

> 训练大型语言模型（LLMs）和其他大型机器学习模型需要在数据中心网络中频繁交换大规模数据。这些训练过程中产生的通信模式表现出高度的规律性和持续性，为优化网络中数据流的路由方式提供了重要机遇。我们提出了一种算法框架，用于在训练LLMs（及其他大规模ML模型）的背景下	extit{量化}网络范围内的效率，并根据这一全局指标	extit{周期性优化}路由方式。

> Training large language models (LLMs), and other large machine learning models, involves repeated communication of large volumes of data across a data center network. The communication patterns induced by these training process exhibit high regularity and persistence, giving rise to significant opportunities for optimizing the manner in which flows are routed across the network. We present an algorithmic framework for \textit{quantifying} network-wide efficiency in the context of training LLMs (and other large-scale ML models), and for periodically \textit{optimizing} routing with respect to this global metric.

[Arxiv](https://arxiv.org/abs/2503.05324)