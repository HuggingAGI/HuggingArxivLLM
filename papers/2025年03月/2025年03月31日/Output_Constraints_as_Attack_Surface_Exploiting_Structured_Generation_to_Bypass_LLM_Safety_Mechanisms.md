# 输出限制作为突破口：利用结构化生成技术绕过 LLM 安全机制

发布时间：2025年03月31日

`LLM应用` `软件开发` `信息安全`

> Output Constraints as Attack Surface: Exploiting Structured Generation to Bypass LLM Safety Mechanisms

# 摘要

> 内容警告：本文可能包含由LLMs生成的不安全或有害内容，可能冒犯读者。大型语言模型（LLMs）被广泛用作工具平台，通过结构化输出API确保语法合规，从而实现与现有软件（如代理系统）的稳健集成。然而，语法引导的结构化输出功能带来了显著的安全漏洞。在这项工作中，我们揭示了一个与传统数据平面漏洞正交的关键控制平面攻击面。我们引入了约束解码攻击（CDA），这是一种新型的越狱攻击类别，利用结构化输出约束绕过安全机制。与之前专注于输入提示的攻击不同，CDA通过在模式级别的语法规则（控制平面）中嵌入恶意意图，同时保持良性表面提示（数据平面）来实现攻击。我们通过一个概念验证Chain Enum Attack来实现这一点，在五个安全基准测试中，针对专有和开源权重的LLMs（包括GPT-4o和Gemini-2.0-flash）实现了96.2%的攻击成功率，仅需一次查询。我们的发现揭示了当前LLM架构中的关键安全盲点，并呼吁在LLM安全性方面进行范式转变，以应对控制平面漏洞，因为当前仅关注数据平面威胁的机制使关键系统暴露无遗。

> Content Warning: This paper may contain unsafe or harmful content generated by LLMs that may be offensive to readers. Large Language Models (LLMs) are extensively used as tooling platforms through structured output APIs to ensure syntax compliance so that robust integration with existing softwares like agent systems, could be achieved. However, the feature enabling functionality of grammar-guided structured output presents significant security vulnerabilities. In this work, we reveal a critical control-plane attack surface orthogonal to traditional data-plane vulnerabilities. We introduce Constrained Decoding Attack (CDA), a novel jailbreak class that weaponizes structured output constraints to bypass safety mechanisms. Unlike prior attacks focused on input prompts, CDA operates by embedding malicious intent in schema-level grammar rules (control-plane) while maintaining benign surface prompts (data-plane). We instantiate this with a proof-of-concept Chain Enum Attack, achieves 96.2% attack success rates across proprietary and open-weight LLMs on five safety benchmarks with a single query, including GPT-4o and Gemini-2.0-flash. Our findings identify a critical security blind spot in current LLM architectures and urge a paradigm shift in LLM safety to address control-plane vulnerabilities, as current mechanisms focused solely on data-plane threats leave critical systems exposed.

[Arxiv](https://arxiv.org/abs/2503.24191)