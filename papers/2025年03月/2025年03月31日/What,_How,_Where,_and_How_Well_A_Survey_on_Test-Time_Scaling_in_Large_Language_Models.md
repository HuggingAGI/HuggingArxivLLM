# 是什么、如何、在哪里以及效果如何？关于大型语言模型测试时扩大的综述研究

发布时间：2025年03月31日

`LLM应用` `问答系统`

> What, How, Where, and How Well? A Survey on Test-Time Scaling in Large Language Models

# 摘要

> 在预训练时代对计算规模的狂热逐渐褪去之际，测试时缩放（TTS）——也被称为“测试时计算”——崭露头角，成为研究焦点。近期研究表明，TTS 能够进一步激发大型语言模型（LLMs）的问题解决能力，不仅在数学和编程等专业推理任务上取得了突破，在开放问答等通用任务上也展现了巨大潜力。尽管近期在这一领域研究如火如荼，但亟需一份全面的综述以系统性地理解这一领域。为此，我们提出一个统一的多维框架，围绕 TTS 研究的四个核心维度构建：缩放什么、如何缩放、在哪里缩放以及缩放效果如何。基于此分类法，我们对方法、应用场景和评估方面进行了全面回顾，并呈现了一个条理清晰的分解，突出了个体技术在更广泛的 TTS 景观中的独特功能角色。通过这一分析，我们提炼了迄今为止 TTS 的主要发展方向，并提供了实用部署的实用指南。此外，我们还识别了几个开放挑战，并对未来有希望的方向提供了见解，包括进一步的缩放、阐明技术的功能本质、推广到更多任务以及更多的归因分析。

> As enthusiasm for scaling computation (data and parameters) in the pretraining era gradually diminished, test-time scaling (TTS), also referred to as ``test-time computing'' has emerged as a prominent research focus. Recent studies demonstrate that TTS can further elicit the problem-solving capabilities of large language models (LLMs), enabling significant breakthroughs not only in specialized reasoning tasks, such as mathematics and coding, but also in general tasks like open-ended Q&A. However, despite the explosion of recent efforts in this area, there remains an urgent need for a comprehensive survey offering a systemic understanding. To fill this gap, we propose a unified, multidimensional framework structured along four core dimensions of TTS research: what to scale, how to scale, where to scale, and how well to scale. Building upon this taxonomy, we conduct an extensive review of methods, application scenarios, and assessment aspects, and present an organized decomposition that highlights the unique functional roles of individual techniques within the broader TTS landscape. From this analysis, we distill the major developmental trajectories of TTS to date and offer hands-on guidelines for practical deployment. Furthermore, we identify several open challenges and offer insights into promising future directions, including further scaling, clarifying the functional essence of techniques, generalizing to more tasks, and more attributions.

[Arxiv](https://arxiv.org/abs/2503.24235)