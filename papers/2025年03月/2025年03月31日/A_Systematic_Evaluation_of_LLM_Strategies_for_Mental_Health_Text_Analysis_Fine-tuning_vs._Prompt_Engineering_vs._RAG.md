# LLM 在心理健康文本分析中的策略对比：微调、提示工程与 RAG 的系统评估

发布时间：2025年03月31日

`LLM应用` `心理健康`

> A Systematic Evaluation of LLM Strategies for Mental Health Text Analysis: Fine-tuning vs. Prompt Engineering vs. RAG

# 摘要

> 本研究系统性地比较了三种基于大型语言模型（LLMs）的心理健康文本分析方法：提示工程、检索增强生成（RAG）和微调。基于LLaMA 3模型，我们在两个数据集上对情绪分类和心理健康状况检测任务进行了评估。结果显示，微调方法在准确率方面表现最佳（情绪分类91%，心理健康状况检测80%），但需要大量计算资源和训练数据。相比之下，提示工程和RAG方法在保持中等性能（准确率40-68%）的同时，提供了更灵活的部署方案。我们的研究发现为在心理健康领域实施基于LLM的解决方案提供了实用见解，揭示了准确率、计算要求和部署灵活性之间的权衡关系。

> This study presents a systematic comparison of three approaches for the analysis of mental health text using large language models (LLMs): prompt engineering, retrieval augmented generation (RAG), and fine-tuning. Using LLaMA 3, we evaluate these approaches on emotion classification and mental health condition detection tasks across two datasets. Fine-tuning achieves the highest accuracy (91% for emotion classification, 80% for mental health conditions) but requires substantial computational resources and large training sets, while prompt engineering and RAG offer more flexible deployment with moderate performance (40-68% accuracy). Our findings provide practical insights for implementing LLM-based solutions in mental health applications, highlighting the trade-offs between accuracy, computational requirements, and deployment flexibility.

[Arxiv](https://arxiv.org/abs/2503.24307)