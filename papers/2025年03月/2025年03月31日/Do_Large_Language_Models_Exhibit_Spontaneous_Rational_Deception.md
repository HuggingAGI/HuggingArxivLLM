# 大型语言模型是否会自发展现理性欺骗？

发布时间：2025年03月31日

`LLM理论` `人工智能` `伦理学`

> Do Large Language Models Exhibit Spontaneous Rational Deception?

# 摘要

> 大型语言模型（LLMs）在被要求欺骗时表现出色，但在什么条件下它们会自发欺骗？研究发现，推理能力更强的模型在被提示欺骗时同样表现出色。那么，当欺骗被视为合乎情理时，它们是否会更频繁地自发欺骗？本研究通过信号理论工具，在预注册的实验协议中评估了LLMs自发欺骗的行为。实验采用经过修改的2x2游戏（类似于囚徒困境），并增加了一个阶段，模型可以使用无约束的语言自由地与其他智能体沟通。这一设置为欺骗创造了机会，条件则根据欺骗对智能体理性自利的潜在有用性而变化。结果表明：1）所有测试的LLMs在某些条件下都会自发地歪曲其行为，2）它们通常更可能在欺骗能为自己带来好处的情况下这样做，3）整体推理能力更强的模型往往欺骗率更高。这些结果表明了LLM推理能力与诚实之间的权衡，同时也揭示了影响LLMs是否会欺骗的情境因素。本研究通过一种新颖的实验配置，提供了LLMs推理类行为的证据。这些发现对当前以及未来推理能力不断提升的LLM驱动的自主人机交互系统具有重要意义。

> Large Language Models (LLMs) are effective at deceiving, when prompted to do so. But under what conditions do they deceive spontaneously? Models that demonstrate better performance on reasoning tasks are also better at prompted deception. Do they also increasingly deceive spontaneously in situations where it could be considered rational to do so? This study evaluates spontaneous deception produced by LLMs in a preregistered experimental protocol using tools from signaling theory. A range of proprietary closed-source and open-source LLMs are evaluated using modified 2x2 games (in the style of Prisoner's Dilemma) augmented with a phase in which they can freely communicate to the other agent using unconstrained language. This setup creates an opportunity to deceive, in conditions that vary in how useful deception might be to an agent's rational self-interest. The results indicate that 1) all tested LLMs spontaneously misrepresent their actions in at least some conditions, 2) they are generally more likely to do so in situations in which deception would benefit them, and 3) models exhibiting better reasoning capacity overall tend to deceive at higher rates. Taken together, these results suggest a tradeoff between LLM reasoning capability and honesty. They also provide evidence of reasoning-like behavior in LLMs from a novel experimental configuration. Finally, they reveal certain contextual factors that affect whether LLMs will deceive or not. We discuss consequences for autonomous, human-facing systems driven by LLMs both now and as their reasoning capabilities continue to improve.

[Arxiv](https://arxiv.org/abs/2504.00285)