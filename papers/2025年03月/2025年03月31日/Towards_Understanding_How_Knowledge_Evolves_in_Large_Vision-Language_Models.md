# 探索大视觉-语言模型中知识的演进之道

发布时间：2025年03月31日

`LLM理论` `人工智能` `视觉-语言模型`

> Towards Understanding How Knowledge Evolves in Large Vision-Language Models

# 摘要

> 大型视觉-语言模型（LVLMs）正在成为人工智能领域的基石。然而，它们的内部工作原理仍是一个未解之谜，这限制了性能的进一步提升。本文旨在探究LVLMs中多模态知识的演变机制及其如何生成自然语言。我们设计了创新的分析策略，从单标记概率、概率分布和特征编码三个维度深入研究多模态知识的演变。研究中发现，知识演变的关键节点包括关键层和突变层，并将其过程分为快速演变、稳定和突变三个阶段。本研究首次揭示了LVLMs中知识演变的轨迹，为理解其内在机制提供了全新视角。我们的代码已开源，地址为https://github.com/XIAO4579/Vlm-interpretability。

> Large Vision-Language Models (LVLMs) are gradually becoming the foundation for many artificial intelligence applications. However, understanding their internal working mechanisms has continued to puzzle researchers, which in turn limits the further enhancement of their capabilities. In this paper, we seek to investigate how multimodal knowledge evolves and eventually induces natural languages in LVLMs. We design a series of novel strategies for analyzing internal knowledge within LVLMs, and delve into the evolution of multimodal knowledge from three levels, including single token probabilities, token probability distributions, and feature encodings. In this process, we identify two key nodes in knowledge evolution: the critical layers and the mutation layers, dividing the evolution process into three stages: rapid evolution, stabilization, and mutation. Our research is the first to reveal the trajectory of knowledge evolution in LVLMs, providing a fresh perspective for understanding their underlying mechanisms. Our codes are available at https://github.com/XIAO4579/Vlm-interpretability.

[Arxiv](https://arxiv.org/abs/2504.02862)