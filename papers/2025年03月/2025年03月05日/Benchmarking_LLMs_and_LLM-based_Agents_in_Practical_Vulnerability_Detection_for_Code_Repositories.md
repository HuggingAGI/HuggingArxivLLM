# 评估LLMs及其代理在代码仓库漏洞检测中的实际表现

发布时间：2025年03月05日

`LLM应用` `软件工程` `网络安全`

> Benchmarking LLMs and LLM-based Agents in Practical Vulnerability Detection for Code Repositories

# 摘要

> 大型语言模型（LLMs）在软件漏洞检测方面展现出潜力，尤其在函数级别基准测试如Devign和BigVul上表现突出。然而，现实中的检测需要跨过程分析，因为漏洞通常通过多跳函数调用而非孤立函数出现。尽管仓库级别基准如ReposVul和VulEval引入了跨过程上下文，但它们计算成本高昂，缺乏漏洞修复的成对评估，并且上下文检索有限，限制了实用性。

我们引入了JitVul，一个即时漏洞检测基准，将每个函数与其引入漏洞和修复的提交关联起来。JitVul基于涵盖91种漏洞类型的879个CVE构建，支持全面检测能力评估。结果显示，ReAct代理通过利用思维-行动-观察和跨过程上下文，在区分漏洞代码和良性代码方面优于LLMs。虽然链式思维等提示策略对LLMs有帮助，但ReAct代理仍需进一步完善。两种方法均存在不一致，要么误识别漏洞，要么过度分析安全防护，表明有显著改进空间。

> Large Language Models (LLMs) have shown promise in software vulnerability detection, particularly on function-level benchmarks like Devign and BigVul. However, real-world detection requires interprocedural analysis, as vulnerabilities often emerge through multi-hop function calls rather than isolated functions. While repository-level benchmarks like ReposVul and VulEval introduce interprocedural context, they remain computationally expensive, lack pairwise evaluation of vulnerability fixes, and explore limited context retrieval, limiting their practicality.
  We introduce JitVul, a JIT vulnerability detection benchmark linking each function to its vulnerability-introducing and fixing commits. Built from 879 CVEs spanning 91 vulnerability types, JitVul enables comprehensive evaluation of detection capabilities. Our results show that ReAct Agents, leveraging thought-action-observation and interprocedural context, perform better than LLMs in distinguishing vulnerable from benign code. While prompting strategies like Chain-of-Thought help LLMs, ReAct Agents require further refinement. Both methods show inconsistencies, either misidentifying vulnerabilities or over-analyzing security guards, indicating significant room for improvement.

[Arxiv](https://arxiv.org/abs/2503.03586)