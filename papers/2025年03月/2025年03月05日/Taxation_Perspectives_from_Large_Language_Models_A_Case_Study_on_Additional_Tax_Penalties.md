# # 税收视角：大型语言模型在额外税收处罚中的应用案例研究

发布时间：2025年03月05日

`LLM应用`

> Taxation Perspectives from Large Language Models: A Case Study on Additional Tax Penalties

# 摘要

> 大型语言模型（LLMs）在税务领域的能力究竟如何？尽管已有诸多研究探讨了法律领域的普遍应用，但专门针对税务的研究仍十分有限。此外，这些研究中使用的数据集要么过于简化，无法反映现实中的复杂情况，要么未开放源代码。为填补这一空白，我们推出了PLAT，这是一个旨在评估LLMs预测额外税收处罚合法性的新基准。PLAT的构建目的是测试LLMs对税法的理解，特别是在解决需要综合运用相关法律条款的问题时的表现。我们对六种LLMs的实验表明，它们的基础能力存在局限，尤其是在处理需要全面理解的矛盾问题时。然而，我们发现，通过启用检索、自我推理以及具有特定角色分配的多智能体之间的讨论，这一局限性可以得到缓解。

> How capable are large language models (LLMs) in the domain of taxation? Although numerous studies have explored the legal domain in general, research dedicated to taxation remain scarce. Moreover, the datasets used in these studies are either simplified, failing to reflect the real-world complexities, or unavailable as open source. To address this gap, we introduce PLAT, a new benchmark designed to assess the ability of LLMs to predict the legitimacy of additional tax penalties. PLAT is constructed to evaluate LLMs' understanding of tax law, particularly in cases where resolving the issue requires more than just applying related statutes. Our experiments with six LLMs reveal that their baseline capabilities are limited, especially when dealing with conflicting issues that demand a comprehensive understanding. However, we found that enabling retrieval, self-reasoning, and discussion among multiple agents with specific role assignments, this limitation can be mitigated.

[Arxiv](https://arxiv.org/abs/2503.03444)