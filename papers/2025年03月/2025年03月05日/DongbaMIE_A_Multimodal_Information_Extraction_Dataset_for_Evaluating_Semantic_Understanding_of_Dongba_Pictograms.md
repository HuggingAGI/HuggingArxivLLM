# DongbaMIE：一个多模态信息提取数据集，用于评估东巴象形文字的语义理解。

发布时间：2025年03月05日

`LLM应用` `人工智能`

> DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating Semantic Understanding of Dongba Pictograms

# 摘要

> 东巴象形文字是世界上唯一仍在使用的象形文字。它们以图画表意，符号中蕴含着丰富的文化和语境信息。然而，由于缺乏相关数据集，现有研究难以深入探索东巴象形文字的语义理解。为此，我们提出了DongbaMIE——首个专注于东巴象形文字语义理解和提取的多模态数据集。该数据集包含东巴象形文字图像及其中文语义标注，涵盖23,530个句子级别和2,539个段落级别的图像，涉及物体、动作、关系和属性四个语义维度。我们对GPT-4o、Gemini-2.0和Qwen2-VL模型进行了系统性评估。实验结果显示，在最佳物体提取任务中，GPT-4o和Gemini的F1分数分别为3.16和3.11。经过监督微调的Qwen2-VL模型F1分数仅为11.49。这些结果表明，当前大型多模态模型在准确识别东巴象形文字中多样化语义信息方面仍面临重大挑战。该数据集可通过此URL获取。

> Dongba pictographs are the only pictographs still in use in the world. They have pictorial ideographic features, and their symbols carry rich cultural and contextual information. Due to the lack of relevant datasets, existing research has difficulty in advancing the study of semantic understanding of Dongba pictographs. To this end, we propose DongbaMIE, the first multimodal dataset for semantic understanding and extraction of Dongba pictographs. The dataset consists of Dongba pictograph images and their corresponding Chinese semantic annotations. It contains 23,530 sentence-level and 2,539 paragraph-level images, covering four semantic dimensions: objects, actions, relations, and attributes. We systematically evaluate the GPT-4o, Gemini-2.0, and Qwen2-VL models. Experimental results show that the F1 scores of GPT-4o and Gemini in the best object extraction are only 3.16 and 3.11 respectively. The F1 score of Qwen2-VL after supervised fine-tuning is only 11.49. These results suggest that current large multimodal models still face significant challenges in accurately recognizing the diverse semantic information in Dongba pictographs. The dataset can be obtained from this URL.

[Arxiv](https://arxiv.org/abs/2503.03644)