# 实验探索：人类与大型语言模型代理之间的协作互动行为研究

发布时间：2025年03月10日

`LLM应用` `社会学` `人机协作`

> Experimental Exploration: Investigating Cooperative Interaction Behavior Between Humans and Large Language Model Agents

# 摘要

> 大型语言模型（LLMs）的兴起使AI代理作为自主决策者在人机协作中既带来机遇，也带来挑战。尽管许多研究关注了人类与AI工具的合作，但LLM增强型自主代理在竞争与合作互动中的作用仍鲜有研究。本研究通过让30名参与者与具有不同特征的LLM代理（声称的人类、声称的基于规则的AI代理和LLM代理）进行重复囚徒困境游戏，深入探究了人类的合作行为。研究发现，合作行为显著受代理特征及参与者性别与特征交互作用的影响。我们还分析了人类的回应模式，包括游戏完成时间、主动有利行为以及对修复努力的接受程度。这些发现为理解人类在竞争合作情境下与LLM代理的互动提供了新视角，例如虚拟化身或未来的物理实体。本研究强调了理解人类对AI代理的偏见以及这些行为如何塑造未来人机协作动态的重要性。

> With the rise of large language models (LLMs), AI agents as autonomous decision-makers present significant opportunities and challenges for human-AI cooperation. While many studies have explored human cooperation with AI as tools, the role of LLM-augmented autonomous agents in competitive-cooperative interactions remains under-examined. This study investigates human cooperative behavior by engaging 30 participants who interacted with LLM agents exhibiting different characteristics (purported human, purported rule-based AI agent, and LLM agent) in repeated Prisoner's Dilemma games. Findings show significant differences in cooperative behavior based on the agents' purported characteristics and the interaction effect of participants' genders and purported characteristics. We also analyzed human response patterns, including game completion time, proactive favorable behavior, and acceptance of repair efforts. These insights offer a new perspective on human interactions with LLM agents in competitive cooperation contexts, such as virtual avatars or future physical entities. The study underscores the importance of understanding human biases toward AI agents and how observed behaviors can influence future human-AI cooperation dynamics.

[Arxiv](https://arxiv.org/abs/2503.07320)