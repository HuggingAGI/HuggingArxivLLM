# 基于大型语言模型的科学声明验证证据检索：支持与反驳

发布时间：2025年03月10日

`RAG` `信息检索`

> LLM-based Corroborating and Refuting Evidence Retrieval for Scientific Claim Verification

# 摘要

> 本文提出了一种名为 CIBER（基于证据检索的声明验证系统）的创新方法，它是检索增强生成（RAG）框架的扩展，专注于识别支持和反驳科学声明的证据文档。CIBER 通过评估大型语言模型（LLMs）在不同质询探针下的响应一致性，有效应对了 LLMs 的固有不确定性。与传统方法不同，CIBER 专注于对 LLMs 的行为分析，无需访问其内部信息，因此能够广泛应用于白盒和黑盒模型。此外，CIBER 采用无监督方式运行，使其具备良好的跨领域适应性。通过在不同语言水平的 LLMs 上进行的全面评估，我们发现 CIBER 的性能显著优于传统的 RAG 方法。这些研究结果不仅验证了 CIBER 的有效性，更为未来基于 LLM 的科学声明验证研究提供了宝贵的启示。

> In this paper, we introduce CIBER (Claim Investigation Based on Evidence Retrieval), an extension of the Retrieval-Augmented Generation (RAG) framework designed to identify corroborating and refuting documents as evidence for scientific claim verification. CIBER addresses the inherent uncertainty in Large Language Models (LLMs) by evaluating response consistency across diverse interrogation probes. By focusing on the behavioral analysis of LLMs without requiring access to their internal information, CIBER is applicable to both white-box and black-box models. Furthermore, CIBER operates in an unsupervised manner, enabling easy generalization across various scientific domains. Comprehensive evaluations conducted using LLMs with varying levels of linguistic proficiency reveal CIBER's superior performance compared to conventional RAG approaches. These findings not only highlight the effectiveness of CIBER but also provide valuable insights for future advancements in LLM-based scientific claim verification.

[Arxiv](https://arxiv.org/abs/2503.07937)