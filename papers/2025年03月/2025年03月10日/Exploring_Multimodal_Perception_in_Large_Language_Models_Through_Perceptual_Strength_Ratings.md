# 借助感知强度评分，探究大型语言模型的多模态感知能力

发布时间：2025年03月10日

`LLM理论` `人机交互` `多模态`

> Exploring Multimodal Perception in Large Language Models Through Perceptual Strength Ratings

# 摘要

> 本研究聚焦于大型语言模型 (LLMs) 的多模态感知能力，特别是其在不同感官模态下模拟人类感知强度评分的能力。通过采用感知强度评分作为评估基准，研究对比了 GPT-3.5、GPT-4、GPT-4o 和 GPT-4o-mini，揭示了多模态输入对模型 grounding 和语言推理的显著影响。尽管 GPT-4 和 GPT-4o 在与人类评估的一致性上表现优异，且较小型模型展现了显著的进步，但定性分析发现它们在处理模式上存在显著差异，例如多感官过高评价以及对松散语义关联的依赖。值得注意的是，尽管 GPT-4o 整合了多模态能力，但在 grounding 方面并未超越 GPT-4，这引发了对其在提升人类化 grounding 中作用的疑问。这些发现表明，LLMs 对语言模式的依赖既能够近似也能偏离人类具身认知，揭示了在模拟感官体验方面的局限性。

> This study investigated the multimodal perception of large language models (LLMs), focusing on their ability to capture human-like perceptual strength ratings across sensory modalities. Utilizing perceptual strength ratings as a benchmark, the research compared GPT-3.5, GPT-4, GPT-4o, and GPT-4o-mini, highlighting the influence of multimodal inputs on grounding and linguistic reasoning. While GPT-4 and GPT-4o demonstrated strong alignment with human evaluations and significant advancements over smaller models, qualitative analyses revealed distinct differences in processing patterns, such as multisensory overrating and reliance on loose semantic associations. Despite integrating multimodal capabilities, GPT-4o did not exhibit superior grounding compared to GPT-4, raising questions about their role in improving human-like grounding. These findings underscore how LLMs' reliance on linguistic patterns can both approximate and diverge from human embodied cognition, revealing limitations in replicating sensory experiences.

[Arxiv](https://arxiv.org/abs/2503.06980)