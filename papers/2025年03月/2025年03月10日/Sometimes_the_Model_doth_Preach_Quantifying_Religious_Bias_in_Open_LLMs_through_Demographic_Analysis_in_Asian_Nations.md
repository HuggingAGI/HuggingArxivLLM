# 有时候模型也会布道：通过亚洲国家的人口统计分析量化开源大型语言模型中的宗教偏见

发布时间：2025年03月10日

`LLM应用` `文化分析` `社会学`

> Sometimes the Model doth Preach: Quantifying Religious Bias in Open LLMs through Demographic Analysis in Asian Nations

# 摘要

> 大型语言模型（LLMs）在生成观点和传播偏见方面具有能力，这些偏见源于数据收集的代表性不足和多样性缺失。此前的研究主要针对西方，尤其是美国，分析了这些观点。然而，这些研究得出的见解可能无法推广到非西方人群。由于不同领域的用户广泛使用LLM系统，每个生成输出的文化敏感性引起了极大的关注。

我们的工作提出了一种新颖的方法，可以定量分析LLMs生成的观点，并在提取模型的社会人口统计信息方面改进了先前的工作。我们通过汉明距离测量LLM响应与调查受访者之间的距离，以此推断模型输出中反映的 demographic 特征。我们在全球南方多个国家/地区（重点关注印度和其他亚洲国家）进行的调查中评估了现代开源LLMs（如Llama和Mistral），特别关注这些模型在宗教宽容和身份认同相关调查中的表现。

我们的分析表明，大多数开源LLMs匹配单一同质化 profile，且这些 profile 在不同国家/地区之间有所不同。这引发了关于LLMs是否会助长霸权世界观、削弱少数群体观点的风险的疑问。我们的框架未来也可用于研究训练数据、模型架构与LLM输出中反映的偏见之间的复杂交集，特别是在宗教宽容和身份认同等敏感话题上。

> Large Language Models (LLMs) are capable of generating opinions and propagating bias unknowingly, originating from unrepresentative and non-diverse data collection. Prior research has analysed these opinions with respect to the West, particularly the United States. However, insights thus produced may not be generalized in non-Western populations. With the widespread usage of LLM systems by users across several different walks of life, the cultural sensitivity of each generated output is of crucial interest. Our work proposes a novel method that quantitatively analyzes the opinions generated by LLMs, improving on previous work with regards to extracting the social demographics of the models. Our method measures the distance from an LLM's response to survey respondents, through Hamming Distance, to infer the demographic characteristics reflected in the model's outputs. We evaluate modern, open LLMs such as Llama and Mistral on surveys conducted in various global south countries, with a focus on India and other Asian nations, specifically assessing the model's performance on surveys related to religious tolerance and identity. Our analysis reveals that most open LLMs match a single homogeneous profile, varying across different countries/territories, which in turn raises questions about the risks of LLMs promoting a hegemonic worldview, and undermining perspectives of different minorities. Our framework may also be useful for future research investigating the complex intersection between training data, model architecture, and the resulting biases reflected in LLM outputs, particularly concerning sensitive topics like religious tolerance and identity.

[Arxiv](https://arxiv.org/abs/2503.07510)