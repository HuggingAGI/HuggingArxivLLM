# ProBench：通过开放性跨领域专家任务评测多模态基础模型

发布时间：2025年03月09日

`LLM应用` `学术研究`

> ProBench: Judging Multimodal Foundation Models on Open-ended Multi-domain Expert Tasks

# 摘要

> 解决专家级多模态任务是迈向通用智能的重要里程碑。随着多模态大型语言模型（MLLMs）能力的持续提升，对这种先进多模态智能的评估变得日益重要，同时也更具挑战性。本研究引入了ProBench——一个基于开放性用户查询的基准测试，这些查询需要专业知识和高级推理能力。ProBench包含4000个高质量样本，由专业人士根据其日常生产力需求独立提交，涵盖科学、艺术、人文、编码、数学和创意写作等10个领域和56个子领域。通过MLLM-as-a-Judge，我们评估并比较了24个最新模型。结果显示，尽管最佳开源模型可与专有模型相媲美，但ProBench在视觉感知、文本理解、领域知识和高级推理方面提出了重大挑战，为未来多模态AI研究提供了宝贵的指导方向。

> Solving expert-level multimodal tasks is a key milestone towards general intelligence. As the capabilities of multimodal large language models (MLLMs) continue to improve, evaluation of such advanced multimodal intelligence becomes necessary yet challenging. In this work, we introduce ProBench, a benchmark of open-ended user queries that require professional expertise and advanced reasoning. ProBench consists of 4,000 high-quality samples independently submitted by professionals based on their daily productivity demands. It spans across 10 fields and 56 sub-fields, including science, arts, humanities, coding, mathematics, and creative writing. Experimentally, we evaluate and compare 24 latest models using MLLM-as-a-Judge. Our results reveal that although the best open-source models rival the proprietary ones, ProBench presents significant challenges in visual perception, textual understanding, domain knowledge and advanced reasoning, thus providing valuable directions for future multimodal AI research efforts.

[Arxiv](https://arxiv.org/abs/2503.06885)