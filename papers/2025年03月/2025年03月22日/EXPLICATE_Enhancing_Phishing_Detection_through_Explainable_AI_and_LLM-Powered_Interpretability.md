# EXPLICATE: 借助可解释AI与大语言模型驱动的解释能力，提升钓鱼检测水平

发布时间：2025年03月22日

`LLM应用

理由：这篇论文探讨了如何利用大型语言模型（LLM）来提升网络钓鱼检测系统的可解释性和用户信任度。它通过结合机器学习分类器、解释模块和LLM增强模块，展示了LLM在实际应用中的潜力和效果，属于LLM应用类别。` `网络安全` `信息安全`

> EXPLICATE: Enhancing Phishing Detection through Explainable AI and LLM-Powered Interpretability

# 摘要

> 网络钓鱼攻击日益猖獗，成为重大网络安全威胁。尽管机器学习技术在检测网络钓鱼方面初露锋芒，但其“黑箱”特性让用户难以理解其决策依据，这不仅降低了用户的信任度，也削弱了威胁响应效果。为此，我们推出EXPLICATE框架，通过三重架构提升网络钓鱼检测能力：基于领域特征的机器学习分类器、结合LIME和SHAP的双层解释模块，以及利用DeepSeek v3的LLM增强模块，将技术解释转化为通俗易懂的自然语言。实验数据显示，EXPLICATE在所有指标上达到了98.4%的准确率，与现有深度学习技术持平，但可解释性更胜一筹。其生成的高质量解释准确率达到94.2%，且LLM输出与模型预测的一致性高达96.8%。我们还将其打造为一款功能齐全的GUI应用和轻量级Chrome扩展，充分展现了其在各类部署环境中的实用性。研究证实，安全应用中卓越的检测性能与有意义的解释性可兼得。更重要的是，EXPLICATE成功架起了自动化AI与用户信任之间的桥梁，为网络钓鱼检测系统注入了新的活力。

> Sophisticated phishing attacks have emerged as a major cybersecurity threat, becoming more common and difficult to prevent. Though machine learning techniques have shown promise in detecting phishing attacks, they function mainly as "black boxes" without revealing their decision-making rationale. This lack of transparency erodes the trust of users and diminishes their effective threat response. We present EXPLICATE: a framework that enhances phishing detection through a three-component architecture: an ML-based classifier using domain-specific features, a dual-explanation layer combining LIME and SHAP for complementary feature-level insights, and an LLM enhancement using DeepSeek v3 to translate technical explanations into accessible natural language. Our experiments show that EXPLICATE attains 98.4 % accuracy on all metrics, which is on par with existing deep learning techniques but has better explainability. High-quality explanations are generated by the framework with an accuracy of 94.2 % as well as a consistency of 96.8\% between the LLM output and model prediction. We create EXPLICATE as a fully usable GUI application and a light Chrome extension, showing its applicability in many deployment situations. The research shows that high detection performance can go hand-in-hand with meaningful explainability in security applications. Most important, it addresses the critical divide between automated AI and user trust in phishing detection systems.

[Arxiv](https://arxiv.org/abs/2503.20796)