# #  摘要  
大型语言模型 (LLMs) 的最新进展推动了从机器人流程自动化 (RPA) 到智能体流程自动化 (AgPAM) 的革命性转变，通过基于 LLMs 自动化工作流编排过程，实现了这一变革。

发布时间：2025年03月22日

`LLM应用` `科学研究`

> A Survey on Mathematical Reasoning and Optimization with Large Language Models

# 摘要

> 数学推理和优化是人工智能和计算问题解决的基石。近年来，大型语言模型（LLMs）的突破性进展显著提升了AI在数学推理、定理证明和优化技术方面的表现。本研究回顾了AI领域数学问题解决的演变历程，从早期的统计学习方法到现代的深度学习和基于变压器模型的方法。我们深入探讨了预训练语言模型和LLMs在算术运算、复杂推理、定理证明和结构化符号计算方面的强大能力。特别值得关注的是，LLMs如何与优化和控制框架无缝集成，包括混合整数规划、线性二次控制和多智能体优化策略。我们详细分析了LLMs在问题构建、约束生成和启发式搜索中的应用，成功地将理论推理与实际应用场景相结合。此外，我们还探讨了多种增强技术，如链式思考推理、指令微调和工具增强方法，这些技术显著提升了LLMs的问题解决能力。尽管取得了显著进展，LLMs在数值精度、逻辑一致性和证明验证方面仍面临挑战。新兴的混合神经符号推理、结构化提示工程和多步自我修正等趋势，为克服这些限制提供了新的可能性。未来的研究方向应着重于提高模型的可解释性、与领域特定求解器的深度集成，以及增强AI驱动决策的鲁棒性。本调查为LLMs在数学推理和优化领域的现状及未来发展方向提供了全面的综述，其应用范围涵盖了工程、金融和科学研究等多个领域。

> Mathematical reasoning and optimization are fundamental to artificial intelligence and computational problem-solving. Recent advancements in Large Language Models (LLMs) have significantly improved AI-driven mathematical reasoning, theorem proving, and optimization techniques. This survey explores the evolution of mathematical problem-solving in AI, from early statistical learning approaches to modern deep learning and transformer-based methodologies. We review the capabilities of pretrained language models and LLMs in performing arithmetic operations, complex reasoning, theorem proving, and structured symbolic computation. A key focus is on how LLMs integrate with optimization and control frameworks, including mixed-integer programming, linear quadratic control, and multi-agent optimization strategies. We examine how LLMs assist in problem formulation, constraint generation, and heuristic search, bridging theoretical reasoning with practical applications. We also discuss enhancement techniques such as Chain-of-Thought reasoning, instruction tuning, and tool-augmented methods that improve LLM's problem-solving performance. Despite their progress, LLMs face challenges in numerical precision, logical consistency, and proof verification. Emerging trends such as hybrid neural-symbolic reasoning, structured prompt engineering, and multi-step self-correction aim to overcome these limitations. Future research should focus on interpretability, integration with domain-specific solvers, and improving the robustness of AI-driven decision-making. This survey offers a comprehensive review of the current landscape and future directions of mathematical reasoning and optimization with LLMs, with applications across engineering, finance, and scientific research.

[Arxiv](https://arxiv.org/abs/2503.17726)