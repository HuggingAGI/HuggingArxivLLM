# 从用户偏好到优化约束：借助大型语言模型

发布时间：2025年03月27日

`LLM应用` `智能家居` `能源管理`

> From User Preferences to Optimization Constraints Using Large Language Models

# 摘要

> 本研究探讨如何利用大型语言模型（LLMs）将用户偏好转化为家用电器的能源优化约束。我们聚焦于一个具体任务：在可再生能源社区（REC）背景下，将自然语言的用户表达转化为智能家电的正式约束，特别针对意大利场景。通过一个包含意大利语用户请求及其对应正式约束表示的试点数据集，我们评估了当前可用于意大利语的多种LLMs在这一任务中的表现，采用经典零样本、单样本和少样本学习设置。我们的贡献包括：为该任务建立基准性能，公开发布数据集和代码以促进进一步研究，并分享在这一特定领域中观察到的最佳实践和LLMs的局限性。

> This work explores using Large Language Models (LLMs) to translate user preferences into energy optimization constraints for home appliances. We describe a task where natural language user utterances are converted into formal constraints for smart appliances, within the broader context of a renewable energy community (REC) and in the Italian scenario. We evaluate the effectiveness of various LLMs currently available for Italian in translating these preferences resorting to classical zero-shot, one-shot, and few-shot learning settings, using a pilot dataset of Italian user requests paired with corresponding formal constraint representation. Our contributions include establishing a baseline performance for this task, publicly releasing the dataset and code for further research, and providing insights on observed best practices and limitations of LLMs in this particular domain

[Arxiv](https://arxiv.org/abs/2503.21360)