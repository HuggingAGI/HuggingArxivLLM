# 大型模型赋能多任务语义通信

发布时间：2025年03月27日

`LLM应用` `通信系统` `语义通信`

> Multi-Task Semantic Communications via Large Models

# 摘要

> 人工智能正在重塑下一代通信系统的设计、优化与管理。本文聚焦于将大型 AI 模型 (LAMs) 与语义通信 (SemCom) 融合，充分发挥其多模态数据处理与生成的优势。尽管 LAMs 在从原始数据中提取语义方面展现非凡潜力，但其应用也面临资源消耗、模型复杂度及跨模态任务适应性等多重挑战。为此，我们提出了一种基于 LAM 的多任务语义通信 (MTSC) 架构，配备自适应模型压缩策略与联邦分割微调方法，助力资源受限环境下 LAM 语义模型的高效部署。同时，我们引入检索增强生成方案，整合本地与全局知识库，优化语义提取与内容生成的精准度，从而显著提升推理效能。仿真结果充分验证了该架构的有效性，在不同信道条件下，其在各类下游任务中的性能均有显著提升。

> Artificial intelligence (AI) promises to revolutionize the design, optimization and management of next-generation communication systems. In this article, we explore the integration of large AI models (LAMs) into semantic communications (SemCom) by leveraging their multi-modal data processing and generation capabilities. Although LAMs bring unprecedented abilities to extract semantics from raw data, this integration entails multifaceted challenges including high resource demands, model complexity, and the need for adaptability across diverse modalities and tasks. To overcome these challenges, we propose a LAM-based multi-task SemCom (MTSC) architecture, which includes an adaptive model compression strategy and a federated split fine-tuning approach to facilitate the efficient deployment of LAM-based semantic models in resource-limited networks. Furthermore, a retrieval-augmented generation scheme is implemented to synthesize the most recent local and global knowledge bases to enhance the accuracy of semantic extraction and content generation, thereby improving the inference performance. Finally, simulation results demonstrate the efficacy of the proposed LAM-based MTSC architecture, highlighting the performance enhancements across various downstream tasks under varying channel conditions.

[Arxiv](https://arxiv.org/abs/2503.22064)