# # 结合人工用户与心理治疗师评估，对基于大型语言模型的智能心理健康聊天机器人进行评测

发布时间：2025年03月27日

`LLM应用` `心理健康` `心理健康服务`

> Combining Artificial Users and Psychotherapist Assessment to Evaluate Large Language Model-based Mental Health Chatbots

# 摘要

> 大型语言模型（LLMs）通过更自然的对话，有望突破传统基于规则的心理健康聊天机器人的局限性。然而，评估基于LLMs的心理健康聊天机器人面临一个重大挑战：其概率性质要求进行全面测试以确保治疗质量，但对抑郁症患者进行此类评估会增加脆弱人群的负担，并可能使他们接触潜在有害内容。本文提出了一种结合虚拟用户生成对话和心理治疗师评估对话的基于LLMs的心理健康聊天机器人评估方法。

我们根据患者案例开发了虚拟用户，系统地改变抑郁严重程度、人格特质和对聊天机器人的态度等特征，并让他们与基于LLMs的行为激活聊天机器人互动。10位心理治疗师使用标准化评分量表评估了48个随机选择的对话，以评估行为激活的质量及其治疗能力。

研究发现，尽管虚拟用户的仿真度中等，但它们能够实现跨不同用户的全面测试。此外，聊天机器人在提供行为激活和保持安全性方面表现出有前景的能力。此外，我们还识别了需要改进的缺陷，例如确保活动计划的适当性，这揭示了聊天机器人必须进行改进的必要性。我们的框架为评估基于LLMs的心理健康聊天机器人提供了一种有效方法，同时在评估过程中保护脆弱人群。未来的研究应提高虚拟用户的仿真度，并开发基于LLMs的增强型评估工具，以使心理治疗师的评估更加高效，从而进一步推动基于LLMs的心理健康聊天机器人评估的发展。

> Large Language Models (LLMs) promise to overcome limitations of rule-based mental health chatbots through more natural conversations. However, evaluating LLM-based mental health chatbots presents a significant challenge: Their probabilistic nature requires comprehensive testing to ensure therapeutic quality, yet conducting such evaluations with people with depression would impose an additional burden on vulnerable people and risk exposing them to potentially harmful content. Our paper presents an evaluation approach for LLM-based mental health chatbots that combines dialogue generation with artificial users and dialogue evaluation by psychotherapists. We developed artificial users based on patient vignettes, systematically varying characteristics such as depression severity, personality traits, and attitudes toward chatbots, and let them interact with a LLM-based behavioral activation chatbot. Ten psychotherapists evaluated 48 randomly selected dialogues using standardized rating scales to assess the quality of behavioral activation and its therapeutic capabilities. We found that while artificial users showed moderate authenticity, they enabled comprehensive testing across different users. In addition, the chatbot demonstrated promising capabilities in delivering behavioral activation and maintaining safety. Furthermore, we identified deficits, such as ensuring the appropriateness of the activity plan, which reveals necessary improvements for the chatbot. Our framework provides an effective method for evaluating LLM-based mental health chatbots while protecting vulnerable people during the evaluation process. Future research should improve the authenticity of artificial users and develop LLM-augmented evaluation tools to make psychotherapist evaluation more efficient, and thus further advance the evaluation of LLM-based mental health chatbots.

[Arxiv](https://arxiv.org/abs/2503.21540)