# 基于LLM的烹饪任务规划并通过图网络验证

发布时间：2025年03月27日

`Agent

理由：这篇论文主要探讨了如何将带字幕的烹饪视频数据转化为机器人可以执行的任务计划，重点在于任务规划和机器人执行。虽然其中提到了LLM的应用，但核心内容是关于机器人如何理解和执行复杂任务，属于智能体（Agent）的研究范畴。` `机器人` `家庭自动化`

> Cooking Task Planning using LLM and Verified by Graph Network

# 摘要

> 烹饪任务因其复杂性，一直是机器人领域的难题。虽然烹饪视频为任务提供了宝贵的信息来源，但如何将这些数据转化为机器人环境下的有效信息，带来了极大的变异性。本研究旨在通过基于LLM的任务与运动规划（TAMP）框架，从带字幕的烹饪视频中自主生成并执行烹饪任务计划，从而简化这一过程，重点关注任务计划生成环节。然而，传统的基于LLM的任务规划方法由于视频中的不确定性和输出中的幻觉风险，难以有效解释烹饪视频数据。为了解决这两个问题，我们探索了将LLM与功能面向对象网络（FOON）结合使用，以验证计划并在出现故障时提供反馈。这种结合生成的任务序列不仅逻辑正确，而且可由机器人执行。我们比较了我们的方法与仅使用LLM的少样本方法在双臂机器人设置下生成的5个烹饪食谱计划的执行情况。结果显示，我们的方法生成的计划中有4个成功执行，而仅使用LLM生成的计划中只有1个成功执行。

> Cooking tasks remain a challenging problem for robotics due to their complexity. Videos of people cooking are a valuable source of information for such task, but introduces a lot of variability in terms of how to translate this data to a robotic environment. This research aims to streamline this process, focusing on the task plan generation step, by using a Large Language Model (LLM)-based Task and Motion Planning (TAMP) framework to autonomously generate cooking task plans from videos with subtitles, and execute them. Conventional LLM-based task planning methods are not well-suited for interpreting the cooking video data due to uncertainty in the videos, and the risk of hallucination in its output. To address both of these problems, we explore using LLMs in combination with Functional Object-Oriented Networks (FOON), to validate the plan and provide feedback in case of failure. This combination can generate task sequences with manipulation motions that are logically correct and executable by a robot. We compare the execution of the generated plans for 5 cooking recipes from our approach against the plans generated by a few-shot LLM-only approach for a dual-arm robot setup. It could successfully execute 4 of the plans generated by our approach, whereas only 1 of the plans generated by solely using the LLM could be executed.

[Arxiv](https://arxiv.org/abs/2503.21564)