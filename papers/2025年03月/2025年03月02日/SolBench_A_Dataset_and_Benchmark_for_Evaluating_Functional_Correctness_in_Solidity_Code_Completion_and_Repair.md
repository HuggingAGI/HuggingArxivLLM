# SolBench：评估Solidity代码补全与修复功能正确性的数据集与基准测试方案

发布时间：2025年03月02日

`LLM应用` `区块链` `软件工程`

> SolBench: A Dataset and Benchmark for Evaluating Functional Correctness in Solidity Code Completion and Repair

# 摘要

> 智能合约作为区块链上的关键程序，其部署后的不可变性使得功能性正确性至关重要。尽管代码补全模型取得了进展，但Solidity（主要的智能合约语言）的基准测试仍然匮乏。现有的指标如BLEU无法充分评估生成智能合约的功能正确性。为填补这一空白，我们引入了SolBench，这是一个用于评估代码补全模型生成的Solidity智能合约功能正确性的基准。SolBench包含来自1,155个已部署在以太坊上的合约的4,178个函数。测试先进模型揭示了在无上下文情况下生成正确代码的挑战，因为Solidity函数依赖于上下文定义的变量和接口。为了解决这一问题，我们提出了一种基于检索增强的代码修复框架。在这个框架中，执行器验证功能正确性，如果需要，LLM使用由执行器跟踪信息指导的检索片段修复代码。我们对不同规模和系列的闭源和开源LLM进行了全面评估，以评估它们在智能合约补全方面的性能。结果显示，代码修复和检索技术有效提高了智能合约补全的正确性，同时降低了计算成本。

> Smart contracts are crucial programs on blockchains, and their immutability post-deployment makes functional correctness vital. Despite progress in code completion models, benchmarks for Solidity, the primary smart contract language, are lacking. Existing metrics like BLEU do not adequately assess the functional correctness of generated smart contracts. To fill this gap, we introduce SolBench, a benchmark for evaluating the functional correctness of Solidity smart contracts generated by code completion models. SolBench includes 4,178 functions from 1,155 Ethereum-deployed contracts. Testing advanced models revealed challenges in generating correct code without context, as Solidity functions rely on context-defined variables and interfaces. To address this, we propose a Retrieval-Augmented Code Repair framework. In this framework, an executor verifies functional correctness, and if necessary, an LLM repairs the code using retrieved snippets informed by executor traces. We conduct a comprehensive evaluation of both closed-source and open-source LLMs across various model sizes and series to assess their performance in smart contract completion. The results show that code repair and retrieval techniques effectively enhance the correctness of smart contract completion while reducing computational costs.

[Arxiv](https://arxiv.org/abs/2503.01098)