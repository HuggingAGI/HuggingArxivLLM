# 大型语言模型规则应用中概念掌握的证据

发布时间：2025年03月02日

`LLM理论`

> Evidence of conceptual mastery in the application of rules by Large Language Models

# 摘要

> 本文通过心理方法探究大型语言模型（LLMs）对规则应用的概念掌握能力。我们设计了一种创新程序，将LLMs生成的思想多样性与人类样本进行匹配，并开展了两项实验，比较人类与LLMs在基于规则决策中的表现差异。研究发现，所有测试的LLMs均能复制人类模式，无论提示语场景是基于训练截止日期前还是后创建的。更有趣的是，我们在人类样本中发现了两组场景间的意外差异，而这些差异甚至被LLMs完整复制。进一步研究发现，人类在被迫延迟时更依赖规则文本而非其目的，而某些模型（如Gemini Pro和Claude 3）对此表现出类似人类的回应，而其他模型（如GPT-4和Llama 3.2 90b）则未能做到。这些发现表明，LLMs对规则概念具有深刻理解，这对法律决策和哲学研究具有重要启示。

> In this paper we leverage psychological methods to investigate LLMs' conceptual mastery in applying rules. We introduce a novel procedure to match the diversity of thought generated by LLMs to that observed in a human sample. We then conducted two experiments comparing rule-based decision-making in humans and LLMs. Study 1 found that all investigated LLMs replicated human patterns regardless of whether they are prompted with scenarios created before or after their training cut-off. Moreover, we found unanticipated differences between the two sets of scenarios among humans. Surprisingly, even these differences were replicated in LLM responses. Study 2 turned to a contextual feature of human rule application: under forced time delay, human samples rely more heavily on a rule's text than on other considerations such as a rule's purpose.. Our results revealed that some models (Gemini Pro and Claude 3) responded in a human-like manner to a prompt describing either forced delay or time pressure, while others (GPT-4o and Llama 3.2 90b) did not. We argue that the evidence gathered suggests that LLMs have mastery over the concept of rule, with implications for both legal decision making and philosophical inquiry.

[Arxiv](https://arxiv.org/abs/2503.00992)