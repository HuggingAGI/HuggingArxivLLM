# 大型语言模型：民主的编程者，充满态度

发布时间：2025年03月28日

`LLM应用` `政治学`

> Large Language Models Are Democracy Coders with Attitudes

# 摘要

> 当前全球政治发展表明，民主倒退研究的重要性与日俱增。近期《政治学与政治》（2/2024）的一次讨论再次凸显了这一领域的一个关键挑战：如何准确测量民主。由于许多民主指标依赖主观评估而非事实观察，时间推移中观察到的民主趋势可能源于这些指标编码中的人类偏见，而非客观事实。本文中，我们利用两种前沿的大型语言模型（LLMs）对来自V-Dem项目的民主指标进行编码。这些模型凭借海量信息的访问能力，可能能够评估制度的许多“软”特征，而不会受到人类可能存在的认知偏见的影响。虽然LLM生成的编码在许多国家与人类专家评估结果大体一致，但我们发现，当这些模型与人类评估不一致时，它们的偏差具有不同的但一致的模式：一些LLM过于悲观，而另一些则系统性高估这些国家的民主质量。尽管结合两种LLM的编码可以缓解这一担忧，但我们最终得出结论，由于这些态度的范围和方向事先未知，难以用LLMs取代人类编码员。


> Current political developments worldwide illustrate that research on democratic backsliding is as important as ever. A recent exchange in Political Science & Politics (2/2024) has highlighted again a fundamental challenge in this literature: the measurement of democracy. With many democracy indicators consisting of subjective assessments rather than factual observations, trends in democracy over time could be due to human biases in the coding of these indicators rather than empirical facts. In this paper, we leverage two cutting-edge Large Language Models (LLMs) for the coding of democracy indicators from the V-Dem project. With access to a huge amount of information, these models may be able to rate the many "soft" characteristics of regimes without the cognitive biases that humans potentially possess. While LLM-generated codings largely align with expert coders for many countries, we show that when these models deviate from human assessments, they do so in different but consistent ways: Some LLMs are too pessimistic, while others consistently overestimate the democratic quality of these countries. While the combination of the two LLM codings can alleviate this concern, we conclude that it is difficult to replace human coders with LLMs, since the extent and direction of these attitudes is not known a priori.

[Arxiv](https://arxiv.org/abs/2503.22315)