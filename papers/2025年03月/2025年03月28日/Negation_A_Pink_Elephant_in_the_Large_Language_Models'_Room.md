# 否定：大型语言模型房间里那只挥之不去的粉色大象？

发布时间：2025年03月28日

`LLM应用` `自然语言推理`

> Negation: A Pink Elephant in the Large Language Models' Room?

# 摘要

> 否定词在句子理解中至关重要，但它们对大型语言模型 (LLMs) 来说依然是一个棘手的挑战。我们构建了两个多语言自然语言推理 (NLI) 数据集，包含成对的否定差异样例。研究发现，模型规模越大，处理否定的能力越强，这一结论与以往研究不同。此外，模型的推理准确性和对否定的鲁棒性都受语言影响，且前提的长度和明确性比语言本身更能影响鲁棒性。我们的数据集为多语言环境下的语言模型推理研究提供了有力支持。

> Negations are key to determining sentence meaning, making them essential for logical reasoning. Despite their importance, negations pose a substantial challenge for large language models (LLMs) and remain underexplored.
  We construct two multilingual natural language inference (NLI) datasets with \textit{paired} examples differing in negation. We investigate how model size and language impact its ability to handle negation correctly by evaluating popular LLMs.
  Contrary to previous work, we show that increasing the model size consistently improves the models' ability to handle negations. Furthermore, we find that both the models' reasoning accuracy and robustness to negation are language-dependent and that the length and explicitness of the premise have a greater impact on robustness than language.
  Our datasets can facilitate further research and improvements of language model reasoning in multilingual settings.

[Arxiv](https://arxiv.org/abs/2503.22395)