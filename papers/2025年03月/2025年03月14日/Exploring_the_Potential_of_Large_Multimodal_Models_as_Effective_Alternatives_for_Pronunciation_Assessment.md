# 大型多模态模型：发音评估的有效替代方案探索

发布时间：2025年03月14日

`LLM应用` `语音处理`

> Exploring the Potential of Large Multimodal Models as Effective Alternatives for Pronunciation Assessment

# 摘要

> 大型多模态模型 (LMMs) 在各领域表现卓越。本文聚焦于其在发音评估中的潜力，特别研究了生成式预训练变换器 (GPT) 模型，尤其是 GPT-4o 的能力。研究考察了其在多粒度和多维度下处理语音和音频进行发音评估的能力，重点在于反馈生成和评分。实验中，我们采用公开的 Speechocean762 数据集。评估主要关注两个方面：多层级评分和生成反馈的实用性。评分结果与 Speechocean762 数据集中的人工评分进行对比，反馈质量则通过大型语言模型 (LLMs) 进行评估。研究结果凸显了将 LMMs 与传统方法相结合在发音评估中的有效性，揭示了模型的优势并指出了进一步改进的方向。

> Large Multimodal Models (LMMs) have demonstrated exceptional performance across a wide range of domains. This paper explores their potential in pronunciation assessment tasks, with a particular focus on evaluating the capabilities of the Generative Pre-trained Transformer (GPT) model, specifically GPT-4o. Our study investigates its ability to process speech and audio for pronunciation assessment across multiple levels of granularity and dimensions, with an emphasis on feedback generation and scoring. For our experiments, we use the publicly available Speechocean762 dataset. The evaluation focuses on two key aspects: multi-level scoring and the practicality of the generated feedback. Scoring results are compared against the manual scores provided in the Speechocean762 dataset, while feedback quality is assessed using Large Language Models (LLMs). The findings highlight the effectiveness of integrating LMMs with traditional methods for pronunciation assessment, offering insights into the model's strengths and identifying areas for further improvement.

[Arxiv](https://arxiv.org/abs/2503.11229)