# # 评估大型语言模型多语言漏洞的框架

发布时间：2025年03月17日

`LLM理论` `多语言`

> A Framework to Assess Multilingual Vulnerabilities of LLMs

# 摘要

> 大型语言模型（LLMs）正在不断扩展其能力，包括理解和用多种语言进行交流。尽管这些模型经过安全训练以避免回答非法问题，但训练数据和人工评估资源的不平衡仍使它们在低资源语言（LRL）中更容易受到攻击。本文提出了一种自动评估常用LLMs多语言漏洞的框架。通过我们的框架，我们对八种代表不同资源可用水平的语言中的六种LLMs进行了评估。我们通过两种语言的人工评估验证了自动化框架生成的评估结果，发现框架的结果在大多数情况下与人工判断一致。研究发现低资源语言中存在漏洞，但这些漏洞通常源于模型表现不佳，导致回答不连贯，因此风险较低。


> Large Language Models (LLMs) are acquiring a wider range of capabilities, including understanding and responding in multiple languages. While they undergo safety training to prevent them from answering illegal questions, imbalances in training data and human evaluation resources can make these models more susceptible to attacks in low-resource languages (LRL). This paper proposes a framework to automatically assess the multilingual vulnerabilities of commonly used LLMs. Using our framework, we evaluated six LLMs across eight languages representing varying levels of resource availability. We validated the assessments generated by our automated framework through human evaluation in two languages, demonstrating that the framework's results align with human judgments in most cases. Our findings reveal vulnerabilities in LRL; however, these may pose minimal risk as they often stem from the model's poor performance, resulting in incoherent responses.

[Arxiv](https://arxiv.org/abs/2503.13081)