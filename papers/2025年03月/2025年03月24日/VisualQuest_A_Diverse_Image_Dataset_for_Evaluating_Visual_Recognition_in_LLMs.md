# VisualQuest：一个多样化图像数据集，旨在评估大型语言模型中的视觉识别能力

发布时间：2025年03月24日

`LLM应用` `视觉识别` `多模态`

> VisualQuest: A Diverse Image Dataset for Evaluating Visual Recognition in LLMs

# 摘要

> 本文介绍了一款名为 VisualQuest 的创新图像数据集，旨在评估大型语言模型 (LLMs) 对非传统、风格化图像的解读能力。与传统摄影基准不同，VisualQuest 通过包含抽象、象征和隐喻元素的图像挑战模型，要求模型结合专业知识和高级推理能力。该数据集经过多阶段筛选、标注和标准化精心策划，确保了高质量和多样性。我们使用多种先进的多模态 LLM 进行的评估显示了显著的性能差异，这凸显了事实背景知识和推理能力在视觉识别任务中的重要性。因此，VisualQuest 为推动多模态推理和模型架构设计的研究提供了一个强大且全面的基准。

> This paper introduces VisualQuest, a novel image dataset designed to assess the ability of large language models (LLMs) to interpret non-traditional, stylized imagery. Unlike conventional photographic benchmarks, VisualQuest challenges models with images that incorporate abstract, symbolic, and metaphorical elements, requiring the integration of domain-specific knowledge and advanced reasoning. The dataset was meticulously curated through multiple stages of filtering, annotation, and standardization to ensure high quality and diversity. Our evaluations using several state-of-the-art multimodal LLMs reveal significant performance variations that underscore the importance of both factual background knowledge and inferential capabilities in visual recognition tasks. VisualQuest thus provides a robust and comprehensive benchmark for advancing research in multimodal reasoning and model architecture design.

[Arxiv](https://arxiv.org/abs/2503.19936)