# 大型语言模型在虚拟人手势选择中的应用

发布时间：2025年03月18日

`LLM应用` `虚拟现实` `人机交互`

> Large Language Models for Virtual Human Gesture Selection

# 摘要

> 共话手势在人际互动中扮演着重要角色，能够传达丰富含义并显著影响听者的参与度、记忆、理解及对说话者的看法。同样地，这些手势也影响着人类与具身虚拟代理的互动。因此，在设计这些代理时，如何选择和动画化有意义的手势成为关键。然而，自动化这一过程充满挑战。

传统手势生成技术从完全自动化的数据驱动方法到耗时且缺乏通用性的手动方法不一而足，但前者常难以生成语境上具有意义的手势。本文利用大型语言模型的语义能力，提出了一种新的手势选择方法，旨在建议既合适又有意义的共话手势。

我们首先介绍了手势信息在GPT-4中的编码方式，随后通过研究评估了不同提示方法在选择有意义且语境相关手势并将其与共话言语适当对齐的能力。最后，详细展示了该方法在虚拟代理系统中的实现，通过自动化手势选择和动画化，显著提升了人机互动体验。

> Co-speech gestures convey a wide variety of meanings and play an important role in face-to-face human interactions. These gestures significantly influence the addressee's engagement, recall, comprehension, and attitudes toward the speaker. Similarly, they impact interactions between humans and embodied virtual agents. The process of selecting and animating meaningful gestures has thus become a key focus in the design of these agents. However, automating this gesture selection process poses a significant challenge. Prior gesture generation techniques have varied from fully automated, data-driven methods, which often struggle to produce contextually meaningful gestures, to more manual approaches that require crafting specific gesture expertise and are time-consuming and lack generalizability. In this paper, we leverage the semantic capabilities of Large Language Models to develop a gesture selection approach that suggests meaningful, appropriate co-speech gestures. We first describe how information on gestures is encoded into GPT-4. Then, we conduct a study to evaluate alternative prompting approaches for their ability to select meaningful, contextually relevant gestures and to align them appropriately with the co-speech utterance. Finally, we detail and demonstrate how this approach has been implemented within a virtual agent system, automating the selection and subsequent animation of the selected gestures for enhanced human-agent interactions.

[Arxiv](https://arxiv.org/abs/2503.14408)