# 探索短视频推荐系统中的过滤气泡现象：借助大语言模型代理

发布时间：2025年03月23日

`LLM应用` `社交媒体` `互联网`

> Simulating Filter Bubble on Short-video Recommender System with Large Language Model Agents

# 摘要

> 短视频平台的推荐系统正引发人们对“过滤气泡”现象的担忧，但其形成机制尚不明确。本文提出了一种基于 LLM 的模拟框架，利用真实短视频数据还原推荐-反馈循环。通过大规模模拟，我们揭示了过滤气泡形成的关键机制，并发现人口特征和内容偏好是加剧同质化的主要因素。我们还设计了多种干预策略，有效缓解了过滤气泡效应。此外，我们分析了 LLM 偏见对推荐的影响，提出了保护弱势群体的方案。这项研究不仅深化了对算法偏见的理解，还为构建包容性数字空间提供了实用工具。

> An increasing reliance on recommender systems has led to concerns about the creation of filter bubbles on social media, especially on short video platforms like TikTok. However, their formation is still not entirely understood due to the complex dynamics between recommendation algorithms and user feedback. In this paper, we aim to shed light on these dynamics using a large language model-based simulation framework. Our work employs real-world short-video data containing rich video content information and detailed user-agents to realistically simulate the recommendation-feedback cycle. Through large-scale simulations, we demonstrate that LLMs can replicate real-world user-recommender interactions, uncovering key mechanisms driving filter bubble formation. We identify critical factors, such as demographic features and category attraction that exacerbate content homogenization. To mitigate this, we design and test interventions including various cold-start and feedback weighting strategies, showing measurable reductions in filter bubble effects. Our framework enables rapid prototyping of recommendation strategies, offering actionable solutions to enhance content diversity in real-world systems. Furthermore, we analyze how LLM-inherent biases may propagate through recommendations, proposing safeguards to promote equity for vulnerable groups, such as women and low-income populations. By examining the interplay between recommendation and LLM agents, this work advances a deeper understanding of algorithmic bias and provides practical tools to promote inclusive digital spaces.

[Arxiv](https://arxiv.org/abs/2504.08742)