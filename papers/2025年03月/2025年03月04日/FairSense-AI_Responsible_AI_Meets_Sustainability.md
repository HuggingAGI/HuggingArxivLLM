# # FairSense-AI：负责任的AI与可持续性携手同行

发布时间：2025年03月04日

`LLM应用` `负责任AI` `伦理与安全`

> FairSense-AI: Responsible AI Meets Sustainability

# 摘要

> 本文介绍了一款名为 FairSense-AI 的多模态框架，专为检测和缓解文本与图像中的偏见而设计。借助大型语言模型（LLMs）和视觉-语言模型（VLMs），FairSense-AI能够揭示内容中潜在的微妙偏见或刻板印象，并为用户提供偏见评分、解释性标注和自动化的公平性优化建议。此外，该框架整合了与MIT AI风险库及NIST AI风险管理框架相兼容的AI风险评估模块，助力系统性识别伦理与安全议题。通过采用模型剪枝与混合精度计算等优化技术，FairSense-AI在提升能效的同时，也减少了环境影响。通过多个案例研究和实际应用，我们展示了 FairSense-AI如何通过兼顾公平性的社会维度与大规模AI部署的可持续性需求，推动负责任的AI实践。

> In this paper, we introduce FairSense-AI: a multimodal framework designed to detect and mitigate bias in both text and images. By leveraging Large Language Models (LLMs) and Vision-Language Models (VLMs), FairSense-AI uncovers subtle forms of prejudice or stereotyping that can appear in content, providing users with bias scores, explanatory highlights, and automated recommendations for fairness enhancements. In addition, FairSense-AI integrates an AI risk assessment component that aligns with frameworks like the MIT AI Risk Repository and NIST AI Risk Management Framework, enabling structured identification of ethical and safety concerns. The platform is optimized for energy efficiency via techniques such as model pruning and mixed-precision computation, thereby reducing its environmental footprint. Through a series of case studies and applications, we demonstrate how FairSense-AI promotes responsible AI use by addressing both the social dimension of fairness and the pressing need for sustainability in large-scale AI deployments. https://vectorinstitute.github.io/FairSense-AI, https://pypi.org/project/fair-sense-ai/

[Arxiv](https://arxiv.org/abs/2503.02865)