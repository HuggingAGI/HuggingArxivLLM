# 在长篇科学文档上实现零样本复杂问答

发布时间：2025年03月04日

`LLM应用

摘要中提到的论文主要关注预训练语言模型的应用，特别是在处理长文档和复杂问题上的应用。论文提出了一种零样本流水线框架，整合预训练语言模型来解决多跨度提取、多跳推理和长答案生成等挑战。这表明该研究属于大型语言模型的应用层面，因此归类为LLM应用。` `社会科学` `文档理解`

> Zero-Shot Complex Question-Answering on Long Scientific Documents

# 摘要

> 基于Transformer的语言模型发展迅速，短文档和简单问题的阅读理解已得到较好解决。然而，知识密集型的科学文献这一长文档领域仍待探索。这些文献常伴以复杂且现实的问题，进一步增加了难度。我们提出了一种零样本流水线框架，使社会科学研究人员无需机器学习专业知识，即可对整篇论文进行复杂但格式预设的问答。我们的方法整合预训练语言模型，有效应对多跨度提取、多跳推理和长答案生成等挑战。通过MLPsych这一标注复杂问题的社会心理学论文数据集的评估，展示了我们的框架通过结合抽取式和生成式模型实现的强劲性能。这项研究不仅推动了社会科学领域的文档理解，更为研究人员提供了开创性工具。
    

> With the rapid development in Transformer-based language models, the reading comprehension tasks on short documents and simple questions have been largely addressed. Long documents, specifically the scientific documents that are densely packed with knowledge discovered and developed by humans, remain relatively unexplored. These documents often come with a set of complex and more realistic questions, adding to their complexity. We present a zero-shot pipeline framework that enables social science researchers to perform question-answering tasks that are complex yet of predetermined question formats on full-length research papers without requiring machine learning expertise. Our approach integrates pre-trained language models to handle challenging scenarios including multi-span extraction, multi-hop reasoning, and long-answer generation. Evaluating on MLPsych, a novel dataset of social psychology papers with annotated complex questions, we demonstrate that our framework achieves strong performance through combination of extractive and generative models. This work advances document understanding capabilities for social sciences while providing practical tools for researchers.

[Arxiv](https://arxiv.org/abs/2503.02695)