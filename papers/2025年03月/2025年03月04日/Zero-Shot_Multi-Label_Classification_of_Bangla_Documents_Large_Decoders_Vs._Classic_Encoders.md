# 孟加拉语文档的多标签零样本分类：大型解码器 vs 经典编码器。

发布时间：2025年03月04日

`LLM应用

分类说明：这篇论文探讨了大型语言模型（LLM）在孟加拉语零样本多标签分类任务中的应用，比较了不同模型的性能，并指出了该领域的研究空白。因此，它属于LLM应用类别。` `语言学` `计算机科学`

> Zero-Shot Multi-Label Classification of Bangla Documents: Large Decoders Vs. Classic Encoders

# 摘要

> 孟加拉语，全球拥有超过3亿母语者，在全球语言排名中位列第六。然而，由于其复杂的形态特征和资源匮乏，孟加拉语在自然语言处理（NLP）领域面临独特挑战。尽管最近的大型解码器模型（如GPT、LLaMA和DeepSeek）在许多NLP任务中表现出色，但它们在孟加拉语上的表现仍未被充分探索。本文首次建立了比较解码器模型与经典编码器模型在孟加拉语零样本多标签分类任务中的基准。通过对32个先进模型的评估，我们发现，现有的所谓强大的编码器和解码器在孟加拉语零样本多标签分类任务上仍难以达到高准确率，这表明孟加拉语NLP领域仍需更多研究和资源投入。

> Bangla, a language spoken by over 300 million native speakers and ranked as the sixth most spoken language worldwide, presents unique challenges in natural language processing (NLP) due to its complex morphological characteristics and limited resources. While recent Large Decoder Based models (LLMs), such as GPT, LLaMA, and DeepSeek, have demonstrated excellent performance across many NLP tasks, their effectiveness in Bangla remains largely unexplored. In this paper, we establish the first benchmark comparing decoder-based LLMs with classic encoder-based models for Zero-Shot Multi-Label Classification (Zero-Shot-MLC) task in Bangla. Our evaluation of 32 state-of-the-art models reveals that, existing so-called powerful encoders and decoders still struggle to achieve high accuracy on the Bangla Zero-Shot-MLC task, suggesting a need for more research and resources for Bangla NLP.

[Arxiv](https://arxiv.org/abs/2503.02993)