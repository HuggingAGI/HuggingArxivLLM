# 大型语言模型在多语言先前事实核查声明检测中的应用

发布时间：2025年03月04日

`LLM应用` `事实核查` `多语言处理`

> Large Language Models for Multilingual Previously Fact-Checked Claim Detection

# 摘要

> 在这个充斥着虚假信息的时代，人类事实核查员常常在验证可能已在其他国家或语言中得到处理的声明时面临重复劳动的挑战。随着虚假信息跨越语言界限，能够自动检测跨语言中已做过事实核查的声明变得越来越重要。本文首次全面评估了大型语言模型（LLMs）在多语言已事实核查声明检测方面的应用。我们对七种LLMs进行了评估，涵盖20种语言，包括单语和跨语设置。结果显示，尽管LLMs在高资源语言中表现良好，但它们在低资源语言中表现不佳。此外，将原文翻译成英文对低资源语言大有裨益。这些发现不仅凸显了LLMs在多语言已事实核查声明检测中的潜力，更为这一有前景的应用方向的进一步研究奠定了基础。

> In our era of widespread false information, human fact-checkers often face the challenge of duplicating efforts when verifying claims that may have already been addressed in other countries or languages. As false information transcends linguistic boundaries, the ability to automatically detect previously fact-checked claims across languages has become an increasingly important task. This paper presents the first comprehensive evaluation of large language models (LLMs) for multilingual previously fact-checked claim detection. We assess seven LLMs across 20 languages in both monolingual and cross-lingual settings. Our results show that while LLMs perform well for high-resource languages, they struggle with low-resource languages. Moreover, translating original texts into English proved to be beneficial for low-resource languages. These findings highlight the potential of LLMs for multilingual previously fact-checked claim detection and provide a foundation for further research on this promising application of LLMs.

[Arxiv](https://arxiv.org/abs/2503.02737)