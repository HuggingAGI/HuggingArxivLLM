# 审视大型语言模型的地理位置推荐偏见：机会均等的挑战

发布时间：2025年03月16日

`LLM应用`

> Unequal Opportunities: Examining the Bias in Geographical Recommendations by Large Language Models

# 摘要

> 大型语言模型（LLMs）的近期进展使其成为终端用户中受欢迎的信息检索工具。然而，LLMs的统计训练方法引发了对其对代表性不足主题的表征的担忧，这可能导致偏见，进而影响现实世界中的决策和机会。随着LLMs的普及，这些偏见可能产生显著的经济、社会和文化影响，无论是通过直接交互（如用户与聊天机器人或自动化助手的互动），还是通过集成到第三方应用程序中（作为代理），其中模型在幕后影响决策过程和功能。

我们的研究聚焦于LLMs在美国城市和城镇推荐中的偏见，涵盖三个领域：搬迁、旅游和创业。我们探讨了两个关键问题：(i) LLMs的响应有多相似，以及(ii) 这种相似性如何可能使某些地区因特定特征而受到青睐，从而引入偏见。我们关注LLMs响应的一致性及其倾向于过度或不足代表特定地点的倾向。研究发现揭示了这些推荐中存在一致的人口统计偏见，这可能导致一种“赢家通吃”的效应，加剧现有的经济差距。

> Recent advancements in Large Language Models (LLMs) have made them a popular information-seeking tool among end users. However, the statistical training methods for LLMs have raised concerns about their representation of under-represented topics, potentially leading to biases that could influence real-world decisions and opportunities. These biases could have significant economic, social, and cultural impacts as LLMs become more prevalent, whether through direct interactions--such as when users engage with chatbots or automated assistants--or through their integration into third-party applications (as agents), where the models influence decision-making processes and functionalities behind the scenes. Our study examines the biases present in LLMs recommendations of U.S. cities and towns across three domains: relocation, tourism, and starting a business. We explore two key research questions: (i) How similar LLMs responses are, and (ii) How this similarity might favor areas with certain characteristics over others, introducing biases. We focus on the consistency of LLMs responses and their tendency to over-represent or under-represent specific locations. Our findings point to consistent demographic biases in these recommendations, which could perpetuate a ``rich-get-richer'' effect that widens existing economic disparities.

[Arxiv](https://arxiv.org/abs/2504.05325)