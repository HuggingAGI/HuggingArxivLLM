# # 多语言、文化优先的解决方案，助力大型语言模型应用中的性别指代问题

发布时间：2025年03月26日

`LLM应用` `性别研究`

> A Multilingual, Culture-First Approach to Addressing Misgendering in LLM Applications

# 摘要

> 误认性别是指使用与某人身份不符的性别称呼，这会让人感到被边缘化，削弱自我认同，造成严重伤害。英语有明确的避免方法，比如使用 ``they'' 代词。但其他语言因语法和文化的差异，带来了独特挑战。我们采用参与式设计方法，开发了针对42种语言和方言的误认性别评估与缓解方法，并设计了适用于所有语言的有效护栏。我们在一个标准的大型语言模型应用（会议记录总结）中测试了这些护栏，数据生成和标注都采用了人机协作方法。结果表明，这些护栏在减少所有语言生成摘要中的误认性别方面非常有效，且不影响质量。我们的人机协作方法展示了一种可行途径，可以在多种语言和文化中扩展包容性和负责任的AI解决方案。

> Misgendering is the act of referring to someone by a gender that does not match their chosen identity. It marginalizes and undermines a person's sense of self, causing significant harm. English-based approaches have clear-cut approaches to avoiding misgendering, such as the use of the pronoun ``they''. However, other languages pose unique challenges due to both grammatical and cultural constructs. In this work we develop methodologies to assess and mitigate misgendering across 42 languages and dialects using a participatory-design approach to design effective and appropriate guardrails across all languages. We test these guardrails in a standard large language model-based application (meeting transcript summarization), where both the data generation and the annotation steps followed a human-in-the-loop approach. We find that the proposed guardrails are very effective in reducing misgendering rates across all languages in the summaries generated, and without incurring loss of quality. Our human-in-the-loop approach demonstrates a method to feasibly scale inclusive and responsible AI-based solutions across multiple languages and cultures.

[Arxiv](https://arxiv.org/abs/2503.20302)