# OmniGeo：迈向地理空间人工智能的多模态大型语言模型

发布时间：2025年03月20日

`LLM应用` `地表人工智能` `地理信息科学`

> OmniGeo: Towards a Multimodal Large Language Models for Geospatial Artificial Intelligence

# 摘要

> 多模态大型语言模型的快速发展为人工智能开辟了新的领域，使整合文本、图像和空间信息等多样化的大型数据类型成为可能。在本文中，我们探讨了多模态LLM（MLLM）在地表人工智能（GeoAI）中的潜力，该领域利用空间数据解决地理语义、健康地理学、城市地理学、城市感知和遥感等领域的挑战。我们提出了一种专门针对地理应用的MLLM（OmniGeo），能够处理和分析异构数据源，包括卫星图像、地理元数据和文本描述。通过结合自然语言理解和空间推理的优势，我们的模型增强了指令遵循能力和GeoAI系统的准确性。实验结果表明，我们的模型在多种地理任务中优于特定任务的模型和现有的LLMs，不仅有效应对了多模态的特性，还在零样本地理任务中取得了具有竞争力的成果。我们的代码将在发表后公开。

> The rapid advancement of multimodal large language models (LLMs) has opened new frontiers in artificial intelligence, enabling the integration of diverse large-scale data types such as text, images, and spatial information. In this paper, we explore the potential of multimodal LLMs (MLLM) for geospatial artificial intelligence (GeoAI), a field that leverages spatial data to address challenges in domains including Geospatial Semantics, Health Geography, Urban Geography, Urban Perception, and Remote Sensing. We propose a MLLM (OmniGeo) tailored to geospatial applications, capable of processing and analyzing heterogeneous data sources, including satellite imagery, geospatial metadata, and textual descriptions. By combining the strengths of natural language understanding and spatial reasoning, our model enhances the ability of instruction following and the accuracy of GeoAI systems. Results demonstrate that our model outperforms task-specific models and existing LLMs on diverse geospatial tasks, effectively addressing the multimodality nature while achieving competitive results on the zero-shot geospatial tasks. Our code will be released after publication.

[Arxiv](https://arxiv.org/abs/2503.16326)