# 评估测试时缩放的大型语言模型在法律推理中的表现：OpenAI o1、DeepSeek-R1 等

发布时间：2025年03月20日

`LLM应用

理由：这篇论文评估了大型语言模型在法律推理任务中的表现，属于模型的实际应用评估。` `法律推理`

> Evaluating Test-Time Scaling LLMs for Legal Reasoning: OpenAI o1, DeepSeek-R1, and Beyond

# 摘要

> 近期，测试时缩放的大型语言模型（LLMs），如DeepSeek-R1和OpenAI o1，在推理等各个领域和任务中展现出了非凡的能力。然而，这些模型在法律等专业领域的表现仍存在疑问。为此，我们对LLMs在中英文法律任务中的表现进行了初步评估，涵盖9个模型和17个法律任务，尤其关注新发布的高难度任务，如多被告法律判决和法律论证推理。研究发现，尽管DeepSeek-R1和OpenAI o1是最强大的模型之一，但它们的法律推理能力仍显不足。具体而言，这些模型在7个中文法律推理任务中的得分低于80%，在2个英文法律推理任务中的得分也低于80%。这表明，即使是最先进的推理模型，其法律推理能力仍有待提升。

> Recently, Test-Time Scaling Large Language Models (LLMs), such as DeepSeek-R1 and OpenAI o1, have demonstrated exceptional capabilities across various domains and tasks, particularly in reasoning. While these models have shown impressive performance on general language tasks, their effectiveness in specialized fields like legal remains unclear. To address this, we present a preliminary evaluation of LLMs in various legal scenarios, covering both Chinese and English legal tasks. Our analysis includes 9 LLMs and 17 legal tasks, with a focus on newly published and more complex challenges such as multi-defendant legal judgments and legal argument reasoning. Our findings indicate that, despite DeepSeek-R1 and OpenAI o1 being among the most powerful models, their legal reasoning capabilities are still lacking. Specifically, these models score below 80\% on seven Chinese legal reasoning tasks and below 80\% on two English legal reasoning tasks. This suggests that, even among the most advanced reasoning models, legal reasoning abilities remain underdeveloped.

[Arxiv](https://arxiv.org/abs/2503.16040)