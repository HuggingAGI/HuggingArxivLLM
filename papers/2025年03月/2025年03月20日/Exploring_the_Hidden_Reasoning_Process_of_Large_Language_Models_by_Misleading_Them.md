# # 摘要
最近大型语言模型（LLMs）的突破性进展引领了一场从机器人流程自动化到智能体流程自动化的革命性转变，这一转变通过基于LLMs自动化工作流编排过程实现了。

发布时间：2025年03月20日

`LLM理论` `人工智能` `机器学习`

> Exploring the Hidden Reasoning Process of Large Language Models by Misleading Them

# 摘要

> 大型语言模型（LLMs）和视觉语言模型（VLMs）在多种场景下能够执行推理任务，但它们是否真的在进行抽象推理，而不仅仅是记忆和模式匹配？为解答这一疑问，我们提出了一种新的实验方法——误导性微调（MisFT），旨在检验LLMs/VLMs是否通过改变对基本规则的理解来进行抽象推理。具体而言，我们构建了一个包含与正确运算原则相矛盾的数学表达式的数据集，对模型进行微调使其学习这些矛盾规则，并评估其在不同测试领域中的泛化能力。通过一系列实验，我们发现当前的LLMs/VLMs能够有效应用矛盾规则解决实际的数学文字题和图像表示的数学表达式，这表明模型内部存在一种先抽象后推理的机制。

> Large language models (LLMs) and Vision language models (VLMs) have been able to perform various forms of reasoning tasks in a wide range of scenarios, but are they truly engaging in task abstraction and rule-based reasoning beyond mere memorization and pattern matching? To answer this question, we propose a novel experimental approach, Misleading Fine-Tuning (MisFT), to examine whether LLMs/VLMs perform abstract reasoning by altering their original understanding of fundamental rules. In particular, by constructing a dataset with math expressions that contradict correct operation principles, we fine-tune the model to learn those contradictory rules and assess its generalization ability on different test domains. Through a series of experiments, we find that current LLMs/VLMs are capable of effectively applying contradictory rules to solve practical math word problems and math expressions represented by images, implying the presence of an internal mechanism that abstracts before reasoning.

[Arxiv](https://arxiv.org/abs/2503.16401)