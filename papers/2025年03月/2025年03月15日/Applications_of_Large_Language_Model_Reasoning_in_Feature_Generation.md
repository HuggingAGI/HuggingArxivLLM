# 特征生成中的大型语言模型推理应用

发布时间：2025年03月15日

`LLM应用

理由：这篇论文探讨了大型语言模型在特征生成和跨领域应用中的应用，属于LLM的实际应用层面。`

> Applications of Large Language Model Reasoning in Feature Generation

# 摘要

> 大型语言模型 (LLMs) 凭借其卓越的推理能力，彻底革新了自然语言处理领域。本文聚焦于 LLM 推理技术与机器学习特征生成的融合，深入探讨了四种核心推理方法：思维链、思维树、检索增强生成以及思维空间探索。研究发现，这些方法无需手动设定搜索空间，即可有效识别特征生成规则。本文对基于 LLM 的特征生成方法进行了跨领域分类，涵盖金融、医疗和文本分析等多个场景。

在医疗领域，LLMs 能够高效提取临床笔记和放射报告中的关键信息；在金融领域，则擅长处理复杂文档的文本生成、摘要及实体提取。我们还探讨了特征质量和下游性能的评估方法，特别关注 OCTree 的决策树推理方法，该方法通过语言反馈实现迭代优化。目前，幻觉、计算效率和领域适应性是主要挑战。

截至 2025 年 3 月，新兴技术包括推理时计算扩展、强化学习和结合蒸馏的监督微调。未来，研究将向多模态特征生成、自我改进系统和神经符号方法等方向发展。本文为这一前沿领域提供了详尽概述，展望了通过语言模型推理实现特征工程自动化与优化的广阔前景。

> Large Language Models (LLMs) have revolutionized natural language processing through their state of art reasoning capabilities. This paper explores the convergence of LLM reasoning techniques and feature generation for machine learning tasks. We examine four key reasoning approaches: Chain of Thought, Tree of Thoughts, Retrieval-Augmented Generation, and Thought Space Exploration. Our analysis reveals how these approaches can be used to identify effective feature generation rules without having to manually specify search spaces. The paper categorizes LLM-based feature generation methods across various domains including finance, healthcare, and text analytics. LLMs can extract key information from clinical notes and radiology reports in healthcare, by enabling more efficient data utilization. In finance, LLMs facilitate text generation, summarization, and entity extraction from complex documents. We analyze evaluation methodologies for assessing feature quality and downstream performance, with particular attention to OCTree's decision tree reasoning approach that provides language-based feedback for iterative improvements. Current challenges include hallucination, computational efficiency, and domain adaptation. As of March 2025, emerging approaches include inference-time compute scaling, reinforcement learning, and supervised fine-tuning with model distillation. Future directions point toward multimodal feature generation, self-improving systems, and neuro-symbolic approaches. This paper provides a detailed overview of an emerging field that promises to automate and enhance feature engineering through language model reasoning.

[Arxiv](https://arxiv.org/abs/2503.11989)