# # 多模态检索增强生成综述
# A Survey of Multimodal Retrieval-Augmented Generation

发布时间：2025年03月25日

`RAG` `多模态` `信息检索`

> A Survey of Multimodal Retrieval-Augmented Generation

# 摘要

> 多模态增强生成（MRAG）通过整合多模态数据（文本、图像、视频）到检索与生成过程中，突破了传统文本增强生成（RAG）的局限性，显著提升了大型语言模型（LLMs）的能力。RAG通过引入外部文本知识提升了回答的准确性，而MRAG进一步扩展了这一框架，实现了多模态检索与生成，充分挖掘了多样数据类型的上下文价值。通过将回答锚定在事实性的多模态知识上，MRAG有效减少了幻觉现象，显著增强了问答系统的可靠性。近期研究表明，MRAG在需要视觉与文本理解的场景中表现尤为突出，超越了传统RAG方法。本研究全面综述了MRAG的核心组件、数据集、评估方法及其局限性，为构建与优化MRAG提供了深入见解。同时，本研究还系统指出了当前研究挑战与未来发展方向，凸显了MRAG在推动多模态信息检索与生成领域革新方面的巨大潜力。通过提供全面视角，本研究旨在激发更多探索，助力这一极具前景的范式走向更广泛应用。

> Multimodal Retrieval-Augmented Generation (MRAG) enhances large language models (LLMs) by integrating multimodal data (text, images, videos) into retrieval and generation processes, overcoming the limitations of text-only Retrieval-Augmented Generation (RAG). While RAG improves response accuracy by incorporating external textual knowledge, MRAG extends this framework to include multimodal retrieval and generation, leveraging contextual information from diverse data types. This approach reduces hallucinations and enhances question-answering systems by grounding responses in factual, multimodal knowledge. Recent studies show MRAG outperforms traditional RAG, especially in scenarios requiring both visual and textual understanding. This survey reviews MRAG's essential components, datasets, evaluation methods, and limitations, providing insights into its construction and improvement. It also identifies challenges and future research directions, highlighting MRAG's potential to revolutionize multimodal information retrieval and generation. By offering a comprehensive perspective, this work encourages further exploration into this promising paradigm.

[Arxiv](https://arxiv.org/abs/2504.08748)