# 人类与大型语音语言模型在社会语言处理上的差异：模型-大脑对齐研究的证据

发布时间：2025年03月25日

`LLM应用` `语音AI` `音频处理`

> Distinct social-linguistic processing between humans and large audio-language models: Evidence from model-brain alignment

# 摘要

> 语音AI开发在处理语言和副语言信息方面面临独特挑战。本研究比较了大型音频语言模型（LALMs）与人类在语音理解过程中整合说话者特征的方式，探讨LALMs是否以与人类认知机制相似的方式处理说话者上下文语言。我们对比了两种LALMs（Qwen2-Audio和Ultravox 0.5）的处理模式与人类EEG反应。通过分析模型的 surprisal 和 entropy 指标，我们研究了它们在社会刻板印象违规（如男性声称经常 manicures）和生物知识违规（如男性声称怀孕）情况下对说话者内容不一致的敏感度。结果显示，Qwen2-Audio在面对说话者不一致内容时表现出更高的 surprisal，且其 surprisal 值显著预测了人类的N400反应，而Ultravox 0.5对说话者特征的敏感度有限。重要的是，两种模型均未能复制人类在社会违规（引发N400效应）和生物违规（引发P600效应）之间的社会语言处理区分。这些发现揭示了当前LALMs在处理说话者上下文语言方面的潜力与局限性，并表明人类与LALMs在社会语言处理机制上存在差异。

> Voice-based AI development faces unique challenges in processing both linguistic and paralinguistic information. This study compares how large audio-language models (LALMs) and humans integrate speaker characteristics during speech comprehension, asking whether LALMs process speaker-contextualized language in ways that parallel human cognitive mechanisms. We compared two LALMs' (Qwen2-Audio and Ultravox 0.5) processing patterns with human EEG responses. Using surprisal and entropy metrics from the models, we analyzed their sensitivity to speaker-content incongruency across social stereotype violations (e.g., a man claiming to regularly get manicures) and biological knowledge violations (e.g., a man claiming to be pregnant). Results revealed that Qwen2-Audio exhibited increased surprisal for speaker-incongruent content and its surprisal values significantly predicted human N400 responses, while Ultravox 0.5 showed limited sensitivity to speaker characteristics. Importantly, neither model replicated the human-like processing distinction between social violations (eliciting N400 effects) and biological violations (eliciting P600 effects). These findings reveal both the potential and limitations of current LALMs in processing speaker-contextualized language, and suggest differences in social-linguistic processing mechanisms between humans and LALMs.

[Arxiv](https://arxiv.org/abs/2503.19586)