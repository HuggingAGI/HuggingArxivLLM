# 在基于LLM的蜜罐代理中注入个性：探究对人类-like议程生成的影响

发布时间：2025年03月25日

`LLM应用

理由：这篇论文探讨了如何利用大型语言模型（LLM）通过个性化的提示模式来模拟逼真的数字替身，用于网络欺骗。它展示了LLM在特定应用场景中的潜力和创新，因此属于LLM应用类别。` `网络安全` `人工智能`

> Inducing Personality in LLM-Based Honeypot Agents: Measuring the Effect on Human-Like Agenda Generation

# 摘要

> 本文介绍了 SANDMAN，一种基于语言代理的网络欺骗架构，能够模拟出逼真的数字替身。我们的“欺骗代理”作为高级网络诱饵，通过延长攻击行为的观察期，实现与攻击者的深度互动。实验结果表明，基于五大人格模型的提示模式能够系统性地为大型语言模型注入不同“个性”。研究发现，基于人格的语言代理在生成多样化、现实行为方面具有巨大潜力，为提升网络欺骗策略提供了全新思路。

> This paper presents SANDMAN, an architecture for cyber deception that leverages Language Agents to emulate convincing human simulacra. Our 'Deceptive Agents' serve as advanced cyber decoys, designed for high-fidelity engagement with attackers by extending the observation period of attack behaviours. Through experimentation, measurement, and analysis, we demonstrate how a prompt schema based on the five-factor model of personality systematically induces distinct 'personalities' in Large Language Models. Our results highlight the feasibility of persona-driven Language Agents for generating diverse, realistic behaviours, ultimately improving cyber deception strategies.

[Arxiv](https://arxiv.org/abs/2503.19752)