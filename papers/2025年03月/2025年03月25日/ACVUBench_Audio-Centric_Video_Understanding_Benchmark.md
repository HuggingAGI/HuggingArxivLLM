# ACVUBench：音频中心视频理解基准测试

发布时间：2025年03月25日

`LLM应用` `计算机视觉` `视频分析`

> ACVUBench: Audio-Centric Video Understanding Benchmark

# 摘要

> 在视听大语言模型的视频理解任务中，音频往往只是作为辅助手段，辅助理解视觉信息。然而，对视频的全面理解在很大程度上依赖于听觉信息，因为音频提供了视觉数据通常缺乏的关键背景、情感线索和语义含义。本文提出了一种以音频为中心的视频理解基准测试（ACVUBench），旨在评估多模态大语言模型在视频理解方面的能力，特别关注听觉信息。ACVUBench包含了涵盖18个不同领域的2,662个视频，这些视频带有丰富的听觉信息，以及超过13,000个高质量的人工标注或验证的问题-答案对。此外，ACVUBench引入了一系列精心设计的以音频为中心的任务，全面测试了对视频中音频内容和音视频交互的理解。我们对多种开源和专有的多模态大语言模型进行了全面评估，并分析了音视频大语言模型的不足之处。演示地址：https://github.com/lark-png/ACVUBench。

> Audio often serves as an auxiliary modality in video understanding tasks of audio-visual large language models (LLMs), merely assisting in the comprehension of visual information. However, a thorough understanding of videos significantly depends on auditory information, as audio offers critical context, emotional cues, and semantic meaning that visual data alone often lacks. This paper proposes an audio-centric video understanding benchmark (ACVUBench) to evaluate the video comprehension capabilities of multimodal LLMs with a particular focus on auditory information. Specifically, ACVUBench incorporates 2,662 videos spanning 18 different domains with rich auditory information, together with over 13k high-quality human annotated or validated question-answer pairs. Moreover, ACVUBench introduces a suite of carefully designed audio-centric tasks, holistically testing the understanding of both audio content and audio-visual interactions in videos. A thorough evaluation across a diverse range of open-source and proprietary multimodal LLMs is performed, followed by the analyses of deficiencies in audio-visual LLMs. Demos are available at https://github.com/lark-png/ACVUBench.

[Arxiv](https://arxiv.org/abs/2503.19951)